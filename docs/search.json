[
  {
    "objectID": "templates/slides-template.html#today",
    "href": "templates/slides-template.html#today",
    "title": "Title of the lecture; Subtitle (optional)",
    "section": "",
    "text": "Point 1\nPoint 2\nPoint 3\n\n\n\n\n\n\n\nTip\n\n\n\nTeaching tip: keep one “workflow map” slide that reappears in every deck."
  },
  {
    "objectID": "templates/slides-template.html#learning-objectives",
    "href": "templates/slides-template.html#learning-objectives",
    "title": "Title of the lecture; Subtitle (optional)",
    "section": "Learning objectives",
    "text": "Learning objectives\nBy the end of this block, you can:\n\nWrite a minimal lavaan model string\nFit it with cfa() / sem()\nInterpret key parameters (loadings / paths)"
  },
  {
    "objectID": "templates/slides-template.html#minimal-example-code-output",
    "href": "templates/slides-template.html#minimal-example-code-output",
    "title": "Title of the lecture; Subtitle (optional)",
    "section": "Minimal example (code + output)",
    "text": "Minimal example (code + output)\n\nlibrary(lavaan)\n\n# Toy measurement model\nmodel &lt;- '\n  f =~ x1 + x2 + x3\n'\n\nfit &lt;- cfa(model, data = HolzingerSwineford1939)\nsummary(fit, fit.measures = TRUE, standardized = TRUE)\n\nlavaan 0.6-19 ended normally after 23 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         6\n\n  Number of observations                           301\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nModel Test Baseline Model:\n\n  Test statistic                               111.271\n  Degrees of freedom                                 3\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    1.000\n  Tucker-Lewis Index (TLI)                       1.000\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -1356.977\n  Loglikelihood unrestricted model (H1)      -1356.977\n                                                      \n  Akaike (AIC)                                2725.955\n  Bayesian (BIC)                              2748.197\n  Sample-size adjusted Bayesian (SABIC)       2729.169\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.000\n  90 Percent confidence interval - lower         0.000\n  90 Percent confidence interval - upper         0.000\n  P-value H_0: RMSEA &lt;= 0.050                       NA\n  P-value H_0: RMSEA &gt;= 0.080                       NA\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.000\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  f =~                                                                  \n    x1                1.000                               0.724    0.621\n    x2                0.778    0.141    5.532    0.000    0.563    0.479\n    x3                1.107    0.214    5.173    0.000    0.801    0.710\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .x1                0.835    0.118    7.064    0.000    0.835    0.614\n   .x2                1.065    0.105   10.177    0.000    1.065    0.771\n   .x3                0.633    0.129    4.899    0.000    0.633    0.496\n    f                 0.524    0.130    4.021    0.000    1.000    1.000"
  },
  {
    "objectID": "templates/slides-template.html#two-column-slide-uses-.two-col-from-slides.scss",
    "href": "templates/slides-template.html#two-column-slide-uses-.two-col-from-slides.scss",
    "title": "Title of the lecture; Subtitle (optional)",
    "section": "Two-column slide (uses .two-col from slides.scss)",
    "text": "Two-column slide (uses .two-col from slides.scss)\n\nConcept - What is identified? - Why constraints matter? - What is the scale of a latent factor?\nQuick check\n\ninspect(fit, \"converged\")\n\n[1] TRUE\n\nfitMeasures(fit, c(\"cfi\", \"rmsea\", \"srmr\"))\n\n  cfi rmsea  srmr \n    1     0     0"
  },
  {
    "objectID": "templates/slides-template.html#exercise",
    "href": "templates/slides-template.html#exercise",
    "title": "Title of the lecture; Subtitle (optional)",
    "section": "Exercise",
    "text": "Exercise\n\n\n\n\n\n\nImportant\n\n\n\nTry it (5–10 min)\n1. Add x4 to the factor (if available) or remove an indicator.\n2. Refit and compare fit measures.\n3. What changes in the standardized loadings?"
  },
  {
    "objectID": "templates/slides-template.html#common-mistakes",
    "href": "templates/slides-template.html#common-mistakes",
    "title": "Title of the lecture; Subtitle (optional)",
    "section": "Common mistakes",
    "text": "Common mistakes\n\nTreating arrows as “causal proof” (Rohrer et al., 2022)\nChasing modification indices without justification\nIgnoring estimator/data-type mismatch"
  },
  {
    "objectID": "templates/slides-template.html#references-manual",
    "href": "templates/slides-template.html#references-manual",
    "title": "Title of the lecture; Subtitle (optional)",
    "section": "References (manual)",
    "text": "References (manual)\n\nRosseel, Y. (2012). lavaan: An R package for structural equation modeling."
  },
  {
    "objectID": "templates/slides-template.html#references",
    "href": "templates/slides-template.html#references",
    "title": "Title of the lecture; Subtitle (optional)",
    "section": "References",
    "text": "References\n\n\nRohrer, J. M., Hünermund, P., Arslan, R. C., & Elson, M. (2022). That’s a Lot to Process! Pitfalls of Popular Path Models. Advances in Methods and Practices in Psychological Science, 5(2), 25152459221095827. https://doi.org/10.1177/25152459221095827"
  },
  {
    "objectID": "templates/lab-solution-template.html",
    "href": "templates/lab-solution-template.html",
    "title": "Lab X — Title",
    "section": "",
    "text": "By the end of this lab, you can:\n\nFit a model in lavaan\nInspect fit measures and key parameters\nMake (and justify) one defensible diagnostic decision"
  },
  {
    "objectID": "templates/lab-solution-template.html#references",
    "href": "templates/lab-solution-template.html#references",
    "title": "Lab X — Title",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "setup.html",
    "href": "setup.html",
    "title": "Setup",
    "section": "",
    "text": "This page helps you get R, packages, and the course repository running smoothly."
  },
  {
    "objectID": "setup.html#installupdate-software",
    "href": "setup.html#installupdate-software",
    "title": "Setup",
    "section": "1) Install/update software",
    "text": "1) Install/update software\n\nR (recommended: recent CRAN release)\nRStudio (recommended)\nQuarto (needed only if you want to render slides/labs locally)"
  },
  {
    "objectID": "setup.html#get-the-course-materials",
    "href": "setup.html#get-the-course-materials",
    "title": "Setup",
    "section": "2) Get the course materials",
    "text": "2) Get the course materials\n\nOption A — Git (recommended)\n\nClone the repository\nPull updates during the course if needed\n\n\n\nOption B — Download ZIP\n\nDownload the ZIP from GitHub\nUnzip and open the project folder in RStudio"
  },
  {
    "objectID": "setup.html#install-packages",
    "href": "setup.html#install-packages",
    "title": "Setup",
    "section": "3) Install packages",
    "text": "3) Install packages\nRun this once (edit if you already have everything):\n\npkgs &lt;- c(\n  \"lavaan\",\n  \"semTools\",\n  \"psych\",\n  \"MVN\",\n  \"mice\",\n  \"modsem\",\n  \"ggplot2\",\n  \"dplyr\",\n  \"tidyr\"\n)\n\nto_install &lt;- setdiff(pkgs, rownames(installed.packages()))\nif (length(to_install) &gt; 0) install.packages(to_install)\n\ninvisible(lapply(pkgs, library, character.only = TRUE))\n\nThis is lavaan 0.6-19\nlavaan is FREE software! Please report any bugs.\n\n\n \n\n\n###############################################################################\n\n\nThis is semTools 0.5-7\n\n\nAll users of R (or SEM) are invited to submit functions or ideas for functions.\n\n\n###############################################################################\n\n\n\nCaricamento pacchetto: 'psych'\n\n\nI seguenti oggetti sono mascherati da 'package:semTools':\n\n    reliability, skew\n\n\nIl seguente oggetto è mascherato da 'package:lavaan':\n\n    cor2cov\n\n\nWarning: il pacchetto 'MVN' è stato creato con R versione 4.5.2\n\n\n\nCaricamento pacchetto: 'MVN'\n\n\nIl seguente oggetto è mascherato da 'package:psych':\n\n    mardia\n\n\nWarning: il pacchetto 'mice' è stato creato con R versione 4.5.2\n\n\n\nCaricamento pacchetto: 'mice'\n\n\nIl seguente oggetto è mascherato da 'package:stats':\n\n    filter\n\n\nI seguenti oggetti sono mascherati da 'package:base':\n\n    cbind, rbind\n\n\nThis is modsem (1.0.11). Please report any bugs!\n\n\n\nCaricamento pacchetto: 'ggplot2'\n\n\nI seguenti oggetti sono mascherati da 'package:psych':\n\n    %+%, alpha\n\n\n\nCaricamento pacchetto: 'dplyr'\n\n\nI seguenti oggetti sono mascherati da 'package:stats':\n\n    filter, lag\n\n\nI seguenti oggetti sono mascherati da 'package:base':\n\n    intersect, setdiff, setequal, union"
  },
  {
    "objectID": "setup.html#reproducibility-option-recommended-renv",
    "href": "setup.html#reproducibility-option-recommended-renv",
    "title": "Setup",
    "section": "4) Reproducibility option (recommended): renv",
    "text": "4) Reproducibility option (recommended): renv\nIf the repo uses renv, you can restore the exact package versions:\n\n# install.packages(\"renv\")\n# renv::restore()"
  },
  {
    "objectID": "setup.html#quick-test-can-you-run-lavaan",
    "href": "setup.html#quick-test-can-you-run-lavaan",
    "title": "Setup",
    "section": "5) Quick test: can you run lavaan?",
    "text": "5) Quick test: can you run lavaan?\n\nlibrary(lavaan)\n\nm &lt;- 'f =~ x1 + x2 + x3'\nfit &lt;- cfa(m, data = HolzingerSwineford1939)\n\ninspect(fit, \"converged\")\n\n[1] TRUE\n\nfitMeasures(fit, c(\"cfi\",\"rmsea\",\"srmr\"))\n\n  cfi rmsea  srmr \n    1     0     0"
  },
  {
    "objectID": "setup.html#troubleshooting",
    "href": "setup.html#troubleshooting",
    "title": "Setup",
    "section": "Troubleshooting",
    "text": "Troubleshooting\n\n“Package X is not available”\n\nUpdate R\nTry a different CRAN mirror\nInstall from source if needed (rare)\n\n\n\n“Quarto not found”\n\nInstall Quarto and restart RStudio\n\n\n\n“Rendering fails”\n\nRe-run package installation\nTry rendering a single file first (e.g., one lab)\nCheck for path issues (especially on Windows)\n\n\n\n\n\n\n\nTip\n\n\n\nIf you run into errors during class, copy-paste the error message + the code you ran into your notes (or send it). It speeds up debugging a lot."
  },
  {
    "objectID": "labs/labs_index.html",
    "href": "labs/labs_index.html",
    "title": "Labs",
    "section": "",
    "text": "These labs are the hands-on part of the course. Each lab is designed to be runnable end-to-end and includes exercises."
  },
  {
    "objectID": "labs/labs_index.html#day-1",
    "href": "labs/labs_index.html#day-1",
    "title": "Labs",
    "section": "Day 1",
    "text": "Day 1\n\nLab 01 — lavaan basics\nOpen lab\nLab 02 — path analysis & mediation\nOpen lab"
  },
  {
    "objectID": "labs/labs_index.html#day-2",
    "href": "labs/labs_index.html#day-2",
    "title": "Labs",
    "section": "Day 2",
    "text": "Day 2\n\nLab 03 — fit diagnostics (residuals, MI/EPC)\nOpen lab\nLab 04 — CFA + reliability (omega)\nOpen lab"
  },
  {
    "objectID": "labs/labs_index.html#day-3",
    "href": "labs/labs_index.html#day-3",
    "title": "Labs",
    "section": "Day 3",
    "text": "Day 3\n\nLab 05 — SEM capstone (flagship dataset)\nOpen lab\nLab 06 — missing data (FIML/MI) + robustness\nOpen lab"
  },
  {
    "objectID": "labs/labs_index.html#day-4",
    "href": "labs/labs_index.html#day-4",
    "title": "Labs",
    "section": "Day 4",
    "text": "Day 4\n\nLab 07 — MG-CFA invariance\nOpen lab\nLab 08 — ordinal SEM + ordinal invariance\nOpen lab"
  },
  {
    "objectID": "labs/labs_index.html#day-5",
    "href": "labs/labs_index.html#day-5",
    "title": "Labs",
    "section": "Day 5",
    "text": "Day 5\n\nLab 09 — longitudinal SEM (growth model)\nOpen lab\nLab 10 — clustered data (robust SE) + two-level CFA\nOpen lab"
  },
  {
    "objectID": "labs/labs_index.html#optional-extra-practice",
    "href": "labs/labs_index.html#optional-extra-practice",
    "title": "Labs",
    "section": "Optional extra practice",
    "text": "Optional extra practice\nIf you want more practice beyond the core labs, check the Extras page."
  },
  {
    "objectID": "glossary.html",
    "href": "glossary.html",
    "title": "Glossary",
    "section": "",
    "text": "Short definitions + “what students usually confuse it with”."
  },
  {
    "objectID": "glossary.html#a",
    "href": "glossary.html#a",
    "title": "Glossary",
    "section": "A",
    "text": "A\nAbsolute fit\nFit measures that evaluate how well the model reproduces the observed covariance structure (e.g., χ², SRMR).\nAIC / BIC\nInformation criteria for comparing models (typically non-nested too). Lower is better (with caveats)."
  },
  {
    "objectID": "glossary.html#c",
    "href": "glossary.html#c",
    "title": "Glossary",
    "section": "C",
    "text": "C\nCFA (Confirmatory Factor Analysis)\nA measurement model where latent variables explain covariances among observed indicators via factor loadings.\nCFI / TLI\nIncremental fit indices comparing your model to a baseline (independence) model.\nCluster-robust standard errors\nA correction to SEs/p-values when observations are clustered (e.g., students in classrooms) without explicitly fitting a multilevel model.\nConfigural / Metric / Scalar invariance\nLevels of measurement invariance across groups/time: - configural: same pattern of loadings - metric: equal loadings - scalar: equal loadings + intercepts (or thresholds for ordinal)"
  },
  {
    "objectID": "glossary.html#d",
    "href": "glossary.html#d",
    "title": "Glossary",
    "section": "D",
    "text": "D\nDWLS / WLSMV\nCommon estimators for ordinal indicators. Naming can be confusing: the practical takeaway is that ordinal models often use a weighted least squares approach with robust corrections."
  },
  {
    "objectID": "glossary.html#e",
    "href": "glossary.html#e",
    "title": "Glossary",
    "section": "E",
    "text": "E\nEquivalent models\nDifferent path diagrams that imply the same covariance structure (same global fit). Fit alone cannot identify the “true” causal story.\nEPC (Expected Parameter Change)\nHow much a parameter estimate would change if a fixed constraint were freed; often reported with modification indices."
  },
  {
    "objectID": "glossary.html#f",
    "href": "glossary.html#f",
    "title": "Glossary",
    "section": "F",
    "text": "F\nFIML (Full Information Maximum Likelihood)\nA likelihood-based approach to handle missing data under MAR assumptions (with ML-family estimators).\nFit indices (global)\nSummaries of how well the overall model fits (CFI/TLI/RMSEA/SRMR/χ²).\nFit indices (local)\nDiagnostics for specific parts of a model (residuals, MI/EPC, standardized residual covariances)."
  },
  {
    "objectID": "glossary.html#i",
    "href": "glossary.html#i",
    "title": "Glossary",
    "section": "I",
    "text": "I\nIdentification\nWhether model parameters can be uniquely estimated from the data (rules of thumb help, but do not guarantee identification).\nIntercepts vs thresholds (ordinal)\n- Intercepts: continuous indicator mean structure - Thresholds: cut-points that map a continuous latent response to ordinal categories"
  },
  {
    "objectID": "glossary.html#l",
    "href": "glossary.html#l",
    "title": "Glossary",
    "section": "L",
    "text": "L\nLatent variable\nUnobserved construct inferred from observed indicators.\nLatent interaction\nAn interaction between latent variables (e.g., F1 × F2 predicting Y). Estimation/interpretation differs from standard linear SEM."
  },
  {
    "objectID": "glossary.html#m",
    "href": "glossary.html#m",
    "title": "Glossary",
    "section": "M",
    "text": "M\nMeasurement model\nThe part of SEM that links indicators to latent factors (loadings, intercepts/thresholds, residual variances).\nMI (Modification Index)\nA statistic indicating how much χ² would drop if a fixed parameter were freed. Useful but easy to abuse.\nMissingness (MCAR/MAR/MNAR)\nAssumptions about why data are missing: - MCAR: unrelated to observed/unobserved variables - MAR: related to observed variables - MNAR: related to unobserved values themselves"
  },
  {
    "objectID": "glossary.html#r",
    "href": "glossary.html#r",
    "title": "Glossary",
    "section": "R",
    "text": "R\nRMSEA\nA parsimony-adjusted fit index; usually reported with a confidence interval."
  },
  {
    "objectID": "glossary.html#s",
    "href": "glossary.html#s",
    "title": "Glossary",
    "section": "S",
    "text": "S\nSAM (Structural After Measurement)\nA two-stage estimation strategy: estimate measurement first, then structural relations using implied latent moments.\nSEM (Structural Equation Model)\nAn integrated model including both measurement (latent variables) and structural relations (regressions/covariances among latents/observeds).\nSRMR\nA fit index based on standardized residuals (difference between observed and model-implied covariances/correlations)."
  },
  {
    "objectID": "glossary.html#t",
    "href": "glossary.html#t",
    "title": "Glossary",
    "section": "T",
    "text": "T\nTwo-step mindset\nA practical workflow: evaluate measurement quality before interpreting structural relations.\n\n\n\n\n\n\n\nTip\n\n\n\nIf you want to add to this glossary during the course, just make a PR / issue or send the term + how you’d define it."
  },
  {
    "objectID": "book/index.html",
    "href": "book/index.html",
    "title": "Structural Equation Modelling in Psychological Sciences",
    "section": "",
    "text": "Welcome! This book is a practical introduction to Structural Equation Modelling (SEM) for psychological research, with examples in R (mainly using lavaan).\nThis book is built from the course materials in the companion repository and is designed to be:"
  },
  {
    "objectID": "book/index.html#how-to-read-this-book",
    "href": "book/index.html#how-to-read-this-book",
    "title": "Structural Equation Modelling in Psychological Sciences",
    "section": "How to read this book",
    "text": "How to read this book\n\nIf you are new to SEM: read chapters 1–5 in order.\nIf you already know basics: jump to the chapter you need (ordinal, invariance, longitudinal, multilevel).\nEach chapter ends with:\n\na summary of key points\ncommon pitfalls\nexercises (optional)"
  },
  {
    "objectID": "book/index.html#what-you-should-know-already",
    "href": "book/index.html#what-you-should-know-already",
    "title": "Structural Equation Modelling in Psychological Sciences",
    "section": "What you should know already",
    "text": "What you should know already\n\nComfortable with R (data wrangling, plotting, writing functions)\nLinear regression basics\nCorrelation/covariance intuition"
  },
  {
    "objectID": "book/index.html#companion-materials",
    "href": "book/index.html#companion-materials",
    "title": "Structural Equation Modelling in Psychological Sciences",
    "section": "Companion materials",
    "text": "Companion materials\n\nSlides and labs: see the course GitHub Pages site\nGlossary: key terms and common confusions\nReporting checklist: copy-paste guidance for papers and theses\nExtras: optional modules (power, latent interactions, SAM today’s methods, etc.)"
  },
  {
    "objectID": "book/index.html#book-roadmap",
    "href": "book/index.html#book-roadmap",
    "title": "Structural Equation Modelling in Psychological Sciences",
    "section": "Book roadmap",
    "text": "Book roadmap\n\nFoundations: SEM logic, identification intuition, estimation choices, lavaan grammar\nPath analysis: regression models in SEM form, mediation, equivalent models\nFit & diagnostics: global vs local fit, residuals, MI discipline\nCFA: measurement models, identification strategies, reliability\nSEM: measurement + structure, two-step mindset, applied workflow\nExtensions: missing data, invariance, ordinal SEM, longitudinal, multilevel\nAppendices: lavaan recipes + reporting templates"
  },
  {
    "objectID": "book/index.html#citation",
    "href": "book/index.html#citation",
    "title": "Structural Equation Modelling in Psychological Sciences",
    "section": "Citation",
    "text": "Citation\nIf you cite this book/course notes, you can use the following format (update the year/date when final):\n\nFeraco, T. (Year). Structural Equation Modelling in Psychological Sciences: Applied SEM with lavaan. Course notes, University of Padova."
  },
  {
    "objectID": "book/index.html#acknowledgements-optional",
    "href": "book/index.html#acknowledgements-optional",
    "title": "Structural Equation Modelling in Psychological Sciences",
    "section": "Acknowledgements (optional)",
    "text": "Acknowledgements (optional)\nThanks to colleagues and students who provided feedback on earlier versions of these materials."
  },
  {
    "objectID": "extras/extras_index.html",
    "href": "extras/extras_index.html",
    "title": "Extras",
    "section": "",
    "text": "These are optional, self-contained modules you can read when relevant. Each module should include: - a short concept note (why/when) - minimal reproducible example (R code) - exercises (+ solutions if provided)"
  },
  {
    "objectID": "extras/extras_index.html#methods-inference",
    "href": "extras/extras_index.html#methods-inference",
    "title": "Extras",
    "section": "Methods & inference",
    "text": "Methods & inference\n\nex01 Power: Monte Carlo for SEM\nex02 Bayesian SEM: quickstart"
  },
  {
    "objectID": "extras/extras_index.html#advanced-sem",
    "href": "extras/extras_index.html#advanced-sem",
    "title": "Extras",
    "section": "Advanced SEM",
    "text": "Advanced SEM\n\nex03 Latent interactions (modsem)\nex04 SAM in lavaan\nex05 MIIVs & consistent factor score regression"
  },
  {
    "objectID": "extras/extras_index.html#longitudinal-deep-dives",
    "href": "extras/extras_index.html#longitudinal-deep-dives",
    "title": "Extras",
    "section": "Longitudinal deep dives",
    "text": "Longitudinal deep dives\n\nex06 RI-CLPM vs CLPM\nex07 Latent change score models"
  },
  {
    "objectID": "extras/extras_index.html#measurement-extensions",
    "href": "extras/extras_index.html#measurement-extensions",
    "title": "Extras",
    "section": "Measurement extensions",
    "text": "Measurement extensions\n\nex09 Alignment / approximate invariance\nex10 Bifactor / ESEM / method factors"
  },
  {
    "objectID": "extras/extras_index.html#missing-data-sensitivity",
    "href": "extras/extras_index.html#missing-data-sensitivity",
    "title": "Extras",
    "section": "Missing data sensitivity",
    "text": "Missing data sensitivity\n\nex08 MNAR sensitivity: conceptual + simple strategies"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Structural Equation Modelling in Psychological Sciences",
    "section": "",
    "text": "Welcome! This repository contains slides (Quarto revealjs), hands-on labs, and extras for self-study."
  },
  {
    "objectID": "index.html#how-to-use-this-repo",
    "href": "index.html#how-to-use-this-repo",
    "title": "Structural Equation Modelling in Psychological Sciences",
    "section": "How to use this repo",
    "text": "How to use this repo\n\nDuring class: open the slides for today + run the matching lab.\nAfter class: use the Glossary and Reporting checklist while doing exercises/projects.\nExtras: optional modules (power, SAM, latent interactions, etc.) you can read when relevant.\n\n\n\n\n\n\n\nTip\n\n\n\nTip\nIf you get lost: come back here. This page is the “map” for everything."
  },
  {
    "objectID": "index.html#timetable-54h-split-into-two-2-hour-blocks",
    "href": "index.html#timetable-54h-split-into-two-2-hour-blocks",
    "title": "Structural Equation Modelling in Psychological Sciences",
    "section": "Timetable (5×4h, split into two 2-hour blocks)",
    "text": "Timetable (5×4h, split into two 2-hour blocks)\n\nLinks will work after rendering the project (or if you open the pre-rendered website).\n\n\n\n\nDay\nBlock A (2h)\nBlock B (2h)\nCore lab\n\n\n\n\n1\n00 Course map + 01 Foundations\n02 Path analysis\nLab 01 + Lab 02\n\n\n2\n03 Fit & diagnostics\n04 CFA\nLab 03 + Lab 04\n\n\n3\n05 SEM capstone\n06 Missing/robust/reporting\nLab 05 + Lab 06\n\n\n4\n07 Invariance (MG-CFA)\n08 Ordinal SEM\nLab 07 + Lab 08\n\n\n5\n09 Longitudinal on-ramp\n10 Multilevel/clustered\nLab 09 + Lab 10"
  },
  {
    "objectID": "index.html#what-you-should-keep-open-while-working",
    "href": "index.html#what-you-should-keep-open-while-working",
    "title": "Structural Equation Modelling in Psychological Sciences",
    "section": "What you should keep open while working",
    "text": "What you should keep open while working\n\nSetup (only once, then keep for troubleshooting)\nGlossary (quick definitions, naming conventions)\nReporting checklist (what to report in CFA/SEM/invariance/ordinal/etc.)\nExtras (optional modules; useful later)"
  },
  {
    "objectID": "index.html#conventions-used-in-this-course",
    "href": "index.html#conventions-used-in-this-course",
    "title": "Structural Equation Modelling in Psychological Sciences",
    "section": "Conventions used in this course",
    "text": "Conventions used in this course\n\nCore fit indices (default): χ², CFI/TLI, RMSEA (+ CI), SRMR\nLocal fit: residuals + MI/EPC (with “modification discipline”)\nDefault mindset: measurement first, then structure (“two-step mindset”)\n\n\n\n\n\n\n\nImportant\n\n\n\nImportant\nSlides are optimized for live teaching. “Extras” are designed to be self-contained reading modules with code + exercises."
  },
  {
    "objectID": "reporting-checklist.html",
    "href": "reporting-checklist.html",
    "title": "Reporting checklist",
    "section": "",
    "text": "Use this as a copy/paste checklist for assignments, papers, and thesis chapters."
  },
  {
    "objectID": "reporting-checklist.html#always-report-any-semcfa",
    "href": "reporting-checklist.html#always-report-any-semcfa",
    "title": "Reporting checklist",
    "section": "Always report (any SEM/CFA)",
    "text": "Always report (any SEM/CFA)\n\nSoftware + version (R, lavaan, semTools, etc.)\nSample size (N) and any exclusions\nVariables (which indicators for each factor; scales; whether ordinal)\nEstimator (ML / MLR / WLSMV etc.) + justification\nMissing data handling (FIML / MI / listwise) + justification\nModel syntax (append or supplement)\nModel identification choices (marker vs std.lv=TRUE, constraints, etc.)\nGlobal fit: χ²(df), CFI/TLI, RMSEA (+ CI), SRMR\nKey parameters: estimates + SE/CI + standardized solution (when meaningful)\nInterpretation tied to the research question\nDiagnostics: what you checked (residuals, MI/EPC) and what you changed (if anything)\nReproducibility: session info (and seed if simulation)"
  },
  {
    "objectID": "reporting-checklist.html#cfa-specific",
    "href": "reporting-checklist.html#cfa-specific",
    "title": "Reporting checklist",
    "section": "CFA-specific",
    "text": "CFA-specific\n\nFactor loadings (unstd + std), indicator residual variances\nFactor variances/covariances\nReliability: ω (omega) and/or other chosen indices (with method stated)\nHandling of cross-loadings / correlated residuals:\n\nwere any added?\nwhat was the substantive rationale?\nwas this preregistered / cross-validated / replicated?"
  },
  {
    "objectID": "reporting-checklist.html#sem-structural-specific",
    "href": "reporting-checklist.html#sem-structural-specific",
    "title": "Reporting checklist",
    "section": "SEM (structural) specific",
    "text": "SEM (structural) specific\n\nStructural paths (standardized + CI)\nR² for endogenous variables\nIndirect effects:\n\nmethod (bootstrap recommended when appropriate)\neffect + CI + interpretation (avoid “p-value only” reporting)\n\nClarify causal language:\n\nobservational vs experimental\nidentification assumptions (temporal ordering, confounding, etc.)"
  },
  {
    "objectID": "reporting-checklist.html#multi-group-invariance",
    "href": "reporting-checklist.html#multi-group-invariance",
    "title": "Reporting checklist",
    "section": "Multi-group / invariance",
    "text": "Multi-group / invariance\n\nGroups (definition, Ns per group)\nInvariance steps tested:\n\nconfigural, metric, scalar (and strict if used)\n\nWhat constraints were imposed at each step\nDecision rules used (e.g., ΔCFI / ΔRMSEA thresholds) and references for your rule\nIf partial invariance:\n\nwhich parameters freed\nrationale (substantive + statistical)\nwhat comparisons remain interpretable (e.g., latent means only after (partial) scalar)"
  },
  {
    "objectID": "reporting-checklist.html#ordinal-indicators",
    "href": "reporting-checklist.html#ordinal-indicators",
    "title": "Reporting checklist",
    "section": "Ordinal indicators",
    "text": "Ordinal indicators\n\nWhich variables treated as ordered\nEstimator and link (e.g., WLSMV / probit-type default framework)\nThresholds vs intercepts (make clear what was constrained in invariance)\nFit interpretation caveat: note if thresholds or residual structures drive misfit\nSensitivity check (optional but strong): treat as continuous vs ordered and compare conclusions"
  },
  {
    "objectID": "reporting-checklist.html#longitudinal-sem",
    "href": "reporting-checklist.html#longitudinal-sem",
    "title": "Reporting checklist",
    "section": "Longitudinal SEM",
    "text": "Longitudinal SEM\n\nTime points and spacing\nWhether you tested longitudinal measurement invariance\nHow you handled correlated uniqueness (same items across time)\nFor growth models:\n\ncoding of slope loadings (0,1,2… or actual time)\nrandom effects included (intercept/slope variance)\n\nFor cross-lagged models:\n\nclarify whether you used CLPM vs alternatives (if relevant)\ninterpret cross-lagged paths cautiously"
  },
  {
    "objectID": "reporting-checklist.html#clustered-multilevel",
    "href": "reporting-checklist.html#clustered-multilevel",
    "title": "Reporting checklist",
    "section": "Clustered / multilevel",
    "text": "Clustered / multilevel\n\nClustering variable (e.g., class, clinic, therapist) and cluster sizes\nStrategy used:\n\ncluster-robust SE (and why sufficient), or\nexplicit multilevel model (within/between)\n\nIf multilevel:\n\nwhich parameters vary within vs between\nICC motivation (optional but helpful)"
  },
  {
    "objectID": "reporting-checklist.html#a-short-results-paragraph-template",
    "href": "reporting-checklist.html#a-short-results-paragraph-template",
    "title": "Reporting checklist",
    "section": "A short “results paragraph” template",
    "text": "A short “results paragraph” template\n\n“We fit a [CFA/SEM] using lavaan (version …) with estimator … . Missing data were handled using … . Model fit was [acceptable/problematic] (χ²(df)=…, CFI=…, RMSEA=… [CI], SRMR=…). The key effect of interest was … (β=…, 95% CI […, …]). Diagnostics indicated … ; we [did/did not] respecify the model. Results suggest …, with limitations including … .”\n\n\n\n\n\n\n\n\nImportant\n\n\n\nRule of thumb\nIf you changed the model after looking at the data, state exactly what you changed and why. “Transparency beats perfection.”"
  },
  {
    "objectID": "slides/slides_index.html",
    "href": "slides/slides_index.html",
    "title": "Slides",
    "section": "",
    "text": "Here are the slide decks for the course (5×4h, split into two blocks each day)."
  },
  {
    "objectID": "slides/slides_index.html#day-1",
    "href": "slides/slides_index.html#day-1",
    "title": "Slides",
    "section": "Day 1",
    "text": "Day 1\n\nBlock A: 00 Course map, 01 Foundations\nBlock B: 02 Path analysis"
  },
  {
    "objectID": "slides/slides_index.html#day-2",
    "href": "slides/slides_index.html#day-2",
    "title": "Slides",
    "section": "Day 2",
    "text": "Day 2\n\nBlock A: 03 Fit & diagnostics\nBlock B: 04 CFA"
  },
  {
    "objectID": "slides/slides_index.html#day-3",
    "href": "slides/slides_index.html#day-3",
    "title": "Slides",
    "section": "Day 3",
    "text": "Day 3\n\nBlock A: 05 SEM capstone\nBlock B: 06 Missing/robust/reporting"
  },
  {
    "objectID": "slides/slides_index.html#day-4",
    "href": "slides/slides_index.html#day-4",
    "title": "Slides",
    "section": "Day 4",
    "text": "Day 4\n\nBlock A: 07 Invariance (MG-CFA)\nBlock B: 08 Ordinal SEM"
  },
  {
    "objectID": "slides/slides_index.html#day-5",
    "href": "slides/slides_index.html#day-5",
    "title": "Slides",
    "section": "Day 5",
    "text": "Day 5\n\nBlock A: 09 Longitudinal on-ramp\nBlock B: 10 Multilevel/clustered"
  },
  {
    "objectID": "templates/report-template.html",
    "href": "templates/report-template.html",
    "title": "SEM Report — Title",
    "section": "",
    "text": "Write 3–6 lines: - What is the substantive question? - What are the constructs? - What would be convincing evidence?"
  },
  {
    "objectID": "templates/report-template.html#sample",
    "href": "templates/report-template.html#sample",
    "title": "SEM Report — Title",
    "section": "2.1 Sample",
    "text": "2.1 Sample\n\nN =\nInclusion/exclusion =\nGrouping variable (if any) =\nClustering (if any) = (e.g., students in classrooms)"
  },
  {
    "objectID": "templates/report-template.html#variables",
    "href": "templates/report-template.html#variables",
    "title": "SEM Report — Title",
    "section": "2.2 Variables",
    "text": "2.2 Variables\nBrief table (optional): - Indicators for each latent factor - Outcomes/predictors - Scale type (continuous vs ordinal Likert)"
  },
  {
    "objectID": "templates/report-template.html#missingness",
    "href": "templates/report-template.html#missingness",
    "title": "SEM Report — Title",
    "section": "2.3 Missingness",
    "text": "2.3 Missingness\n\n% missing overall =\nKey variables with missingness =\nStrategy (FIML / MI / listwise) + short justification\n\n\n\nShow code\n# Optional quick checks (edit to match your data)\n# summary(dat)\n# colMeans(is.na(dat))"
  },
  {
    "objectID": "templates/report-template.html#conceptual-model-diagram",
    "href": "templates/report-template.html#conceptual-model-diagram",
    "title": "SEM Report — Title",
    "section": "3.1 Conceptual model (diagram)",
    "text": "3.1 Conceptual model (diagram)\nInsert a figure if you have one:"
  },
  {
    "objectID": "templates/report-template.html#lavaan-syntax",
    "href": "templates/report-template.html#lavaan-syntax",
    "title": "SEM Report — Title",
    "section": "3.2 lavaan syntax",
    "text": "3.2 lavaan syntax\n\n\nShow code\nlibrary(lavaan)\n\nmodel &lt;- '\n  # Measurement\n  f1 =~ x1 + x2 + x3\n  f2 =~ y1 + y2 + y3\n\n  # Structural\n  f2 ~ f1\n'"
  },
  {
    "objectID": "templates/report-template.html#global-fit",
    "href": "templates/report-template.html#global-fit",
    "title": "SEM Report — Title",
    "section": "5.1 Global fit",
    "text": "5.1 Global fit\nReport a small set consistently (and add CI where relevant): - χ²(df) = - CFI = - TLI = - RMSEA [90% CI] = - SRMR =\n\n\nShow code\n# Example\n# fitMeasures(fit, c(\"chisq\",\"df\",\"cfi\",\"tli\",\"rmsea\",\"rmsea.ci.lower\",\"rmsea.ci.upper\",\"srmr\"))"
  },
  {
    "objectID": "templates/report-template.html#key-parameters",
    "href": "templates/report-template.html#key-parameters",
    "title": "SEM Report — Title",
    "section": "5.2 Key parameters",
    "text": "5.2 Key parameters\nFocus on the parameters tied to your research question. - Main paths (standardized estimates + CI) - Loadings (and any problematic indicators) - R² for outcomes\n\n\nShow code\n# Example: parameter table\n# pe &lt;- parameterEstimates(fit, standardized = TRUE)\n# pe[pe$op %in% c(\"~\",\"=~\"), c(\"lhs\",\"op\",\"rhs\",\"est\",\"se\",\"pvalue\",\"std.all\")]"
  },
  {
    "objectID": "templates/report-template.html#interpretation-write-up",
    "href": "templates/report-template.html#interpretation-write-up",
    "title": "SEM Report — Title",
    "section": "5.3 Interpretation (write-up)",
    "text": "5.3 Interpretation (write-up)\nWrite 1–2 short paragraphs: - What do the results mean substantively? - Are effects small/medium/large in context? - What alternative explanations remain?\nInclude citations when relevant, e.g. (rosseel2012lavaan?)."
  },
  {
    "objectID": "templates/report-template.html#references",
    "href": "templates/report-template.html#references",
    "title": "SEM Report — Title",
    "section": "10.1 References",
    "text": "10.1 References"
  },
  {
    "objectID": "slides/00_introduction.html#outline",
    "href": "slides/00_introduction.html#outline",
    "title": "Introducing the introduction",
    "section": "Outline",
    "text": "Outline\n\nCourse contents\nApproaching the course"
  },
  {
    "objectID": "slides/00_introduction.html#topics-that-we-will-hopefully-cover-in-the-course",
    "href": "slides/00_introduction.html#topics-that-we-will-hopefully-cover-in-the-course",
    "title": "Introducing the introduction",
    "section": "Topics that we will (hopefully) cover in the course",
    "text": "Topics that we will (hopefully) cover in the course\n\nlavaan\nBasic knowledge about SEM\nModels with manifest variables - path analysis\nMeasurement models with SEM - CFA\nFull SEM: measurement + structural part\nModel invariance - MG-CFA\nModels for ordinal data\nPower analysis for SEM\nOther miscellaneous topics (briefly)"
  },
  {
    "objectID": "slides/00_introduction.html#why-am-i-here",
    "href": "slides/00_introduction.html#why-am-i-here",
    "title": "Introducing the introduction",
    "section": "Why am I here?",
    "text": "Why am I here?\nI am convinced that SEM is a fundamental tool for research in psychology and most, if not all, researchers in this area should know it. Indeed, it is key for many aspects of your research:\n\nMeasurement\nMultivariate analyses\nComplex regression models\nLongitudinal analyses\n…"
  },
  {
    "objectID": "slides/00_introduction.html#what-you-can-expect-from-this-course",
    "href": "slides/00_introduction.html#what-you-can-expect-from-this-course",
    "title": "Introducing the introduction",
    "section": "What you can expect from this course",
    "text": "What you can expect from this course\nI am not a statisticians. This will have negative consequences on your statistical knowledge at the end of the course, but hopefully more practical and psychology-based examples and experiences.\n\nPractical example\nData simulation\nFew equations\nOpen discussions\nHands-on your data"
  },
  {
    "objectID": "slides/00_introduction.html#what-i-need-from-you",
    "href": "slides/00_introduction.html#what-i-need-from-you",
    "title": "Introducing the introduction",
    "section": "What I need from you",
    "text": "What I need from you\n\nA PC (optional)\nBasic R knowledge\n‘for’ loops knowledge\nSome packages installed\n\n\ninstall.packages(c(\"lavaan\", \"semTools\", \n                   \"semPlot\", \"MASS\"))"
  },
  {
    "objectID": "slides/00_introduction.html#materials-and-organization",
    "href": "slides/00_introduction.html#materials-and-organization",
    "title": "Introducing the introduction",
    "section": "Materials and organization",
    "text": "Materials and organization\n\nThe material is divided in arguments\nFor each argument you will find\nSlides\nAdditional code\nData\nWe will probably do live coding when needed. I will work on this file: LiveCode\nI also prepared this file where we can collect questions, if it is too early to answer or if you want to save it: Q doc\nIn general, live materials are in this folder"
  },
  {
    "objectID": "slides/00_introduction.html#moodle",
    "href": "slides/00_introduction.html#moodle",
    "title": "Introducing the introduction",
    "section": "Moodle",
    "text": "Moodle\nSlides and materials are in the Moodle page of the course\n\nOR moodle psicologia unipd &gt; Formazione Post Lauream &gt; Corsi di Dottorato &gt; Psychological Sciences aa 2023/2024 &gt; Structural Equations"
  },
  {
    "objectID": "slides/00_introduction.html#registro-didattico",
    "href": "slides/00_introduction.html#registro-didattico",
    "title": "Introducing the introduction",
    "section": "Registro didattico",
    "text": "Registro didattico\nlogbook: Please fill the logbook everyday."
  },
  {
    "objectID": "slides/00_introduction.html#contacts",
    "href": "slides/00_introduction.html#contacts",
    "title": "Introducing the introduction",
    "section": "Contacts",
    "text": "Contacts\ntommaso.feraco@unipd.it"
  },
  {
    "objectID": "slides/00_introduction.html#introduction",
    "href": "slides/00_introduction.html#introduction",
    "title": "Introducing the introduction",
    "section": "Introduction",
    "text": "Introduction\nStructural Equation Modeling\nDoctoral School in Psychological Sciences\nUniversity of Padova — 2023\nCREDITS TO PROF. MASSIMILIANO PASTORE FOR THE SLIDES"
  },
  {
    "objectID": "slides/00_introduction.html#outline-1",
    "href": "slides/00_introduction.html#outline-1",
    "title": "Introducing the introduction",
    "section": "Outline",
    "text": "Outline\n\nBasics\nVariables and relationships\nSteps\nBasic concepts\nGraphics\nSEM world\nAppendix\nnew section"
  },
  {
    "objectID": "slides/00_introduction.html#how-do-you-fit-these",
    "href": "slides/00_introduction.html#how-do-you-fit-these",
    "title": "Introducing the introduction",
    "section": "How do you fit these?",
    "text": "How do you fit these?"
  },
  {
    "objectID": "slides/00_introduction.html#sem-structural-equation-modeling",
    "href": "slides/00_introduction.html#sem-structural-equation-modeling",
    "title": "Introducing the introduction",
    "section": "SEM = Structural Equation Modeling",
    "text": "SEM = Structural Equation Modeling\n\nSEM is a multivariate statistical modeling technique\n\nit includes path-analysis, causal models, factorial models, measurement models, Latent Growth Models, but even simple multiple regression or ANOVA could be considered particular cases of SEM.\nAll these techniques use the covariance matrix (\\(\\boldsymbol{S}\\)) for estimating target model parameters.\n\nSEM allows us to test a hypothesis/model about the data\n\nwe postulate a data-generating model\nwe evaluate whether this model fits the data or not\n\nWhat is so special about SEM?\n\nwe can model latent variables (e.g., ‘invisible constructs’)\nwe can test indirect and reciprocal effects and more\nlast but not least, we can make diagrams (or PAINTINGS if theory is weak!)"
  },
  {
    "objectID": "slides/00_introduction.html#variance-covariance-matrices",
    "href": "slides/00_introduction.html#variance-covariance-matrices",
    "title": "Introducing the introduction",
    "section": "Variance-covariance matrices",
    "text": "Variance-covariance matrices\n\n\n\noptions(digits = 2)\ncov(PoliticalDemocracy[1:7])\n\n    y1   y2   y3   y4  y5   y6   y7\ny1 6.9  6.3  5.8  6.1 5.1  5.7  5.8\ny2 6.3 15.6  5.8  9.5 5.6  9.4  7.5\ny3 5.8  5.8 10.8  6.7 4.9  4.7  7.0\ny4 6.1  9.5  6.7 11.2 5.7  7.4  7.5\ny5 5.1  5.6  4.9  5.7 6.8  5.0  5.8\ny6 5.7  9.4  4.7  7.4 5.0 11.4  6.7\ny7 5.8  7.5  7.0  7.5 5.8  6.7 10.8\n\n\n\nSEM works with matrices\n\n\\(\\boldsymbol{S}\\) observed var-cov\n\\(\\boldsymbol{\\Sigma}\\) true var-cov\n\\(\\boldsymbol{\\hat{\\Sigma}}\\) model-implied var-cov\n\\(\\boldsymbol{\\Sigma}(\\theta)\\)\n\n\nTHE MAIN AIM OF SEM IS TO RECONSTRUCT THE TRUE VARIANCE-COVARIANCE MATRIX"
  },
  {
    "objectID": "slides/00_introduction.html#classification-of-variables",
    "href": "slides/00_introduction.html#classification-of-variables",
    "title": "Introducing the introduction",
    "section": "Classification of variables",
    "text": "Classification of variables\nVariables are the way those attributes that vary across individuals are operationalized and represented for further data processing. These can be categorized according to many criteria (e.g, dependent/independent…), but in SEM we classify them firstly as:\n\nLatent variables\n\nhypothetical variables that correspond to more or less abstract concepts\nformative or reflective\nexamples are intelligence, anxiety, executive functions, personality traits…\n\nObserved variables\n\nvariables that can be directly observed and measured\nexamples can be weight, height, gender, income…"
  },
  {
    "objectID": "slides/00_introduction.html#classification-of-variables-1",
    "href": "slides/00_introduction.html#classification-of-variables-1",
    "title": "Introducing the introduction",
    "section": "Classification of variables",
    "text": "Classification of variables\nIn SEM we also have an additional type of classification:\n\nExogenous variables\n\nVariables whose causes lie outside the model; they will be used only as predictors in the model. They do not receive arrows.\nThey are indicated with \\(x\\), if observed, or with \\(\\xi\\), if latent.\n\nEndogenous variables\n\nVariables that are determined by variables within the model (they receive arrows); can be used as predictors or dependent variables in the model.\nThey are indicated with \\(y\\), if observed, or with \\(\\eta\\), if latent.\n\n\nThis brings us to deepen the relationships between variables."
  },
  {
    "objectID": "slides/00_introduction.html#relationships-between-variables",
    "href": "slides/00_introduction.html#relationships-between-variables",
    "title": "Introducing the introduction",
    "section": "Relationships between variables",
    "text": "Relationships between variables\n\nThe general aim of statistical analysis is to study relationship among variables\nOn the basis of the relationship among the variables, we distinguish two kind of models: symmetrical and asymmetrical."
  },
  {
    "objectID": "slides/00_introduction.html#asymmetrical-relationships",
    "href": "slides/00_introduction.html#asymmetrical-relationships",
    "title": "Introducing the introduction",
    "section": "Asymmetrical relationships",
    "text": "Asymmetrical relationships\nX -&gt; Y\n\nVariables are divided into two sets: dependent or response variables and predictors or explanatory variables\nX is the set of explanatory variables, \\(Y\\) is the set of response variables, arrows represents the direction of the hypothesized relationship.\nThese models imply cause-and-effect relationships.\n\nExample\nPeople who study more obtain higher grades."
  },
  {
    "objectID": "slides/00_introduction.html#symmetrical-relationships",
    "href": "slides/00_introduction.html#symmetrical-relationships",
    "title": "Introducing the introduction",
    "section": "Symmetrical relationships",
    "text": "Symmetrical relationships\n\\[\nX_i \\Leftrightarrow Y_j \\quad \\forall i,j\n\\]\n\nThis means that neither a variable causes the other, neither a variable can be considered prior in time to the other; all these relationships are bidirectional.\nThese models do not imply nor consider causality.\n\nExample\nPeople who have higher grades in math have higher grades in art."
  },
  {
    "objectID": "slides/00_introduction.html#regression-model",
    "href": "slides/00_introduction.html#regression-model",
    "title": "Introducing the introduction",
    "section": "Regression model",
    "text": "Regression model\nAsymmetrical relationships are usually tested with regressions!\nAs you remember, regression models can be written, using classical formulation, as the expression below and graphically depicted (getting closer to SEM) like this:"
  },
  {
    "objectID": "slides/00_introduction.html#more-regression",
    "href": "slides/00_introduction.html#more-regression",
    "title": "Introducing the introduction",
    "section": "More regression?",
    "text": "More regression?\nBut what if we have in mind a more complex pattern of relationships? What if we have more regression models in mind and need to estimate all of them contemporarily?\n\nWhat we need is a system of equations."
  },
  {
    "objectID": "slides/00_introduction.html#more-regression-1",
    "href": "slides/00_introduction.html#more-regression-1",
    "title": "Introducing the introduction",
    "section": "More regression?",
    "text": "More regression?\nThis system can also be drawn with SEM notation, but is actually the same…just better!"
  },
  {
    "objectID": "slides/00_introduction.html#covariance-matrix",
    "href": "slides/00_introduction.html#covariance-matrix",
    "title": "Introducing the introduction",
    "section": "Covariance matrix",
    "text": "Covariance matrix\nThe covariance matrix is the input for the estimation process. In general, given \\(q\\) exogenous (\\(x\\)) and \\(p\\) endogenous (\\(y\\)) variables, the covariance matrix will be:\n\nIn which the diagonal elements are variances and off diagonal elements are covariances."
  },
  {
    "objectID": "slides/00_introduction.html#variables-and-errors",
    "href": "slides/00_introduction.html#variables-and-errors",
    "title": "Introducing the introduction",
    "section": "Variables and errors",
    "text": "Variables and errors\n\nVariables\n\n\\(x\\) exogenous observed (\\(q\\))\n\\(\\xi\\) exogenous latent (\\(n\\))\n\\(y\\) endogenous observed (\\(p\\))\n\\(\\eta\\) endogenous latent (\\(m\\))\n\nStochastic errors\n\n\\(\\delta\\) measurement errors in \\(x\\)\n\\(\\epsilon\\) measurement errors in \\(y\\)\n\\(\\zeta\\) equation errors in the structural relationship between \\(\\eta\\) and \\(\\xi\\)"
  },
  {
    "objectID": "slides/00_introduction.html#sem-matrices---lavaan-model",
    "href": "slides/00_introduction.html#sem-matrices---lavaan-model",
    "title": "Introducing the introduction",
    "section": "SEM matrices - lavaan model",
    "text": "SEM matrices - lavaan model\n\nParameter matrices\n\n\\(\\boldsymbol{\\Lambda}\\) relationship between latent (\\(\\xi\\) and \\(\\eta\\)) and observed (\\(x\\) and \\(y\\)) [\\((p + q) X (m + n)\\)]\n\\(\\boldsymbol{B}\\) relationship between latent variables [\\((m + n) X (m + n)\\)]\n\nCovariance matrices\n\n\\(Cov\\)(\\(\\zeta\\), \\(\\xi\\)) = \\(\\boldsymbol{\\Psi}\\) matrix [\\((m + n) X (m + n)\\)]\n\\(Cov\\)(\\(\\epsilon\\), \\(\\delta\\)) = \\(\\boldsymbol{\\Theta}\\) matrix [\\((p + q) X (p + q)\\)]"
  },
  {
    "objectID": "slides/00_introduction.html#sem-equations",
    "href": "slides/00_introduction.html#sem-equations",
    "title": "Introducing the introduction",
    "section": "SEM equations",
    "text": "SEM equations\nThe SEM model in its most general form consists of two parts\n\nThe measurement model\n\n\\(x = \\boldsymbol{\\Lambda}_x\\boldsymbol{\\xi} + \\boldsymbol{\\delta}\\)\n\\(y = \\boldsymbol{\\Lambda}_y\\boldsymbol{\\eta} + \\boldsymbol{\\epsilon}\\)\n\nThe structural model\n\n\\(\\boldsymbol{\\eta} = \\boldsymbol{B\\eta} + \\boldsymbol{\\Gamma\\xi} + \\boldsymbol{\\zeta}\\)\n\\(\\boldsymbol{\\eta} = \\boldsymbol{B(\\eta\\xi} + \\boldsymbol{\\zeta})\\)"
  },
  {
    "objectID": "slides/00_introduction.html#sem-assumtions",
    "href": "slides/00_introduction.html#sem-assumtions",
    "title": "Introducing the introduction",
    "section": "SEM assumtions",
    "text": "SEM assumtions\n\nExpected values of latent variables and stochastic errors are 0:\n\\(E\\)(\\(\\eta\\)) = 0\n\\(E\\)(\\(\\xi\\)) = 0\n\\(E\\)(\\(\\zeta\\)) = 0\n\\(E\\)(\\(\\epsilon\\)) = 0\n\\(E\\)(\\(\\delta\\)) = 0\nErrors are uncorrelated with latent variables and are mutually uncorrelated:"
  },
  {
    "objectID": "slides/00_introduction.html#sem-steps",
    "href": "slides/00_introduction.html#sem-steps",
    "title": "Introducing the introduction",
    "section": "SEM steps",
    "text": "SEM steps\nThere are 5 principal steps in Structural Equation Modeling:\n\nmodel specification\nmodel identification\nparameters estimation\ntesting\nmodel modification\n\nAs usual, these steps are like a cycle: when you arrive at step 5 you can always come back to step 1."
  },
  {
    "objectID": "slides/00_introduction.html#model-specification",
    "href": "slides/00_introduction.html#model-specification",
    "title": "Introducing the introduction",
    "section": "1. Model specification",
    "text": "1. Model specification\nAim of the model\n\nWe fit models because we want to better understand the data and the process of data generation (to better understand this we will use simulation…simulate, simulate, simulate!)\n\nWhat is a model\n\nA model is a formal representation of a theory and is composed by a set of parameters that we will estimate.\n\nExamples"
  },
  {
    "objectID": "slides/00_introduction.html#model-identification",
    "href": "slides/00_introduction.html#model-identification",
    "title": "Introducing the introduction",
    "section": "2. Model identification",
    "text": "2. Model identification\nBasically, we want to know if there is enough information to identify a solution (aka estimate all the unknown parameters).\nA model can be:\n\nUnder-identified\nJust-identified\nOver-identified"
  },
  {
    "objectID": "slides/00_introduction.html#model-identification-1",
    "href": "slides/00_introduction.html#model-identification-1",
    "title": "Introducing the introduction",
    "section": "2. Model identification",
    "text": "2. Model identification\nBasically, we want to know if there is enough information to identify a solution (aka estimate all the unknown parameters).\nA model can be:\n\nUnder-identified: there are MORE parameters to be estimated than elements in the covariance matrix (e.g., \\(X + Y = 10\\))\nJust-identified: the number of parameters to be estimated equals the number of elements in the covariance matrix (\\(df = 0\\))\nOver-identified: there are LESS parameters to be estimated than elements in the covariance matrix (\\(df &gt; 0\\))"
  },
  {
    "objectID": "slides/00_introduction.html#model-identification-2",
    "href": "slides/00_introduction.html#model-identification-2",
    "title": "Introducing the introduction",
    "section": "3. Model identification",
    "text": "3. Model identification\nTo ensure that the number of unknown parameters (\\(t\\)) is not greater than the number of nonredundant elements in the covariance matrix of \\(q\\) observed variables. We can use the following formula:\n\\[\nt \\leq \\frac{q(q+1)}{2}\n\\]"
  },
  {
    "objectID": "slides/00_introduction.html#an-under-identified-model",
    "href": "slides/00_introduction.html#an-under-identified-model",
    "title": "Introducing the introduction",
    "section": "An under-identified model",
    "text": "An under-identified model\nTo ensure that the number of unknown parameters (\\(t\\)) is not greater than the number of nonredundant elements in the covariance matrix of \\(q\\) observed variables. We can use the following formula:\n\\[\nt \\leq \\frac{q(q+1)}{2}\n\\]"
  },
  {
    "objectID": "slides/00_introduction.html#an-over-identified-model",
    "href": "slides/00_introduction.html#an-over-identified-model",
    "title": "Introducing the introduction",
    "section": "An over-identified model",
    "text": "An over-identified model\nTo ensure that the number of unknown parameters (\\(t\\)) is not greater than the number of nonredundant elements in the covariance matrix of \\(q\\) observed variables. We can use the following formula:\n\\[\nt \\leq \\frac{q(q+1)}{2}\n\\]"
  },
  {
    "objectID": "slides/00_introduction.html#parameter-estimation",
    "href": "slides/00_introduction.html#parameter-estimation",
    "title": "Introducing the introduction",
    "section": "3. Parameter estimation",
    "text": "3. Parameter estimation\nTo estimate the model parameters we can use different estimation methods. These aim to estimate the model implied (theoretical) correlation matrix \\(\\boldsymbol{\\Sigma}\\), which is a function of the model parameters, and should hopefully be similar to the observed correlation matrix \\(\\boldsymbol{S}\\).\nSome of the many estimation methods are:\n\nMaximum Likelihood (ML), default in lavaan\nUnweighted Least Squares (ULS)\nGeneralized Least Squares (GLS)\nDiagonally Weighted Least Squares (DWLS), default for ordinal variables in lavaan"
  },
  {
    "objectID": "slides/00_introduction.html#model-evaluation",
    "href": "slides/00_introduction.html#model-evaluation",
    "title": "Introducing the introduction",
    "section": "4. Model evaluation",
    "text": "4. Model evaluation\nIs the model adequate? Are our parameter able to construct a theoretical matrix (\\(\\boldsymbol{\\Sigma}\\)) which is close to the original empirical covariance matrix \\(\\boldsymbol{S}\\)?\nThis is the goal of a good model: reproduce, from a set of theoretical associations/effects (aka covariance matrix), the original covariance matrix.\nFormally:\n\\[\nH_0 : \\boldsymbol{\\hat{\\Sigma}}(\\theta) = \\boldsymbol{\\Sigma}\n\\] where \\(\\boldsymbol{\\Sigma}\\) is the true covariance matrix among model variables, \\(\\theta\\) the parameters vector, and \\(\\boldsymbol{\\hat{\\Sigma}}\\) the reproduced covariance matrix."
  },
  {
    "objectID": "slides/00_introduction.html#model-modification",
    "href": "slides/00_introduction.html#model-modification",
    "title": "Introducing the introduction",
    "section": "5. Model modification",
    "text": "5. Model modification\nAt this point you are free to modify the model based on the results obtained…AND THE THEORY!"
  },
  {
    "objectID": "slides/00_introduction.html#a-full-representation",
    "href": "slides/00_introduction.html#a-full-representation",
    "title": "Introducing the introduction",
    "section": "A full representation",
    "text": "A full representation\n img credits to dr. Johnny Lin"
  },
  {
    "objectID": "slides/00_introduction.html#graphical-representation",
    "href": "slides/00_introduction.html#graphical-representation",
    "title": "Introducing the introduction",
    "section": "Graphical representation",
    "text": "Graphical representation\nIf that all seemed difficult and boring, now comes the funny part: colors, figures, and arrows!\nGraphical representation is a key attribute of structural equation modeling:\n\nIt helps understanding the model\nIt helps thinking and reasoning about the model (a priori)\nIt helps writing and formalizing the model\nIt is easy, but few rules must be followed to have a readable model"
  },
  {
    "objectID": "slides/00_introduction.html#graphical-representation-1",
    "href": "slides/00_introduction.html#graphical-representation-1",
    "title": "Introducing the introduction",
    "section": "Graphical representation",
    "text": "Graphical representation\n\nLatent variables are circles or ellipses\n\nManifest/observed variables are square or rectangular boxes\n\nErrors are represented by corresponding letters (or values) only\n\n\\[\n\\delta_1  /  \\epsilon_1  /  \\zeta_1\n\\]"
  },
  {
    "objectID": "slides/00_introduction.html#graphic-relationships",
    "href": "slides/00_introduction.html#graphic-relationships",
    "title": "Introducing the introduction",
    "section": "Graphic relationships",
    "text": "Graphic relationships\n\nAll model relationships are represented by arrows;\n NO relationship NO arrow... \n\n ...and usually NO arrow NO relationship\nEach arrow is a model parameter and has two indices (e.g., \\(\\beta_{21}\\))\nAsymmetrical relationship are represented by a single headed arrow: the first index indicates the variable the arrow is pointing to, the second index indicates the variable of origin.\nSymmetrical relationships are represented by double-headed arrows and two indices, one for each variable."
  },
  {
    "objectID": "slides/00_introduction.html#graphic-relationships-1",
    "href": "slides/00_introduction.html#graphic-relationships-1",
    "title": "Introducing the introduction",
    "section": "Graphic relationships",
    "text": "Graphic relationships\nA summary"
  },
  {
    "objectID": "slides/00_introduction.html#asymmetrical-relationships-1",
    "href": "slides/00_introduction.html#asymmetrical-relationships-1",
    "title": "Introducing the introduction",
    "section": "Asymmetrical relationships",
    "text": "Asymmetrical relationships"
  },
  {
    "objectID": "slides/00_introduction.html#symmetrical-relationships-1",
    "href": "slides/00_introduction.html#symmetrical-relationships-1",
    "title": "Introducing the introduction",
    "section": "Symmetrical relationships",
    "text": "Symmetrical relationships"
  },
  {
    "objectID": "slides/00_introduction.html#graphical-errors",
    "href": "slides/00_introduction.html#graphical-errors",
    "title": "Introducing the introduction",
    "section": "Graphical errors",
    "text": "Graphical errors\n\nAll errors have a single headed arrow pointing to a variable; all variables, except \\(\\xi\\), may have an error.\nDouble-headed arrows associated to errors indicate error variances."
  },
  {
    "objectID": "slides/00_introduction.html#a-full-representation-1",
    "href": "slides/00_introduction.html#a-full-representation-1",
    "title": "Introducing the introduction",
    "section": "A full representation",
    "text": "A full representation\n img credits to dr. Johnny Lin"
  },
  {
    "objectID": "slides/00_introduction.html#univariate-regressions",
    "href": "slides/00_introduction.html#univariate-regressions",
    "title": "Introducing the introduction",
    "section": "Univariate regressions",
    "text": "Univariate regressions"
  },
  {
    "objectID": "slides/00_introduction.html#multivariate-regressions",
    "href": "slides/00_introduction.html#multivariate-regressions",
    "title": "Introducing the introduction",
    "section": "Multivariate regressions",
    "text": "Multivariate regressions"
  },
  {
    "objectID": "slides/00_introduction.html#path-analysis",
    "href": "slides/00_introduction.html#path-analysis",
    "title": "Introducing the introduction",
    "section": "Path analysis",
    "text": "Path analysis"
  },
  {
    "objectID": "slides/00_introduction.html#confirmatory-factor-analysis-cfa",
    "href": "slides/00_introduction.html#confirmatory-factor-analysis-cfa",
    "title": "Introducing the introduction",
    "section": "Confirmatory factor analysis (CFA)",
    "text": "Confirmatory factor analysis (CFA)"
  },
  {
    "objectID": "slides/00_introduction.html#sem-path-analysis",
    "href": "slides/00_introduction.html#sem-path-analysis",
    "title": "Introducing the introduction",
    "section": "SEM path analysis",
    "text": "SEM path analysis"
  },
  {
    "objectID": "slides/00_introduction.html#t-test-with-latent-variables",
    "href": "slides/00_introduction.html#t-test-with-latent-variables",
    "title": "Introducing the introduction",
    "section": "t test with latent variables",
    "text": "t test with latent variables"
  },
  {
    "objectID": "slides/00_introduction.html#cross-lagged-panel-models",
    "href": "slides/00_introduction.html#cross-lagged-panel-models",
    "title": "Introducing the introduction",
    "section": "Cross-lagged panel models",
    "text": "Cross-lagged panel models"
  },
  {
    "objectID": "slides/00_introduction.html#growth-curve-models",
    "href": "slides/00_introduction.html#growth-curve-models",
    "title": "Introducing the introduction",
    "section": "Growth curve models",
    "text": "Growth curve models"
  },
  {
    "objectID": "slides/00_introduction.html#and-much-more",
    "href": "slides/00_introduction.html#and-much-more",
    "title": "Introducing the introduction",
    "section": "And much more",
    "text": "And much more\n…and much more\nTHERE IS EVEN A JOURNAL ON SEM\nStructural Equation Modeling: A Multidisciplinary Journal"
  },
  {
    "objectID": "slides/00_introduction.html#contacts-1",
    "href": "slides/00_introduction.html#contacts-1",
    "title": "Introducing the introduction",
    "section": "Contacts",
    "text": "Contacts\ntommaso.feraco@unipd.it"
  },
  {
    "objectID": "slides/00_introduction.html#sem-assumptions",
    "href": "slides/00_introduction.html#sem-assumptions",
    "title": "Introducing the introduction",
    "section": "SEM assumptions",
    "text": "SEM assumptions\n\nExpected values of latent variables and stochastic errors are 0:\n\n\\(E\\)(\\(\\eta\\)) = 0\n\\(E\\)(\\(\\xi\\)) = 0\n\\(E\\)(\\(\\zeta\\)) = 0\n\\(E\\)(\\(\\epsilon\\)) = 0\n\\(E\\)(\\(\\delta\\)) = 0\n\nErrors are uncorrelated with latent variables and are mutually uncorrelated:"
  },
  {
    "objectID": "slides/01_path_models.html#outline",
    "href": "slides/01_path_models.html#outline",
    "title": "Models with observed variables",
    "section": "Outline",
    "text": "Outline\n\nFrom lm to lavaan\nExercise 1\nPath models\nExercise 2\nModel fit\nMediation analysis"
  },
  {
    "objectID": "slides/01_path_models.html#regression-models",
    "href": "slides/01_path_models.html#regression-models",
    "title": "Models with observed variables",
    "section": "Regression models",
    "text": "Regression models\nWhat you did since the beginning of the year (with link functions or not) was something like this \\[\ny = X\\beta + \\epsilon\n\\] Where \\(y\\) is the response variable, \\(X\\) the set of predictors and \\(\\epsilon\\) the error term. \nThese models, - assume that all variables are directly observed/manifest - allow measurement errors only in endogenous variables - are just particular cases of SEM"
  },
  {
    "objectID": "slides/01_path_models.html#sem-formula",
    "href": "slides/01_path_models.html#sem-formula",
    "title": "Models with observed variables",
    "section": "SEM formula",
    "text": "SEM formula\nIn fact, the structural model of a SEM (i.e., excluding latent variables) can be expressed with the following equation: \\[\nY = X^\\ast B' + \\zeta\n\\] Where - \\(Y\\) is the (n x p) matrix of endogenous variables - \\(X^\\ast\\) is the n x (p + q) matrix of endogenous and exogenous variables - \\(B\\) is the (p + q) x (p + q) coefficient matrices - \\(\\zeta\\) is the (p x q) matrix of errors in the equations This looks pretty similar to the regression formula, but with some matrices!  Univariate regression models are just a special case of this formula where the parameter matrix is full of 0!"
  },
  {
    "objectID": "slides/01_path_models.html#lets-try-to-fit-and-compare-regression-models",
    "href": "slides/01_path_models.html#lets-try-to-fit-and-compare-regression-models",
    "title": "Models with observed variables",
    "section": "LET’S TRY TO FIT AND COMPARE REGRESSION MODELS",
    "text": "LET’S TRY TO FIT AND COMPARE REGRESSION MODELS\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   y x1 x2 x3\ny  0  1  2  3\nx1 0  0  0  0\nx2 0  0  0  0\nx3 0  0  0  0\n\n\n\n\n   y x3 x2 x1\ny  0  3  2  1\nx3 0  0  5  4\nx2 0  0  0  6\nx1 0  0  0  0\n\n\n\nLET'S TRY TO FIT AND COMPARE REGRESSION MODELS"
  },
  {
    "objectID": "slides/01_path_models.html#a-first-example-with-simulated-data",
    "href": "slides/01_path_models.html#a-first-example-with-simulated-data",
    "title": "Models with observed variables",
    "section": "A first example with simulated data",
    "text": "A first example with simulated data\nImagine you want to predict scores in the test we will do at the end of this corse (\\(y\\)), based on your prior statistical knowledge (\\(x_1\\)) and interest (\\(x_2\\)): - First define the model\n\n\nSecond simulate the data"
  },
  {
    "objectID": "slides/01_path_models.html#a-first-example-with-simulated-data-1",
    "href": "slides/01_path_models.html#a-first-example-with-simulated-data-1",
    "title": "Models with observed variables",
    "section": "A first example with simulated data",
    "text": "A first example with simulated data\n\n# Simulate knowledge and interest as predictors of Y\nset.seed(12)\nN = 100\nx1 = rnorm(N)\nx2 = rnorm(N)\ny = .35*x1 + .20*x2 + rnorm(N)\nd &lt;- data.frame(x1,x2,y)\n\n\ncor(d)\n\n       x1     x2     y\nx1 1.0000 0.0159 0.386\nx2 0.0159 1.0000 0.118\ny  0.3863 0.1185 1.000\n\n#\ncov(d)\n\n       x1     x2     y\nx1 0.7484 0.0138 0.364\nx2 0.0138 0.9982 0.129\ny  0.3644 0.1291 1.189"
  },
  {
    "objectID": "slides/01_path_models.html#lm-regression",
    "href": "slides/01_path_models.html#lm-regression",
    "title": "Models with observed variables",
    "section": "lm regression",
    "text": "lm regression\n\n# fit a regression model\nm &lt;- lm(y ~ x1 + x2, data = d)\nsummary(m)\n\n\nCall:\nlm(formula = y ~ x1 + x2, data = d)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.8022 -0.6244 -0.0259  0.7150  1.8090 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  -0.0251     0.1009   -0.25     0.80    \nx1            0.4846     0.1172    4.14  7.5e-05 ***\nx2            0.1226     0.1015    1.21     0.23    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.01 on 97 degrees of freedom\nMultiple R-squared:  0.162, Adjusted R-squared:  0.145 \nF-statistic: 9.36 on 2 and 97 DF,  p-value: 0.000191"
  },
  {
    "objectID": "slides/01_path_models.html#introducing-lavaan",
    "href": "slides/01_path_models.html#introducing-lavaan",
    "title": "Models with observed variables",
    "section": "Introducing lavaan",
    "text": "Introducing lavaan\nlavaan (latent variable analysis) is actually THE package for SEM. You can use it to estimate a wide family of latent variable models, including: factor analysis, structural equation, longitudinal, multilevel, latent class, item respons, and missing data models… \n..But also simple regressions"
  },
  {
    "objectID": "slides/01_path_models.html#model-fit-and-info",
    "href": "slides/01_path_models.html#model-fit-and-info",
    "title": "Models with observed variables",
    "section": "Model fit and info",
    "text": "Model fit and info\n\nlibrary(lavaan)\nml &lt;- \"y ~ 1 + x1 + x2\" #1 + gives the intercept\nfit &lt;- sem(ml, data = d)\n# summary(fit, rsquare=T)\n\n\n\nlavaan 0.6-19 ended normally after 1 iteration\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         4\n\n  Number of observations                           100\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\n[...]"
  },
  {
    "objectID": "slides/01_path_models.html#model-parameters",
    "href": "slides/01_path_models.html#model-parameters",
    "title": "Models with observed variables",
    "section": "Model parameters",
    "text": "Model parameters\n\n\n[...]\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  y ~                                                 \n    x1                0.485    0.115    4.199    0.000\n    x2                0.123    0.100    1.227    0.220\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .y                -0.025    0.099   -0.253    0.800\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .y                 0.987    0.140    7.071    0.000\n\nR-Square:\n                   Estimate\n    y                 0.162\n\n[...]\n\n\nQUESTIONS? COMMENTS? What about lm?"
  },
  {
    "objectID": "slides/01_path_models.html#model-plot",
    "href": "slides/01_path_models.html#model-plot",
    "title": "Models with observed variables",
    "section": "Model plot",
    "text": "Model plot\n\n\n\n# And we can plot it\nlibrary(semPlot)\nsemPaths(fit, whatLabels = \"parameters\",\n         edge.label.cex = 1.5, rotation = 2,\n         residuals = F,\n         sizeMan = 10,\n         curve = 1.9,\n         edge.color=\"black\", edge.label.color=\"black\")"
  },
  {
    "objectID": "slides/01_path_models.html#model-matrices",
    "href": "slides/01_path_models.html#model-matrices",
    "title": "Models with observed variables",
    "section": "Model matrices",
    "text": "Model matrices\n\n#We can also look at the matrices\n#The parameters matrix\ninspect(fit)$beta\n\n   y x1 x2\ny  0  2  3\nx1 0  0  0\nx2 0  0  0\n\ninspect(fit, \"estimates\")$beta\n\n   y    x1    x2\ny  0 0.485 0.123\nx1 0 0.000 0.000\nx2 0 0.000 0.000\n\n#The residual var-covar matrix\ninspect(fit)$psi\n\n   y x1 x2\ny  4      \nx1 0  0   \nx2 0  0  0\n\ninspect(fit, \"estimates\")$psi\n\n       y    x1    x2\ny  0.987            \nx1 0.000 0.741      \nx2 0.000 0.014 0.988"
  },
  {
    "objectID": "slides/01_path_models.html#basic-lavaan-syntax",
    "href": "slides/01_path_models.html#basic-lavaan-syntax",
    "title": "Models with observed variables",
    "section": "Basic lavaan syntax",
    "text": "Basic lavaan syntax\nAs you can see, the regression syntax of lavaan is actually the same as lm, but there is much more in lavaan. \nModel specification sintax:\n\n\n\n\n\n\n\n\nSyntax\nFunction\nExample\n\n\n\n\n~\nRegress onto\nRegress B onto A: B ~ A\n\n\n~~\nResidual (co)variance\nVariance of A: A ~~ A  Variance of A and B: A ~~ B\n\n\n=~\nDefine a reflective LV\nF1 is defined by items 1-4: F1 =~ i1 + i2 + i3 + i4\n\n\n&lt;~\nDefine a formative LV\nF1 is defined by items 1-4: F1 &lt;~ i1 + i2 + i3 + i4\n\n\n:=\nDefine non-model parameters\nu2 := x + y\n\n\n*\nLabel or fix parameter\nZ ~ b*X labels the regression as b"
  },
  {
    "objectID": "slides/01_path_models.html#exercise-1",
    "href": "slides/01_path_models.html#exercise-1",
    "title": "Models with observed variables",
    "section": "Exercise 1",
    "text": "Exercise 1\nJust a very easy exercise to start practicing with the lavaan sintax. The example is similar to the one above.  The dataset “Exercise1.csv” contains: - N = 1100 participants - 5 variables - - gender: coded 1;2 - age: between 13 and 19 - anxiety - nevroticism - math We want to know whether anxiety and nevroticism have an effect on math achievement. Additionally, is there any effect of demographics variables?"
  },
  {
    "objectID": "slides/01_path_models.html#plot-of-the-exercise",
    "href": "slides/01_path_models.html#plot-of-the-exercise",
    "title": "Models with observed variables",
    "section": "Plot of the exercise",
    "text": "Plot of the exercise\n\n# E1 &lt;- read.csv(\"data/Exercise1.csv\")\nsemPaths(fitE1, rotation = 2, sizeMan = 10,\n         edge.color=\"black\", edge.label.color=\"black\",\n         residuals = F, exoCov = F)"
  },
  {
    "objectID": "slides/01_path_models.html#results---estimation-info",
    "href": "slides/01_path_models.html#results---estimation-info",
    "title": "Models with observed variables",
    "section": "Results - estimation info",
    "text": "Results - estimation info\n\n\nlavaan 0.6-19 ended normally after 1 iteration\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         5\n\n  Number of observations                           723\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\n[...]"
  },
  {
    "objectID": "slides/01_path_models.html#regression-results",
    "href": "slides/01_path_models.html#regression-results",
    "title": "Models with observed variables",
    "section": "Regression results",
    "text": "Regression results\n\n\n[...]\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  math ~                                                                \n    age               0.052    0.009    5.452    0.000    0.052    0.170\n    anxiety           0.357    0.021   16.878    0.000    0.357    0.591\n    nevroticism      -0.156    0.021   -7.354    0.000   -0.156   -0.257\n    gender            0.020    0.039    0.518    0.604    0.020    0.016\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .math              0.263    0.014   19.013    0.000    0.263    0.698"
  },
  {
    "objectID": "slides/01_path_models.html#indirect-effects",
    "href": "slides/01_path_models.html#indirect-effects",
    "title": "Models with observed variables",
    "section": "Indirect effects?",
    "text": "Indirect effects?\nWE JUST ANALYZED NEUROTICISM AND ANXIETY. DO WE REALLY BELIEVE THEY ARE ON THE SAME LEVEL?"
  },
  {
    "objectID": "slides/01_path_models.html#path-models",
    "href": "slides/01_path_models.html#path-models",
    "title": "Models with observed variables",
    "section": "Path models",
    "text": "Path models\nPath models are just pictorial representations of theoretical relationships between variables.  Representations (and simulations) should be the starting point of almost every study.  Based on these representations, we can build a statistical model and estimate the theoretical paths.\n\nThis, of course, is possible in lavaan."
  },
  {
    "objectID": "slides/01_path_models.html#path-models---the-previous-example",
    "href": "slides/01_path_models.html#path-models---the-previous-example",
    "title": "Models with observed variables",
    "section": "Path models - the previous example",
    "text": "Path models - the previous example\nFor example, do we really believe that anxiety and nevroticism could stay on the same level? Isn’t there a theoretical effect of one on the other?"
  },
  {
    "objectID": "slides/01_path_models.html#path-models---the-previous-example-1",
    "href": "slides/01_path_models.html#path-models---the-previous-example-1",
    "title": "Models with observed variables",
    "section": "Path models - the previous example",
    "text": "Path models - the previous example\nFor example, do we really believe that anxiety and nevroticism could stay on the same level? Isn’t there a theoretical effect of one on the other?"
  },
  {
    "objectID": "slides/01_path_models.html#path-models---the-previous-example-2",
    "href": "slides/01_path_models.html#path-models---the-previous-example-2",
    "title": "Models with observed variables",
    "section": "Path models - the previous example",
    "text": "Path models - the previous example\nCode: We can write the additional regression just by adding one line to the model (plus some additional things for indirect and total effects): \n\nm &lt;- \"math ~ age + anxiety + nevroticism + gender\n      anxiety ~ nevroticism\"\nfitE1 &lt;- sem(m, data = E1)\n\n\nm &lt;- \"math ~ age + am*anxiety + nm*nevroticism + gender\n      anxiety ~ n*nevroticism\n      # Indirect effect\n      ind := n*am\n      # Total effect\n      tot := n*am + nm\"\nfitE1 &lt;- sem(m, data = E1)"
  },
  {
    "objectID": "slides/01_path_models.html#path-model-example",
    "href": "slides/01_path_models.html#path-model-example",
    "title": "Models with observed variables",
    "section": "Path model example",
    "text": "Path model example\nWe have collected data from 1100 Italian cities.  Research question: to what extent do economic factors, education, and environmental policies influence the quality of life of Italian people? Are these relationships mediated by social cohesion? - gdp - education - environment - wellbeing - cohesion The model can be expressed with the following equations: \\[\n\\begin{cases}\n\\text{cohesion} & = \\beta_{13} X_{\\text{gdp}} + \\beta_{14} X_{\\text{education}} + \\beta_{15} X_{\\text{environment}} + \\zeta_1 \\\\\n\\text{wellbeing} & = \\beta_{23} X_{\\text{gdp}} + \\beta_{24} X_{\\text{education}} + \\beta_{25} X_{\\text{environment}} + \\beta_{21} X_{\\text{cohesion}} + \\zeta_2\n\\end{cases}\n\\]"
  },
  {
    "objectID": "slides/01_path_models.html#script",
    "href": "slides/01_path_models.html#script",
    "title": "Models with observed variables",
    "section": "Script",
    "text": "Script\n\nm &lt;- \"\ncohesion ~ gdp + education + environment\nwellbeing ~ gdp + education + environment + cohesion\n\"\nfit &lt;- sem(m, data = Dprov)"
  },
  {
    "objectID": "slides/01_path_models.html#results",
    "href": "slides/01_path_models.html#results",
    "title": "Models with observed variables",
    "section": "Results",
    "text": "Results\nThere is an effect of cohesion, which is in the middle.\n\n\n[...]\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  cohesion ~                                          \n    gdp              -0.324    0.030  -10.722    0.000\n    education         0.178    0.030    5.883    0.000\n    environment       0.453    0.030   15.177    0.000\n  wellbeing ~                                         \n    gdp               0.371    0.030   12.372    0.000\n    education         0.154    0.029    5.304    0.000\n    environment      -0.132    0.031   -4.251    0.000\n    cohesion          0.678    0.028   23.821    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .cohesion          1.004    0.043   23.452    0.000\n   .wellbeing         0.896    0.038   23.452    0.000"
  },
  {
    "objectID": "slides/01_path_models.html#matrices-again",
    "href": "slides/01_path_models.html#matrices-again",
    "title": "Models with observed variables",
    "section": "Matrices, again",
    "text": "Matrices, again\n\ninspect(fit, \"estimates\")$psi\n\n            cohesn wllbng    gdp eductn envrnm\ncohesion     1.004                            \nwellbeing    0.000  0.896                     \ngdp          0.000  0.000  1.032              \neducation    0.000  0.000  0.173  1.035       \nenvironment  0.000  0.000  0.038 -0.065  1.029\n\n#\ninspect(fit, \"estimates\")$beta\n\n            cohesn wllbng    gdp eductn envrnm\ncohesion     0.000      0 -0.324  0.178  0.453\nwellbeing    0.678      0  0.371  0.154 -0.132\ngdp          0.000      0  0.000  0.000  0.000\neducation    0.000      0  0.000  0.000  0.000\nenvironment  0.000      0  0.000  0.000  0.000"
  },
  {
    "objectID": "slides/01_path_models.html#the-lavaan-psi-matrix",
    "href": "slides/01_path_models.html#the-lavaan-psi-matrix",
    "title": "Models with observed variables",
    "section": "The lavaan Psi matrix",
    "text": "The lavaan Psi matrix\nIt is composed by the actual residual covariance matrix \\(\\Psi\\)\n\ninspect(fit, \"estimates\")$psi[1:2,1:2]\n\n          cohesion wellbeing\ncohesion         1     0.000\nwellbeing        0     0.896\n\n\nAnd the fitted/reproduced covariance matrix \\(\\hat{\\Sigma}(\\theta)\\)\n\ninspect(fit, \"estimates\")$psi[3:5, 3:5]\n\n               gdp education environment\ngdp         1.0318     0.173      0.0378\neducation   0.1727     1.035     -0.0650\nenvironment 0.0378    -0.065      1.0294"
  },
  {
    "objectID": "slides/01_path_models.html#forgetting-a-mediator",
    "href": "slides/01_path_models.html#forgetting-a-mediator",
    "title": "Models with observed variables",
    "section": "Forgetting a mediator?",
    "text": "Forgetting a mediator?\n\nround(cor(Dprov),2)\n\n            cohesion wellbeing   gdp education environment\ncohesion        1.00      0.53 -0.25      0.08        0.38\nwellbeing       0.53      1.00  0.17      0.24        0.14\ngdp            -0.25      0.17  1.00      0.17        0.04\neducation       0.08      0.24  0.17      1.00       -0.06\nenvironment     0.38      0.14  0.04     -0.06        1.00\n\n## m &lt;- lm(wellbeing ~ gdp + education + environment, data = Dprov)\n## summary(m)"
  },
  {
    "objectID": "slides/01_path_models.html#exercise-2",
    "href": "slides/01_path_models.html#exercise-2",
    "title": "Models with observed variables",
    "section": "Exercise 2",
    "text": "Exercise 2\n\nN = 483\nm &lt;- \"\nlifeSatisfaction ~ .05*attachment + .25*selfEsteem + .40*parentalSupport + .30*salary\nselfEsteem ~ .40*parentalSupport + .20*attachment\nattachment ~~ .30*parentalSupport\n\"\nm1 &lt;- \"\nlifeSatisfaction ~ selfEsteem + salary #+ parentalSupport\nselfEsteem ~ parentalSupport + attachment\n#attachment ~~ parentalSupport\n\"\nE2 &lt;- simulateData(m, sample.nobs = N, seed = 12)\n\nThe dataset “Exercise2.csv” contains:\n\nN = 1100 participants\n5 variables\n\n\nsalary\n\n\nattachment\nparental support\nself-esteem\nlife satisfaction\n\nWe want to fit this model (also calculate indirect effects):"
  },
  {
    "objectID": "slides/01_path_models.html#fit-a-model-with-indirect-effects",
    "href": "slides/01_path_models.html#fit-a-model-with-indirect-effects",
    "title": "Models with observed variables",
    "section": "Fit a model with indirect effects",
    "text": "Fit a model with indirect effects\n\nmE2 &lt;- \"\n#we name (_*variable) the parameters of interest\nlifeSatisfaction ~ a*selfEsteem + salary\nselfEsteem ~ b*parentalSupport + c*attachment\nattachment ~ salary\nparentalSupport ~ salary\n\n#and then define the non-model parameters\nindAttSelf  := c*a\nindSuppSelf := b*a\n\"\nfitE2 &lt;- sem(mE2, data = E2) #, se = \"bootstrap\")"
  },
  {
    "objectID": "slides/01_path_models.html#results---estimation-info-1",
    "href": "slides/01_path_models.html#results---estimation-info-1",
    "title": "Models with observed variables",
    "section": "Results - estimation info",
    "text": "Results - estimation info\n\n\nlavaan 0.6-19 ended normally after 10 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        10\n\n  Number of observations                           483\n\nModel Test User Model:\n                                                      \n  Test statistic                               114.172\n  Degrees of freedom                                 4\n  P-value (Chi-square)                           0.000\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\n[...]"
  },
  {
    "objectID": "slides/01_path_models.html#regression-results-1",
    "href": "slides/01_path_models.html#regression-results-1",
    "title": "Models with observed variables",
    "section": "Regression results",
    "text": "Regression results\n\n\n[...]\nRegressions:\n                     Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  lifeSatisfaction ~                                                      \n    selfEsteem (a)      0.373    0.044    8.379    0.000    0.373    0.349\n    salary              0.234    0.049    4.805    0.000    0.234    0.200\n  selfEsteem ~                                                            \n    prntlSpprt (b)      0.360    0.049    7.349    0.000    0.360    0.314\n    attachment (c)      0.145    0.046    3.177    0.001    0.145    0.136\n  attachment ~                                                            \n    salary             -0.009    0.047   -0.198    0.843   -0.009   -0.009\n  parentalSupport ~                                                       \n    salary              0.001    0.043    0.025    0.980    0.001    0.001\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .lifeSatisfactn    1.112    0.072   15.540    0.000    1.112    0.838\n   .selfEsteem        1.028    0.066   15.540    0.000    1.028    0.883\n   .attachment        1.016    0.065   15.540    0.000    1.016    1.000\n   .parentalSupprt    0.885    0.057   15.540    0.000    0.885    1.000\n\n[...]"
  },
  {
    "objectID": "slides/01_path_models.html#indirect-effects-1",
    "href": "slides/01_path_models.html#indirect-effects-1",
    "title": "Models with observed variables",
    "section": "Indirect effects",
    "text": "Indirect effects\nThe indirect effects estimated with lavaan in this way are just a mere multiplication of the parameters. You can apply bootstrap procedures to obtain more robust results and errors! \n\n\n[...]\nDefined Parameters:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n    indAttSelf        0.054    0.018    2.971    0.003    0.054    0.047\n    indSuppSelf       0.134    0.024    5.525    0.000    0.134    0.110"
  },
  {
    "objectID": "slides/01_path_models.html#model-fit",
    "href": "slides/01_path_models.html#model-fit",
    "title": "Models with observed variables",
    "section": "Model fit",
    "text": "Model fit\nYou surely remember this slide from before:\n*’This is the goal of a good model: reproduce, from a set of theoretical associations/effects (aka covariance matrix), the original covariance matrix.\nFormally:\n\\[\nH_0 : \\hat{\\Sigma}(\\theta) = \\Sigma\n\\]\nwhere \\(\\Sigma\\) is the true covariance matrix among model variables, \\(\\theta\\) the parameters vector, and \\(\\hat{\\Sigma}\\) the reproduced covariance matrix.’*"
  },
  {
    "objectID": "slides/01_path_models.html#model-fit-1",
    "href": "slides/01_path_models.html#model-fit-1",
    "title": "Models with observed variables",
    "section": "Model fit",
    "text": "Model fit\n\\[\nH_0 : \\hat{\\Sigma}(\\theta) = \\Sigma\n\\]\n\nIt’s time to evaluate whether our model is capable of it. To do it, we mainly compare the two matrices and obtain different fit indices."
  },
  {
    "objectID": "slides/01_path_models.html#fit-measures",
    "href": "slides/01_path_models.html#fit-measures",
    "title": "Models with observed variables",
    "section": "Fit measures",
    "text": "Fit measures\nModel fit refers to the ability of a model to reproduce the original covariance matrix. Fit indexes are the tools we use to estimate how good is our model in reproducing such mutrix. Most fit indexes only work with overidentified models, but some (e.g., the residualbased ones) can work with just-identified models, as well.\n\n\\(\\chi^2\\) based\nAlternative indexes\n\nIncremental indexes (or relative or comparative fit indexes)\nParsimony indexes\nAbsolute (Standalone) indexes\nResiduals"
  },
  {
    "objectID": "slides/01_path_models.html#chi2-based",
    "href": "slides/01_path_models.html#chi2-based",
    "title": "Models with observed variables",
    "section": "\\(\\chi^2\\) based",
    "text": "\\(\\chi^2\\) based\nA T statistics following \\(\\chi^2\\) distribution can be obtained by multiplying the sample size with the value of the fit function. df will be equal to the amount of non-redundant information minus the number of estimated parameters (remember?).  This is rarely used because of its assumptions - independent observations - the non-standardized sample cov matrix is used - N is sufficiently large - manifest endogenous variables follow a multivariate normal …and because it tends to reject \\(H_0\\), especially with large sample sizes.\n\nfitmeasures(fit,fit.measures=c(\"npar\", \"chisq\", \"df\", \"pvalue\"))\n\n  npar  chisq     df pvalue \n     9      0      0     NA"
  },
  {
    "objectID": "slides/01_path_models.html#comparative-indices",
    "href": "slides/01_path_models.html#comparative-indices",
    "title": "Models with observed variables",
    "section": "Comparative indices",
    "text": "Comparative indices\nThese include: - Comparative Fit Index (CFI) - Normed Fit Index (NFI) - Tucker Lewis Index (TLI) These indices compare the user model with a baseline model (the worst model).\n\nfitmeasures(fit, fit.measures =\nc(\"cfi\", \"tli\", \"nfi\"))\n\ncfi tli nfi \n  1   1   1"
  },
  {
    "objectID": "slides/01_path_models.html#baseline-model",
    "href": "slides/01_path_models.html#baseline-model",
    "title": "Models with observed variables",
    "section": "Baseline model",
    "text": "Baseline model\n\nbm &lt;- \"lifeSatisfaction ~~ lifeSatisfaction\n       selfEsteem ~~ selfEsteem\n       salary ~~ salary\n       parentalSupport ~~ parentalSupport\n       attachment ~~  attachment\"\nfitbm &lt;- sem(bm, data = E2)"
  },
  {
    "objectID": "slides/01_path_models.html#baseline-vs-user-model",
    "href": "slides/01_path_models.html#baseline-vs-user-model",
    "title": "Models with observed variables",
    "section": "Baseline vs user model",
    "text": "Baseline vs user model\n\n\n\n# summary(fitE2, fit.measures=TRUE)\n\n\n\nlavaan 0.6-19 ended normally after 10 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        10\n\n  Number of observations                           483\n\nModel Test User Model:\n                                                      \n  Test statistic                               114.172\n  Degrees of freedom                                 4\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                               276.610\n  Degrees of freedom                                10\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.587\n  Tucker-Lewis Index (TLI)                      -0.033\n\n[...]\n\n\n\n[ = ] [ = ]\nWith \\(\\delta\\) being the difference between \\(\\chi^2\\) and \\(df\\) and \\(\\delta(\\text{Saturated}) = 0\\)"
  },
  {
    "objectID": "slides/01_path_models.html#parsimony-indexes",
    "href": "slides/01_path_models.html#parsimony-indexes",
    "title": "Models with observed variables",
    "section": "Parsimony indexes",
    "text": "Parsimony indexes\nThese include: - Information Criteria (AIC, BIC, SABIC) - Noncentrality Parameter-Based Indexes (RNI, Mc/MFI) - RMSEA: Root Mean Square Error of Approximation These models favor parsimony and penalize complex models.  Among these, the RMSEA is probably the most used index. It assess how well the model approximate the data (as opposed to assessing if it is an exact fit). It is bounded between 0.0 and 1.0, with values closer to 0 (ZERO) indicating better fit.\n\nfitmeasures(fit, fit.measures =\nc(\"rmsea\", \"rmsea.ci.lower\", \"rmsea.ci.upper\", \"aic\", \"bic\"))\n\n         rmsea rmsea.ci.lower rmsea.ci.upper            aic            bic \n             0              0              0           6145           6190"
  },
  {
    "objectID": "slides/01_path_models.html#absolute-fit-indexes",
    "href": "slides/01_path_models.html#absolute-fit-indexes",
    "title": "Models with observed variables",
    "section": "Absolute fit indexes",
    "text": "Absolute fit indexes\nThese include: - \\(\\chi^2 / *df*\\) ratio - GFI: Goodness of Fit Index - AGFI: Adjusted Goodness of Fit Index - SRMR/RMR: (Standardized) Root Mean Square Residual GFI and AGFI want to be 1, while the SRMR wants to be 0!\n\nfitmeasures(fit,fit.measures=c(\"gfi\", \"agfi\", \"srmr\", \"rmr\"))\n\n gfi agfi srmr  rmr \n   1    1    0    0"
  },
  {
    "objectID": "slides/01_path_models.html#models-that-fit",
    "href": "slides/01_path_models.html#models-that-fit",
    "title": "Models with observed variables",
    "section": "Models that fit",
    "text": "Models that fit\nRemember that just because your model fits the data, doesn’t allow to conclude that your model is correct nor that the data generation process follows your hypothesized paths. - With path analysis, the same fit might be achieved with opposite arrows! - Test alternative models - Errors are included in manifest variables…and in the estimates! As usual all models are false, but some are useful."
  },
  {
    "objectID": "slides/01_path_models.html#what-about-our-model",
    "href": "slides/01_path_models.html#what-about-our-model",
    "title": "Models with observed variables",
    "section": "What about our model?",
    "text": "What about our model?\nIn Exercise 2 we fit a perfect model, all our hypotheses were confirmed, effects were significant with three stars.  We were happy…"
  },
  {
    "objectID": "slides/01_path_models.html#what-about-our-model-1",
    "href": "slides/01_path_models.html#what-about-our-model-1",
    "title": "Models with observed variables",
    "section": "What about our model?",
    "text": "What about our model?\nIn Exercise 2 we fit a perfect model, all our hypotheses were confirmed, effects were significant with three stars.  We were happy…"
  },
  {
    "objectID": "slides/01_path_models.html#step-5-model-modification",
    "href": "slides/01_path_models.html#step-5-model-modification",
    "title": "Models with observed variables",
    "section": "Step 5 model modification",
    "text": "Step 5 model modification\nUnfortunately, it’s time to modify the model or to accept that something was wrong in our hypotheses."
  },
  {
    "objectID": "slides/01_path_models.html#modification-indices",
    "href": "slides/01_path_models.html#modification-indices",
    "title": "Models with observed variables",
    "section": "Modification indices",
    "text": "Modification indices\nIf you have no clue about the reason why the model doesn’t converge, statistics could help you.\n\nmodificationindices(fitE2, sort. = T)[,1:7]\n\n                lhs op              rhs     mi    epc sepc.lv sepc.all\n14 lifeSatisfaction ~~       selfEsteem 63.000 -1.128  -1.128   -1.055\n27  parentalSupport  ~ lifeSatisfaction 62.255  0.337   0.337    0.412\n21 lifeSatisfaction  ~  parentalSupport 56.583  0.404   0.404    0.330\n16 lifeSatisfaction ~~  parentalSupport 56.583  0.358   0.358    0.361\n25       attachment  ~       selfEsteem 48.860  0.945   0.945    1.012\n29  parentalSupport  ~       attachment 48.570  0.296   0.296    0.317\n26       attachment  ~  parentalSupport 48.570  0.340   0.340    0.317\n19       attachment ~~  parentalSupport 48.570  0.301   0.301    0.317\n28  parentalSupport  ~       selfEsteem 48.473  2.032   2.032    2.332\n22       selfEsteem  ~ lifeSatisfaction 38.716 -0.670  -0.670   -0.715\n24       attachment  ~ lifeSatisfaction  9.730  0.136   0.136    0.155\n15 lifeSatisfaction ~~       attachment  5.275  0.112   0.112    0.105\n20 lifeSatisfaction  ~       attachment  5.275  0.110   0.110    0.097\n17       selfEsteem ~~       attachment  0.752  4.478   4.478    4.380\n23       selfEsteem  ~           salary  0.752  0.041   0.041    0.037\n31           salary  ~       selfEsteem  0.752  0.038   0.038    0.042\n30           salary  ~ lifeSatisfaction  0.752  0.103   0.103    0.120\n\n\nUse it with caution!\n\nm &lt;- \"\nlifeSatisfaction ~ .05*attachment + .25*selfEsteem + .40*parentalSupport + .30*salary\nselfEsteem ~ .40*parentalSupport + .20*attachment\nattachment ~~ .30*parentalSupport\n\""
  },
  {
    "objectID": "slides/01_path_models.html#mediation-analysis",
    "href": "slides/01_path_models.html#mediation-analysis",
    "title": "Models with observed variables",
    "section": "Mediation analysis",
    "text": "Mediation analysis\nWhile the independent variable is assumed to cause the outcome variable, it’s total effect (\\(c\\)) is partially/totally mediated by another intervening variable, the mediator variable.\n\nNote that our independent causes the mediator (\\(a\\)), and the mediator causes the outcome (\\(b\\)). The independent can still cause the outcome, but the path might have changed to \\(c'\\)."
  },
  {
    "objectID": "slides/01_path_models.html#total-effects",
    "href": "slides/01_path_models.html#total-effects",
    "title": "Models with observed variables",
    "section": "Total effects",
    "text": "Total effects\nWhen we have a mediation, the effect of the independent variable (X) on the outcome is given by the sum of the direct and indirect effect.\ntotal effect = direct effect + indirect effect  OR  c = c’ + ab\n\nm &lt;- \"\n# Regressions\nY ~ c*X + b*M\nM ~ a*X\n# Indirect effect\nindirect := a*b\n# Total effect\ntotal := c + a*b\n\"\n# Here of course we have no c'...to avoid R errors\n\nCOMMENTS?"
  },
  {
    "objectID": "slides/01_path_models.html#assumptions",
    "href": "slides/01_path_models.html#assumptions",
    "title": "Models with observed variables",
    "section": "Assumptions",
    "text": "Assumptions\nThe problem with mediation analyses is that they rely on often-neglected assumptions:\n\nNo X-M Interaction: The effect of M on Y or b does not vary across levels of X.\nCausal Direction: The variable M causes Y, but Y does not cause M.\nPerfect Reliability in M: The reliability of M is perfect.\nNo Confounding: There is no variable that causes M and Y."
  },
  {
    "objectID": "slides/01_path_models.html#other-limitations",
    "href": "slides/01_path_models.html#other-limitations",
    "title": "Models with observed variables",
    "section": "Other limitations",
    "text": "Other limitations\n\nFull mediation models are saturated models and we cannot obtain fit indices\n\nYou can use BIC, AIC, or SABIC and test (and compare) different models:\nno direct effect model\n\nno effect from causal variable to the mediator\nno effect from the mediator to outcome\nModels with inverted arrows fit the model as well as opposite models\n\nThis is true for all equivalent models. Avoid drawing paintings and base your models on strong theoretical assumptions!"
  },
  {
    "objectID": "slides/01_path_models.html#thinking-first",
    "href": "slides/01_path_models.html#thinking-first",
    "title": "Models with observed variables",
    "section": "Thinking first",
    "text": "Thinking first"
  },
  {
    "objectID": "slides/01_path_models.html#comparison",
    "href": "slides/01_path_models.html#comparison",
    "title": "Models with observed variables",
    "section": "Comparison",
    "text": "Comparison\n\n\n\n\n\n\n\n\n\n\n\n  cfi   tli  srmr rmsea \n0.976 0.853 0.031 0.094 \n\n\n\n\n\n\n\n\n\n\n\n  cfi   tli  srmr rmsea \n0.976 0.853 0.031 0.094 \n\n\n\n\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  math ~                                              \n    anxiety           0.350    0.050    6.979    0.000\n    sex               0.143    0.106    1.347    0.178\n    height            0.034    0.048    0.699    0.484\n  sex ~                                               \n    anxiety           0.075    0.024    3.092    0.002\n  height ~                                            \n    sex               0.984    0.091   10.807    0.000\n\n[...]\n\n\n\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  math ~                                              \n    anxiety           0.350    0.050    6.979    0.000\n    sex               0.143    0.106    1.347    0.178\n    height            0.034    0.048    0.699    0.484\n  anxiety ~                                           \n    sex               0.271    0.088    3.092    0.002\n  height ~                                            \n    sex               0.984    0.091   10.807    0.000\n\n[...]"
  },
  {
    "objectID": "slides/01_path_models.html#readings",
    "href": "slides/01_path_models.html#readings",
    "title": "Models with observed variables",
    "section": "Readings",
    "text": "Readings\nAbout mediation analyses, you can read: - the webpages by Dave Kenny: - - The history of mediations - Mediations explained and advanced topics - Roher et al. publication…but there’s a lot of information"
  },
  {
    "objectID": "slides/01_path_models.html#contacts",
    "href": "slides/01_path_models.html#contacts",
    "title": "Models with observed variables",
    "section": "Contacts",
    "text": "Contacts\ntommaso.feraco@unipd.it"
  },
  {
    "objectID": "slides/01_path_models.html#basic-lavaan-functions",
    "href": "slides/01_path_models.html#basic-lavaan-functions",
    "title": "Models with observed variables",
    "section": "Basic lavaan functions",
    "text": "Basic lavaan functions\n\n\n\n\n\n\n\nFunction\nCommand\n\n\n\n\nsem() / cfa()\nFit the SEM model (cfa is nested in sem…which is nested in lavaan)\n\n\nfitMeasures()\nReturn fit indices of the SEM model\n\n\ninspect()\nInspect/extract information that is stored in a fitted model\n\n\nlavPredict()\nCompute estimated latent scores\n\n\nlavTestLRT()\nCompare (nested) lavaan models\n\n\nmodificationIndices()\nCompute the modification indices of a model\n\n\nparameterEstimates()\nParameter estimates of a latent variable model\n\n\nparameterTable()\nShow the table of the parameters of a fitted model\n\n\nsimulateData()\nSimulate data starting from a lavaan model syntax"
  },
  {
    "objectID": "slides/02_cfa.html#outline",
    "href": "slides/02_cfa.html#outline",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Outline",
    "text": "Outline\n\nIntro\nCFA\nIdentification and fit\nCFA and validity - R\nExercise 3.2\nA neglected implication\nReadings"
  },
  {
    "objectID": "slides/02_cfa.html#factor-analysis",
    "href": "slides/02_cfa.html#factor-analysis",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Factor analysis",
    "text": "Factor analysis\n\nFactor analysis is a statistical technique widely used in the social sciences\nIt is a statistical method used to describe variability among observed, correlated variables in terms of a potentially lower number of unobserved variables called factors.\nIn its original definition (Spearman, 1904) the relationship between observed and latent variables is not defined a priori (Exploratory Factor Analysis, EFA).\nIn SEM framework, the researcher first develops a hypothesis about what factors s/he believes are underlying the measures s/he has used and may impose constraints on the model based on these a priori hypotheses (Confirmatory Factor Analysis, CFA)."
  },
  {
    "objectID": "slides/02_cfa.html#exploratory-factor-analysis-efa",
    "href": "slides/02_cfa.html#exploratory-factor-analysis-efa",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Exploratory Factor Analysis (EFA)",
    "text": "Exploratory Factor Analysis (EFA)\nYou can run an exploratory factor analysis in R using the in-built function factanal. (you can also do it in lavaan: efa())\n\n\n\n\n\nThe number of latent factor is not predetermined\nAll latent variables are free to influence all the observed variables\nMeasurement errors are not allowed to correlate\n\n\nIs this a good way to find latent variables? YOUR OPINION?"
  },
  {
    "objectID": "slides/02_cfa.html#confirmatory-factor-analysis-cfa",
    "href": "slides/02_cfa.html#confirmatory-factor-analysis-cfa",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Confirmatory Factor Analysis (CFA)",
    "text": "Confirmatory Factor Analysis (CFA)\nYou can run an CFA in R using the lavaan functions cfa.\n\n\n\n\n\nWe personally determine the model and the latent variables a priori\nLatent variables only affect predefined observed variables\nMeasurement errors may correlate\n\n\nIs this a good way to find latent variables? YOUR OPINION?"
  },
  {
    "objectID": "slides/02_cfa.html#general-formula",
    "href": "slides/02_cfa.html#general-formula",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "General formula",
    "text": "General formula\n\nThe general model for confirmatory factor analysis can be written as:\n\n\\[\n\\begin{aligned}\n\\mathbf{x} &= \\mathbf{\\Lambda}_x\\,\\mathbf{\\xi} + \\mathbf{\\delta} \\\\\n\\mathbf{y} &= \\mathbf{\\Lambda}_y\\,\\mathbf{\\eta} + \\mathbf{\\epsilon}\n\\end{aligned}\n\\]\nwhere \\(\\mathbf{x}\\) and \\(\\mathbf{y}\\) are observed variables, \\(\\mathbf{\\xi}\\) and \\(\\mathbf{\\eta}\\) are latent factors, and \\(\\mathbf{\\delta}\\) and \\(\\mathbf{\\epsilon}\\) are errors of measurement.\n\nThe coefficients in \\(\\mathbf{\\Lambda}_x\\) and \\(\\mathbf{\\Lambda}_y\\) describe the effects of the latent variables on the observed variables."
  },
  {
    "objectID": "slides/02_cfa.html#the-general-formula-explained",
    "href": "slides/02_cfa.html#the-general-formula-explained",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "The general formula explained",
    "text": "The general formula explained\n\\[\n\\begin{aligned}\ny &= b_0 + b_1 x + \\epsilon \\\\\ny_1 &= \\tau_1 + \\lambda_1\\eta + \\epsilon_1\n\\end{aligned}\n\\]\n\\[\n\\begin{bmatrix}\n  y_1 \\\\\n  y_2 \\\\\n  y_3\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n  \\tau_1 \\\\\n  \\tau_2 \\\\\n  \\tau_3\n\\end{bmatrix}\n+\n\\begin{bmatrix}\n  \\lambda_1 \\\\\n  \\lambda_2 \\\\\n  \\lambda_3\n\\end{bmatrix}\n(\\eta_1)\n\\begin{bmatrix}\n  \\epsilon_1 \\\\\n  \\epsilon_2 \\\\\n  \\epsilon_3\n\\end{bmatrix}\n\\]\n\\[\n\\begin{aligned}\ny_1 &= \\tau_1 + \\lambda_1\\eta_1 + \\epsilon_1 \\\\\ny_2 &= \\tau_2 + \\lambda_2\\eta_1 + \\epsilon_2 \\\\\ny_3 &= \\tau_3 + \\lambda_3\\eta_1 + \\epsilon_3\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/02_cfa.html#reflective-variables-in-a-realist-definition",
    "href": "slides/02_cfa.html#reflective-variables-in-a-realist-definition",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Reflective variables in a realist definition",
    "text": "Reflective variables in a realist definition\nWhen we talk about an effect \\(\\mathbf{\\Lambda}\\) (\\(\\Rightarrow\\)) of a latent variable on an observed variable (\\(\\mathbf{x}\\)), we are basing our model on a realist framework of reflective latent variables. In other words, we assume that:\n\nARROWS are ARROWS: it is the latent construct that affects the observed responses\nA realist interpretation is needed: the latent variable is something that really exists!\nObservations are things that are really affected/produced by the latent variable + some error\n\nPragmatic interpretation of latent variables are of no help: “a factor model is just a good way of summarizing a large number of items”."
  },
  {
    "objectID": "slides/02_cfa.html#reflective-variables-in-a-realist-definition-1",
    "href": "slides/02_cfa.html#reflective-variables-in-a-realist-definition-1",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Reflective variables in a realist definition",
    "text": "Reflective variables in a realist definition\nREMEMBER: every statistical method applied to psychology has theoretical implications that not only concerns the results obtained. The selected method/model has implication on its own, and CFA is no exception!\nIf you do not want to assume any realist position or reflective assumptions on your latent variables, you should adopt other methods of data reduction:\n\nPCA\nEGA\n…"
  },
  {
    "objectID": "slides/02_cfa.html#one-factor-model",
    "href": "slides/02_cfa.html#one-factor-model",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "One-factor model",
    "text": "One-factor model"
  },
  {
    "objectID": "slides/02_cfa.html#two-factor-model-with-correlated-variables",
    "href": "slides/02_cfa.html#two-factor-model-with-correlated-variables",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Two-factor model with correlated variables",
    "text": "Two-factor model with correlated variables"
  },
  {
    "objectID": "slides/02_cfa.html#two-factor-model-with-hortogonal-variables",
    "href": "slides/02_cfa.html#two-factor-model-with-hortogonal-variables",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Two-factor model with hortogonal variables",
    "text": "Two-factor model with hortogonal variables"
  },
  {
    "objectID": "slides/02_cfa.html#hierarchical-model",
    "href": "slides/02_cfa.html#hierarchical-model",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Hierarchical model",
    "text": "Hierarchical model"
  },
  {
    "objectID": "slides/02_cfa.html#in-r",
    "href": "slides/02_cfa.html#in-r",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "In R",
    "text": "In R\n\n\n\nm &lt;- \"\nlatent1 =~ x1 + x2 + x3 \nlatent2 =~ x4 + x5 + x6\n\"\nsemPlot::semPaths(fit)\n\n\n\n\n\n\n\n\n\n\nThe first latent variable explains item 1,2,3\nThe second latent variable explains item 4,5,6\nThe diagram represents the hypothesized model"
  },
  {
    "objectID": "slides/02_cfa.html#matrices",
    "href": "slides/02_cfa.html#matrices",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Matrices",
    "text": "Matrices\n\n\nLambda: matrix of loadings\n\n\nPhi: latent variance-covariance matrix\n\n\nTheta: observed variance-covariance matrix"
  },
  {
    "objectID": "slides/02_cfa.html#constraints",
    "href": "slides/02_cfa.html#constraints",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Constraints",
    "text": "Constraints\nIn order to estimate the parameters in structural equation models with latent variables, you must set some identification constraints in these models. Otherwise, you won’t be able to estimate the variables (the model is not identifiable).\nWe can choose one of the two following strategies:\n\nTo standardize latent variables such that factor means are fixed to 0 and factor variances are fixed to 1.\nTo set to one a loading (\\(\\lambda\\)) for each latent variable.\n\nIn R, the function sem() or cfa() uses the second strategy as default. To change it, use the std.lv option to TRUE.\n\nfit &lt;- sem(m, std.lv = TRUE, ...)"
  },
  {
    "objectID": "slides/02_cfa.html#constraints-explained",
    "href": "slides/02_cfa.html#constraints-explained",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Constraints explained",
    "text": "Constraints explained\n\n\n\\[\n\\Sigma(\\eta) = \\Lambda\\Psi\\Lambda' + \\Theta_{\\epsilon}\n\\]\nMarker method\n\\[\n\\Sigma(\\eta)\n=\n\\psi_{11}\n\\begin{bmatrix}\n  1 \\\\\n  \\lambda_2 \\\\\n  \\lambda_3\n\\end{bmatrix}\n(1\\,\\lambda_2\\,\\lambda_3)\n\\begin{bmatrix}\n  \\theta_{11} & 0 & 0 \\\\\n  0 & \\theta_{22} & 0 \\\\\n  0 & 0 & \\theta_{33}\n\\end{bmatrix}\n\\]\nStandardization\n\\[\n\\Sigma(\\eta)\n=\n(1)\n\\begin{bmatrix}\n  \\lambda_1 \\\\\n  \\lambda_2 \\\\\n  \\lambda_3\n\\end{bmatrix}\n(\\lambda_1\\,\\lambda_2\\,\\lambda_3)\n\\begin{bmatrix}\n  \\theta_{11} & 0 & 0 \\\\\n  0 & \\theta_{22} & 0 \\\\\n  0 & 0 & \\theta_{33}\n\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "slides/02_cfa.html#identification-rules",
    "href": "slides/02_cfa.html#identification-rules",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Identification rules",
    "text": "Identification rules\nIf you remember, we talked about identification in the Introduction. For CFA models, the following identification rules can be followed:\n\nthe t-rule\nthe Three-Indicator Rules\nthe Two-Indicator Rules"
  },
  {
    "objectID": "slides/02_cfa.html#the-t-rule",
    "href": "slides/02_cfa.html#the-t-rule",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "the t-rule",
    "text": "the t-rule\nWe have already seen it. This is a necessary but not sufficient condition:\n\\[\nt \\leq \\frac{q(q+1)}{2}\n\\]\nwhere \\(t\\) is the number of free parameters and \\(q\\) the number of observed variables.\nIn this case:\n\nThe number of free parameters (\\(t\\)) must be less or equal to the number of nonredundant elements in the covariance matrix of the observed variables\n\nIn other words: the number of nonredundant elements in \\(\\mathbf{S}\\) is the maximum number of possible equations; if the number of unknowns exceeds the number of equations, the identification of \\(\\mathbf{\\theta}\\) is not possible."
  },
  {
    "objectID": "slides/02_cfa.html#the-three-indicator-rules",
    "href": "slides/02_cfa.html#the-three-indicator-rules",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "the Three-Indicator Rules",
    "text": "the Three-Indicator Rules\nThe three-indicatore rules is a sufficient but not necessary condition. It poses no restrictions on \\(\\mathbf{\\Phi}\\) (the var-covar of exogenous latent variables)\n\nA sufficient condition to identify a one-factor model is to have at least three indicators with nonzero loadings (\\(\\lambda\\)) and \\(\\mathbf{\\Theta}\\) diagonal.\nA multifactor model is identified when:\n\nIt has three or more indicators per latent variable.\nEach row of \\(\\mathbf{\\Lambda}\\) has one and only one nonzero element.\n\\(\\mathbf{\\Theta}\\) is diagonal."
  },
  {
    "objectID": "slides/02_cfa.html#the-two-indicator-rules",
    "href": "slides/02_cfa.html#the-two-indicator-rules",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "the Two-Indicator Rules",
    "text": "the Two-Indicator Rules\nThe two-indicatore rules is a sufficient but not necessary condition for models with more than one \\(\\mathbf{\\xi}\\).\n\n\\(\\mathbf{\\Theta}\\) is diagonal\nEach latent variable is scaled (one \\(\\lambda_{ij}\\) set to 1 for each \\(\\mathbf{\\xi}\\)).\nIt requires the following conditions:\n\nThere are at least two indicators per latent variable\nEach row of \\(\\mathbf{\\Lambda}\\) has one and only one nonzero element\n\\(\\mathbf{\\Theta}\\) is diagonal\nEach row of \\(\\mathbf{\\Phi}\\) has at least one nonzero off-diagonal element"
  },
  {
    "objectID": "slides/02_cfa.html#model-fit",
    "href": "slides/02_cfa.html#model-fit",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Model fit",
    "text": "Model fit\nAs before, we can evaluate model fit of a CFA using:\n\n\\(\\chi^2\\) test\n\n\nAbsolute fit indices\n\n\ninspect(fit, \"fit\")[c(\"gfi\", \"agfi\")]\n\n\nAbsolute fit indices based on residuals\n\n\ninspect(fit, \"fit\")[c(\"srmr\", \"rmsea\")]\n\n\nIncremental fit indices\n\n\ninspect(fit, \"fit\")[c(\"cfi\", \"nnfi\")]\n\n\nInformation criterion based indices\n\n\ninspect(fit, \"fit\")[c(\"aic\", \"bic\")]\n\n\n\\(R^2\\) and the total coefficient of determination\n\n\ninspect(fit, \"rsquare\")"
  },
  {
    "objectID": "slides/02_cfa.html#the-total-coefficient-of-determination",
    "href": "slides/02_cfa.html#the-total-coefficient-of-determination",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "The total coefficient of determination",
    "text": "The total coefficient of determination\nWhile \\(R^2\\) gives the portion of explained variance in single dependent variables\n\ninspect(fit, \"rsquare\")\n\n  x1   x2   x3   x4   x5   x6 \n0.27 0.46 0.32 0.31 0.40 0.29 \n\n\n… the total coefficient of determination represents the proportion of variance in the dependent variables that is explained by all the variables in the model, both directly and indirectly.\n\nTH &lt;- inspect(fit, \"estimates\")$theta\nS &lt;- fitted(fit)$cov\n1 - det(TH) / det(S)\n\n[1] 0.85"
  },
  {
    "objectID": "slides/02_cfa.html#introduction-to-cfa-and-validity",
    "href": "slides/02_cfa.html#introduction-to-cfa-and-validity",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Introduction to CFA and validity",
    "text": "Introduction to CFA and validity\nWhenever we estimate a latent variable, we are MEASURING a latent trait that explains observed (or other latent) factors.\nIn other words, CFA is a tool that is used to measure constructs that are not directly observable (remember the realist framework)."
  },
  {
    "objectID": "slides/02_cfa.html#step-1-the-construct",
    "href": "slides/02_cfa.html#step-1-the-construct",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Step 1: the construct",
    "text": "Step 1: the construct\n… this is not the topic of this course but, after theoretical reflections, answer at least these questions that will guide your modeling and draw it:\n\n\n\nis it unidimensional?\nis it multidimensional?\nare the factors correlated?\nis it hierarchic?\nhas it a bifactor structure?\n\nAll these answers have statistical and theoretical consequences / assumptions."
  },
  {
    "objectID": "slides/02_cfa.html#step-2-items-and-scale-construction",
    "href": "slides/02_cfa.html#step-2-items-and-scale-construction",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Step 2: items and scale construction",
    "text": "Step 2: items and scale construction\nAssuming that the construct exists, you need\n\nan explicit, precise definition of the measured attribute or construct\na set of items sensible to variations of the measured attribute or construct\n\nIn fact, we assume that the observations (item responses) should change according to modifications of the latent trait.\nItems should (possibly) cover all the aspects of the construct.\nTo help your work, there are tools that can be used:\n\nSpoto et al., 2023 https://doi.org/10.1037/met0000545\n\nthis of course happens if the questionnaire/test is new (or if you want to develop a new version)"
  },
  {
    "objectID": "slides/02_cfa.html#step-3-collect-the-data",
    "href": "slides/02_cfa.html#step-3-collect-the-data",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Step 3: collect the data!",
    "text": "Step 3: collect the data!\nData collection is not obvious and follows your previous decisions. We might plan:\n\n2 data collections (cfa measurement + nomological network)\n3 data collections (efa + cfa + nomological network)\nfocus groups + pilot on item comprension + […]\n[…]\n[…]"
  },
  {
    "objectID": "slides/02_cfa.html#step-4-data-analysis-cfa-only",
    "href": "slides/02_cfa.html#step-4-data-analysis-cfa-only",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Step 4: data analysis (CFA only)",
    "text": "Step 4: data analysis (CFA only)\nOf all the possible options, we will only focus on the CFA.\nImagine we have collected data for 862 participants using the WISC-IV, one of the most famous tests of intelligence. It comprises 15 subtests measuring:\n\n\n\nVCI: verbal comprehension ind\nSI: Similarities\nVC: Vocabulary\nCO: Comprehension\nWMI: working memory index\nDS: Digit span\nLN: Letter-Number seq.\n\n\n\nPRI: perceptual reasoning index\nBD: Block design\nPCn: Picture concepts\nMR: Matrix reasoning\nPSI: processing speed index\nCD: Coding\nSS: Symbol search\n\n\nThe subtests are assumed to belong to specific abilities (bold), that are influenced by a general factor: we have a hierarchical structure."
  },
  {
    "objectID": "slides/02_cfa.html#open-the-data",
    "href": "slides/02_cfa.html#open-the-data",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Open the data",
    "text": "Open the data\nOps, the data are not in standard form!\n\n# Exercise 3.1\nload(\"../data/Exercise3_1.Rdata\")\n# view(d)\n\n\n\n\n\n\nBD\nSI\nDS\nPCn\nCD\nVC\nLN\nMR\nCO\nSS\n\n\n\n\n1.00\n0.38\n0.26\n0.34\n0.25\n0.33\n0.29\n0.42\n0.27\n0.30\n\n\n0.38\n1.00\n0.35\n0.43\n0.14\n0.62\n0.35\n0.41\n0.51\n0.27\n\n\n0.26\n0.35\n1.00\n0.28\n0.15\n0.33\n0.42\n0.29\n0.24\n0.20\n\n\n0.34\n0.43\n0.28\n1.00\n0.11\n0.41\n0.35\n0.43\n0.35\n0.24\n\n\n0.25\n0.14\n0.15\n0.11\n1.00\n0.13\n0.19\n0.20\n0.15\n0.46\n\n\n0.33\n0.62\n0.33\n0.41\n0.13\n1.00\n0.38\n0.40\n0.59\n0.24\n\n\n0.29\n0.35\n0.42\n0.35\n0.19\n0.38\n1.00\n0.35\n0.30\n0.24\n\n\n0.42\n0.41\n0.29\n0.43\n0.20\n0.40\n0.35\n1.00\n0.30\n0.26\n\n\n0.27\n0.51\n0.24\n0.35\n0.15\n0.59\n0.30\n0.30\n1.00\n0.22\n\n\n0.30\n0.27\n0.20\n0.24\n0.46\n0.24\n0.24\n0.26\n0.22\n1.00"
  },
  {
    "objectID": "slides/02_cfa.html#the-theoretical-model",
    "href": "slides/02_cfa.html#the-theoretical-model",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "The theoretical model",
    "text": "The theoretical model\nIntelligence theory suppose that test scores are affected by specific abilities (e.g., processing speed), that are directly influenced by an overarching latent factor (g)\n\nTry to write the model"
  },
  {
    "objectID": "slides/02_cfa.html#specify-and-fit-the-mode",
    "href": "slides/02_cfa.html#specify-and-fit-the-mode",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Specify and fit the mode",
    "text": "Specify and fit the mode\nWe are skipping some steps (validity of single tests and of first-order abilities) … you cannot do it!\n\nm &lt;- \"\nVCI=~SI+VC+CO\nPRI=~BD+PCn+MR\nWMI=~DS+LN\nPSI=~CD+SS\ng=~VCI+PRI+WMI+PSI\n\"\nfit &lt;- sem(m, std.lv = TRUE, sample.cov = d, sample.nobs = N)"
  },
  {
    "objectID": "slides/02_cfa.html#model-parameters",
    "href": "slides/02_cfa.html#model-parameters",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Model parameters",
    "text": "Model parameters\n\nparameterestimates(fit, standardized = TRUE)[1:14, 1:11]\n\n   lhs op rhs  est    se    z pvalue ci.lower ci.upper std.lv std.all\n1  VCI =~  SI 0.46 0.032 14.4  0.000    0.394     0.52   0.77    0.77\n2  VCI =~  VC 0.48 0.033 14.5  0.000    0.419     0.55   0.82    0.82\n3  VCI =~  CO 0.41 0.030 13.6  0.000    0.348     0.46   0.68    0.69\n4  PRI =~  BD 0.19 0.052  3.6  0.000    0.087     0.29   0.58    0.59\n5  PRI =~ PCn 0.21 0.057  3.6  0.000    0.095     0.32   0.64    0.64\n6  PRI =~  MR 0.22 0.060  3.6  0.000    0.100     0.33   0.67    0.67\n7  WMI =~  DS 0.36 0.038  9.5  0.000    0.284     0.43   0.60    0.60\n8  WMI =~  LN 0.42 0.045  9.2  0.000    0.327     0.50   0.70    0.70\n9  PSI =~  CD 0.48 0.037 12.9  0.000    0.405     0.55   0.55    0.55\n10 PSI =~  SS 0.71 0.059 12.1  0.000    0.599     0.83   0.83    0.83\n11   g =~ VCI 1.36 0.129 10.5  0.000    1.107     1.61   0.80    0.80\n12   g =~ PRI 2.92 0.865  3.4  0.001    1.220     4.61   0.95    0.95\n13   g =~ WMI 1.35 0.171  7.9  0.000    1.013     1.68   0.80    0.80\n14   g =~ PSI 0.59 0.067  8.8  0.000    0.457     0.72   0.51    0.51\n\n# [...]"
  },
  {
    "objectID": "slides/02_cfa.html#model-parameters-1",
    "href": "slides/02_cfa.html#model-parameters-1",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Model parameters",
    "text": "Model parameters\n\n# [...]\nparameterestimates(fit, standardized = TRUE)[15:20, 1:11]\n\n   lhs op rhs  est    se  z pvalue ci.lower ci.upper std.lv std.all\n15  SI ~~  SI 0.40 0.028 14      0     0.35     0.46   0.40    0.41\n16  VC ~~  VC 0.33 0.027 12      0     0.28     0.38   0.33    0.33\n17  CO ~~  CO 0.53 0.031 17      0     0.47     0.59   0.53    0.53\n18  BD ~~  BD 0.66 0.037 18      0     0.58     0.73   0.66    0.66\n19 PCn ~~ PCn 0.59 0.036 16      0     0.52     0.66   0.59    0.59\n20  MR ~~  MR 0.55 0.035 16      0     0.48     0.62   0.55    0.55"
  },
  {
    "objectID": "slides/02_cfa.html#model-fit-1",
    "href": "slides/02_cfa.html#model-fit-1",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Model fit",
    "text": "Model fit\n\nfi &lt;- c(\"cfi\", \"tli\", \"nnfi\", \"agfi\", \"srmr\", \"rmsea\")\nround(inspect(fit, \"fit\")[fi], 3)\n\n  cfi   tli  nnfi  agfi  srmr rmsea \n0.985 0.978 0.978 0.973 0.028 0.037"
  },
  {
    "objectID": "slides/02_cfa.html#reliability",
    "href": "slides/02_cfa.html#reliability",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Reliability",
    "text": "Reliability\n\nsemTools::reliability(fit)\n\n        VCI  PRI  WMI  PSI\nalpha  0.80 0.66 0.59 0.63\nomega  0.80 0.67 0.59 0.66\nomega2 0.80 0.67 0.59 0.66\nomega3 0.80 0.67 0.59 0.66\navevar 0.58 0.40 0.42 0.50\n\n\n\nsemTools::reliabilityL2(fit, secondFactor = \"g\")\n\n       omegaL1        omegaL2 partialOmegaL1 \n          0.75           0.91           0.85"
  },
  {
    "objectID": "slides/02_cfa.html#graphical-representation",
    "href": "slides/02_cfa.html#graphical-representation",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Graphical representation",
    "text": "Graphical representation\n\nsemPlot::semPaths(\n  fit,\n  edge.label.cex = .8,\n  what = \"std\",\n  sizeMan = 7,\n  sizeLat = 7,\n  edge.color = \"black\",\n  edge.label.color = \"black\"\n)"
  },
  {
    "objectID": "slides/02_cfa.html#a-second-theoretical-model",
    "href": "slides/02_cfa.html#a-second-theoretical-model",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "A second theoretical model",
    "text": "A second theoretical model\nParallel theories of intelligence suppose that test scores are affected by a general factor (g) AND by specific abilities that explain the remaining variance. Both type of factors directly influence observed scores.\nAll factors are set to be orthogonal!"
  },
  {
    "objectID": "slides/02_cfa.html#bifactor-model-in-r",
    "href": "slides/02_cfa.html#bifactor-model-in-r",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Bifactor model in R",
    "text": "Bifactor model in R\n\n# Modello bifattoriale\nmb &lt;- \"\nVCI=~a*SI+a*VC+a*CO\nPRI=~b*BD+b*PCn+b*MR\nWMI=~c*DS+c*LN\nPSI=~d*CD+d*SS\ng=~SI+VC+CO+BD+PCn+MR+DS+LN+CD+SS\n\"\n\nfitb &lt;- sem(\n  mb,\n  orthogonal = TRUE,\n  std.lv = TRUE,\n  sample.cov = d,\n  sample.nobs = N\n)\n\nThis model fits the data like the previous one.\nCOMMENTS? QUESTIONS?"
  },
  {
    "objectID": "slides/02_cfa.html#exercise-3.2",
    "href": "slides/02_cfa.html#exercise-3.2",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Exercise 3.2",
    "text": "Exercise 3.2\n\n# 2. Exercise 3.2 - working with real data and Likert scales\n# The dataset contains data collected from 1083 students on one questionnaire\n# The questionnaire aims to measure adaptability with 9 items on a 7-point scale\n# The first column is just the student's id\nD.ad &lt;- read.csv(\"../data/Exercise3_2.csv\")\n\n# We want to test the factorial validity of the Italian questionnaire\n# Martin et al., 2012 hypothesize three subscales:\n# (behavior [1:3], cognition [4:6], and emotion[7:9])\n# But found 1 or 2 factors in an EFA:\n# (cognitive-bahavioral [1:6] AND affective [7:9])\n# Later, they tested these models with a CFA\n# Test the two models, compare them and make your decisions"
  },
  {
    "objectID": "slides/02_cfa.html#predictions-with-latent-variables",
    "href": "slides/02_cfa.html#predictions-with-latent-variables",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Predictions with latent variables",
    "text": "Predictions with latent variables\nThis will directly bring us to the next set of slides, but some questions before:\n\nCan we use a latent variable to ‘predict’ another variable?"
  },
  {
    "objectID": "slides/02_cfa.html#predictions-with-latent-variables-1",
    "href": "slides/02_cfa.html#predictions-with-latent-variables-1",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Predictions with latent variables",
    "text": "Predictions with latent variables\nThis will directly bring us to the next set of slides, but some questions before:\n\nCan we use a latent variable to ‘predict’ another variable?\nHow (in R)?"
  },
  {
    "objectID": "slides/02_cfa.html#predictions-with-latent-variables-2",
    "href": "slides/02_cfa.html#predictions-with-latent-variables-2",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Predictions with latent variables",
    "text": "Predictions with latent variables\nThis will directly bring us to the next set of slides, but some questions before:\n\nCan we use a latent variable to ‘predict’ another variable?\nHow (in R)?\nAfter we confirm that a latent variable ‘exists’, can we use manifest variables as predictors?\n\nLET'S SIMULATE"
  },
  {
    "objectID": "slides/02_cfa.html#predictions-with-latent-variables-3",
    "href": "slides/02_cfa.html#predictions-with-latent-variables-3",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Predictions with latent variables",
    "text": "Predictions with latent variables\nThis will directly bring us to the next set of slides, but some questions before:\n\nCan we use a latent variable to ‘predict’ another variable?\nHow (in R)?\nAfter we confirm that a latent variable ‘exists’, can we use manifest variables as predictors?\nCan we use residuals as predictors?"
  },
  {
    "objectID": "slides/02_cfa.html#suggested-readings",
    "href": "slides/02_cfa.html#suggested-readings",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Suggested readings",
    "text": "Suggested readings\n\nBest practices for scale development: https://doi.org/10.3389/fpubh.2018.00149\nContent validity: https://doi.org/10.1037/met0000545\n(as always) Latent Variable Modeling Using R: A Step-by-Step Guide (Beaujean, 2014)"
  },
  {
    "objectID": "slides/02_cfa.html#references",
    "href": "slides/02_cfa.html#references",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "slides/03_sem.html#outline",
    "href": "slides/03_sem.html#outline",
    "title": "Structural Equation Models",
    "section": "Outline",
    "text": "Outline\n\nIntroduction\nIdentification\nExample\nExercise\nResults"
  },
  {
    "objectID": "slides/03_sem.html#structural-equation-models",
    "href": "slides/03_sem.html#structural-equation-models",
    "title": "Structural Equation Models",
    "section": "Structural equation models",
    "text": "Structural equation models\nUp to now, we have seen how to model the relationship between different variables/constructs at the same time (path analysis) and how to build a measurement model with one or more latent variables.\nA complete SEM takes both of these things and put them together"
  },
  {
    "objectID": "slides/03_sem.html#the-two-parts-of-a-sem",
    "href": "slides/03_sem.html#the-two-parts-of-a-sem",
    "title": "Structural Equation Models",
    "section": "The two parts of a SEM",
    "text": "The two parts of a SEM\n\nThe measurement model \\[\n\\begin{aligned}\nx = \\Lambda_x\\xi + \\delta\ny =\\Lambda_y\\eta + \\epsilon\n\\end{aligned}\n\\]\nThe structural model \\[\n\\begin{aligned}\n\\eta = B\\eta + \\Gamma\\xi + \\zeta\n\\end{aligned}\n\\]\n\nalready seen in the first slides"
  },
  {
    "objectID": "slides/03_sem.html#matrices",
    "href": "slides/03_sem.html#matrices",
    "title": "Structural Equation Models",
    "section": "Matrices",
    "text": "Matrices\nThese models (can) have all the possible matrices: - Loadings and coefficients matrices \\[\n\\begin{aligned}\n\\Lambda^x &  - relation among  \\xi  and  x\n    \\Lambda^y &  - relation among  \\eta  and  y\n    B &  - relation among  \\eta  and  \\eta\n    \\Gamma &  - relation among  \\xi  and  \\eta\n\\end{aligned}\n\\] - Covariance matrices \\[\n\\begin{aligned}\n\\Theta^\\delta &  -  x  errors\n    \\Theta^\\epsilon &  -  y  errors\n    \\Psi &  -  \\eta  errors\n    \\Phi &  - relations among  \\eta\n\\end{aligned}\n\\] Different models are allowew based on the way we define relationships among variables"
  },
  {
    "objectID": "slides/03_sem.html#lavaan-matrices",
    "href": "slides/03_sem.html#lavaan-matrices",
    "title": "Structural Equation Models",
    "section": "… lavaan matrices",
    "text": "… lavaan matrices\nlavaan does not distinguish between endogenous and exogenous variables. This leads to an easier parametrization and to four matrices only: 1. \\(\\Lambda\\) factor loadings matrix \\([p x m]\\) 1. \\(\\Theta\\) measurement residual errors covariance matrix \\([p x p]\\) 1. \\(B\\) regression coefficients matrix \\([m x m]\\) 1. \\(\\Psi\\) residual structural errors covariance matrix \\([m x m]\\) With p being the number of manifest variables and m being the number of latent variables."
  },
  {
    "objectID": "slides/03_sem.html#the-lavaan-matrices",
    "href": "slides/03_sem.html#the-lavaan-matrices",
    "title": "Structural Equation Models",
    "section": "The lavaan matrices",
    "text": "The lavaan matrices\n{Lambda: matrix of loadings}\n\n{Beta: regression coefficients}\n\n{Psi: residual structural errors matrix}\n\n{Theta: observed variance-covariance matrix}"
  },
  {
    "objectID": "slides/03_sem.html#a-sem-example---simulation",
    "href": "slides/03_sem.html#a-sem-example---simulation",
    "title": "Structural Equation Models",
    "section": "A SEM example - simulation",
    "text": "A SEM example - simulation\n\nlibrary(lavaan)\ndSEM &lt;- simulateData(\"xi =~ .74*x1 + .65*x2\n                      eta =~ .56*y1 + .75*y2\n                      eta ~ .30*xi\n                     \", sample.nobs = 1000)"
  },
  {
    "objectID": "slides/03_sem.html#a-sem-example---specification-and-constraints",
    "href": "slides/03_sem.html#a-sem-example---specification-and-constraints",
    "title": "Structural Equation Models",
    "section": "A SEM example - specification and constraints",
    "text": "A SEM example - specification and constraints\n\nfit &lt;- sem(model = \"xi =~ x1 + x2\n                     eta =~ y1 + y2\n                     eta ~ xi\", data = dSEM)\n\nConstraints\nTo estimate the model we need to set constraints: - the sem or cfa functions default is setting to 1 one loading for each latent variable - an alternative is to standardized latent variables using the std.lv = TRUE option"
  },
  {
    "objectID": "slides/03_sem.html#constraints-default",
    "href": "slides/03_sem.html#constraints-default",
    "title": "Structural Equation Models",
    "section": "Constraints: default",
    "text": "Constraints: default\n\n\n[...]\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  xi =~                                                                 \n    x1                1.000                               0.769    0.644\n    x2                0.728    0.296    2.464    0.014    0.560    0.476\n  eta =~                                                                \n    y1                1.000                               0.630    0.548\n    y2                1.227    0.459    2.672    0.008    0.773    0.595\n\n[...]\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .x1                0.835    0.243    3.440    0.001    0.835    0.586\n   .x2                1.070    0.136    7.865    0.000    1.070    0.773\n   .y1                0.923    0.154    5.986    0.000    0.923    0.699\n   .y2                1.092    0.229    4.766    0.000    1.092    0.646\n    xi                0.591    0.245    2.409    0.016    1.000    1.000\n   .eta               0.373    0.145    2.574    0.010    0.941    0.941\n\n[...]"
  },
  {
    "objectID": "slides/03_sem.html#constraints-std.lvt",
    "href": "slides/03_sem.html#constraints-std.lvt",
    "title": "Structural Equation Models",
    "section": "Constraints: std.lv=T",
    "text": "Constraints: std.lv=T\n\n\n[...]\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  xi =~                                                                 \n    x1                0.769    0.160    4.818    0.000    0.769    0.644\n    x2                0.560    0.119    4.710    0.000    0.560    0.476\n  eta =~                                                                \n    y1                0.611    0.119    5.148    0.000    0.630    0.548\n    y2                0.750    0.147    5.113    0.000    0.773    0.595\n\n[...]\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .x1                0.835    0.243    3.440    0.001    0.835    0.586\n   .x2                1.070    0.136    7.865    0.000    1.070    0.773\n   .y1                0.923    0.154    5.986    0.000    0.923    0.699\n   .y2                1.092    0.229    4.766    0.000    1.092    0.646\n    xi                1.000                               1.000    1.000\n   .eta               1.000                               0.941    0.941\n\n[...]"
  },
  {
    "objectID": "slides/03_sem.html#lavaan-matrices-1",
    "href": "slides/03_sem.html#lavaan-matrices-1",
    "title": "Structural Equation Models",
    "section": "lavaan matrices",
    "text": "lavaan matrices\n\ninspect(fit, \"std\") # OR \"est\"\n\n\n\n$lambda\n     xi  eta\nx1 0.64 0.00\nx2 0.48 0.00\ny1 0.00 0.55\ny2 0.00 0.59\n\n$theta\n     x1   x2   y1   y2\nx1 0.59               \nx2 0.00 0.77          \ny1 0.00 0.00 0.70     \ny2 0.00 0.00 0.00 0.65\n\n\n\n\n$psi\n      xi  eta\nxi  1.00     \neta 0.00 0.94\n\n$beta\n      xi eta\nxi  0.00   0\neta 0.24   0"
  },
  {
    "objectID": "slides/03_sem.html#sem-identification",
    "href": "slides/03_sem.html#sem-identification",
    "title": "Structural Equation Models",
    "section": "SEM identification",
    "text": "SEM identification\nOnce again, remember that identification is a topic relevant to all structural equation models.\nIf an unknown parameter in \\(\\theta\\) can be written as a function of one or more elements of \\(\\Sigma\\), that parameter is identified.\nIf all unknown parameters in \\(\\theta\\) are identified, the model is identified. - the t-rule (again) - the Two-Steps rule"
  },
  {
    "objectID": "slides/03_sem.html#two-steps-rule",
    "href": "slides/03_sem.html#two-steps-rule",
    "title": "Structural Equation Models",
    "section": "Two-Steps rule",
    "text": "Two-Steps rule\n\nStep 1. Treat the model as a confirmatory factor analysis: view the original \\(x\\) and \\(y\\) as \\(x\\) variables and the original \\(\\xi\\) and \\(\\eta\\) as \\(\\xi\\) variables. The only relationship between latent variables of interest are their variance and covariance \\(Phi\\). That is, ignore the \\(B\\), \\(\\Gamma\\), and \\(\\Psi\\) elements.\n\\(\\rightarrow\\) apply CFA identification rules\nStep 2. Examine the latent variable equation of the original model (\\(\\eta = B\\eta + \\Gamma\\xi + \\zeta\\)), assuming that each latent variable is an observed variable that is perfectly measured."
  },
  {
    "objectID": "slides/03_sem.html#two-steps-rule-1",
    "href": "slides/03_sem.html#two-steps-rule-1",
    "title": "Structural Equation Models",
    "section": "Two-Steps rule",
    "text": "Two-Steps rule\nSummary\nIf the first step shows that the measurement parameters are identified and the second step shows that the latent variable model parameters also are identified, then this is suficient to identify the whole model."
  },
  {
    "objectID": "slides/03_sem.html#political-democracy-dataset",
    "href": "slides/03_sem.html#political-democracy-dataset",
    "title": "Structural Equation Models",
    "section": "Political democracy dataset",
    "text": "Political democracy dataset\nBollen (1989) studied the relation between industrialization in 1960 and political democracy of developing countries in 1960 and 1965.\nWe have 11 variables\n\n\n   y1  y2   y3  y4  y5  y6   y7   y8  x1  x2  x3\n1 2.5 0.0  3.3 0.0 1.2 0.0  3.7 3.33 4.4 3.6 2.6\n2 1.2 0.0  3.3 0.0 6.2 1.1  6.7 0.74 5.4 5.1 3.6\n3 7.5 8.8 10.0 9.2 8.8 8.1 10.0 8.21 6.0 6.3 5.2\n\n\nA first latent variable, Industrialization (\\(I = x_1 + x_2 + x_3\\))\nA second latent variable, political democracy in 1960 (\\(D60 = y_1 + y_2 + y_3 + y_4\\))\nA third latent variable, political democracy in 1965 (\\(D65 = y_5 + y_6 + y_7 + y_8\\)).\nLET'S APLLY THE TWO-STEPS RULE"
  },
  {
    "objectID": "slides/03_sem.html#step-1---model-plot",
    "href": "slides/03_sem.html#step-1---model-plot",
    "title": "Structural Equation Models",
    "section": "Step 1 - model plot",
    "text": "Step 1 - model plot\nThe CFA model"
  },
  {
    "objectID": "slides/03_sem.html#step-1---model-specification-and-results",
    "href": "slides/03_sem.html#step-1---model-specification-and-results",
    "title": "Structural Equation Models",
    "section": "Step 1 - model specification and results",
    "text": "Step 1 - model specification and results\nThe CFA model\n\nm &lt;- \"I =~ x1 + x2 + x3\nD60 =~ y1 + y2 + y3 + y4\nD65 =~ y5 + y6 + y7 + y8\n\"\n\n\nfit1 &lt;- sem(m, data = PoliticalDemocracy)\nfit1@Fit@converged\n\n[1] TRUE\n\n\nPARAMETERS ARE ALL IDENTIFIED. LET'S GO TO STEP 2"
  },
  {
    "objectID": "slides/03_sem.html#step-2---model-plot",
    "href": "slides/03_sem.html#step-2---model-plot",
    "title": "Structural Equation Models",
    "section": "Step 2 - model plot",
    "text": "Step 2 - model plot\nThe structural model"
  },
  {
    "objectID": "slides/03_sem.html#step-2---model-specification-and-results",
    "href": "slides/03_sem.html#step-2---model-specification-and-results",
    "title": "Structural Equation Models",
    "section": "Step 2 - model specification and results",
    "text": "Step 2 - model specification and results\nThe structural model\n\nm2 &lt;- \"I =~ x1 + x2 + x3\nD60 =~ y1 + y2 + y3 + y4\nD65 =~ y5 + y6 + y7 + y8\nD65 ~ I + D60\nD60 ~ I\n\"\n\n\nfit2 &lt;- sem(m2, data = PoliticalDemocracy)\nfit2@Fit@converged\n\n[1] TRUE\n\n\nSTRUCTURAL PARAMETERS ARE ALSO IDENTIFIED.\nLET'S DEFINE THE MODEL CONSIDERING LONGITUDINAL MEASURES"
  },
  {
    "objectID": "slides/03_sem.html#final-model",
    "href": "slides/03_sem.html#final-model",
    "title": "Structural Equation Models",
    "section": "Final model",
    "text": "Final model\nThe modified model"
  },
  {
    "objectID": "slides/03_sem.html#final-model-specification",
    "href": "slides/03_sem.html#final-model-specification",
    "title": "Structural Equation Models",
    "section": "Final model specification",
    "text": "Final model specification\nThe modified model\n\nm3 &lt;- \"I =~ x1 + x2 + x3\nD60 =~ y1 + y2 + y3 + y4\nD65 =~ y5 + y6 + y7 + y8\nD65 ~ I + D60\nD60 ~ I\ny1 ~~ y5\ny2 ~~ y6\ny3 ~~ y7\ny4 ~~ y8\n\"\n\nSAME ITEMS AT DIFFERENT TIME POINTS HAVE CORRELATED RESIDUALS"
  },
  {
    "objectID": "slides/03_sem.html#final-model-results",
    "href": "slides/03_sem.html#final-model-results",
    "title": "Structural Equation Models",
    "section": "Final model results",
    "text": "Final model results\nThe modified model\n\n(fit3 &lt;- sem(m3, data = PoliticalDemocracy))\n\nlavaan 0.6-19 ended normally after 58 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        29\n\n  Number of observations                            75\n\nModel Test User Model:\n                                                      \n  Test statistic                                50.835\n  Degrees of freedom                                37\n  P-value (Chi-square)                           0.064\n\ninspect(fit3, what = \"fitmeasures\")[\n  c(\"cfi\", \"srmr\", \"rmsea\")]\n\n  cfi  srmr rmsea \n0.980 0.050 0.071 \n\n\nMODEL FIT IS GOOD!"
  },
  {
    "objectID": "slides/03_sem.html#model-comparisons",
    "href": "slides/03_sem.html#model-comparisons",
    "title": "Structural Equation Models",
    "section": "Model comparisons",
    "text": "Model comparisons\n\nanova(fit1,fit2,fit3)\n\nWarning: lavaan-&gt;lavTestLRT():  \n   some models have the same degrees of freedom\n\n\n\nChi-Squared Difference Test\n\n     Df  AIC  BIC Chisq Chisq diff RMSEA Df diff Pr(&gt;Chisq)    \nfit3 37 3166 3233  50.8                                        \nfit1 41 3180 3238  72.5       21.6 0.242       4    0.00024 ***\nfit2 41 3180 3238  72.5        0.0 0.000       0               \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "slides/03_sem.html#model-comparisons-1",
    "href": "slides/03_sem.html#model-comparisons-1",
    "title": "Structural Equation Models",
    "section": "Model comparisons",
    "text": "Model comparisons\nWe can also compare the models using fit indices:\n\n\n\n\n\n\nchisq\ndf\ncfi\ntli\nsrmr\nrmsea\naic\nbic\n\n\n\n\nmodel1\n72\n41\n0.95\n0.94\n0.055\n0.101\n3180\n3238\n\n\nmodel2\n72\n41\n0.95\n0.94\n0.055\n0.101\n3180\n3238\n\n\nmodel3\n51\n37\n0.98\n0.97\n0.050\n0.071\n3166\n3233\n\n\n\n\n\nWHAT IS THE BEST MODEL? QUESTIONS? COMMENTS?"
  },
  {
    "objectID": "slides/03_sem.html#the-eat-dataset",
    "href": "slides/03_sem.html#the-eat-dataset",
    "title": "Structural Equation Models",
    "section": "The EAT dataset",
    "text": "The EAT dataset\nThe dataset includes 13 items that measure ‘peer pressure’, ‘social media use’, ‘social comparison’, and ‘eating disorders’.\n\nload(\"../data/Exercise4_1.Rdata\")\nround(head(dE4_1),2)\n\n    PP1   PP2   PP3   PP4   SM1   SM2   SM3   SM4  SC1   SC2   SC3   ED1   ED2\n1  0.23  1.91  0.59 -0.70  2.31  1.06  1.43 -0.77  1.2  2.20  0.18 -0.38  1.61\n2 -0.65 -3.18 -0.84 -0.43  0.69  0.10  1.24  0.51 -1.9 -1.17 -1.23 -1.74 -1.73\n3  0.26 -1.46 -0.43 -0.05 -0.21 -0.46 -0.02  1.26  1.4  1.03  0.90  1.07  2.04\n4 -0.68 -0.29 -0.08 -2.24 -0.64  0.47 -0.76  0.58  1.2  0.97  2.73  0.71  0.32\n5 -0.06  0.89  0.04 -0.41  0.17  1.02  0.18  0.61  3.7  1.38  1.85  1.25  0.66\n6 -0.29 -2.74 -0.52  2.58  0.15 -1.08  1.08  0.99  1.3 -0.24  0.93 -0.97 -0.68"
  },
  {
    "objectID": "slides/03_sem.html#the-theoretical-model",
    "href": "slides/03_sem.html#the-theoretical-model",
    "title": "Structural Equation Models",
    "section": "The theoretical model",
    "text": "The theoretical model"
  },
  {
    "objectID": "slides/03_sem.html#the-exercise",
    "href": "slides/03_sem.html#the-exercise",
    "title": "Structural Equation Models",
    "section": "The exercise",
    "text": "The exercise\n\nApply the two-step rule:\n\nTest the CFA model\nTest the structural model\n\nInspect model results and fit indices\n\nAre the hypotheses confirmed?\nDoes the model fit the data well?\n\nIf the model is not satisfactory, understand why and change it\nDraw the model (in R, ppt, or with a pencil)\nTry to fit a simple path model using sum scores instead of latent scores"
  },
  {
    "objectID": "slides/03_sem.html#model-specification",
    "href": "slides/03_sem.html#model-specification",
    "title": "Structural Equation Models",
    "section": "Model specification",
    "text": "Model specification\nSTEP 1 and 2\n\nm1 &lt;- \"\n # CFA model\n peerPressure =~ PP1 + PP2 + PP3 + PP4\n socialMedia =~ SM1 + SM2 + SM3 + SM4\n socialComparison =~ SC1 + SC2 + SC3\n eatingDisorder =~ ED1 + ED2\n\"\nfit1 &lt;- sem(m1, data = dE4_1, std.lv=T)\nfit1@Fit@converged\nm2 &lt;- \"\n [...]\n # Structural model\n eatingDisorder ~ socialComparison\n socialComparison ~ peerPressure + socialMedia\"\nfit2 &lt;- sem(m2, data = dE4_1, std.lv=T)\nfit2@Fit@converged\n\nOK?"
  },
  {
    "objectID": "slides/03_sem.html#results-and-fit",
    "href": "slides/03_sem.html#results-and-fit",
    "title": "Structural Equation Models",
    "section": "Results and fit",
    "text": "Results and fit\n\nsummary(fitE4_1, std=T)\n\n\n\n[...]\nRegressions:\n                     Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  eatingDisorder ~                                                        \n    socialComparsn      0.344    0.047    7.322    0.000    0.356    0.356\n  socialComparison ~                                                      \n    peerPressure        0.139    0.038    3.636    0.000    0.125    0.125\n    socialMedia         0.455    0.049    9.221    0.000    0.411    0.411\n\n[...]\n\n\n\nfitmeasures(fitE4_1, \n            fit.measures = \n            c(\"cfi\", \"tli\", \"srmr\", \"rmsea\"))\n\n  cfi   tli  srmr rmsea \n0.880 0.846 0.044 0.065"
  },
  {
    "objectID": "slides/03_sem.html#model-modification",
    "href": "slides/03_sem.html#model-modification",
    "title": "Structural Equation Models",
    "section": "Model modification",
    "text": "Model modification\n\nmodificationIndices(fitE4_1, sort. = T)[1:10,]\n\n                 lhs op rhs  mi   epc sepc.lv sepc.all sepc.nox\n120              SM1 ~~ SC2 329  0.56    0.56     0.63     0.63\n49       socialMedia =~ SC2  57  0.38    0.38     0.29     0.29\n57  socialComparison =~ SM1  55  0.29    0.32     0.28     0.28\n121              SM1 ~~ SC3  52 -0.23   -0.23    -0.23    -0.23\n50       socialMedia =~ SC3  31 -0.28   -0.28    -0.21    -0.21\n119              SM1 ~~ SC1  22 -0.15   -0.15    -0.15    -0.15\n143              SC1 ~~ SC3  19  0.29    0.29     0.28     0.28\n74               PP1 ~~ PP2  18  0.66    0.66     1.20     1.20\n97               PP3 ~~ PP4  15  0.13    0.13     0.11     0.11\n58  socialComparison =~ SM2  13 -0.15   -0.16    -0.14    -0.14\n\n\n\nm2.1 &lt;- \"\n[...]\n# Residual correlations\nSM1 ~~ SC2\n\"\nfitmeasures(fit2.1, ...)\n\n\n\n  cfi   tli  srmr rmsea \n0.995 0.994 0.023 0.013"
  },
  {
    "objectID": "slides/03_sem.html#sum-scores",
    "href": "slides/03_sem.html#sum-scores",
    "title": "Structural Equation Models",
    "section": "Sum scores",
    "text": "Sum scores\n\nd2 &lt;- data.frame(\n  peerPressure = dE4_1$PP1 + dE4_1$PP2 + dE4_1$PP3 + dE4_1$PP4, \n  socialMedia = dE4_1$SM1 + dE4_1$SM2 + dE4_1$SM3 + dE4_1$SM4,\n  socialComparison = dE4_1$SC1 + dE4_1$SC2 + dE4_1$SC3,\n  eatingDisorder = dE4_1$ED1 + dE4_1$ED2)\npath &lt;- \"\neatingDisorder ~ socialComparison\nsocialComparison ~ peerPressure + socialMedia\"\nfitP &lt;- sem(path, d2)\nfitmeasures(fitP, fit.measures = \n              c(\"cfi\", \"tli\", \"srmr\", \"rmsea\"))\n\n  cfi   tli  srmr rmsea \n0.978 0.946 0.019 0.037"
  },
  {
    "objectID": "slides/03_sem.html#sum-scores-vs-latent-scores",
    "href": "slides/03_sem.html#sum-scores-vs-latent-scores",
    "title": "Structural Equation Models",
    "section": "Sum scores VS latent scores",
    "text": "Sum scores VS latent scores\nHowever, the debate is still open:\n\nThinking twice about sum scores\n\nThinking thrice about sum scores, and then some more about measurement and analysis\n\nPsychometric properties of sum scores and factor scores differ even when their correlation is 0.98: A response to Widaman and Revelle\n\nOr some more Schimmack:\n\nSchimmack vs Gelman 1\nSchimmack vs Gelman 2"
  },
  {
    "objectID": "slides/03_sem.html#the-ground-truth",
    "href": "slides/03_sem.html#the-ground-truth",
    "title": "Structural Equation Models",
    "section": "The ground truth",
    "text": "The ground truth\n\n# peer pressure AND social media -&gt; social comparison -&gt; eating disorder\nmE4_1 &lt;- \"\n # CFA model\n peerPressure =~ .75*PP1 + .72*PP2 + .59*PP3 + .65*PP4\n socialMedia =~ .45*SM1 + .55*SM2 + .59*SM3 + .65*SM4\n socialComparison =~ .81*SC1 + .75*SC2 + .86*SC3\n eatingDisorder =~ .70*ED1 + .65*ED2\n \n # Structural model\n eatingDisorder ~ .37*socialComparison\n socialComparison ~ .23*peerPressure + .41*socialMedia\n \n # Misspecifications\n # within construct\n PP1 ~~ .43*PP2\n # between construct\n SM1 ~~ .53*SC2\n\""
  },
  {
    "objectID": "slides/03_sem.html#sum-scores-vs-latent-scores-1",
    "href": "slides/03_sem.html#sum-scores-vs-latent-scores-1",
    "title": "Structural Equation Models",
    "section": "Sum scores VS latent scores",
    "text": "Sum scores VS latent scores\nHowever, the debate is still open:\n\nThinking twice about sum scores\n\nThinking thrice about sum scores, and then some more about measurement and analysis\n\nPsychometric properties of sum scores and factor scores differ even when their correlation is 0.98: A response to Widaman and Revelle\n\nOr some more Schimmack:\n\nSchimmack vs Gelman 1\nSchimmack vs Gelman 2"
  },
  {
    "objectID": "slides/03_sem.html#the-indifference-of-the-indicator",
    "href": "slides/03_sem.html#the-indifference-of-the-indicator",
    "title": "Structural Equation Models",
    "section": "The indifference of the indicator",
    "text": "The indifference of the indicator\n\nHow many indicators do we need?\nHow should I select them?\n… LET'S SEE THE ADDITIONAL CODE"
  },
  {
    "objectID": "slides/04_invariance.html#outline",
    "href": "slides/04_invariance.html#outline",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Outline",
    "text": "Outline\n\nTheoretical Background\nR code\nA real case study\nRegressions\nReferences"
  },
  {
    "objectID": "slides/04_invariance.html#a-hot-topic",
    "href": "slides/04_invariance.html#a-hot-topic",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "A hot topic",
    "text": "A hot topic"
  },
  {
    "objectID": "slides/04_invariance.html#introduction",
    "href": "slides/04_invariance.html#introduction",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\nCOMMENTS?"
  },
  {
    "objectID": "slides/04_invariance.html#the-importance-of-measurement-invariance",
    "href": "slides/04_invariance.html#the-importance-of-measurement-invariance",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "The importance of Measurement Invariance",
    "text": "The importance of Measurement Invariance\n\nResearchers often compare groups of subjects on psychological variables … assuming that the adopted instruments similarly measure the same latent constructs across groups\n\nDespite its appeal, this assumption is often not justified and needs to be tested to make comparisons across groups valid and interpretable\nThe assessment of Measurement Invariance is a prerequisite for meaningful comparisons across groups (or across time for the same groups)\n\n\n…but not everyone (fully) agrees: doi:10.1080/10705511.2023.2191292"
  },
  {
    "objectID": "slides/04_invariance.html#invariance-of-a-structural-equation-model",
    "href": "slides/04_invariance.html#invariance-of-a-structural-equation-model",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Invariance of a Structural Equation Model",
    "text": "Invariance of a Structural Equation Model\nMore generally, testing for Invariance allows us to evaluate to what extent a hypothesized Structural Equation Model (SEM) can be considered invariant (i.e., having the same parameters) across groups"
  },
  {
    "objectID": "slides/04_invariance.html#some-applications",
    "href": "slides/04_invariance.html#some-applications",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "(Some) Applications",
    "text": "(Some) Applications\n\nEvaluation of the psychometric properties of a psychological test or of a theoretical model on different sub-groups\n\nFor example, assessment of invariance across:\n  -  gender\n  -  age group\n  -  pathological state\n  -  culture, ethnicity, nationality\n\\end {itemize} - Longitudinal factorial invariance: the invariance of corresponding parameters across time within a group"
  },
  {
    "objectID": "slides/04_invariance.html#assessing-invariance-the-multi-group-analysis",
    "href": "slides/04_invariance.html#assessing-invariance-the-multi-group-analysis",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Assessing Invariance:\\ The Multi-Group Analysis",
    "text": "Assessing Invariance:\\ The Multi-Group Analysis\n\nThe Multi-group analysis is the most widely used method to assess invariance of a SEM model\n\nIn this lesson we will focus on a particular class of SEM models:\n\n\nThe Confirmatory Factor Analysis (CFA) models - In particular, we will adopt The Multi-Group Confirmatory Factor Analysis (MG-CFA) approach"
  },
  {
    "objectID": "slides/04_invariance.html#assessing-invariance-the-starting-point",
    "href": "slides/04_invariance.html#assessing-invariance-the-starting-point",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Assessing Invariance: The starting point",
    "text": "Assessing Invariance: The starting point"
  },
  {
    "objectID": "slides/04_invariance.html#assessing-invariance-the-idea",
    "href": "slides/04_invariance.html#assessing-invariance-the-idea",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Assessing Invariance: The idea",
    "text": "Assessing Invariance: The idea\n\nIn MG analysis we start from a baseline situation in which the hypothesized CFA model is simultaneously estimated on all groups. At the beginning, all structural parameters are free to vary across groups\n\nNext, more restrictive models are built in which some parameters (e.g., factor loadings) are constrained to be invariant across groups\nThe comparison of increasingly restrictive models allows to evaluate the increasing level of invariance between groups"
  },
  {
    "objectID": "slides/04_invariance.html#invariance-steps",
    "href": "slides/04_invariance.html#invariance-steps",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Invariance steps:",
    "text": "Invariance steps:\n\nConfigural Invariance: the structure of the latent variable(s) is the same across groups (\\(g \\ne g'\\)) and/or over time (\\(\\xi_g = \\xi_{g'}\\))\n\nMetric Invariance (or Weak Invariance): factor loadings are equivalent across groups and/or over time (\\(\\Lambda_g = \\Lambda_{g'}\\))\nScalar Invariance (or Strong Invariance): intercepts of observed variables are equivalent across groups and/or over time (\\(\\tau_g = \\tau_{g'}\\))\nStrict Invariance (or Residual or Invariant Uniqueness Invariance): residual variances of observed exogenous variables are equivalent across groups and/or over time (\\(\\Theta_{\\delta,g} = \\Theta_{\\delta,g'}\\))\n…\nScalar/Strong invariance is required for meaningful mean comparisons"
  },
  {
    "objectID": "slides/04_invariance.html#assessing-factorial-invariance-a-step-by-step-guide",
    "href": "slides/04_invariance.html#assessing-factorial-invariance-a-step-by-step-guide",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Assessing Factorial Invariance: A step-by-step guide",
    "text": "Assessing Factorial Invariance: A step-by-step guide\n\n\n\n\n\n\n\n\n\n#\nInvariance\nConstrained parameters\nComparison model\n\n\n\n\n0\nSeparete models\n-\n-\n\n\n1\nConfigural\nNone\n-\n\n\n2\nMetric\n\\(\\lambda_{ij}\\)\nConfigural\n\n\n3\nScalar\n\\(\\lambda_{ij}\\; , \\tau_{i}\\)\nMetric\n\n\n4\nObserved residual var.\n\\(\\lambda_{ij}\\; , \\tau_{i}\\; , \\theta_{ii}^{\\delta}\\)\nScalar\n\n\n5\nLatent variances\n${ij}; , {i}; , {ii}^{}; , {ii} $\nObserved residual var.\n\n\n6\nLatent covariances\n${ij}; , {i}; , {ii}^{}; , {ii}; , _{ij} $\nLatent variances\n\n\n7\nLatent means\n\\(\\lambda_{ij}\\; , \\tau_{i}\\; , \\theta_{ii}^{\\delta}\\; , \\phi_{ii}\\;  , \\phi_{ij}\\; , \\kappa_{i}\\)\nLatent covariances\n\n\n\n-  **Steps from 1 to 4:** *Measurement Invariance*\n\n-  **Steps from 5 to 7:** *Structural Invariance*"
  },
  {
    "objectID": "slides/04_invariance.html#mg-cfa-scheme-steps-1-4",
    "href": "slides/04_invariance.html#mg-cfa-scheme-steps-1-4",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "MG-CFA scheme (steps 1-4)",
    "text": "MG-CFA scheme (steps 1-4)"
  },
  {
    "objectID": "slides/04_invariance.html#step-0-separate-models-for-each-group",
    "href": "slides/04_invariance.html#step-0-separate-models-for-each-group",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Step 0: Separate models for each group",
    "text": "Step 0: Separate models for each group"
  },
  {
    "objectID": "slides/04_invariance.html#step-1-configural-invariance",
    "href": "slides/04_invariance.html#step-1-configural-invariance",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Step 1: Configural invariance",
    "text": "Step 1: Configural invariance"
  },
  {
    "objectID": "slides/04_invariance.html#step-1-configural-non-invariance",
    "href": "slides/04_invariance.html#step-1-configural-non-invariance",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Step 1: Configural (non-)invariance",
    "text": "Step 1: Configural (non-)invariance\nConfigural invariance means that the “form” of the models is the same in the groups of interest. Form entails both the number of latent variables and whether the loadings are non-zero to begin with."
  },
  {
    "objectID": "slides/04_invariance.html#step-2-metric-invariance",
    "href": "slides/04_invariance.html#step-2-metric-invariance",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Step 2: Metric invariance",
    "text": "Step 2: Metric invariance"
  },
  {
    "objectID": "slides/04_invariance.html#step-2-metric-non-invariance",
    "href": "slides/04_invariance.html#step-2-metric-non-invariance",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Step 2: Metric (non-)invariance",
    "text": "Step 2: Metric (non-)invariance\nMetric invariance means that for each item, the loading of the factor on the item is the same in the two groups (or, again more precisely, that we cannot reject the hypothesis that the loadings are the same)."
  },
  {
    "objectID": "slides/04_invariance.html#step-2-metric-non-invariance-1",
    "href": "slides/04_invariance.html#step-2-metric-non-invariance-1",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Step 2: Metric (non-)invariance",
    "text": "Step 2: Metric (non-)invariance\nThe source of group differences does not come from the latent variable!"
  },
  {
    "objectID": "slides/04_invariance.html#step-3-scalar-invariance",
    "href": "slides/04_invariance.html#step-3-scalar-invariance",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Step 3: Scalar invariance",
    "text": "Step 3: Scalar invariance"
  },
  {
    "objectID": "slides/04_invariance.html#step-3-scalar-invariance-1",
    "href": "slides/04_invariance.html#step-3-scalar-invariance-1",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Step 3: Scalar invariance",
    "text": "Step 3: Scalar invariance\nScalar invariance means that for each item, the intercept is the same. This means that group differences in the item responses are fully accounted for by group differences in the latent construct."
  },
  {
    "objectID": "slides/04_invariance.html#step-4-invariance-of-observed-residual-variances",
    "href": "slides/04_invariance.html#step-4-invariance-of-observed-residual-variances",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Step 4: Invariance of observed residual variances",
    "text": "Step 4: Invariance of observed residual variances\nResidual invariance means that for each item, the residual variance—the variance of the ominous E pointing into the items—is the same. We can again phrase this statistically: if we regressed the item scores on the factor, then the variance of the remaining residual would be the same in the groups (i.e., there would be homoscedasticity)."
  },
  {
    "objectID": "slides/04_invariance.html#step-4-invariance-of-observed-residual-variances-1",
    "href": "slides/04_invariance.html#step-4-invariance-of-observed-residual-variances-1",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Step 4: Invariance of observed residual variances",
    "text": "Step 4: Invariance of observed residual variances\n\nThe thing about the residual is that it captures everything that’s not explained in the model, and explaining changes in the amount of unexplained things seems a bit futile. Residual invariance is often not tested because it’s not necessary for latent mean comparisons. It’s a bit of an anticlimactic level to end on."
  },
  {
    "objectID": "slides/04_invariance.html#step-5-invariance-of-latent-variances",
    "href": "slides/04_invariance.html#step-5-invariance-of-latent-variances",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Step 5: Invariance of latent variances",
    "text": "Step 5: Invariance of latent variances"
  },
  {
    "objectID": "slides/04_invariance.html#step-6-invariance-of-latent-covariances",
    "href": "slides/04_invariance.html#step-6-invariance-of-latent-covariances",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Step 6: Invariance of latent covariances",
    "text": "Step 6: Invariance of latent covariances"
  },
  {
    "objectID": "slides/04_invariance.html#step-7-invariance-of-latent-means",
    "href": "slides/04_invariance.html#step-7-invariance-of-latent-means",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Step 7: Invariance of latent means",
    "text": "Step 7: Invariance of latent means"
  },
  {
    "objectID": "slides/04_invariance.html#evaluation-of-level-of-invariance",
    "href": "slides/04_invariance.html#evaluation-of-level-of-invariance",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Evaluation of level of invariance",
    "text": "Evaluation of level of invariance\n\nAnalysis of fit indices of the considered invariance model (\\(\\chi^{2}\\), \\(RMSEA\\), \\(CFI\\), \\(NNFI\\)):\n\nA good fit supports the validity of invariance - Comparison between fit indices of the considered invariance model and a less restrictive model:\n    -   $\\Delta_{\\chi^{2}}$  (strongly dependent on $n$)\n    -  $\\Delta_{CFI}$\n    -  $\\Delta_{BIC}$\n    -  ...\nA marked worsening of fit indices indicates that the considered invariance model is too restrictive and thus must be rejected\nNote: It is strongly recommended to make a comprehensive evaluation based on different fit indices, rather than on a single fit criterion"
  },
  {
    "objectID": "slides/04_invariance.html#some-general-indications-on-model-comparison",
    "href": "slides/04_invariance.html#some-general-indications-on-model-comparison",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Some general indications on model comparison",
    "text": "Some general indications on model comparison\nLet:\n-  $MOD_{A}$ be a model of invariance taken as reference model\n-  $MOD_{B}$ be a more restrictive model of invariance than $MOD_{A}$\nWe will have:\n-  $\\Delta_{\\chi^{2}_{BA}} = \\chi^{2}_{MOD_{B}} - \\chi^{2}_{MOD_{A}} \\sim \\chi^{2}_{BA}$ with $df$ equal to $df_{Mod_{B}} - df_{Mod_{A}}$  \nIf the \\(p-value\\) associated with \\(\\chi^{2}_{BA}\\) is less than a critical \\(\\alpha\\) value then \\({MOD_{B}}\\) must be rejected Always assume \\(\\alpha_{CRITICAL}=.05\\) is not reasonable - \\(\\Delta_{CFI_{BA}} = CFI_{MOD_B}-CFI_{MOD_A}\\) If \\(\\Delta_{CFI_{BA}} &gt; -.01\\) then \\({MOD_{B}}\\) can be accepted - \\(\\Delta_{BIC_{BA}} = BIC_{MOD_B}-BIC_{MOD_A}\\) If ${BIC{BA}} &lt; 0 $ then \\({MOD_{B}}\\) is more plausible than \\({MOD_{A}}\\)"
  },
  {
    "objectID": "slides/04_invariance.html#partial-invariance",
    "href": "slides/04_invariance.html#partial-invariance",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Partial invariance",
    "text": "Partial invariance\nWhen model invariance is untenable at a certain level (scalar, metric, or residual) we can determine what specific indicator(s) contribute to the misfit. Partial invariance is when most but not all parameters are constrained to be invariant. If partial invariance exists at a given level for a model, there are a variety of ways to proceed:\n1.  Leave the non-invariant indicator variables in the model, but not constrain them to be invariant across groups, arguing that the invariant indicators are sufficient to establish comparability of the constructs.\n2.  Argue that the differences between indicator variables are small enough that they would not make a substantive difference and proceed with invariance constraints in place.\n3.  Remove the indicator variables that are not fully invariant, and then re-run the invariance assessment.\n4.  Conclude that because there is not full invariance, the indicator variables must be measuring different constructs across the groups and, therefore, not use the indicators."
  },
  {
    "objectID": "slides/04_invariance.html#how-can-we-recognize-the-parameters-to-free",
    "href": "slides/04_invariance.html#how-can-we-recognize-the-parameters-to-free",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "How can we recognize the parameters to ``free’’?",
    "text": "How can we recognize the parameters to ``free’’?\n\nInspection of parameters estimated separately for each group\n\nThe more the same parameter differs among groups, the more it will be plausible to free it - Inspection of Modification indices\n    -  The *Modification Index* of a constrained parameter indicates the extent to which the model could improve if the parameter would be left free to vary across groups\n    -  In general, we start from a more restrictive model and free one by one the parameters with higher Modification indices... until we obtain invariance\nNote: Parameters left to vary freely across groups must be interpreted based on relevant theory"
  },
  {
    "objectID": "slides/04_invariance.html#cfa-hypothesized-model",
    "href": "slides/04_invariance.html#cfa-hypothesized-model",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "CFA hypothesized model",
    "text": "CFA hypothesized model"
  },
  {
    "objectID": "slides/04_invariance.html#the-data",
    "href": "slides/04_invariance.html#the-data",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "The Data",
    "text": "The Data\n\nData are in the data frame ``d’’\n\n\nstr(d)\n\n'data.frame':   589 obs. of  8 variables:\n $ x1   : num  1.21 -1.34 1.05 1.02 2.51 ...\n $ x2   : num  0.725 -0.927 -1.037 1.953 1.823 ...\n $ x3   : num  1.153 -1.635 3.148 -0.183 2.449 ...\n $ x4   : num  2.185 -1.788 -0.101 0.978 0.77 ...\n $ x5   : num  0.668 -0.414 1.843 -1.994 -1.774 ...\n $ x6   : num  -1.0233 -0.4756 -0.0675 -0.1684 1.2472 ...\n $ x7   : num  1.046 -0.213 1.572 -1.513 0.194 ...\n $ Group: int  1 0 0 1 1 1 1 0 1 1 ...\n\n\n\nThe groups are composed by:\n\n\ntable(d$Group)\n\n\n  0   1 \n234 355"
  },
  {
    "objectID": "slides/04_invariance.html#model-building-in-r",
    "href": "slides/04_invariance.html#model-building-in-r",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Model building in R",
    "text": "Model building in R\nThis is the reference theoretical model that we want to evaluate\n\nm &lt;- \"\nf1 =~ x1 + x2 + x3 + x4\nf2 =~ x5 + x6 + x7\n\""
  },
  {
    "objectID": "slides/04_invariance.html#step-0-separate-models-for-each-group-1",
    "href": "slides/04_invariance.html#step-0-separate-models-for-each-group-1",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Step 0: Separate models for each group",
    "text": "Step 0: Separate models for each group\nFirst of all, try to fit the model separately in the two groups.\nThis is not configural invariance! We are just testing if the model works in the two groups, not if the model has the same ‘form’ in the two groups.\n\n# Fit the model in the two groups\nm0&lt;-cfa(m, data=d[d$Group==0,])\nm1&lt;-cfa(m, data=d[d$Group==1,])\n\n# Evaluating parameters and goodness-of-fit indices\nsummary(m0,fit.measures=TRUE)\nsummary(m1,fit.measures=TRUE)"
  },
  {
    "objectID": "slides/04_invariance.html#step-1-configural-invariance-1",
    "href": "slides/04_invariance.html#step-1-configural-invariance-1",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Step 1: Configural invariance",
    "text": "Step 1: Configural invariance\nFitting a configural model is very easy: just add group=“groupVariableName” to the cfa sintax.\n\n# Fit the configural model\nm.conf&lt;-cfa(m, data=d, group = \"Group\")\n\n# Evaluating parameters and goodness-of-fit indices\nsummary(m.conf)\nfitmeasures(m.conf, fit.measures = fi)\n\n# Do they decrease compared to the full model?"
  },
  {
    "objectID": "slides/04_invariance.html#step-2-metric-invariance-1",
    "href": "slides/04_invariance.html#step-2-metric-invariance-1",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Step 2: Metric invariance",
    "text": "Step 2: Metric invariance\nAdding metric invariance to the model means fixing the loadings to force them to be equal in the two groups.\n\n# Fit the model for metric invariance\nm.metr&lt;-cfa(m, data=d, group = \"Group\",\n            group.equal = \"loadings\")\n\n# Evaluating parameters and goodness-of-fit indices\nsummary(m.metr)\nfitmeasures(m.metr, fit.measures = fi)\n# Comparison between metric and configural invariance (delta chi)\nanova(m.metr,m.conf)\n# Comparison between metric and configural invariance (delta CFI)\nfitMeasures(m.metr,\"cfi\") - fitMeasures(m.conf,\"cfi\")\n# Comparison between metric and configural invariance (delta BIC)\nfitMeasures(m.metr,\"bic\")-fitMeasures(m.conf,\"bic\")\n# Inspection of the modification indices\nlavTestScore(m.metr)\nparameterTable(m.metr)"
  },
  {
    "objectID": "slides/04_invariance.html#steps-3-7-evaluation-of-different-invariance-models",
    "href": "slides/04_invariance.html#steps-3-7-evaluation-of-different-invariance-models",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Steps 3-7: Evaluation of different invariance models",
    "text": "Steps 3-7: Evaluation of different invariance models\nThrough the option group.equal , it is possible to constrain groups of parameters to be equal across groups in order to assess increasingly restrictive invariance hypotheses:\n\n\n\nConstrained parameters\nIn R\n\n\n\n\nFactor loadings\nloadings\n\n\nIntercepts of manifest variables\nintercepts\n\n\nResidual variances of manifest variables\nresiduals\n\n\nResidual covariances of manifest variables\nresidual.covariances\n\n\nResidual variances of latent variables\nlv.variances\n\n\nResidual covariances of latent variable\nlv.covariances\n\n\nIntercepts/means of latent variables\nmeans\n\n\nAll regression coefficients\nregressions\n\n\n\n\n# Example: Model for assessing scalar invariance\nm.scal&lt;-cfa(m,d,group=\"Group\",\n            group.equal=c(\"loadings\",\"intercepts\"))"
  },
  {
    "objectID": "slides/04_invariance.html#a-magic",
    "href": "slides/04_invariance.html#a-magic",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "A magic ",
    "text": "A magic \n\nlibrary(semTools)\nmeasurementInvariance(model = model,\n                      d,group=\"Group\",\n                      fit.measures = fi)\n\nThis is DEPRECATED from the authors of the package and will be deleted from future versions of semTools.\nYou can use it exploratorily, but you cannot:\n\nfollow and interpret the estimates step by step\nmodel partial invariance!\n\nLet’s see what partial invariance is."
  },
  {
    "objectID": "slides/04_invariance.html#models-of-partial-invariance",
    "href": "slides/04_invariance.html#models-of-partial-invariance",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Models of partial invariance",
    "text": "Models of partial invariance\nThrough the option group.partial , you can test for partial invariance by allowing a few parameters to remain free:\n\n# After the inspection of MI, we decided to estimate a model\n# of partial metric invariance in which the loadgin of the\n# item x5 is free to vary between groups:\nm.metr&lt;-cfa(m,data=d,group=\"Group\",\n            group.equal=\"loadings\",\n            group.partial=\"f2 =~ x5\")\n\nWhat should we do now?\nShould we compare this model with what?\nHow can we interpret the results?\n\n… Now it’s time for a real case study!"
  },
  {
    "objectID": "slides/04_invariance.html#the-case-study",
    "href": "slides/04_invariance.html#the-case-study",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "The case study",
    "text": "The case study\n\n*SEM work with variance-covariance matrices. For this reason, it is sufficient to find it in the original articles to use their “data”!. The data we will use have been generated based on the parameters provided in the article, modifying the sample size. How? Open dataGen.R* in the \\texttt{'data' folder}"
  },
  {
    "objectID": "slides/04_invariance.html#theoretical-model-and-reference-groups",
    "href": "slides/04_invariance.html#theoretical-model-and-reference-groups",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Theoretical model and reference groups",
    "text": "Theoretical model and reference groups\n\n-  Group A: Youths With Manics  Symptoms ($n=150$)\n-  Group B: Control Group ($n=150$)"
  },
  {
    "objectID": "slides/04_invariance.html#the-data-on-moodle-dmg.rdata",
    "href": "slides/04_invariance.html#the-data-on-moodle-dmg.rdata",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "The Data (On MOODLE: dmg.RData)",
    "text": "The Data (On MOODLE: dmg.RData)\n\nrm(list=ls())\n# Loading useful packages:\nlibrary(lavaan) ; library(semTools) ; library (semPlot)\nload(\"../data/dmg.RData\")\nstr(dmg)\n\n'data.frame':   300 obs. of  10 variables:\n $ id       : int  1 2 3 4 5 6 7 8 9 10 ...\n $ diagnosis: Factor w/ 2 levels \"manic\",\"norming\": 1 1 1 1 1 1 1 1 1 1 ...\n $ Info     : num  8.95 11.94 5.8 14.69 6 ...\n $ Sim      : num  9.34 9.93 6.64 17.72 6.56 ...\n $ Vocab    : num  12.39 4.57 6.03 13.21 7.83 ...\n $ Comp     : num  11.61 8.86 5.03 13.38 5.77 ...\n $ PicComp  : num  11.15 4.95 8.02 11.54 8.84 ...\n $ PicArr   : num  15.7 5.46 7.65 12.06 5.39 ...\n $ BlkDsgn  : num  11.45 3.43 9.28 10.46 7.39 ...\n $ ObjAsmb  : num  15.54 3.8 8.63 14.38 9.92 ..."
  },
  {
    "objectID": "slides/04_invariance.html#evaluation-of-multivariate-normality",
    "href": "slides/04_invariance.html#evaluation-of-multivariate-normality",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Evaluation of multivariate normality",
    "text": "Evaluation of multivariate normality\n\nlibrary(QuantPsyc)\nmult.norm(dmg[,3:10])$mult.test # (Mardia, 1970)\n\n          Beta-hat       kappa     p-val\nSkewness  2.110397 105.5198437 0.8242484\nKurtosis 79.118959  -0.6032073 0.5463708\n\n# We can assume multivariate normality\n#   and therefore use, in SEM,\n#   the Maximum Likelihood Method"
  },
  {
    "objectID": "slides/04_invariance.html#theoretical-model-in-r",
    "href": "slides/04_invariance.html#theoretical-model-in-r",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Theoretical model in R",
    "text": "Theoretical model in R\n\nmodel&lt;-\"gc =~ Info + Sim + Vocab + Comp\n        gv =~ PicComp + PicArr + BlkDsgn + ObjAsmb\""
  },
  {
    "objectID": "slides/04_invariance.html#separate-models-for-each-group",
    "href": "slides/04_invariance.html#separate-models-for-each-group",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Separate models for each group",
    "text": "Separate models for each group\n\n# Separate models\nm.man&lt;-cfa(model,data=dmg[dmg$diagnosis==\"manic\",])\nm.nor&lt;-cfa(model,data=dmg[dmg$diagnosis==\"norming\",])\n# Inspection of fit indices\nfitMeasures(m.man,c(\"chisq\",\"df\",\"rmsea\",\"cfi\",\"nnfi\"))\n\n chisq     df  rmsea    cfi   nnfi \n54.052 19.000  0.111  0.949  0.924 \n\nfitMeasures(m.nor,c(\"chisq\",\"df\",\"rmsea\",\"cfi\",\"nnfi\"))\n\n chisq     df  rmsea    cfi   nnfi \n18.151 19.000  0.000  1.000  1.003 \n\n# ANY COMMENTS?"
  },
  {
    "objectID": "slides/04_invariance.html#configural-invariance",
    "href": "slides/04_invariance.html#configural-invariance",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Configural Invariance",
    "text": "Configural Invariance\n\nm.conf&lt;-cfa(model,data=dmg,group=\"diagnosis\")\n# Inspection of fit indices\nfitMeasures(m.conf,c(\"chisq\",\"df\",\"rmsea\",\"cfi\",\"nnfi\"))\n\n chisq     df  rmsea    cfi   nnfi \n72.203 38.000  0.077  0.971  0.957 \n\n# ANY COMMENTS?"
  },
  {
    "objectID": "slides/04_invariance.html#metric-invariance-1",
    "href": "slides/04_invariance.html#metric-invariance-1",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Metric invariance (1)",
    "text": "Metric invariance (1)\n\n# Model of metric invariance\nm.metr&lt;-cfa(model,dmg,group=\"diagnosis\",group.equal=\"loadings\")\n# Inspection of fit indices\nfitMeasures(m.metr,c(\"chisq\",\"df\",\"rmsea\",\"cfi\",\"nnfi\"))\n\n chisq     df  rmsea    cfi   nnfi \n88.153 44.000  0.082  0.963  0.952"
  },
  {
    "objectID": "slides/04_invariance.html#metric-invariance-2",
    "href": "slides/04_invariance.html#metric-invariance-2",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Metric invariance (2)",
    "text": "Metric invariance (2)\n\n#### Metric vs. Configural invariance:\nanova(m.metr,m.conf) # (delta chi-square)\n\n\nChi-Squared Difference Test\n\n       Df   AIC   BIC  Chisq Chisq diff   RMSEA Df diff Pr(&gt;Chisq)  \nm.conf 38 11239 11424 72.203                                        \nm.metr 44 11243 11406 88.153      15.95 0.10515       6    0.01402 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nfitMeasures(m.metr,\"cfi\")-fitMeasures(m.conf,\"cfi\") # (delta cfi)\n\n   cfi \n-0.008 \n\nfitMeasures(m.metr,\"bic\")-fitMeasures(m.conf,\"bic\") # (delta BIC)\n\n    bic \n-18.272 \n\n# ANY COMMENTS?"
  },
  {
    "objectID": "slides/04_invariance.html#scalar-invariance-1",
    "href": "slides/04_invariance.html#scalar-invariance-1",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Scalar invariance (1)",
    "text": "Scalar invariance (1)\n\n# Model of Scalar invariance\nm.scal&lt;-cfa(model,dmg,group=\"diagnosis\",\n            group.equal=c(\"loadings\",\"intercepts\"))\n# Inspection of fit indices\nfitMeasures(m.scal,c(\"chisq\",\"df\",\"rmsea\",\"cfi\",\"nnfi\"))\n\n  chisq      df   rmsea     cfi    nnfi \n144.667  50.000   0.112   0.920   0.910 \n\n# ANY COMMENTS?"
  },
  {
    "objectID": "slides/04_invariance.html#scalar-invariance-2",
    "href": "slides/04_invariance.html#scalar-invariance-2",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Scalar invariance (2)",
    "text": "Scalar invariance (2)\n\n# Evaluation of Scalar invariance\nfitMeasures(m.scal,c(\"chisq\",\"df\",\"rmsea\",\"cfi\",\"nnfi\"))\n\n  chisq      df   rmsea     cfi    nnfi \n144.667  50.000   0.112   0.920   0.910 \n\nanova(m.scal,m.metr)\n\n\nChi-Squared Difference Test\n\n       Df   AIC   BIC   Chisq Chisq diff   RMSEA Df diff Pr(&gt;Chisq)    \nm.metr 44 11243 11406  88.153                                          \nm.scal 50 11287 11428 144.667     56.513 0.23691       6  2.292e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nfitMeasures(m.scal,\"cfi\")-fitMeasures(m.metr,\"cfi\")\n\n   cfi \n-0.043 \n\nfitMeasures(m.scal,\"bic\")-fitMeasures(m.metr,\"bic\")\n\n   bic \n22.291 \n\n# ANY COMMENTS?  ... Global Scalar invariance is not satisfactory\n# ... let's try with Partial Scalar invariance"
  },
  {
    "objectID": "slides/04_invariance.html#inspection-of-equality-constraints",
    "href": "slides/04_invariance.html#inspection-of-equality-constraints",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Inspection of equality constraints",
    "text": "Inspection of equality constraints\n\nlavTestScore(m.scal)$uni\n\n\n\n\nunivariate score tests:\n\n     lhs op   rhs     X2 df p.value\n1   .p2. == .p31.  0.419  1   0.517\n2   .p3. == .p32.  0.335  1   0.563\n3   .p4. == .p33.  2.389  1   0.122\n4   .p6. == .p35.  7.026  1   0.008\n5   .p7. == .p36.  0.072  1   0.789\n6   .p8. == .p37.  0.000  1   0.988\n7  .p20. == .p49.  8.342  1   0.004\n8  .p21. == .p50. 42.173  1   0.000\n9  .p22. == .p51.  2.691  1   0.101\n10 .p23. == .p52. 11.089  1   0.001\n11 .p24. == .p53.  2.042  1   0.153\n12 .p25. == .p54.  3.555  1   0.059\n13 .p26. == .p55.  1.018  1   0.313\n14 .p27. == .p56.  3.018  1   0.082\n\n\n\n# From a first analysis, we can see that the intercept of the variable \"Sim\"\n# (constraint p21 == p50) has a high Modification Index\n# ... freeing this parameter results in an improved fit\n# (see parTable(m.scal), column id, to \"find the meaning\" of p21 and p50)\n# Let's build a model of Partial Metric invariance by freeing the intercept of \"Sim\" ..."
  },
  {
    "objectID": "slides/04_invariance.html#partial-scalar-invariance-1",
    "href": "slides/04_invariance.html#partial-scalar-invariance-1",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Partial Scalar invariance (1)",
    "text": "Partial Scalar invariance (1)\n\nm.scal.P=cfa(model,dmg,group=\"diagnosis\",\n             group.equal=c(\"loadings\",\"intercepts\"),\n             group.partial=\"Sim~1\")\n# Inspection of fit indices\nfitMeasures(m.scal.P,c(\"chisq\",\"df\",\"rmsea\",\"cfi\",\"nnfi\"))\n\n  chisq      df   rmsea     cfi    nnfi \n100.174  49.000   0.083   0.957   0.950 \n\n# ANY COMMENTS?\n# What model can we now compare with the\n# Partial Invariance model?"
  },
  {
    "objectID": "slides/04_invariance.html#partial-scalar-invariance-2",
    "href": "slides/04_invariance.html#partial-scalar-invariance-2",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Partial Scalar invariance (2)",
    "text": "Partial Scalar invariance (2)\n\n# Evaluation. Partial Scalar invariance\nanova(m.scal.P,m.metr) # Note: Comparison model Metric invariance\n\n\nChi-Squared Difference Test\n\n         Df   AIC   BIC   Chisq Chisq diff    RMSEA Df diff Pr(&gt;Chisq)  \nm.metr   44 11243 11406  88.153                                         \nm.scal.P 49 11245 11389 100.174     12.021 0.096752       5     0.0345 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nfitMeasures(m.scal.P,\"cfi\")-fitMeasures(m.metr,\"cfi\")\n\n   cfi \n-0.006 \n\nfitMeasures(m.scal.P,\"bic\")-fitMeasures(m.metr,\"bic\")\n\n    bic \n-16.498 \n\n# Partial Scalar invariance is satisfactory\n# and now becomes our reference model\n# Question: How can we interpret this result?"
  },
  {
    "objectID": "slides/04_invariance.html#invariance-of-residuals-of-observed-variables1",
    "href": "slides/04_invariance.html#invariance-of-residuals-of-observed-variables1",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Invariance of Residuals of observed variables(1)",
    "text": "Invariance of Residuals of observed variables(1)\n\n# Note: parameter \"Sim~1\" remains free\nm.rvo=cfa(model,dmg,group=\"diagnosis\",\n          group.equal=c(\"loadings\",\"intercepts\",\"residuals\"),\n          group.partial=\"Sim~1\") #Note that this is still here\n# Inspection of fit indices\nfitMeasures(m.rvo,c(\"chisq\",\"df\",\"rmsea\",\"cfi\",\"nnfi\"))\n\n  chisq      df   rmsea     cfi    nnfi \n127.344  57.000   0.091   0.940   0.941"
  },
  {
    "objectID": "slides/04_invariance.html#invariance-of-residuals-of-observed-variables-2",
    "href": "slides/04_invariance.html#invariance-of-residuals-of-observed-variables-2",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Invariance of Residuals of observed variables (2)",
    "text": "Invariance of Residuals of observed variables (2)\n\n# Evaluation of Invariance of Residuals of observed variables\nanova(m.rvo,m.scal.P) # Note: Comparison model Partial Scalar invariance\n\n\nChi-Squared Difference Test\n\n         Df   AIC   BIC  Chisq Chisq diff   RMSEA Df diff Pr(&gt;Chisq)    \nm.scal.P 49 11245 11389 100.17                                          \nm.rvo    57 11256 11371 127.34     27.169 0.12639       8  0.0006609 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nfitMeasures(m.rvo,\"cfi\")-fitMeasures(m.scal.P,\"cfi\")\n\n   cfi \n-0.016 \n\nfitMeasures(m.rvo,\"bic\")-fitMeasures(m.scal.P,\"bic\")\n\n    bic \n-18.461 \n\n# The Invariance of Residuals of observed variables\n#   is not satisfactory. Let's take a look at equality constraints"
  },
  {
    "objectID": "slides/04_invariance.html#inspection-of-equality-constraints-1",
    "href": "slides/04_invariance.html#inspection-of-equality-constraints-1",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Inspection of equality constraints",
    "text": "Inspection of equality constraints\n\nlavTestScore(m.rvo)$uni\n\n\n# (... see complete output )\n# From a first analysis, we can see that\n#  the residuals of variables  “Comp” and “PicComp”\n#  have Modification indices that are\n#  particularly high, so let's free them"
  },
  {
    "objectID": "slides/04_invariance.html#invariance-of-residuals-of-observed-variables-1",
    "href": "slides/04_invariance.html#invariance-of-residuals-of-observed-variables-1",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Invariance of Residuals of observed variables (1)",
    "text": "Invariance of Residuals of observed variables (1)\n\n# Partial Invariance of Residuals of observed variables\nm.rvo.P=cfa(model,dmg,group=\"diagnosis\",\n            group.equal=c(\"loadings\",\"intercepts\",\"residuals\"),\n            group.partial=c(\"Sim~1\",\"PicComp~~PicComp\",\"Comp~~Comp\"))\n# Fit indices\nfitMeasures(m.rvo.P,c(\"chisq\",\"df\",\"rmsea\",\"cfi\",\"nnfi\"))\n\n  chisq      df   rmsea     cfi    nnfi \n102.420  55.000   0.076   0.960   0.959"
  },
  {
    "objectID": "slides/04_invariance.html#partial-invariance-of-residuals-of-observed-variables-2",
    "href": "slides/04_invariance.html#partial-invariance-of-residuals-of-observed-variables-2",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Partial Invariance of Residuals of observed variables (2)",
    "text": "Partial Invariance of Residuals of observed variables (2)\n\n# Evaluation of Partial Invariance of Residuals of observed variables\nanova(m.rvo.P,m.scal.P) # Note: Comparison model Partial Scalar invariance\n\n\nChi-Squared Difference Test\n\n         Df   AIC   BIC  Chisq Chisq diff RMSEA Df diff Pr(&gt;Chisq)\nm.scal.P 49 11245 11389 100.17                                    \nm.rvo.P  55 11235 11357 102.42     2.2458     0       6     0.8958\n\nfitMeasures(m.rvo.P,\"cfi\")-fitMeasures(m.scal.P,\"cfi\")\n\n  cfi \n0.003 \n\nfitMeasures(m.rvo.P,\"bic\")-fitMeasures(m.scal.P,\"bic\")\n\n    bic \n-31.977 \n\n# Paartial Invariance of Residuals of observed variables\n# is satisfactory.\n# Question: What can we say about overall\n# Measurement Invariance of the baseline theoretical model?"
  },
  {
    "objectID": "slides/04_invariance.html#invariance-of-variance-of-latent-variables-1",
    "href": "slides/04_invariance.html#invariance-of-variance-of-latent-variables-1",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Invariance of Variance of latent variables (1)",
    "text": "Invariance of Variance of latent variables (1)\n\nm.vvl=cfa(model,dmg,group=\"diagnosis\",\n          group.equal=c(\"loadings\",\"intercepts\",\"residuals\",\n                        \"lv.variances\"),\n          group.partial=c(\"Sim~1\",\"PicComp~~PicComp\",\"Comp~~Comp\"))\n# Fit indices\nfitMeasures(m.vvl,c(\"chisq\",\"df\",\"rmsea\",\"cfi\",\"nnfi\"))\n\n  chisq      df   rmsea     cfi    nnfi \n105.825  57.000   0.076   0.959   0.959"
  },
  {
    "objectID": "slides/04_invariance.html#invariance-of-variance-of-latent-variables-2",
    "href": "slides/04_invariance.html#invariance-of-variance-of-latent-variables-2",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Invariance of Variance of latent variables (2)",
    "text": "Invariance of Variance of latent variables (2)\n\n# Evaluation of Invariance of latent variables\nanova(m.vvl,m.rvo.P)\n\n\nChi-Squared Difference Test\n\n        Df   AIC   BIC  Chisq Chisq diff    RMSEA Df diff Pr(&gt;Chisq)\nm.rvo.P 55 11235 11357 102.42                                       \nm.vvl   57 11234 11349 105.83     3.4056 0.068449       2     0.1822\n\nfitMeasures(m.vvl,\"cfi\")-fitMeasures(m.rvo.P,\"cfi\")\n\n   cfi \n-0.001 \n\nfitMeasures(m.vvl,\"bic\")-fitMeasures(m.rvo.P,\"bic\")\n\n   bic \n-8.002 \n\n# OK, this looks good!"
  },
  {
    "objectID": "slides/04_invariance.html#invariance-of-covariance-of-latent-variables-1",
    "href": "slides/04_invariance.html#invariance-of-covariance-of-latent-variables-1",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Invariance of Covariance of latent variables (1)",
    "text": "Invariance of Covariance of latent variables (1)\n\nm.cvl=cfa(model,dmg,group=\"diagnosis\",\n          group.equal=c(\"loadings\",\"intercepts\"\n                        ,\"residuals\",\"lv.variances\",\"lv.covariances\"),\n          group.partial=c(\"Sim~1\",\"PicComp~~PicComp\",\"Comp~~Comp\"))\n# Fit indices\nfitMeasures(m.cvl,c(\"chisq\",\"df\",\"rmsea\",\"cfi\",\"nnfi\"))\n\n  chisq      df   rmsea     cfi    nnfi \n106.412  58.000   0.075   0.959   0.960"
  },
  {
    "objectID": "slides/04_invariance.html#invariance-of-covariance-of-latent-variables2",
    "href": "slides/04_invariance.html#invariance-of-covariance-of-latent-variables2",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Invariance of Covariance of latent variables(2)",
    "text": "Invariance of Covariance of latent variables(2)\n\n# Evaluation of Invariance of Covariance of latent variables\nanova(m.cvl,m.vvl)\n\n\nChi-Squared Difference Test\n\n      Df   AIC   BIC  Chisq Chisq diff RMSEA Df diff Pr(&gt;Chisq)\nm.vvl 57 11234 11349 105.83                                    \nm.cvl 58 11233 11344 106.41    0.58642     0       1     0.4438\n\nfitMeasures(m.cvl,\"cfi\")-fitMeasures(m.vvl,\"cfi\")\n\ncfi \n  0 \n\nfitMeasures(m.cvl,\"bic\")-fitMeasures(m.vvl,\"bic\")\n\n   bic \n-5.117 \n\n# OK, we're almost there!"
  },
  {
    "objectID": "slides/04_invariance.html#invariance-of-means-of-latent-variables-1",
    "href": "slides/04_invariance.html#invariance-of-means-of-latent-variables-1",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Invariance of Means of latent variables (1)",
    "text": "Invariance of Means of latent variables (1)\n\n# last step\nm.med=cfa(model,dmg,group=\"diagnosis\",\n          group.equal=c(\"loadings\",\"intercepts\"\n                        ,\"residuals\",\"lv.variances\",\"lv.covariances\",\n                        \"means\"),\n          group.partial=c(\"Sim~1\",\"PicComp~~PicComp\",\"Comp~~Comp\"))\n# Fit indices\nfitMeasures(m.med,c(\"chisq\",\"df\",\"rmsea\",\"cfi\",\"nnfi\"))\n\n  chisq      df   rmsea     cfi    nnfi \n110.933  60.000   0.075   0.957   0.960"
  },
  {
    "objectID": "slides/04_invariance.html#invariance-of-means-of-latent-variables-2",
    "href": "slides/04_invariance.html#invariance-of-means-of-latent-variables-2",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Invariance of Means of latent variables (2)",
    "text": "Invariance of Means of latent variables (2)\n\n# Evaluation of Invariance of Means of latent variables\nanova(m.med,m.cvl)\n\n\nChi-Squared Difference Test\n\n      Df   AIC   BIC  Chisq Chisq diff    RMSEA Df diff Pr(&gt;Chisq)\nm.cvl 58 11233 11344 106.41                                       \nm.med 60 11234 11337 110.93     4.5212 0.091673       2     0.1043\n\nfitMeasures(m.med,\"cfi\")-fitMeasures(m.cvl,\"cfi\")\n\n   cfi \n-0.002 \n\nfitMeasures(m.med,\"bic\")-fitMeasures(m.cvl,\"bic\")\n\n   bic \n-6.886 \n\n# This last model is also satisfactory\n# ANY COMMENTS?"
  },
  {
    "objectID": "slides/04_invariance.html#summing-up",
    "href": "slides/04_invariance.html#summing-up",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Summing up",
    "text": "Summing up\n\n\n\n\n\nModels\nnpar\ndf\nchisq\ncfi\ntli\nnnfi\nagfi\nsrmr\nrmsea\nbic\naic\n\n\n\n\nManics\n17\n19\n54.05\n0.95\n0.92\n0.92\n0.84\n0.05\n0.11\n5590.65\n5539.47\n\n\nNorming\n17\n19\n18.15\n1\n1\n1\n0.94\n0.03\n0\n5718.64\n5667.46\n\n\nConfigural\n50\n38\n72.2\n0.97\n0.96\n0.96\n0.98\n0.04\n0.08\n11424.11\n11238.93\n\n\nMetric\n44\n44\n88.15\n0.96\n0.95\n0.95\n0.98\n0.06\n0.08\n11405.84\n11242.88\n\n\nScalar\n38\n50\n144.67\n0.92\n0.91\n0.91\n0.97\n0.08\n0.11\n11428.13\n11287.39\n\n\nScalar Partial\n39\n49\n100.17\n0.96\n0.95\n0.95\n0.98\n0.07\n0.08\n11389.34\n11244.9\n\n\nResidual Variances\n31\n57\n127.34\n0.94\n0.94\n0.94\n0.98\n0.08\n0.09\n11370.88\n11256.07\n\n\nResidual Variances Partial\n33\n55\n102.42\n0.96\n0.96\n0.96\n0.98\n0.07\n0.08\n11357.37\n11235.14\n\n\nLatent Variances\n31\n57\n105.83\n0.96\n0.96\n0.96\n0.98\n0.09\n0.08\n11349.36\n11234.55\n\n\nLatent Covariances\n30\n58\n106.41\n0.96\n0.96\n0.96\n0.98\n0.09\n0.07\n11344.25\n11233.13\n\n\nLatent Means\n28\n60\n110.93\n0.96\n0.96\n0.96\n0.98\n0.09\n0.08\n11337.36\n11233.66\n\n\n\n\n\nInterpretations, comments, or questions?"
  },
  {
    "objectID": "slides/04_invariance.html#to-combine-usefulness-and-fun",
    "href": "slides/04_invariance.html#to-combine-usefulness-and-fun",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "To combine usefulness and fun …",
    "text": "To combine usefulness and fun …\nGraphical representation of the Configural Invariance model with standardized parameters (attached R code)\n\nExcercise: Graphically represent the former invariance models using the function semPaths of the package semPlot"
  },
  {
    "objectID": "slides/04_invariance.html#invariance-of-regression-coefficients",
    "href": "slides/04_invariance.html#invariance-of-regression-coefficients",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Invariance of regression coefficients",
    "text": "Invariance of regression coefficients\nTest of multigroup invariance can also be used to compare differences in the regression coefficients of two or more groups."
  },
  {
    "objectID": "slides/04_invariance.html#invariance-of-regression-coefficients-1",
    "href": "slides/04_invariance.html#invariance-of-regression-coefficients-1",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Invariance of regression coefficients",
    "text": "Invariance of regression coefficients\nFollowing the same steps of the previous example, we can add the \"regressions\" to the group.equal argument.\n\nfitPreg &lt;- sem(path, d, group = \"group\",\n               group.equal = \"regressions\")\n\nYou can apply this to a path model with manifest variables only or to a full SEM after measurement invariance is tested.\nQUESTIONS? LET'S SEE THE \"code\""
  },
  {
    "objectID": "slides/04_invariance.html#useful-references",
    "href": "slides/04_invariance.html#useful-references",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Useful references",
    "text": "Useful references\n\nBeaujean, Freeman, Youngstrom & Carlson (2012). The structure of cognitive abilities in youths with manic symptoms: a factorial invariance study. Assessment, 19, 462 - 471\n\nNon-invariance materials were directly taken from the wonderful blogpost of Julia Rohrer. READ IT!\nHow much is invariance disregarded?\nProtzko’s humorous preprint on what we can actually claim with measurement invariance…without good measures!\nlavaan.ugent.be/tutorial/groups.html\nwww.structuralequations.com/\n\nbut also some controversies\n… more controversies"
  },
  {
    "objectID": "slides/04_invariance.html#contact",
    "href": "slides/04_invariance.html#contact",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Contact",
    "text": "Contact\ntommaso.feraco@unipd.it"
  },
  {
    "objectID": "slides/04_invariance.html#references",
    "href": "slides/04_invariance.html#references",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "slides/05_ordinal.html#credits",
    "href": "slides/05_ordinal.html#credits",
    "title": "SEM with ordinal variables",
    "section": "Credits",
    "text": "Credits\nCredits to Prof. Massimiliano Pastore for the original slides."
  },
  {
    "objectID": "slides/05_ordinal.html#outline",
    "href": "slides/05_ordinal.html#outline",
    "title": "SEM with ordinal variables",
    "section": "Outline",
    "text": "Outline\n\nIntroduction\nIn lavaan\nModel fit\nMG-CFA with ordinal data"
  },
  {
    "objectID": "slides/05_ordinal.html#introduction",
    "href": "slides/05_ordinal.html#introduction",
    "title": "SEM with ordinal variables",
    "section": "Introduction",
    "text": "Introduction\nIn psychology we rarely have data that are normally distributed or that follow a continuous distribution. Our data are probably ordinal or the consequence of ordinal/dichotomous processes:\n\nset.seed(42); n=10000; items = 30;\nscore &lt;- rbinom(n,items, rnorm(n,.80,.10))\n\n\nCOMMENTS?"
  },
  {
    "objectID": "slides/05_ordinal.html#introduction-1",
    "href": "slides/05_ordinal.html#introduction-1",
    "title": "SEM with ordinal variables",
    "section": "Introduction",
    "text": "Introduction\nHowever, we postulate that they are generated from continuous normal latent distributions\n\nCOMMENTS?"
  },
  {
    "objectID": "slides/05_ordinal.html#likert-scales",
    "href": "slides/05_ordinal.html#likert-scales",
    "title": "SEM with ordinal variables",
    "section": "Likert scales",
    "text": "Likert scales\nThis also applies to Liker scales, where the difference between reporting a score of 1 or 2, and the difference between reporting a score of 2 or 3 is not the same!"
  },
  {
    "objectID": "slides/05_ordinal.html#the-adaptability-data",
    "href": "slides/05_ordinal.html#the-adaptability-data",
    "title": "SEM with ordinal variables",
    "section": "The adaptability data",
    "text": "The adaptability data\nAnd in real data they are often not normally distributed"
  },
  {
    "objectID": "slides/05_ordinal.html#wrong-correlations",
    "href": "slides/05_ordinal.html#wrong-correlations",
    "title": "SEM with ordinal variables",
    "section": "Wrong correlations",
    "text": "Wrong correlations\nUnfortunately, when we use data that follow discrete distributions and treat them as they were continuous, we can fail to recreate true correlation matrices accurately. That’s why you usually use polychoric correlations when you calculate correlations with dichotomous or ordinal variables.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData were generated from a multivariate normal distribution using MASS::mvrnorm and then manually truncated on a 3-point scale\nThis, of course, has consequences on SEM parameters, which are based on covariance"
  },
  {
    "objectID": "slides/05_ordinal.html#in-lavaan-and-sem",
    "href": "slides/05_ordinal.html#in-lavaan-and-sem",
    "title": "SEM with ordinal variables",
    "section": "In lavaan and SEM",
    "text": "In lavaan and SEM\nTo estimate a model treating items/observations as ordinal data, we need to change the estimationd method - ML is not always accurate with ordinal data (especially with few categories) - lavaan, when ordered is TRUE, automatically use DWLS (diagonally weighted least squares) - A great alternative is ULS, which usually performs better, but has more convergence problems - We can also use robust ML alternatives, like MLR - Other available estimators: lavaan tutorial on estimators (see course site)"
  },
  {
    "objectID": "slides/05_ordinal.html#how-to-fit-a-cfa-with-ordinal-data",
    "href": "slides/05_ordinal.html#how-to-fit-a-cfa-with-ordinal-data",
    "title": "SEM with ordinal variables",
    "section": "How to fit a CFA with ordinal data",
    "text": "How to fit a CFA with ordinal data\n\nlibrary(lavaan)\n\n\n# THE MODEL IS SPECIFIED AS USUAL\nmOrd &lt;- \"\ncb =~ Adaptability_1 + Adaptability_2 + Adaptability_3 + \n      Adaptability_4 + Adaptability_5 + Adaptability_6\nem =~ Adaptability_7 + Adaptability_8 + Adaptability_9\nem ~~ cb\n\"\n# WE JUST NEED TO ADD\nfitOrd &lt;- sem(mOrd, D.ad, std.lv=T,\n              estimator = \"ULS\", # optional\n              ordered = colnames(D.ad)) # the list of ord vars\n#             ordered = T) # or just \"TRUE\" if all ordered"
  },
  {
    "objectID": "slides/05_ordinal.html#results-1",
    "href": "slides/05_ordinal.html#results-1",
    "title": "SEM with ordinal variables",
    "section": "Results (1)",
    "text": "Results (1)\n\ntemp = capture.output(summary(fitOrd, std=T))\ncat(c(temp[1:21], \"[...]\"), sep = \"\\n\")\n\nlavaan 0.6-19 ended normally after 16 iterations\n\n  Estimator                                        ULS\n  Optimization method                           NLMINB\n  Number of model parameters                        64\n\n                                                  Used       Total\n  Number of observations                          1044        1083\n\nModel Test User Model:\n                                                      \n  Test statistic                                73.746\n  Degrees of freedom                                26\n  P-value (Unknown)                                 NA\n\nParameter Estimates:\n\n  Parameterization                               Delta\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model        Unstructured\n[...]"
  },
  {
    "objectID": "slides/05_ordinal.html#results-2",
    "href": "slides/05_ordinal.html#results-2",
    "title": "SEM with ordinal variables",
    "section": "Results (2)",
    "text": "Results (2)\n\n\n[...]\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  cb =~                                                                 \n    Adaptability_1    0.659    0.021   30.831    0.000    0.659    0.659\n    Adaptability_2    0.659    0.021   30.841    0.000    0.659    0.659\n    Adaptability_3    0.664    0.021   30.983    0.000    0.664    0.664\n    Adaptability_4    0.551    0.020   26.957    0.000    0.551    0.551\n    Adaptability_5    0.619    0.021   29.486    0.000    0.619    0.619\n    Adaptability_6    0.553    0.020   27.012    0.000    0.553    0.553\n  em =~                                                                 \n    Adaptability_7    0.642    0.026   24.949    0.000    0.642    0.642\n    Adaptability_8    0.671    0.026   25.513    0.000    0.671    0.671\n    Adaptability_9    0.699    0.027   25.983    0.000    0.699    0.699\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  cb ~~                                                                 \n    em                0.587    0.022   26.729    0.000    0.587    0.587\n[...]"
  },
  {
    "objectID": "slides/05_ordinal.html#results-3",
    "href": "slides/05_ordinal.html#results-3",
    "title": "SEM with ordinal variables",
    "section": "Results (3)",
    "text": "Results (3)\n\n\n[...]\n\nThresholds:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n    Adaptblty_1|t1   -2.114    0.031  -68.285    0.000   -2.114   -2.114\n    Adaptblty_1|t2   -1.647    0.031  -53.181    0.000   -1.647   -1.647\n    Adaptblty_1|t3   -1.056    0.031  -34.089    0.000   -1.056   -1.056\n    Adaptblty_1|t4   -0.320    0.031  -10.331    0.000   -0.320   -0.320\n    Adaptblty_1|t5    0.495    0.031   15.982    0.000    0.495    0.495\n    Adaptblty_1|t6    1.181    0.031   38.145    0.000    1.181    1.181\n    Adaptblty_2|t1   -2.071    0.031  -66.899    0.000   -2.071   -2.071\n    Adaptblty_2|t2   -1.421    0.031  -45.908    0.000   -1.421   -1.421\n    Adaptblty_2|t3   -0.794    0.031  -25.642    0.000   -0.794   -0.794\n    Adaptblty_2|t4   -0.188    0.031   -6.084    0.000   -0.188   -0.188\n    Adaptblty_2|t5    0.492    0.031   15.895    0.000    0.492    0.492\n    Adaptblty_2|t6    1.257    0.031   40.590    0.000    1.257    1.257\n    Adaptblty_3|t1   -1.930    0.031  -62.322    0.000   -1.930   -1.930\n    Adaptblty_3|t2   -1.415    0.031  -45.696    0.000   -1.415   -1.415\n    Adaptblty_3|t3   -0.858    0.031  -27.715    0.000   -0.858   -0.858\n    Adaptblty_3|t4   -0.250    0.031   -8.070    0.000   -0.250   -0.250\n    Adaptblty_3|t5    0.350    0.031   11.316    0.000    0.350    0.350\n    Adaptblty_3|t6    1.162    0.031   37.529    0.000    1.162    1.162\n[...]"
  },
  {
    "objectID": "slides/05_ordinal.html#results-4",
    "href": "slides/05_ordinal.html#results-4",
    "title": "SEM with ordinal variables",
    "section": "Results (4)",
    "text": "Results (4)\n\n\n[...]\n    Adaptblty_4|t1   -1.962    0.031  -63.351    0.000   -1.962   -1.962\n    Adaptblty_4|t2   -1.476    0.031  -47.680    0.000   -1.476   -1.476\n    Adaptblty_4|t3   -0.817    0.031  -26.393    0.000   -0.817   -0.817\n    Adaptblty_4|t4   -0.257    0.031   -8.310    0.000   -0.257   -0.257\n    Adaptblty_4|t5    0.295    0.031    9.518    0.000    0.295    0.295\n    Adaptblty_4|t6    1.094    0.031   35.332    0.000    1.094    1.094\n    Adaptblty_5|t1   -1.978    0.031  -63.891    0.000   -1.978   -1.978\n    Adaptblty_5|t2   -1.408    0.031  -45.486    0.000   -1.408   -1.408\n    Adaptblty_5|t3   -0.781    0.031  -25.219    0.000   -0.781   -0.781\n    Adaptblty_5|t4   -0.196    0.031   -6.321    0.000   -0.196   -0.196\n    Adaptblty_5|t5    0.397    0.031   12.812    0.000    0.397    0.397\n    Adaptblty_5|t6    1.081    0.031   34.912    0.000    1.081    1.081\n    Adaptblty_6|t1   -1.705    0.031  -55.076    0.000   -1.705   -1.705\n    Adaptblty_6|t2   -1.186    0.031  -38.302    0.000   -1.186   -1.186\n    Adaptblty_6|t3   -0.654    0.031  -21.106    0.000   -0.654   -0.654\n    Adaptblty_6|t4   -0.055    0.031   -1.784    0.074   -0.055   -0.055\n    Adaptblty_6|t5    0.519    0.031   16.776    0.000    0.519    0.519\n    Adaptblty_6|t6    1.211    0.031   39.097    0.000    1.211    1.211\n[...]\n[...]"
  },
  {
    "objectID": "slides/05_ordinal.html#thresholds-1",
    "href": "slides/05_ordinal.html#thresholds-1",
    "title": "SEM with ordinal variables",
    "section": "Thresholds (1)",
    "text": "Thresholds (1)\n\nWe can assume that a discrete variable \\(x\\) (expressed with \\(k\\) ordered categories) represents an approximation of a continuous latent variable \\(\\xi\\), normally distributed with mean 0.\nTherefore, when we observe \\(x = i\\), it means that the true corresponding value \\(\\xi\\) is ranging between two values, i.e.\n\n\\[\n\\alpha_{i-1} &lt; \\xi \\leq \\alpha_i\n\\] where \\(\\alpha_0 = - \\infty, \\alpha_1 &lt; \\alpha_2 &lt; \\dots &lt; \\alpha_{k-1}\\) e \\(\\alpha_k = +\\infty\\) are the thresholds - Consequenlty we will have that, given a discrete ordered variable with \\(k\\) possible values, there are \\(k - 1\\) unknown thresholds."
  },
  {
    "objectID": "slides/05_ordinal.html#thresholds-2",
    "href": "slides/05_ordinal.html#thresholds-2",
    "title": "SEM with ordinal variables",
    "section": "Thresholds (2)",
    "text": "Thresholds (2)\nThresholds represent the link between the (continuous) latent variable \\(\\xi\\) and the observed values (on a discrete scale).\nFor example, the item Adaptability_1\n\n\n[1] -2.11 -1.65 -1.06 -0.32  0.49  1.18\n\n\nThat we can manually compute as:\n\nround(qnorm(cumsum(table(D.ad$Adaptability_1)) /\n             sum(table(D.ad$Adaptability_1))),2)\n\n    1     2     3     4     5     6     7 \n-2.12 -1.65 -1.06 -0.32  0.49  1.18   Inf"
  },
  {
    "objectID": "slides/05_ordinal.html#results-5",
    "href": "slides/05_ordinal.html#results-5",
    "title": "SEM with ordinal variables",
    "section": "Results (5)",
    "text": "Results (5)\n\n\n[...]\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .Adaptability_1    0.566                               0.566    0.566\n   .Adaptability_2    0.565                               0.565    0.565\n   .Adaptability_3    0.559                               0.559    0.559\n   .Adaptability_4    0.696                               0.696    0.696\n   .Adaptability_5    0.616                               0.616    0.616\n   .Adaptability_6    0.695                               0.695    0.695\n   .Adaptability_7    0.588                               0.588    0.588\n   .Adaptability_8    0.550                               0.550    0.550\n   .Adaptability_9    0.511                               0.511    0.511\n    cb                1.000                               1.000    1.000\n    em                1.000                               1.000    1.000\n\n[...]"
  },
  {
    "objectID": "slides/05_ordinal.html#model-fit",
    "href": "slides/05_ordinal.html#model-fit",
    "title": "SEM with ordinal variables",
    "section": "Model fit",
    "text": "Model fit\nThis works as usual\n\nfi &lt;- c(\"npar\", \"df\", \"chisq\", \n        \"cfi\", \"tli\", \"nnfi\", \"agfi\", \n        \"srmr\", \"rmsea\", \"bic\", \"aic\")\nfitmeasures(fitOrd, fit.measures = fi)\n# OR inspect(fitOrd, \"fit\")[fi]\n\n\n\n    npar       df    chisq \n64.00000 26.00000 73.74574 \n\n\n      cfi       tli      nnfi      agfi \n0.9883022 0.9838030 0.9838030 0.9964375 \n\n\n      srmr      rmsea        bic        aic \n0.03963876 0.04196029         NA         NA \n\n\nBUT YOU CANNOT INTERPRET THEM AS WE USED TO DO!"
  },
  {
    "objectID": "slides/05_ordinal.html#model-fit-references",
    "href": "slides/05_ordinal.html#model-fit-references",
    "title": "SEM with ordinal variables",
    "section": "Model fit, references",
    "text": "Model fit, references\nSome references for model fit with ordinal data: - RMSEA (doi:10.1080/10705511.2019.1611434) tends to reject models with large datasets and 5-point scales - CFI and TLI tend to overestimate model fit - SRMR seems to be less biased\nBut there are many contradictory suggestions and it is not easy to navigate them. Look for what you need as simulation studies depend on many variables.\nThis (doi:10.1027/2698-1866/a000034) might be a helpful summary/reflection."
  },
  {
    "objectID": "slides/05_ordinal.html#reviewer-2",
    "href": "slides/05_ordinal.html#reviewer-2",
    "title": "SEM with ordinal variables",
    "section": "Reviewer 2",
    "text": "Reviewer 2"
  },
  {
    "objectID": "slides/05_ordinal.html#prerequisites",
    "href": "slides/05_ordinal.html#prerequisites",
    "title": "SEM with ordinal variables",
    "section": "Prerequisites",
    "text": "Prerequisites\nWhen we test multigroup invariance with ordinal data we assume that the THRESHOLDS are also equal between the two groups, but before running the analysis, remember: - the number of parameters is higher than with continuous data…and you split the data in two or more parts! Be sure you have enough data in each group - all the observed indicators hold the same categories in each group, otherwise you cannot fit the model"
  },
  {
    "objectID": "slides/05_ordinal.html#steps",
    "href": "slides/05_ordinal.html#steps",
    "title": "SEM with ordinal variables",
    "section": "Steps",
    "text": "Steps\nThe steps that you should follow fo MG-CFA with ordinal data are slightly different: - Baseline model, as the configural model - Equal thresholds model, you should start by forcing the thresholds to be equal across groups - Equal loadings and thresholds model, only now you can fix the loadings to be equal across groups"
  },
  {
    "objectID": "slides/05_ordinal.html#in-r",
    "href": "slides/05_ordinal.html#in-r",
    "title": "SEM with ordinal variables",
    "section": "In R",
    "text": "In R\nI use again the adaptability items. I manually added a group variable.\n\nD.ad$group &lt;- c(rep(\"G1\", 428), rep(\"G2\", 1083-428))\n# 1. FIT THE BASELINE/CONFIGURAL MODEL\nfConf &lt;- sem(mOrd, D.ad, std.lv=T, estimator = \"ULS\",\n             ordered = T, group = \"group\")\n# 2. FIT THE FIXED THRESHOLDS MODEL\nfTresh&lt;- sem(mOrd, D.ad, std.lv=T, estimator = \"ULS\",\n             ordered = T, group = \"group\",\n             group.equal = c(\"thresholds\"))\n# 3. FIT THE FIXED LOADINGS MODEL\nfLoad &lt;- sem(mOrd, D.ad, std.lv=T, estimator = \"ULS\",\n             ordered = T, group = \"group\",\n             group.equal = c(\"thresholds\", \"loadings\"))"
  },
  {
    "objectID": "slides/05_ordinal.html#model-fit-comparison",
    "href": "slides/05_ordinal.html#model-fit-comparison",
    "title": "SEM with ordinal variables",
    "section": "Model fit comparison",
    "text": "Model fit comparison\n\nfitTable &lt;- rbind(fitmeasures(fConf, fi),\n                  fitmeasures(fTresh, fi),\n                  fitmeasures(fLoad, fi))\n\n\n\n\n\nnpar\ndf\nchisq\ncfi\ntli\nnnfi\nagfi\nsrmr\nrmsea\nbic\naic\n\n\n\n\nbaseline\n128\n52\n91.652\n0.990\n0.987\n0.987\n0.996\n0.044\n0.038\nNA\nNA\n\n\nthresholds\n85\n95\n166.552\n0.983\n0.987\n0.987\n0.996\n0.044\n0.038\nNA\nNA\n\n\nloadings\n78\n102\n173.785\n0.983\n0.988\n0.988\n0.996\n0.046\n0.037\nNA\nNA"
  },
  {
    "objectID": "slides/05_ordinal.html#model-results",
    "href": "slides/05_ordinal.html#model-results",
    "title": "SEM with ordinal variables",
    "section": "Model results",
    "text": "Model results\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGroup 1\n\n\n\nGroup 2\n\n\n\nlhs\nop\nrhs\nest\n||\nlhs\nop\nrhs\nest\n\n\n\n\nLoadings\n\n\ncb\n=~\nAdaptability_1\n0.69\n||\ncb\n=~\nAdaptability_1\n0.64\n\n\ncb\n=~\nAdaptability_2\n0.69\n||\ncb\n=~\nAdaptability_2\n0.64\n\n\ncb\n=~\nAdaptability_3\n0.70\n||\ncb\n=~\nAdaptability_3\n0.64\n\n\ncb\n=~\nAdaptability_4\n0.54\n||\ncb\n=~\nAdaptability_4\n0.56\n\n\ncb\n=~\nAdaptability_5\n0.66\n||\ncb\n=~\nAdaptability_5\n0.59\n\n\ncb\n=~\nAdaptability_6\n0.65\n||\ncb\n=~\nAdaptability_6\n0.49\n\n\nem\n=~\nAdaptability_7\n0.66\n||\nem\n=~\nAdaptability_7\n0.63\n\n\nem\n=~\nAdaptability_8\n0.67\n||\nem\n=~\nAdaptability_8\n0.67\n\n\nem\n=~\nAdaptability_9\n0.73\n||\nem\n=~\nAdaptability_9\n0.67\n\n\nLatent covariance\n\n\ncb\n~~\nem\n0.62\n||\ncb\n~~\nem\n0.56\n\n\nThresholds\n\n\nAdaptability_1\n|\nt1\n-2.13\n||\nAdaptability_1\n|\nt1\n-2.11\n\n\nAdaptability_1\n|\nt2\n-1.69\n||\nAdaptability_1\n|\nt2\n-1.62\n\n\nAdaptability_1\n|\nt3\n-1.06\n||\nAdaptability_1\n|\nt3\n-1.05\n\n\nAdaptability_1\n|\nt4\n-0.36\n||\nAdaptability_1\n|\nt4\n-0.30\n\n\nAdaptability_1\n|\nt5\n0.52\n||\nAdaptability_1\n|\nt5\n0.48\n\n\nAdaptability_1\n|\nt6\n1.14\n||\nAdaptability_1\n|\nt6\n1.21"
  },
  {
    "objectID": "slides/05_ordinal.html#additional-materials",
    "href": "slides/05_ordinal.html#additional-materials",
    "title": "SEM with ordinal variables",
    "section": "Additional materials",
    "text": "Additional materials\n\nSvetina et al. (doi:10.1080/10705511.2019.1602776) tutorial, suggestions, and model fit recommendations for MG-CFA with ordinal data\nEnrico Perinelli held a psicostat meeting on the topic following Svetina et al.’s code"
  },
  {
    "objectID": "slides/05_ordinal.html#contacts",
    "href": "slides/05_ordinal.html#contacts",
    "title": "SEM with ordinal variables",
    "section": "Contacts",
    "text": "Contacts\ntommaso.feraco@unipd.it"
  },
  {
    "objectID": "extras/ex90_power_misc.html#outline",
    "href": "extras/ex90_power_misc.html#outline",
    "title": "Power analysis for path and SEM models",
    "section": "Outline",
    "text": "Outline\n\nPower\nfor loops\nPath analysis — an example\nPower for model selection"
  },
  {
    "objectID": "extras/ex90_power_misc.html#power",
    "href": "extras/ex90_power_misc.html#power",
    "title": "Power analysis for path and SEM models",
    "section": "Power",
    "text": "Power\nWe can define power as the probability to reject the null hypothesis (\\(H_0\\)) when the hypothesized alternative hypothesis (\\(H_{1}\\)) is true.\nIt usually depends on:\n\nPrecision of the measurements\nPrecision of the effects\nSize of the (hypothesized) effect\nSample size\nNumber of effects of interest\n\\(\\alpha\\) level (e.g., .05, or the probability of making a type I error)\n\\(\\beta\\) level (e.g., .80, or the probability of making a type II error)\n\nIf we do not have the power, our results are inconclusive and estimates, in case we reject \\(H_0\\), inflated."
  },
  {
    "objectID": "extras/ex90_power_misc.html#calculating-the-power",
    "href": "extras/ex90_power_misc.html#calculating-the-power",
    "title": "Power analysis for path and SEM models",
    "section": "Calculating the power",
    "text": "Calculating the power\nFor power calculations we can:\n\nApply specific formulas\nUse monograms\nUse apps\n[…]\n\nSimulate data!"
  },
  {
    "objectID": "extras/ex90_power_misc.html#calculating-power-for-sem",
    "href": "extras/ex90_power_misc.html#calculating-power-for-sem",
    "title": "Power analysis for path and SEM models",
    "section": "Calculating power for SEM",
    "text": "Calculating power for SEM\nIn a SEM framework there are many ways to calculate power via simulation. We will only implement it manually in R. Here a list of alternatives:\n\nIf you want to detect specific effects\n\nUse the pwrSEM shiny app (Wang et al., 2021): https://doi.org/10.1177/2515245920918253\n\nUse simsem package (lavaan objects): https://simsem.org/ (see also Beaujean, 2014, chapter 8)\n\n[…]\n\nIf you want to detect model misspecification / fit\n\nUse semPower package\n\nUse the power4SEM shiny app (Jak et al., 2021): https://doi.org/10.3758/s13428-020-01479-0\n\nSatorra & Saris (1985)\n\nUse MBESS functions for power (e.g., ss.aipe.rmsea(); ss.aipe.sem.path(); ss.power.sem())\n\n[…]\n\n\nOr you can apply rules of thumb that recommend either absolute minimum sample sizes (e.g., \\(N = 100\\) or \\(200\\); Boomsma, 1982, 1985) or sample sizes based on model complexity (e.g., \\(n = 5\\)–\\(10\\) per estimated parameter; Bentler & Chou, 1987; \\(n = 3\\)–\\(6\\) per variable; Cattell, 1978) BUT, NO, PLEASE!"
  },
  {
    "objectID": "extras/ex90_power_misc.html#what-is-this",
    "href": "extras/ex90_power_misc.html#what-is-this",
    "title": "Power analysis for path and SEM models",
    "section": "What is this?",
    "text": "What is this?\n\n\nThis is a loop!"
  },
  {
    "objectID": "extras/ex90_power_misc.html#for-loops",
    "href": "extras/ex90_power_misc.html#for-loops",
    "title": "Power analysis for path and SEM models",
    "section": "for loops",
    "text": "for loops\nA fundamental skill that you should possess is doing for (or while) cycles in R. This is crucial for estimating power via simulation, but also for many other ordinary analyses."
  },
  {
    "objectID": "extras/ex90_power_misc.html#what-you-can-do",
    "href": "extras/ex90_power_misc.html#what-you-can-do",
    "title": "Power analysis for path and SEM models",
    "section": "What you can do",
    "text": "What you can do\nWith a for loop you can iterate one or more action along a sequence of values. This values usually go from 1 to N, but can also be character or unordered sequences, or sequences of increasing but random numbers.\n\n\n\nfor(i in 1:3){\n  #Sys.sleep(0.5)\n  print(i)\n  print(\"Well done!\")\n}\n\n[1] 1\n[1] \"Well done!\"\n[1] 2\n[1] \"Well done!\"\n[1] 3\n[1] \"Well done!\"\n\n\n\n\ncomplimento &lt;- c(\"bravo\",\n                 \"very well\",\n                 \"wow\")\nfor(i in complimento){\n  #Sys.sleep(1)\n  print(paste0(i,\n               \"Tommaso\"))\n}\n\n[1] \"bravoTommaso\"\n[1] \"very wellTommaso\"\n[1] \"wowTommaso\"\n\n\n\n\niter &lt;- c(2,4,11)\nfor (i in iter) {\n  #Sys.sleep(0.5)\n  print(4 + i)\n}\n\n[1] 6\n[1] 8\n[1] 15"
  },
  {
    "objectID": "extras/ex90_power_misc.html#more-difficult",
    "href": "extras/ex90_power_misc.html#more-difficult",
    "title": "Power analysis for path and SEM models",
    "section": "…more difficult",
    "text": "…more difficult\n\nrm(list = ls())\niter &lt;- 100\nd &lt;- data.frame(exam = rep(NA, iter),\n                M = rep(NA, iter),\n                X = 1:iter)\nfor (i in 1:iter) {\n  # simulate an exam\n  d$exam[i] &lt;- sample(18:30, 1)\n  # calculate mean at each step\n  d$M[i] &lt;- mean(d$exam, na.rm = TRUE)\n}"
  },
  {
    "objectID": "extras/ex90_power_misc.html#for-loops-for-power-analysis",
    "href": "extras/ex90_power_misc.html#for-loops-for-power-analysis",
    "title": "Power analysis for path and SEM models",
    "section": "for loops for power analysis",
    "text": "for loops for power analysis\nIf we want to run a power analysis via simulation using a for loop, in general we need the following structure and elements:\n\n# A set of basic info\niter = 100 # number of desired iterations (i)\nN = 400 # the sample size we test\npopulation = 1e6\n\n# A population with hypothesized effects\nx = rnorm(population); z = rnorm(population) # predictors\ny = .30*x + .20*z + rnorm(population) # hypothetical model with ES\nd = data.frame(x, y, z)\n\n# A set of objects to store the results\np &lt;- c()\n\n# A model\nm &lt;- \"y ~ x + z\"\n\n# The loop with minimum three parts\nfor (i in 1:iter) {\n  # Data simulation/sampling\n  dfor &lt;- d[sample(1:nrow(d), N), ]\n  # Test\n  fit &lt;- sem(m, dfor)\n  # Storage\n  p[i] &lt;- parameterEstimates(fit)[1, \"pvalue\"]\n}\n\nmean(p &lt; .05) # calculate power\n\nYou can do the same thing with any model (lm, glm, m-clust, meta-analysis…)."
  },
  {
    "objectID": "extras/ex90_power_misc.html#the-question",
    "href": "extras/ex90_power_misc.html#the-question",
    "title": "Power analysis for path and SEM models",
    "section": "The question",
    "text": "The question\nDoes adaptability predict academic achievement?"
  },
  {
    "objectID": "extras/ex90_power_misc.html#a-simple-association",
    "href": "extras/ex90_power_misc.html#a-simple-association",
    "title": "Power analysis for path and SEM models",
    "section": "A simple association",
    "text": "A simple association\nH: adaptability directly influence achievement with an effect = .20.\n\nlibrary(lavaan)\nlibrary(MASS)\n\n# Generate and rename two correlated variables (r = .20)\nCovMat &lt;- lav_matrix_lower2full(c(\n  1,\n  .20, 1\n))\ncolnames(CovMat) &lt;- rownames(CovMat) &lt;- c(\"Ad\", \"Gp\")\n\n# The for cycle\nN = 200 # Is this N sufficient to have power?\niter = 500 # How many iterations we want?\np = c() # store p-values\nb = c() # store betas\n\nfor (i in 1:iter) {\n  # Simulate the data\n  db &lt;- as.data.frame(\n    mvrnorm(CovMat, n = N, mu = c(0, 0),\n            empirical = FALSE) # EMPIRICAL IS FALSE HERE!\n  )\n  # Fit the model\n  m &lt;- lm(Gp ~ Ad, data = db)\n  # Storage\n  p[i] &lt;- summary(m)$coefficients[\"Ad\", \"Pr(&gt;|t|)\"]\n  b[i] &lt;- summary(m)$coefficients[\"Ad\", \"Estimate\"]\n}\n\nmean(p &lt; .05)  # calculate power\nmean(b &gt; .15)  # ..."
  },
  {
    "objectID": "extras/ex90_power_misc.html#things-are-not-so-easy-in-the-real-world",
    "href": "extras/ex90_power_misc.html#things-are-not-so-easy-in-the-real-world",
    "title": "Power analysis for path and SEM models",
    "section": "Things are not so easy in the real world",
    "text": "Things are not so easy in the real world\nThere are too many things that are important for achievement to ignore them!\n\n# A more complete matrix Ad Em Se Sr Gp\nCovMat &lt;- lav_matrix_lower2full(c(\n  1,\n  .30, 1,\n  .40, .30, 1,\n  .40, .30, .35, 1,\n  .20, .15, .45, .30, 1\n))\ncolnames(CovMat) &lt;- rownames(CovMat) &lt;- c(\"Ad\", \"Em\", \"Se\", \"Sr\", \"Gp\")\n\n# For cycle\niter = 1000\nN = 5000\n\np = as.data.frame(matrix(nrow = iter, ncol = 5))\ncolnames(p) &lt;- c(\"intercept\", \"ad\", \"em\", \"se\", \"sr\")\n\nfor (i in 1:iter) {\n  db &lt;- data.frame(mvrnorm(n = N, mu = c(0, 0, 0, 0, 0),\n                           CovMat, empirical = FALSE))\n  m &lt;- lm(Gp ~ Ad + Em + Se + Sr, data = db)\n  p[i, ] &lt;- summary(m)$coefficients[, \"Pr(&gt;|t|)\"]\n}\n\ncolMeans(p &lt; .05)                       # power for each effect\nmean(rowSums(p[, 2:5] &lt; .05) == 4)      # power for all effects together"
  },
  {
    "objectID": "extras/ex90_power_misc.html#and-finally-a-path",
    "href": "extras/ex90_power_misc.html#and-finally-a-path",
    "title": "Power analysis for path and SEM models",
    "section": "and finally a path",
    "text": "and finally a path\nHowever, we know that all these variables interact and we also have a hypothetical pattern of associations that suggests that adaptability has no direct link to achievement. Adaptability is associated with achievement only through the mediation of emotions, self-efficacy, and self-regulation.\n\nlibrary(lavaan)\n\npath &lt;- \"\n\n# REGRESSIONS\nGp ~ em*Em + se*Se + sr*Sr\nEm ~ ae*Ad\nSe ~ as*Ad\nSr ~ ar*Ad\n\n# INDIRECT EFFECTS\nad_em := ae*em\nad_se := as*se\nad_sr := ar*sr\n\n\""
  },
  {
    "objectID": "extras/ex90_power_misc.html#and-its-power",
    "href": "extras/ex90_power_misc.html#and-its-power",
    "title": "Power analysis for path and SEM models",
    "section": "…and its power",
    "text": "…and its power\nWe want to test whether the indirect effects are significant. Nothing else!\n\niter = 1000\nN = 500\n\n# Store only the three indirect effects\nps = as.data.frame(matrix(nrow = iter, ncol = 3))\ncolnames(ps) &lt;- c(\"em\", \"se\", \"sr\")\n\nfor (i in 1:iter) {\n  db &lt;- data.frame(mvrnorm(n = N, mu = c(0, 0, 0, 0, 0),\n                           CovMat, empirical = FALSE))\n  fit &lt;- sem(path, data = db)\n  ps[i, ] &lt;- parameterEstimates(fit)[12:14, \"pvalue\"]\n}\n\ncolMeans(ps &lt; .05) # specific powers\ncolMeans(ps &lt; .01)\n\nmean(rowSums(ps &lt; .05) == 3) # total power: all 3 indirect effects\nmean(rowSums(ps[, c(\"se\", \"sr\")] &lt; .05) == 2)\nmean(rowSums(ps[, c(\"se\", \"sr\")] &lt; .01) == 2)\n\n\nQUESTIONS? COMMENTS?"
  },
  {
    "objectID": "extras/ex90_power_misc.html#simulate-from-the-process-and-not-the-correlation-matrix",
    "href": "extras/ex90_power_misc.html#simulate-from-the-process-and-not-the-correlation-matrix",
    "title": "Power analysis for path and SEM models",
    "section": "Simulate from the process and not the correlation matrix",
    "text": "Simulate from the process and not the correlation matrix\nWe simulated the covariance matrix directly from a correlation matrix.\n\nThis might be useless (you could make a meta-sem)\nYou understand less what’s going on behind the data"
  },
  {
    "objectID": "extras/ex90_power_misc.html#simulatedata-function",
    "href": "extras/ex90_power_misc.html#simulatedata-function",
    "title": "Power analysis for path and SEM models",
    "section": "simulateData() function",
    "text": "simulateData() function\nAn easy way to do all these steps is to use the simulateData() function in lavaan. This make it easier to simulate the data:\n\nlibrary(lavaan)\n\n# YOU JUST SPECIFY A MODEL WITH PARAMETERS\nsimM &lt;- \"\n Y ~ .20*x1 + .40*x2 + .15*x3\n x1 ~ .40*x2 + .30*x3\n\"\n\nd &lt;- simulateData(simM, sample.nobs = N)\nhead(d)"
  },
  {
    "objectID": "extras/ex90_power_misc.html#and-put-it-in-the-loop",
    "href": "extras/ex90_power_misc.html#and-put-it-in-the-loop",
    "title": "Power analysis for path and SEM models",
    "section": "and put it in the loop",
    "text": "and put it in the loop\n\nN = 100\niter = 1000\n\nm &lt;- \"\n Y ~ x1 + x2 + x3\n x1 ~ x2 + x3\n\"\n\nps = as.data.frame(matrix(nrow = iter, ncol = 3))\nfor (i in 1:iter) {\n  d &lt;- simulateData(simM, sample.nobs = N)\n  fit &lt;- sem(m, data = d)\n  ps[i, ] &lt;- parameterEstimates(fit)[1:3, \"pvalue\"]\n}\n\n\nQUESTIONS? COMMENTS?"
  },
  {
    "objectID": "extras/ex90_power_misc.html#iterate-with-a-while-loop",
    "href": "extras/ex90_power_misc.html#iterate-with-a-while-loop",
    "title": "Power analysis for path and SEM models",
    "section": "Iterate with a while loop",
    "text": "Iterate with a while loop\nIf you don’t want to manually change N each time, you can nest multiple for loops one into the other, or use a while loop.\n\niter = 1000        # How many interactions\np = c()            # Save only what we are interested in\npower_at_n = c(0)  # Here we calculate the power every time a cycle ends\nN = 5000           # The sample size of the first cycle\nk = 2              # This is only needed to make the while loop work\nsample = c()       # Just to keep track of the 'N' used\n\nwhile (power_at_n[k-1] &lt; 0.80) { # Until power_at_n reaches 0.80, we continue\n  for (i in 1:iter) {\n    db &lt;- data.frame(mvrnorm(n = N, mu = c(0, 0, 0, 0, 0),\n                             CovMat, empirical = FALSE))\n    m &lt;- lm(Gp ~ Ad + Em + Se + Sr, data = db)\n    p[i] &lt;- summary(m)$coefficients[2, 4]\n  }\n  power_at_n[k] &lt;- mean(p &lt; .05) # Calculate the power\n  sample[k-1] &lt;- N               # Save the used N\n  N = N + 500                    # Increase the sample size\n  k = k + 1                      # Move on to the next cycle\n}"
  },
  {
    "objectID": "extras/ex90_power_misc.html#results",
    "href": "extras/ex90_power_misc.html#results",
    "title": "Power analysis for path and SEM models",
    "section": "Results",
    "text": "Results\n\nplot(sample, power_at_n[-1], ylab = \"power\")\nabline(h = 0.80, col = \"red\")"
  },
  {
    "objectID": "extras/ex90_power_misc.html#model-comparison-power",
    "href": "extras/ex90_power_misc.html#model-comparison-power",
    "title": "Power analysis for path and SEM models",
    "section": "Model comparison power?",
    "text": "Model comparison power?\nThe same concepts of power for statistical significance can be applied to every analysis and statistics. It might be interesting for you to compare alternative models (e.g., hierarchical vs oblique model).\nHow to do it is pretty straightforward."
  },
  {
    "objectID": "extras/ex90_power_misc.html#the-theoretical-model",
    "href": "extras/ex90_power_misc.html#the-theoretical-model",
    "title": "Power analysis for path and SEM models",
    "section": "The theoretical model",
    "text": "The theoretical model\nLet’s say we have a four-factor structure with three items per factor. We will keep loadings always equal for simplicity.\n\n\n\n# PREPARE THE MODEL FOR SIMULATION\nset.seed(12)\nN &lt;- 450; l &lt;- .65\n\n# Step 1. Simulate the latent variables (hierarchical model)\nhfactor &lt;- rnorm(N)\n\n# Step 2. Simulate the four specific factors\ns1 &lt;- l*hfactor + rnorm(N); s2 &lt;- l*hfactor + rnorm(N)\ns3 &lt;- l*hfactor + rnorm(N); s4 &lt;- l*hfactor + rnorm(N)\n\n# Step 3. Simulate the items of each specific factor\nd &lt;- matrix(nrow = N, ncol = 12)\ncolnames(d) &lt;- paste0(\n  rep(c(\"s1\", \"s2\", \"s3\", \"s4\"), each = 3),\n  rep(c(\".1\", \".2\", \".3\"), 4)\n)\n\nfor (i in 1:3) {\n  d[, i]    &lt;- l*s1 + rnorm(N)\n  d[, i+3]  &lt;- l*s2 + rnorm(N)\n  d[, i+6]  &lt;- l*s3 + rnorm(N)\n  d[, i+9]  &lt;- l*s4 + rnorm(N)\n}\n\nct &lt;- cor(d) # correlation matrix\n\n\n\n# quick visual check\ncorrplot::corrplot(ct, tl.cex = .7)"
  },
  {
    "objectID": "extras/ex90_power_misc.html#simulate",
    "href": "extras/ex90_power_misc.html#simulate",
    "title": "Power analysis for path and SEM models",
    "section": "Simulate",
    "text": "Simulate\nWe can simulate all the process each time, or use the correlation matrix as input for the simulation. You can do it either way. For space reason, let’s use the correlation matrix ct.\n\n\n\n# Hierarchical model\nmH &lt;- \"\ns1 =~ s1.1 + s1.2 + s1.3\ns2 =~ s2.1 + s2.2 + s2.3\ns3 =~ s3.1 + s3.2 + s3.3\ns4 =~ s4.1 + s4.2 + s4.3\nlv =~ s1 + s2 + s3 + s4\n\"\n\n# Oblique model\nmO &lt;- \"\ns1 =~ s1.1 + s1.2 + s1.3\ns2 =~ s2.1 + s2.2 + s2.3\ns3 =~ s3.1 + s3.2 + s3.3\ns4 =~ s4.1 + s4.2 + s4.3\ns1 ~~ s2 + s3 + s4\ns2 ~~ s3 + s4\ns3 ~~ s4\n\"\n\niter &lt;- 1000\nN &lt;- 200\nfi &lt;- c(\"cfi\", \"rmsea\", \"bic\", \"aic\")\n\n\n\nlibrary(MASS)\nlibrary(lavaan)\n\nfit &lt;- matrix(ncol = 4, nrow = iter)\ncompare &lt;- matrix(ncol = 4, nrow = iter)\n\nfor (i in 1:iter) {\n  tryCatch({\n    db &lt;- data.frame(mvrnorm(n = N, mu = rep(0, 12),\n                             ct, empirical = FALSE))\n    fH &lt;- sem(mH, data = db)\n    fO &lt;- sem(mO, data = db)\n\n    fitH &lt;- fitmeasures(fH, fi)\n    fitO &lt;- fitmeasures(fO, fi)\n\n    fit[i, ] &lt;- c(\n      ifelse(fitH[\"cfi\"] &gt; .95, 1, 0),\n      ifelse(fitH[\"rmsea\"] &lt; .08, 1, 0),\n      ifelse(fitO[\"cfi\"] &gt; .95, 1, 0),\n      ifelse(fitO[\"rmsea\"] &lt; .08, 1, 0)\n    )\n\n    compare[i, ] &lt;- c(\n      ifelse(fitH[\"cfi\"] &gt; fitO[\"cfi\"], 1, 0),\n      ifelse(fitH[\"rmsea\"] &lt; fitO[\"rmsea\"], 1, 0),\n      ifelse(fitH[\"bic\"] &lt; fitO[\"bic\"], 1, 0),\n      ifelse(fitH[\"aic\"] &lt; fitO[\"aic\"], 1, 0)\n    )\n  }, error = function(e) {\n    fit[i, ] &lt;- NA\n    compare[i, ] &lt;- NA\n  })\n}"
  },
  {
    "objectID": "extras/ex90_power_misc.html#results-1",
    "href": "extras/ex90_power_misc.html#results-1",
    "title": "Power analysis for path and SEM models",
    "section": "Results",
    "text": "Results\n\ncolnames(compare) &lt;- fi\ncolMeans(compare, na.rm = TRUE)\n\ncolnames(fit) &lt;- c(\"cfi\", \"rmsea\", \"cfi\", \"rmsea\")\ncolMeans(fit, na.rm = TRUE)\n\nsum(is.na(fit[, 1]))\n\n\nQUESTIONS? COMMENTS?"
  },
  {
    "objectID": "extras/ex90_power_misc.html#part-ii-miscellaneous-topics",
    "href": "extras/ex90_power_misc.html#part-ii-miscellaneous-topics",
    "title": "Power analysis for path and SEM models",
    "section": "Part II — Miscellaneous topics",
    "text": "Part II — Miscellaneous topics"
  },
  {
    "objectID": "extras/ex90_power_misc.html#outline-1",
    "href": "extras/ex90_power_misc.html#outline-1",
    "title": "Power analysis for path and SEM models",
    "section": "Outline",
    "text": "Outline\n\nMissing values\nBayesian SEM\nFit indices\nMore"
  },
  {
    "objectID": "extras/ex90_power_misc.html#missing-values-in-lavaan",
    "href": "extras/ex90_power_misc.html#missing-values-in-lavaan",
    "title": "Power analysis for path and SEM models",
    "section": "Missing values in lavaan",
    "text": "Missing values in lavaan\n\nThe default option in lavaan is a listwise deletion\nYou can set different options for missing values:\n\n\"pairwise\"\n\"ml\" or \"fiml\"\n\n\n\nfit &lt;- sem(m, data = d, missing = \"fiml\")\n\n\nIf you switch the estimator to estimator=\"MLR\", you will also estimate robust standard errors\n\nYou can also set standard errors with the se argument:\n\n\"robust\" or \"robust.mlm\" or \"robust.mlr\"\n\"bootstrap\"\n\"none\"\n\n\nfit &lt;- sem(m, data = d, se = \"robust\")"
  },
  {
    "objectID": "extras/ex90_power_misc.html#na-example",
    "href": "extras/ex90_power_misc.html#na-example",
    "title": "Power analysis for path and SEM models",
    "section": "NA example",
    "text": "NA example\n\noptions(digits = 2)\n\n# THESE ARE THE SAME DATA OF THE SEM SLIDES\nd &lt;- readxl::read_excel(\"../data/Dmissing.xlsx\")\n\ncolSums(apply(d, 2, is.na))\nsum(complete.cases(d))\nsum(complete.cases(d)) / nrow(d)\n\nm &lt;- \"\n# CFA model\npeerPressure =~ PP1 + PP2 + PP3 + PP4\nsocialMedia =~ SM1 + SM2 + SM3 + SM4\nsocialComparison =~ SC1 + SC2 + SC3\neatingDisorder =~ ED1 + ED2\n\n# Structural model\neatingDisorder ~ socialComparison\nsocialComparison ~ peerPressure + socialMedia\n\""
  },
  {
    "objectID": "extras/ex90_power_misc.html#results-with-missing-data",
    "href": "extras/ex90_power_misc.html#results-with-missing-data",
    "title": "Power analysis for path and SEM models",
    "section": "Results with missing data",
    "text": "Results with missing data\n\nfit &lt;- sem(m, d)\nsummary(fit, std = TRUE)"
  },
  {
    "objectID": "extras/ex90_power_misc.html#results-with-fiml-imputation",
    "href": "extras/ex90_power_misc.html#results-with-fiml-imputation",
    "title": "Power analysis for path and SEM models",
    "section": "Results with fiml imputation",
    "text": "Results with fiml imputation\n\nfitna &lt;- sem(m, d, missing = \"fiml\")\nsummary(fitna, std = TRUE)"
  },
  {
    "objectID": "extras/ex90_power_misc.html#estimates-comparison",
    "href": "extras/ex90_power_misc.html#estimates-comparison",
    "title": "Power analysis for path and SEM models",
    "section": "Estimates comparison",
    "text": "Estimates comparison\n\np00 &lt;- parameterEstimates(fit, standardized = TRUE)[1:16, 1:3]\npt1 &lt;- parameterEstimates(fit, standardized = TRUE)[1:16, 11]\np0 &lt;- rep(\"||\", 16)\npt2 &lt;- parameterEstimates(fitna, standardized = TRUE)[1:16, 11]\n\npt &lt;- cbind(p00, p0, pt1, p0, pt2)\npt[, c(5, 7)] &lt;- round(pt[, c(5, 7)], 3)\nnames(pt)[c(4, 6)] &lt;- \"||\"\n\nknitr::kable(pt)"
  },
  {
    "objectID": "extras/ex90_power_misc.html#bayesian-sem",
    "href": "extras/ex90_power_misc.html#bayesian-sem",
    "title": "Power analysis for path and SEM models",
    "section": "Bayesian SEM",
    "text": "Bayesian SEM\nIf you are interested in using Bayesian analyses, this can also be applied to the SEM framework.\nThis is not the place where we will learn Bayesian analysis, but let’s see how to code it using blavaan."
  },
  {
    "objectID": "extras/ex90_power_misc.html#blavaan",
    "href": "extras/ex90_power_misc.html#blavaan",
    "title": "Power analysis for path and SEM models",
    "section": "blavaan",
    "text": "blavaan\n\n# install.packages(\"blavaan\")\nlibrary(blavaan)\n\nmodel &lt;- '\n  # latent variable definitions\n  ind60 =~ x1 + x2 + x3\n  dem60 =~ y1 + y2 + y3 + y4\n  dem65 =~ y5 + y6 + y7 + y8\n\n  # regressions\n  dem60 ~ ind60\n  dem65 ~ ind60 + dem60\n\n  # residual covariances\n  y1 ~~ y5\n  y2 ~~ y4 + y6\n  y3 ~~ y7\n  y4 ~~ y8\n  y6 ~~ y8\n'\n\nbfit &lt;- bsem(model, data = PoliticalDemocracy)"
  },
  {
    "objectID": "extras/ex90_power_misc.html#results-2",
    "href": "extras/ex90_power_misc.html#results-2",
    "title": "Power analysis for path and SEM models",
    "section": "Results",
    "text": "Results\n\nsummary(bfit)"
  },
  {
    "objectID": "extras/ex90_power_misc.html#priors",
    "href": "extras/ex90_power_misc.html#priors",
    "title": "Power analysis for path and SEM models",
    "section": "Priors",
    "text": "Priors\nBut of course you need priors.\n\ndpriors(bfit)\n\nnu     = \"normal(0,32)\"     # MV intercept\nalpha  = \"normal(0,10)\"     # LV intercept\nlambda = \"normal(0,10)\"     # loading\nbeta   = \"normal(0,10)\"     # regression\ntheta  = \"gamma(1,.5)[sd]\"  # MV precision\npsi    = \"gamma(1,.5)[sd]\"  # LV precision\nrho    = \"beta(1,1)\"        # correlation\nibpsi  = \"wishart(3,iden)\"  # covariance matrix\ntau    = \"normal(0,1.5)\"    # threshold\n\n# AND YOU CAN CHANGE THEM\nmydp &lt;- dpriors(lambda = \"normal(1,2)\")"
  },
  {
    "objectID": "extras/ex90_power_misc.html#priors-for-individual-parameters",
    "href": "extras/ex90_power_misc.html#priors-for-individual-parameters",
    "title": "Power analysis for path and SEM models",
    "section": "Priors for individual parameters",
    "text": "Priors for individual parameters\nThe priors we just saw are used to set the same prior to all the parameters of a kind (e.g., all loadings).\nWe can also (we should probably), set priors for individual parameters. This is done within the model specification.\n\nHS.model &lt;- '\n  visual  =~ x1 + prior(\"normal(1,2)\")*x2 + x3\n  textual =~ x4 + x5 + prior(\"normal(3,1.5)\")*x6\n  speed   =~ x7 + x8 + x9\n  x1 ~~ prior(\"gamma(3,3)[sd]\")*x1\n  visual ~~ prior(\"beta(1,1)\")*textual\n'\n\nHSbfit &lt;- bsem(HS.model, data = HolzingerSwineford1939)"
  },
  {
    "objectID": "extras/ex90_power_misc.html#full-results",
    "href": "extras/ex90_power_misc.html#full-results",
    "title": "Power analysis for path and SEM models",
    "section": "Full results",
    "text": "Full results\n\n\n\nsp &lt;- standardizedposterior(bfit)\nhead(sp)[, 1:5]\n\nfitMeasures(bfit)\nblavFitIndices(bfit)\n\n\n\nplot(density(sp[, \"dem60~ind60\"]))\nabline(v = median(sp[, \"dem60~ind60\"]))"
  },
  {
    "objectID": "extras/ex90_power_misc.html#more-about-fit-indices",
    "href": "extras/ex90_power_misc.html#more-about-fit-indices",
    "title": "Power analysis for path and SEM models",
    "section": "More about fit indices",
    "text": "More about fit indices\nThe story about fit indices does not finish where we said. There is much more and much more is still going on."
  },
  {
    "objectID": "extras/ex90_power_misc.html#should-we-abandon-predefined-cut-offs",
    "href": "extras/ex90_power_misc.html#should-we-abandon-predefined-cut-offs",
    "title": "Power analysis for path and SEM models",
    "section": "Should we abandon predefined cut-offs?",
    "text": "Should we abandon predefined cut-offs?\n\n\n\nGroskurth et al. (2023): https://doi.org/10.3758/s13428-023-02193-3\nFit indices do not only depend on model fit/misfit, but also on intrinsic characteristics of the models/analysis."
  },
  {
    "objectID": "extras/ex90_power_misc.html#dynamic-fit-indices",
    "href": "extras/ex90_power_misc.html#dynamic-fit-indices",
    "title": "Power analysis for path and SEM models",
    "section": "Dynamic fit indices",
    "text": "Dynamic fit indices\n\n\n\nDynamic shiny app: https://www.dynamicfit.app/connect/"
  },
  {
    "objectID": "extras/ex90_power_misc.html#dynamic-fit-indices-1",
    "href": "extras/ex90_power_misc.html#dynamic-fit-indices-1",
    "title": "Power analysis for path and SEM models",
    "section": "Dynamic fit indices",
    "text": "Dynamic fit indices\n\n\n\nMcNeish & Wolf (2023): https://doi.org/10.1037/met0000425"
  },
  {
    "objectID": "extras/ex90_power_misc.html#random-materials",
    "href": "extras/ex90_power_misc.html#random-materials",
    "title": "Power analysis for path and SEM models",
    "section": "Random materials",
    "text": "Random materials\n\nSlides by Rosseel on lavaan basics: https://users.ugent.be/~yrosseel/lavaan/lavaan2.pdf\nblavaan introduction: https://ecmerkle.github.io/blavaan/index.html"
  },
  {
    "objectID": "extras/ex90_power_misc.html#contact",
    "href": "extras/ex90_power_misc.html#contact",
    "title": "Power analysis for path and SEM models",
    "section": "Contact",
    "text": "Contact\n\ntommaso.feraco@unipd.it"
  },
  {
    "objectID": "extras/ex90_power_misc.html#more-difficult-1",
    "href": "extras/ex90_power_misc.html#more-difficult-1",
    "title": "Power analysis for path and SEM models",
    "section": "…more difficult",
    "text": "…more difficult\n\nlibrary(ggplot2)\nlibrary(gganimate)\np &lt;- ggplot(d, aes(x = X, y = M)) +\n  geom_point(size = 5, color = \"red\") +\n  geom_line() +\n  theme_bw()\n\npanim &lt;- p +\n  gganimate::transition_reveal(X) +\n  gganimate::shadow_wake(wake_length = 0.1, alpha = FALSE)"
  },
  {
    "objectID": "slides/00_welcome_course-map.html#today-in-the-workflow",
    "href": "slides/00_welcome_course-map.html#today-in-the-workflow",
    "title": "Welcome & course map",
    "section": "Today in the workflow",
    "text": "Today in the workflow\n\n\n\nWelcome deck (today): logistics + course map + how we’ll work\nNext deck (01): workflow + lavaan foundations (from Specify → Identify → Estimate → Evaluate → Revise/Report)"
  },
  {
    "objectID": "slides/00_welcome_course-map.html#who-is-this-course-for",
    "href": "slides/00_welcome_course-map.html#who-is-this-course-for",
    "title": "Welcome & course map",
    "section": "Who is this course for?",
    "text": "Who is this course for?\n\nPsychology PhD students with solid R skills\nYou’ve run regressions/GLMs; you want to model constructs + relations with SEM\nYou’re willing to think in models (not just tests)"
  },
  {
    "objectID": "slides/00_welcome_course-map.html#what-youll-be-able-to-do-by-the-end",
    "href": "slides/00_welcome_course-map.html#what-youll-be-able-to-do-by-the-end",
    "title": "Welcome & course map",
    "section": "What you’ll be able to do (by the end)",
    "text": "What you’ll be able to do (by the end)\n\nTranslate a verbal theory into a diagram and a lavaan model\nEvaluate global fit and local misfit (and respecify responsibly)\nFit and report:\n\npath models / mediation\nCFA and SEM (measurement + structure)\ninvariance (MG-CFA), ordinal SEM, longitudinal and clustered strategies\n\nProduce reproducible reports (Quarto + a reporting checklist)"
  },
  {
    "objectID": "slides/00_welcome_course-map.html#course-contents-big-picture",
    "href": "slides/00_welcome_course-map.html#course-contents-big-picture",
    "title": "Welcome & course map",
    "section": "Course contents (big picture)",
    "text": "Course contents (big picture)\nWe will (hopefully) cover:\n\nlavaan workflow + foundations\n\nPath analysis & mediation (equivalence and interpretation)\n\nModel fit & diagnostics (global vs local; disciplined respecification)\n\nCFA (measurement first; reliability/validity)\n\nFull SEM (measurement + structural part; capstone)\n\nMeasurement invariance (MG-CFA; partial invariance)\n\nOrdinal SEM (thresholds; WLSMV/ULS; ordinal invariance)\n\nMissing/robustness/reporting (FIML/MI; robust SE; write-up)\n\nLongitudinal SEM (growth + invariance over time)\n\nClustered/multilevel strategies (robust SE; two-level CFA)"
  },
  {
    "objectID": "slides/00_welcome_course-map.html#what-we-will-not-focus-on-in-live-sessions",
    "href": "slides/00_welcome_course-map.html#what-we-will-not-focus-on-in-live-sessions",
    "title": "Welcome & course map",
    "section": "What we will not focus on (in live sessions)",
    "text": "What we will not focus on (in live sessions)\n\nEFA (we’ll mention it, but we are not doing an EFA course)\nBayesian SEM (optional extra)\nAdvanced/rare models (optional extras: latent interactions, SAM/MIIVs, etc.)\n\n\n\n\nIf you need something specific for your project, let me know: I’ll try to fit it into the right module."
  },
  {
    "objectID": "slides/00_welcome_course-map.html#format-5-mornings-4-hours",
    "href": "slides/00_welcome_course-map.html#format-5-mornings-4-hours",
    "title": "Welcome & course map",
    "section": "Format: 5 mornings × 4 hours",
    "text": "Format: 5 mornings × 4 hours\nEach morning is split into two 2-hour blocks including:\n\ntheoretical and practical concepts\nlive coding\nlab and excercises\noptional extra topics\ndiscussion"
  },
  {
    "objectID": "slides/00_welcome_course-map.html#the-repository-is-the-course",
    "href": "slides/00_welcome_course-map.html#the-repository-is-the-course",
    "title": "Welcome & course map",
    "section": "The repository is the course",
    "text": "The repository is the course\nSEM-phd-course is a Quarto website + source files:\n\n/slides/ revealjs decks (what you see in class)\n/labs/ hands-on labs (what you do)\n/extras/ self-study (or extra) modules\n/R/ helper functions (fit, plots, reporting)\n\n\n\n\nGoal: everything is “book-ready”: coherent headings, reproducible code, and consistent reporting. At some point, a discursive content might be available."
  },
  {
    "objectID": "slides/00_welcome_course-map.html#how-to-use-materials-during-class",
    "href": "slides/00_welcome_course-map.html#how-to-use-materials-during-class",
    "title": "Welcome & course map",
    "section": "How to use materials during class",
    "text": "How to use materials during class\n\nKeep the slides open (concepts + code snippets)\nWork in the lab file in parallel (copy/adapt code)\nWhen stuck:\n\nidentify where you are in the workflow (Specify / Identify / Estimate / Evaluate / Revise-Report)\nbring the smallest reproducible example\ntalk"
  },
  {
    "objectID": "slides/00_welcome_course-map.html#software-checklist-do-this-before-we-start",
    "href": "slides/00_welcome_course-map.html#software-checklist-do-this-before-we-start",
    "title": "Welcome & course map",
    "section": "Software checklist (do this before we start)",
    "text": "Software checklist (do this before we start)\n\nR (recent), RStudio\nQuarto\nPackages (minimum):\n\nlavaan, semTools, semPlot, tidyverse, quarto\n\nOptional but useful:\n\npsych, MVN, performance, broom, parameters\n\n\n\npkgs &lt;- c(\"lavaan\",\"semTools\",\"semPlot\",\"tidyverse\")\nto_install &lt;- pkgs[!pkgs %in% rownames(installed.packages())]\nif(length(to_install)) install.packages(to_install)"
  },
  {
    "objectID": "slides/00_welcome_course-map.html#ground-rules-so-this-is-actually-useful",
    "href": "slides/00_welcome_course-map.html#ground-rules-so-this-is-actually-useful",
    "title": "Welcome & course map",
    "section": "Ground rules (so this is actually useful)",
    "text": "Ground rules (so this is actually useful)\n\nMeasurement-first (“two-step mindset”): measure → then relate constructs\n\nFit ≠ truth: use theory + diagnostics; respecify with discipline\n\nPrefer transparent reporting over “hunting for good fit”"
  },
  {
    "objectID": "slides/00_welcome_course-map.html#what-i-need-from-you",
    "href": "slides/00_welcome_course-map.html#what-i-need-from-you",
    "title": "Welcome & course map",
    "section": "What I need from you",
    "text": "What I need from you\n\nBring a dataset and one research question (even if rough)\nBe ready to:\n\ndraw your model\nstate what would falsify it\naccept that “good fit” can still be a bad model"
  },
  {
    "objectID": "slides/00_welcome_course-map.html#parking-lot-questions",
    "href": "slides/00_welcome_course-map.html#parking-lot-questions",
    "title": "Welcome & course map",
    "section": "Parking lot questions",
    "text": "Parking lot questions\nIf your question is:\n\nabout your own project’s model → keep it; we’ll connect it to a module\n\nabout R/lavaan syntax → ask immediately\n\nabout advanced variants (Bayesian, latent interactions, MIIVs, etc.) → likely an extra. We can cover it if we have time."
  },
  {
    "objectID": "slides/00_welcome_course-map.html#take-home-3-things",
    "href": "slides/00_welcome_course-map.html#take-home-3-things",
    "title": "Welcome & course map",
    "section": "Take-home: 3 things",
    "text": "Take-home: 3 things\n\nSEM is not just a model, but also a mindset\nSEM is both theory and stat\n\nSEM is both measurement and structure, tests\n\n\nThe repo is your long-term reference (slides, labs, extras, helpers)"
  },
  {
    "objectID": "slides/00_welcome_course-map.html#next",
    "href": "slides/00_welcome_course-map.html#next",
    "title": "Welcome & course map",
    "section": "Next",
    "text": "Next\nNext deck (01): SEM foundations + workflow + lavaan basics\n→ we start coding immediately.\n\n\n\nOpen the repo, run the package check, and make sure Quarto renders."
  },
  {
    "objectID": "slides/00_welcome_course-map.html#references",
    "href": "slides/00_welcome_course-map.html#references",
    "title": "Welcome & course map",
    "section": "References",
    "text": "References\n(References for this welcome deck are mostly course materials; substantive citations start in the next modules.)"
  },
  {
    "objectID": "slides/00_welcome_course-map.html#why-am-i-here",
    "href": "slides/00_welcome_course-map.html#why-am-i-here",
    "title": "Welcome & course map",
    "section": "Why am I here?",
    "text": "Why am I here?\nI am convinced that SEM is a fundamental tool for research in psychology and most, if not all, researchers in this area should know it. Indeed, it is key for many aspects of your research:\n\nMeasurement\nMultivariate analyses\nComplex regression models\nLongitudinal analyses\n…"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#today-in-the-workflow",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#today-in-the-workflow",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Today in the workflow",
    "text": "Today in the workflow\nSpecify → Identify → Estimate → Evaluate → Revise/Report\n\n\n\nToday: SEM language + diagram grammar + the workflow, then first translation to lavaan.\nNext (02): path analysis & mediation (indirect effects, equivalence, interpretation)."
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#learning-objectives",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#learning-objectives",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Learning objectives",
    "text": "Learning objectives\nBy the end of this session you should be able to:\n\nTranslate a verbal hypothesis into a diagram\nUse the basic SEM “grammar” (variables, errors, arrows, covariances)\nExplain the SEM workflow: Specify → Identify → Estimate → Evaluate → Revise/Report\nWrite and run a minimal model in lavaan (and read the key parts of the output)"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#a-quick-motivation-how-do-you-fit-these",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#a-quick-motivation-how-do-you-fit-these",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "A quick motivation: “how do you fit these?”",
    "text": "A quick motivation: “how do you fit these?”"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#sem-structural-equation-modeling",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#sem-structural-equation-modeling",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "SEM = Structural Equation Modeling",
    "text": "SEM = Structural Equation Modeling\nA family of models that lets you:\n\nrepresent hypotheses as a system of relations\n\npostulate a data-generating model\nevaluate whether this model fits the data or not\n\nwork with measurement error (explicitly)\nmodel means and covariances implied by your theory\n\n\n\n\nit includes path-analysis, causal models, factorial models, measurement models, Latent Growth Models, but even regressions, ANOVAs, t-tests could be considered particular cases of SEM.\n\n\n\n\nmodel latent variables (e.g., ‘invisible constructs’)\ntest indirect, moderated, and reciprocal effects\nmake diagrams (or PAINTINGS if theory is weak!)\n\n\n\n\nnetwork models are better if you want good paintings with no theory."
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#variancecovariance-matrices-the-currency",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#variancecovariance-matrices-the-currency",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Variance–covariance matrices (the “currency”)",
    "text": "Variance–covariance matrices (the “currency”)\n\n\n\noptions(digits = 2)\ncov(PoliticalDemocracy[1:7])\n\n    y1   y2   y3   y4  y5   y6   y7\ny1 6.9  6.3  5.8  6.1 5.1  5.7  5.8\ny2 6.3 15.6  5.8  9.5 5.6  9.4  7.5\ny3 5.8  5.8 10.8  6.7 4.9  4.7  7.0\ny4 6.1  9.5  6.7 11.2 5.7  7.4  7.5\ny5 5.1  5.6  4.9  5.7 6.8  5.0  5.8\ny6 5.7  9.4  4.7  7.4 5.0 11.4  6.7\ny7 5.8  7.5  7.0  7.5 5.8  6.7 10.8\n\n\n\nSEM works with matrices\n\n\\(\\boldsymbol{S}\\) observed var-cov\n\\(\\boldsymbol{\\Sigma}\\) true var-cov\n\\(\\boldsymbol{\\hat{\\Sigma}}\\) model-implied var-cov\n\\(\\boldsymbol{\\Sigma}(\\theta)\\)\n\n\nTHE MAIN AIM OF SEM IS TO RECONSTRUCT THE TRUE VARIANCE-COVARIANCE MATRIX"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#classification-of-variables",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#classification-of-variables",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Classification of variables",
    "text": "Classification of variables\nVariables are the way those attributes that vary across individuals are operationalized and represented for further data processing. These can be categorized according to many criteria (e.g, dependent/independent…), but in SEM we classify them firstly as:\n\nLatent variables\n\nhypothetical variables that correspond to more or less abstract concepts (e.g., intelligence, anxiety, executive functions, personality traits…)\ncould be formative or reflective\n\nObserved variables\n\nvariables that can be directly observed and measured\nexamples can be weight, height, gender, income, items, HRV…"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#relationships-between-variables",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#relationships-between-variables",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Relationships between variables",
    "text": "Relationships between variables\n\nThe general aim of statistical analysis is to study relationships among variables\nOn the basis of the relationship among the variables, we distinguish two kind of models:\n\nsymmetrical\nasymmetrical"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#regression-model-as-an-sem-special-case",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#regression-model-as-an-sem-special-case",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Regression model (as an SEM special case)",
    "text": "Regression model (as an SEM special case)\nA familiar form:\n[ y = X+ ]\n\nall variables are manifest\nmeasurement error is only “hidden” in () for endogenous variables"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#from-one-equation-to-a-system",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#from-one-equation-to-a-system",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "From one equation to a system",
    "text": "From one equation to a system\nSEM often treats your hypothesis as multiple linked equations."
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#variables-and-errors-be-explicit",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#variables-and-errors-be-explicit",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Variables and errors (be explicit)",
    "text": "Variables and errors (be explicit)\nSEM forces you to draw/declare:\n\nresidual variances (errors/disturbances)\ncovariances (exogenous covariances; correlated residuals if justified)"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#sem-in-one-picture",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#sem-in-one-picture",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "SEM “in one picture”",
    "text": "SEM “in one picture”\nA full representation (we’ll decode it gradually):"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#sem-assumptions-conceptual-version",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#sem-assumptions-conceptual-version",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "SEM assumptions (conceptual version)",
    "text": "SEM assumptions (conceptual version)\n\nThe model is confirmatory: you propose it before looking for “fixes”\nThe model must be identified (estimable)\nEstimation relies on distributional assumptions"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#sem-steps-the-workflow",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#sem-steps-the-workflow",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "SEM steps (the workflow)",
    "text": "SEM steps (the workflow)\n\nModel specification (theory → diagram → equations)\nModel identification (can we estimate the parameters?)\nParameter estimation (choose estimator, get estimated matrices)\nModel evaluation (global + local diagnostics)\nModel modification / reporting (disciplined, transparent)"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#model-specification",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#model-specification",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "1) Model specification",
    "text": "1) Model specification\nWhat is a model\n\nA model is a formal representation of a theory and is composed by a set of parameters that we will estimate.\n\nWhat you must state explicitly:\n\nwhich variables are connected (and in what direction)\nwhich errors/covariances are allowed\nwhich parameters are fixed, free, or constrained"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#model-identification-intuition",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#model-identification-intuition",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "2) Model identification (intuition)",
    "text": "2) Model identification (intuition)\n\n\nTo ensure that the number of unknown parameters (\\(t\\)) is not greater than the number of nonredundant elements in the covariance matrix of \\(q\\) observed variables.\n\\[\nt \\leq \\frac{q(q+1)}{2}\n\\]\n\n\n\nIf the model is not identified, nothing else matters (no fit, no estimates).\n\n\n\n\nJust-identified\n\nUnder-identified\n\nOver-identified"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#identification-examples-visual",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#identification-examples-visual",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Identification examples (visual)",
    "text": "Identification examples (visual)\n\n\nJust-identified\n\n\nUnder-identified\n\n\nOver-identified\n\n\n\n\n\nIf the model is not identified, nothing else matters (no fit, no estimates)."
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#parameter-estimation-what-software-does",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#parameter-estimation-what-software-does",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "3) Parameter estimation (what software does)",
    "text": "3) Parameter estimation (what software does)\nTo estimate the model parameters we can use different estimation methods. These aim to estimate the model implied (theoretical) correlation matrix \\(\\boldsymbol{\\Sigma}\\), which is a function of the model parameters, and should hopefully be similar to the observed correlation matrix \\(\\boldsymbol{S}\\).\nSome of the many estimation methods are:\n\nMaximum Likelihood (ML), default in lavaan\nUnweighted Least Squares (ULS)\nGeneralized Least Squares (GLS)\nWeighted Least Squares, Mean- and Variance-adjusted (WLSMV), default for ordinal variables in lavaan\nDiagonally Weighted Least Squares (DWLS)"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#model-evaluation-preview",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#model-evaluation-preview",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "4) Model evaluation (preview)",
    "text": "4) Model evaluation (preview)\nIs the model adequate? Are our parameter able to construct a theoretical matrix (\\(\\boldsymbol{\\Sigma}\\)) which is close to the original empirical covariance matrix \\(\\boldsymbol{S}\\)?\nThis is the goal of a good model: reproduce, from a set of theoretical associations/effects (aka covariance matrix), the original covariance matrix.\n\nGlobal fit: is the overall model plausible?\nLocal fit: where does the model misfit?\n\n\n\n\nWe’ll do this properly in deck 03. Today: just remember that fit ≠ truth.\n\n\n\nFormally:\n\\[\nH_0 : \\boldsymbol{\\hat{\\Sigma}}(\\theta) = \\boldsymbol{\\Sigma}\n\\]\nwhere \\(\\boldsymbol{\\Sigma}\\) is the true covariance matrix among model variables, \\(\\theta\\) the parameters vector, and \\(\\boldsymbol{\\hat{\\Sigma}}\\) the reproduced covariance matrix."
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#model-modification-disciplined-respecification",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#model-modification-disciplined-respecification",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "5) Model modification (disciplined respecification)",
    "text": "5) Model modification (disciplined respecification)\nAt this point you are ‘free’ to modify the model based on the results obtained…AND THE THEORY!\n\nmodifications are hypotheses\nmodifications must be explicitly reported: both what you changed and why\navoid overfitting (change only what is strictly needed/justified)"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#diagram-grammar-legend",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#diagram-grammar-legend",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Diagram grammar (legend)",
    "text": "Diagram grammar (legend)\nCommon SEM symbols:"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#where-these-models-show-up-across-the-course",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#where-these-models-show-up-across-the-course",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Where these models show up across the course",
    "text": "Where these models show up across the course\n(These pictures are “landmarks” you’ll keep seeing.)"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#longitudinal-landmarks-later",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#longitudinal-landmarks-later",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Longitudinal landmarks (later)",
    "text": "Longitudinal landmarks (later)\nPanel / repeated measures:\n\nGrowth / change:"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#bridge-from-diagrams-to-lavaan",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#bridge-from-diagrams-to-lavaan",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Bridge: from diagrams to lavaan",
    "text": "Bridge: from diagrams to lavaan\nlavaan is mostly a model syntax language:\n\nyou write relations like “y ~ x”\nlavaan estimates the parameters\nyou read estimates + standard errors + fit indices + diagnostics\n\n\n\n\nThink: “diagram ↔︎ equations ↔︎ lavaan syntax” (three representations of the same model)."
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#from-lm-to-lavaansem",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#from-lm-to-lavaansem",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "From lm() to lavaan::sem()",
    "text": "From lm() to lavaan::sem()\nA regression in base R:\n\nfit_lm &lt;- lm(y ~ x1 + x2, data = dat)\nsummary(fit_lm)\n\nThe same idea in lavaan :\n\nlibrary(lavaan)\n\nmod &lt;- '\n  y ~ x1 + x2\n'\n\nfit &lt;- sem(mod, data = dat)\nsummary(fit, standardized = TRUE)"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#key-lavaan-syntax-operators",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#key-lavaan-syntax-operators",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Key lavaan syntax operators",
    "text": "Key lavaan syntax operators\n\n~ regression (single-headed arrow)\n~~ (co)variance (double-headed arrow)\n=~ measurement model (factor loading)\n\n\nmod &lt;- '\n  # regression\n  y ~ x1 + x2\n\n  # (co)variances\n  x1 ~~ x2\n  y  ~~ y\n\n  # measurement (example)\n  F =~ y1 + y2 + y3\n'"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#a-minimal-runnable-example-built-in-data",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#a-minimal-runnable-example-built-in-data",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "A minimal, runnable example (built-in data)",
    "text": "A minimal, runnable example (built-in data)\n\nlibrary(lavaan)\ndat &lt;- HolzingerSwineford1939\n\nmod_cfa &lt;- '\n  visual  =~ x1 + x2 + x3\n  textual =~ x4 + x5 + x6\n  speed   =~ x7 + x8 + x9\n'\n\nfit_cfa &lt;- cfa(mod_cfa, data = dat)\nsummary(fit_cfa, standardized = TRUE, fit.measures = TRUE)\n\n\n\n\nDon’t worry about fit indices yet—this is just to see the pipeline end-to-end."
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#visual-check-plot-the-model",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#visual-check-plot-the-model",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Visual check: plot the model",
    "text": "Visual check: plot the model\n\nlibrary(semPlot)\nsemPaths(fit_cfa, what = \"std\", layout = \"tree\", residuals = FALSE)\n\n(Plotting is optional—but very helpful for teaching your brain the diagram grammar.)"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#common-early-mistakes-and-how-to-debug",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#common-early-mistakes-and-how-to-debug",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Common early mistakes (and how to debug)",
    "text": "Common early mistakes (and how to debug)\n\n“lavaan ERROR: model is not identified” → go back to Identify\n“nothing converges” → simplify; check scaling; check data (missing, outliers)\n“why are SE huge?” → identification / multicollinearity / small N\n\n\n\n\nIn this course, debugging starts by asking: Which workflow step am I in?"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#exercises-lab-01",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#exercises-lab-01",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Exercises (Lab 01)",
    "text": "Exercises (Lab 01)\nGo to:\n\nlabs/lab01_lavaan-basics.qmd\n\nYou’ll practice:\n\nwriting tiny models (~, ~~, =~)\nfitting with sem() / cfa()\nextracting key output (estimates, standardized, basic fit)"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#take-home-3-things",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#take-home-3-things",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Take-home: 3 things",
    "text": "Take-home: 3 things\n\nSEM is a language: diagrams, equations, syntax\n\nSEM is a workflow: Specify → Identify → Estimate → Evaluate → Revise/Report\n\nlavaan is your translator from theory → estimable model"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#further-reading-self-study",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#further-reading-self-study",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Further reading / self-study",
    "text": "Further reading / self-study\n\nRevisit the glossary in the repo as new terms appear\n\n(Add materials list.)"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#references",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#references",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "References",
    "text": "References\n(Add citations as we stabilize the final reading list for the course website.)"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#variancecovariance-matrices-the-currency-1",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#variancecovariance-matrices-the-currency-1",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Variance–covariance matrices (the “currency”)",
    "text": "Variance–covariance matrices (the “currency”)\nSEM compares what you observe (S) with what your model implies (Σ(θ))."
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#classification-of-variables-1",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#classification-of-variables-1",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Classification of variables",
    "text": "Classification of variables\nIn SEM we also have an additional classification:\n\nExogenous variables\n\nVariables whose causes lie outside the model; they will be used only as predictors in the model. They do not receive arrows.\nThey are indicated with \\(x\\), if observed, or with \\(\\xi\\), if latent.\n\nEndogenous variables\n\nVariables that are determined by variables within the model (they receive arrows); can be used as predictors or dependent variables in the model.\nThey are indicated with \\(y\\), if observed, or with \\(\\eta\\), if latent."
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#classification-of-variables-2",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#classification-of-variables-2",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Classification of variables",
    "text": "Classification of variables\nVariables are the way those attributes that vary across individuals are operationalized and represented for further data processing. These can be categorized according to many criteria (e.g, dependent/independent…), but in SEM we classify them firstly as:\n\nLatent variables\n\nhypothetical variables that correspond to more or less abstract concepts\nformative or reflective\nexamples are intelligence, anxiety, executive functions, personality traits…\n\nObserved variables\n\nvariables that can be directly observed and measured\nexamples can be weight, height, gender, income…"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#classification-of-variables-3",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#classification-of-variables-3",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Classification of variables",
    "text": "Classification of variables\nIn SEM we also have an additional type of classification:\n\nExogenous variables\n\nVariables whose causes lie outside the model; they will be used only as predictors in the model. They do not receive arrows.\nThey are indicated with \\(x\\), if observed, or with \\(\\xi\\), if latent.\n\nEndogenous variables\n\nVariables that are determined by variables within the model (they receive arrows); can be used as predictors or dependent variables in the model.\nThey are indicated with \\(y\\), if observed, or with \\(\\eta\\), if latent.\n\n\nThis brings us to deepen the relationships between variables."
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#asymmetrical-relationships",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#asymmetrical-relationships",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Asymmetrical relationships",
    "text": "Asymmetrical relationships\n\\[\nX \\rightarrow Y\n\\]\n\nVariables are divided into two sets: dependent or response variables and predictors or explanatory variables\n\\(X\\) is the set of explanatory variables, \\(Y\\) is the set of response variables, arrows represents the direction of the hypothesized relationship.\nThese models imply cause-and-effect relationships.\n\nExample\nPeople who study more obtain higher grades."
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#symmetrical-relationships",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#symmetrical-relationships",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Symmetrical relationships",
    "text": "Symmetrical relationships\n\\[\nX_i \\Leftrightarrow Y_j \\quad \\forall i,j\n\\]\n\nThis means that neither a variable causes the other, neither a variable can be considered prior in time to the other; all these relationships are bidirectional.\nThese models do not imply nor consider causality.\n\nExample\nPeople who have higher grades in math have higher grades in art."
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#regression-model",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#regression-model",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Regression model",
    "text": "Regression model\nAsymmetrical relationships are usually tested with regressions!\nAs you remember, regression models can be written, using classical formulation, as the expression below and graphically depicted (getting closer to SEM) like this:"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#more-regression",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#more-regression",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "More regression?",
    "text": "More regression?\nBut what if we have in mind a more complex pattern of relationships? What if we have more regression models in mind and need to estimate all of them contemporarily?\n\nWhat we need is a system of equations."
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#more-regression-1",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#more-regression-1",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "More regression?",
    "text": "More regression?\nThis system can also be drawn with SEM notation, but is actually the same…just better!"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#variables-and-errors",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#variables-and-errors",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Variables and errors",
    "text": "Variables and errors\n\nVariables\n\n\\(x\\) exogenous observed (\\(q\\))\n\\(\\xi\\) exogenous latent (\\(n\\))\n\\(y\\) endogenous observed (\\(p\\))\n\\(\\eta\\) endogenous latent (\\(m\\))\n\nStochastic errors\n\n\\(\\delta\\) measurement errors in \\(x\\)\n\\(\\epsilon\\) measurement errors in \\(y\\)\n\\(\\zeta\\) equation errors in the structural relationship between \\(\\eta\\) and \\(\\xi\\)"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#sem-matrices---lavaan-model",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#sem-matrices---lavaan-model",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "SEM matrices - lavaan model",
    "text": "SEM matrices - lavaan model\n\nParameter matrices\n\n\\(\\boldsymbol{\\Lambda}\\) relationship between latent (\\(\\xi\\) and \\(\\eta\\)) and observed (\\(x\\) and \\(y\\)) [\\((p + q) X (m + n)\\)]\n\\(\\boldsymbol{B}\\) relationship between latent variables [\\((m + n) X (m + n)\\)]\n\nCovariance matrices\n\n\\(Cov\\)(\\(\\zeta\\), \\(\\xi\\)) = \\(\\boldsymbol{\\Psi}\\) matrix [\\((m + n) X (m + n)\\)]\n\\(Cov\\)(\\(\\epsilon\\), \\(\\delta\\)) = \\(\\boldsymbol{\\Theta}\\) matrix [\\((p + q) X (p + q)\\)]"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#sem-equations",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#sem-equations",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "SEM equations",
    "text": "SEM equations\nThe SEM model in its most general form consists of two parts\n\nThe measurement model\n\n\\(x = \\boldsymbol{\\Lambda}_x\\boldsymbol{\\xi} + \\boldsymbol{\\delta}\\)\n\\(y = \\boldsymbol{\\Lambda}_y\\boldsymbol{\\eta} + \\boldsymbol{\\epsilon}\\)\n\nThe structural model\n\n\\(\\boldsymbol{\\eta} = \\boldsymbol{B\\eta} + \\boldsymbol{\\Gamma\\xi} + \\boldsymbol{\\zeta}\\)\n\\(\\boldsymbol{\\eta} = \\boldsymbol{B(\\eta\\xi} + \\boldsymbol{\\zeta})\\)"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#sem-assumptions",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#sem-assumptions",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "SEM assumptions",
    "text": "SEM assumptions\n\nExpected values of latent variables and stochastic errors are 0:\n\n\\(E\\)(\\(\\eta\\)) = 0\n\\(E\\)(\\(\\xi\\)) = 0\n\\(E\\)(\\(\\zeta\\)) = 0\n\\(E\\)(\\(\\epsilon\\)) = 0\n\\(E\\)(\\(\\delta\\)) = 0\n\nErrors are uncorrelated with latent variables and are mutually uncorrelated:"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#classification-of-variables-4",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#classification-of-variables-4",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Classification of variables",
    "text": "Classification of variables\n latent variables (constructs)\n observed/manifest variables (items, scores)\n\n\n\nMeasurement-first mindset: define/validate constructs first, then relate them."
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#relationships-between-variables-1",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#relationships-between-variables-1",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Relationships between variables",
    "text": "Relationships between variables\nTwo basic arrow types:\n\n\n\nSingle-headed: regression / directional effect (A → B)\nDouble-headed: covariance/correlation (A ↔︎ B)"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#a-full-representation",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#a-full-representation",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "A full representation",
    "text": "A full representation\n img credits to dr. Johnny Lin"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#graphical-representation",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#graphical-representation",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Graphical representation",
    "text": "Graphical representation\nIf that all seemed difficult and boring, now comes the funny part: colors, figures, and arrows!\nGraphical representation is a key attribute of structural equation modeling:\n\nIt helps understanding the model\nIt helps thinking and reasoning about the model (a priori)\nIt helps writing and formalizing the model\nIt is easy, but few rules must be followed to have a readable model"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#graphical-representation-1",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#graphical-representation-1",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Graphical representation",
    "text": "Graphical representation\n\nLatent variables are circles or ellipses\n\nManifest/observed variables are square or rectangular boxes\n\nErrors are represented by corresponding letters (or values) only\n\n\\[\n\\delta_1  /  \\epsilon_1  /  \\zeta_1\n\\]"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#graphic-relationships",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#graphic-relationships",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Graphic relationships",
    "text": "Graphic relationships\n\nAll model relationships are represented by arrows;\n\n\n\n\n\n\n\nImportant\n\n\nNO relationship NO arrow…\n…and usually NO arrow NO relationship\n\n\n\n\nEach arrow is a model parameter and has two indices (e.g., \\(\\beta_{21}\\))\nAsymmetrical relationship are represented by a single headed arrow: the first index indicates the variable the arrow is pointing to, the second index indicates the variable of origin.\nSymmetrical relationships are represented by double-headed arrows and two indices, one for each variable."
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#graphic-relationships-1",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#graphic-relationships-1",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Graphic relationships",
    "text": "Graphic relationships\nA summary"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#asymmetrical-relationships-1",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#asymmetrical-relationships-1",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Asymmetrical relationships",
    "text": "Asymmetrical relationships"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#symmetrical-relationships-1",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#symmetrical-relationships-1",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Symmetrical relationships",
    "text": "Symmetrical relationships"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#graphical-errors",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#graphical-errors",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Graphical errors",
    "text": "Graphical errors\n\nAll errors have a single headed arrow pointing to a variable; all variables, except \\(\\xi\\), may have an error.\nDouble-headed arrows associated to errors indicate error variances."
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#a-full-representation-1",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#a-full-representation-1",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "A full representation",
    "text": "A full representation\n img credits to dr. Johnny Lin"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#model-identification",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#model-identification",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "2) Model identification",
    "text": "2) Model identification\nBasically, we want to know if there is enough information to identify a solution (aka estimate all the unknown parameters).\nA model can be:\n\nUnder-identified: there are MORE parameters to be estimated than elements in the covariance matrix (e.g., \\(X + Y = 10\\))\nJust-identified: the number of parameters to be estimated equals the number of elements in the covariance matrix (\\(df = 0\\))\nOver-identified: there are LESS parameters to be estimated than elements in the covariance matrix (\\(df &gt; 0\\))"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#univariate-regressions",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#univariate-regressions",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Univariate regressions",
    "text": "Univariate regressions"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#multivariate-regressions",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#multivariate-regressions",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Multivariate regressions",
    "text": "Multivariate regressions"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#path-analysis",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#path-analysis",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Path analysis",
    "text": "Path analysis"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#confirmatory-factor-analysis-cfa",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#confirmatory-factor-analysis-cfa",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Confirmatory factor analysis (CFA)",
    "text": "Confirmatory factor analysis (CFA)"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#sem-path-analysis",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#sem-path-analysis",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "SEM path analysis",
    "text": "SEM path analysis"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#t-test-with-latent-variables",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#t-test-with-latent-variables",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "t test with latent variables",
    "text": "t test with latent variables"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#cross-lagged-panel-models",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#cross-lagged-panel-models",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Cross-lagged panel models",
    "text": "Cross-lagged panel models"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#growth-curve-models",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#growth-curve-models",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Growth curve models",
    "text": "Growth curve models"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#and-much-more",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#and-much-more",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "And much more",
    "text": "And much more\n…and much more\nTHERE IS EVEN A JOURNAL ON SEM\nStructural Equation Modeling: A Multidisciplinary Journal"
  },
  {
    "objectID": "labs/lab01_lavaan-basics.html",
    "href": "labs/lab01_lavaan-basics.html",
    "title": "Lab 01 — lavaan basics with observed variables",
    "section": "",
    "text": "By the end of this lab, you can:\n\nFit observed-variable models in lavaan (no latent variables yet)\nExpress (multi)regression models using lavaan syntax (~, ~~)\nExtract and interpret key output (estimates, SE, standardized estimates)\nTest a simple equality constraint using nested model comparison"
  },
  {
    "objectID": "labs/lab01_lavaan-basics.html#packages",
    "href": "labs/lab01_lavaan-basics.html#packages",
    "title": "Lab 01 — lavaan basics with observed variables",
    "section": "Packages",
    "text": "Packages\n\nlibrary(lavaan)"
  },
  {
    "objectID": "labs/lab01_lavaan-basics.html#data",
    "href": "labs/lab01_lavaan-basics.html#data",
    "title": "Lab 01 — lavaan basics with observed variables",
    "section": "Data",
    "text": "Data\nWe will use the built-in dataset mtcars (motor trends cars; a classic toy dataset).\n\n\nShow code\ndat &lt;- mtcars\n\n# Keep only variables we use (and make names explicit)\ndat &lt;- dat[, c(\"mpg\", \"qsec\", \"wt\", \"hp\")]\n\n# Quick look\nsummary(dat)\n\n\n      mpg             qsec             wt              hp       \n Min.   :10.40   Min.   :14.50   Min.   :1.513   Min.   : 52.0  \n 1st Qu.:15.43   1st Qu.:16.89   1st Qu.:2.581   1st Qu.: 96.5  \n Median :19.20   Median :17.71   Median :3.325   Median :123.0  \n Mean   :20.09   Mean   :17.85   Mean   :3.217   Mean   :146.7  \n 3rd Qu.:22.80   3rd Qu.:18.90   3rd Qu.:3.610   3rd Qu.:180.0  \n Max.   :33.90   Max.   :22.90   Max.   :5.424   Max.   :335.0  \n\n\n\n\n\n\n\n\nWhy this dataset? It’s small, clean, and lets us practice the SEM workflow with manifest variables only."
  },
  {
    "objectID": "labs/lab01_lavaan-basics.html#extracting-parameters-programmatically",
    "href": "labs/lab01_lavaan-basics.html#extracting-parameters-programmatically",
    "title": "Lab 01 — lavaan basics with observed variables",
    "section": "Extracting parameters programmatically",
    "text": "Extracting parameters programmatically\nUse the function parameterEstimates() to obtain the estimates. How do you extract standardized estimate?\n\n\nShow code\npe &lt;- parameterEstimates(fit_sem, standardized = TRUE)\nhead(pe, 10)\n\n\n  lhs op rhs      est    se      z pvalue ci.lower ci.upper   std.lv std.all\n1 mpg  ~  wt   -3.878 0.602 -6.438      0   -5.058   -2.697   -3.878  -0.630\n2 mpg  ~  hp   -0.032 0.009 -3.696      0   -0.049   -0.015   -0.032  -0.361\n3 mpg ~~ mpg    6.095 1.524  4.000      0    3.109    9.082    6.095   0.173\n4  wt ~~  wt    0.927 0.000     NA     NA    0.927    0.927    0.927   1.000\n5  wt ~~  hp   42.812 0.000     NA     NA   42.812   42.812   42.812   0.659\n6  hp ~~  hp 4553.965 0.000     NA     NA 4553.965 4553.965 4553.965   1.000\n7 mpg ~1       37.227 1.522 24.459      0   34.244   40.210   37.227   6.276\n8  wt ~1        3.217 0.000     NA     NA    3.217    3.217    3.217   3.341\n9  hp ~1      146.688 0.000     NA     NA  146.688  146.688  146.688   2.174\n   std.nox\n1   -0.654\n2   -0.005\n3    0.173\n4    0.927\n5   42.812\n6 4553.965\n7    6.276\n8    3.217\n9  146.688\n\n\n\nop tells you the operator (~ regression, ~~ variance/covariance, ~1 intercept)\nest is the estimate\nse is the standard error\nz and pvalue are the usual Wald test outputs\nstd.all is the fully standardized estimate\n\n\n\n\n\n\n\nAt this stage, focus on estimates only. We’ll talk about modeling strategy and diagnostics later.\n\n\n\n\n\n\n\n\n\nCheck-in: You just used lavaan as a “regression engine”. SEM becomes interesting when we connect multiple equations and allow covariances explicitly."
  },
  {
    "objectID": "labs/lab01_lavaan-basics.html#compare-to-two-separate-regressions",
    "href": "labs/lab01_lavaan-basics.html#compare-to-two-separate-regressions",
    "title": "Lab 01 — lavaan basics with observed variables",
    "section": "Compare to two separate regressions",
    "text": "Compare to two separate regressions\n\n\nShow code\nfit_lm_mpg  &lt;- lm(mpg  ~ wt + hp, data = dat)\nfit_lm_qsec &lt;- lm(qsec ~ wt + hp, data = dat)\n\nsummary(fit_lm_mpg)$coef\n\n\n               Estimate Std. Error   t value     Pr(&gt;|t|)\n(Intercept) 37.22727012 1.59878754 23.284689 2.565459e-20\nwt          -3.87783074 0.63273349 -6.128695 1.119647e-06\nhp          -0.03177295 0.00902971 -3.518712 1.451229e-03\n\n\nShow code\nsummary(fit_lm_qsec)$coef\n\n\n               Estimate  Std. Error   t value     Pr(&gt;|t|)\n(Intercept) 18.82558525 0.671867025 28.019808 1.493575e-22\nwt           0.94153237 0.265896975  3.540967 1.368578e-03\nhp          -0.02730962 0.003794603 -7.196964 6.362107e-08\n\n\n\n\n\n\n\n\nSeparate lm() fits ignore the joint structure (e.g., residual covariance). lavaan makes it explicit."
  },
  {
    "objectID": "labs/lab01_lavaan-basics.html#a-unconstrained-model",
    "href": "labs/lab01_lavaan-basics.html#a-unconstrained-model",
    "title": "Lab 01 — lavaan basics with observed variables",
    "section": "4a) Unconstrained model",
    "text": "4a) Unconstrained model\n(You already fit it as fit_mv.)"
  },
  {
    "objectID": "labs/lab01_lavaan-basics.html#b-constrained-model",
    "href": "labs/lab01_lavaan-basics.html#b-constrained-model",
    "title": "Lab 01 — lavaan basics with observed variables",
    "section": "4b) Constrained model",
    "text": "4b) Constrained model\nLabel the two wt slopes with the same name (e.g., b_wt):\n\n\nShow code\nmod_mv_equal &lt;- '\n  mpg  ~ b_wt*wt + hp\n  qsec ~ b_wt*wt + hp\n\n  wt ~~ hp\n  mpg ~~ qsec\n'\n\nfit_mv_equal &lt;- sem(mod_mv_equal, data = dat, meanstructure = TRUE)\nsummary(fit_mv_equal, standardized = TRUE)\n\n\nlavaan 0.6-19 ended normally after 64 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        14\n  Number of equality constraints                     1\n\n  Number of observations                            32\n\nModel Test User Model:\n                                                      \n  Test statistic                                35.243\n  Degrees of freedom                                 1\n  P-value (Chi-square)                           0.000\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nRegressions:\n                   Estimate  Std.Err  z-value   P(&gt;|z|)   Std.lv  Std.all\n  mpg ~                                                                  \n    wt      (b_wt)    0.524    0.248     2.114    0.035    0.524    0.082\n    hp               -0.073    0.011    -6.762    0.000   -0.073   -0.805\n  qsec ~                                                                 \n    wt      (b_wt)    0.524    0.248     2.114    0.035    0.524    0.298\n    hp               -0.023    0.004    -6.378    0.000   -0.023   -0.932\n\nCovariances:\n                   Estimate  Std.Err  z-value   P(&gt;|z|)   Std.lv  Std.all\n  wt ~~                                                                  \n    hp               42.812    8.643     4.953    0.000   42.812    0.659\n .mpg ~~                                                                 \n   .qsec             -0.416    0.774    -0.537    0.591   -0.416   -0.095\n\nIntercepts:\n                   Estimate  Std.Err  z-value   P(&gt;|z|)   Std.lv  Std.all\n   .mpg              29.136    1.766    16.502    0.000   29.136    4.751\n   .qsec             19.594    0.645    30.368    0.000   19.594   11.579\n    wt                3.217    0.170    18.898    0.000    3.217    3.341\n    hp              146.687   11.929    12.296    0.000  146.687    2.174\n\nVariances:\n                   Estimate  Std.Err  z-value   P(&gt;|z|)   Std.lv  Std.all\n   .mpg              16.266    4.066     4.000    0.000   16.266    0.432\n   .qsec              1.168    0.292     4.000    0.000    1.168    0.408\n    wt                0.927    0.209     4.440    0.000    0.927    1.000\n    hp             4553.971    0.081 56034.919    0.000 4553.971    1.000"
  },
  {
    "objectID": "labs/lab01_lavaan-basics.html#c-compare-nested-models",
    "href": "labs/lab01_lavaan-basics.html#c-compare-nested-models",
    "title": "Lab 01 — lavaan basics with observed variables",
    "section": "4c) Compare nested models",
    "text": "4c) Compare nested models\n\n\nShow code\nanova(fit_mv, fit_mv_equal)\n\n\n\nChi-Squared Difference Test\n\n             Df    AIC    BIC  Chisq Chisq diff  RMSEA Df diff Pr(&gt;Chisq)    \nfit_mv        0 698.87 719.40  0.000                                         \nfit_mv_equal  1 732.12 751.17 35.243     35.243 1.0345       1  2.911e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nInterpretation questions\n\nIf the constrained model fits significantly worse, what does that imply?\nIf there is little/no difference, what does that imply?\nWhich model would you prefer and why (think theory + parsimony)?\n\n\n\n\n\n\n\nWe’ll later discuss when χ² difference tests are appropriate, and what changes under robust estimators."
  },
  {
    "objectID": "labs/lab01_lavaan-basics.html#what-you-should-take-away",
    "href": "labs/lab01_lavaan-basics.html#what-you-should-take-away",
    "title": "Lab 01 — lavaan basics with observed variables",
    "section": "What you should take away",
    "text": "What you should take away\n\nlavaan models are written with a small “grammar”: ~, ~~, ~1 (and later =~)\nEven with manifest variables only, SEM lets you model systems of equations and covariances\nEquality constraints are easy: reuse parameter labels"
  },
  {
    "objectID": "labs/lab01_lavaan-basics.html#whats-next",
    "href": "labs/lab01_lavaan-basics.html#whats-next",
    "title": "Lab 01 — lavaan basics with observed variables",
    "section": "What’s next",
    "text": "What’s next\n\nIn the next lecture we move from “multivariate regression” to path models and mediation\nYou will reuse the same syntax you practiced today (plus parameter labels for effects)"
  },
  {
    "objectID": "templates/slides-template.html",
    "href": "templates/slides-template.html",
    "title": "Title of the lecture; Subtitle (optional)",
    "section": "",
    "text": "Point 1\nPoint 2\nPoint 3\n\n\n\n\n\n\n\nTip\n\n\n\nTeaching tip: keep one “workflow map” slide that reappears in every deck."
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#regression-models",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#regression-models",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Regression models",
    "text": "Regression models\nWhat you did since the beginning of the year (with link functions or not) was something like this \\[\ny = X\\beta + \\epsilon\n\\] Where \\(y\\) is the response variable, \\(X\\) the set of predictors and \\(\\epsilon\\) the error term. \nThese models,\n\nassume that all variables are directly observed/manifest\nallow measurement errors only in endogenous variables\nare just particular cases of SEM"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#sem-formula",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#sem-formula",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "SEM formula",
    "text": "SEM formula\nIn fact, the structural model of a SEM (i.e., excluding latent variables) is:\n\\[\nY = X^\\ast B' + \\zeta\n\\]\nWhere\n\n\\(Y\\) is the (n x p) matrix of endogenous variables\n\\(X^\\ast\\) is the n x (p + q) matrix of endogenous and exogenous variables\n\\(B\\) is the (p + q) x (p + q) coefficient matrices\n\\(\\zeta\\) is the (p x q) matrix of errors in the equations\n\nThis looks pretty similar to the regression formula, but with some matrices! Univariate regression models are just a special case of this formula where the parameter matrix is full of 0"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#regressions-in-matrices",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#regressions-in-matrices",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Regressions in matrices",
    "text": "Regressions in matrices\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   y x1 x2 x3\ny  0  1  2  3\nx1 0  0  0  0\nx2 0  0  0  0\nx3 0  0  0  0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   y x3 x2 x1\ny  0  3  2  1\nx3 0  0  5  4\nx2 0  0  0  6\nx1 0  0  0  0"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#a-first-example-with-simulated-data",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#a-first-example-with-simulated-data",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "A first example with simulated data",
    "text": "A first example with simulated data\n\n\nImagine you want to predict scores in the test we will do at the end of this corse (\\(y\\)), based on your prior statistical knowledge (\\(x_1\\)) and interest (\\(x_2\\)):\nFirst define the model\n\n\n\n\n\n\n\n\n\n\nSecond simulate the data\n\n# Simulate knowledge and interest as predictors of Y\nset.seed(12)\nN = 100\nx1 = rnorm(N)\nx2 = rnorm(N)\ny = .35*x1 + .20*x2 + rnorm(N)\nd &lt;- data.frame(x1,x2,y)\n\n\ncor(d)\n\n      x1    x2    y\nx1 1.000 0.016 0.39\nx2 0.016 1.000 0.12\ny  0.386 0.118 1.00\n\ncov(d)\n\n      x1    x2    y\nx1 0.748 0.014 0.36\nx2 0.014 0.998 0.13\ny  0.364 0.129 1.19"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#a-first-example-with-simulated-data-1",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#a-first-example-with-simulated-data-1",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "A first example with simulated data",
    "text": "A first example with simulated data\n\n# Simulate knowledge and interest as predictors of Y\nset.seed(12)\nN = 100\nx1 = rnorm(N)\nx2 = rnorm(N)\ny = .35*x1 + .20*x2 + rnorm(N)\nd &lt;- data.frame(x1,x2,y)\n\n\ncor(d)\n\n      x1    x2    y\nx1 1.000 0.016 0.39\nx2 0.016 1.000 0.12\ny  0.386 0.118 1.00\n\n#\ncov(d)\n\n      x1    x2    y\nx1 0.748 0.014 0.36\nx2 0.014 0.998 0.13\ny  0.364 0.129 1.19"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#lm-regression",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#lm-regression",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "lm regression",
    "text": "lm regression\n\n# fit a regression model\nm &lt;- lm(y ~ x1 + x2, data = d)\nsummary(m)\n\n\nCall:\nlm(formula = y ~ x1 + x2, data = d)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.8022 -0.6244 -0.0259  0.7150  1.8090 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  -0.0251     0.1009   -0.25     0.80    \nx1            0.4846     0.1172    4.14  7.5e-05 ***\nx2            0.1226     0.1015    1.21     0.23    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1 on 97 degrees of freedom\nMultiple R-squared:  0.162, Adjusted R-squared:  0.145 \nF-statistic: 9.36 on 2 and 97 DF,  p-value: 0.000191"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#introducing-lavaan",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#introducing-lavaan",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Introducing lavaan",
    "text": "Introducing lavaan\nlavaan (latent variable analysis) is actually THE package for SEM. You can use it to estimate a wide family of latent variable models, including: factor analysis, structural equation, longitudinal, multilevel, latent class, item respons, and missing data models… \n..But also simple regressions"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#model-fit-and-info",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#model-fit-and-info",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Model fit and info",
    "text": "Model fit and info\n\nlibrary(lavaan)\nml &lt;- \"y ~ 1 + x1 + x2\" #1 + gives the intercept\nfit &lt;- sem(ml, data = d)\n# summary(fit, rsquare=T)\n\n\n\nlavaan 0.6-19 ended normally after 1 iteration\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         4\n\n  Number of observations                           100\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\n[...]"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#model-parameters",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#model-parameters",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Model parameters",
    "text": "Model parameters\n\n\n[...]\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  y ~                                                 \n    x1                0.485    0.115    4.199    0.000\n    x2                0.123    0.100    1.227    0.220\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .y                -0.025    0.099   -0.253    0.800\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .y                 0.987    0.140    7.071    0.000\n\nR-Square:\n                   Estimate\n    y                 0.162\n\n[...]\n\n\nQUESTIONS? COMMENTS? What about lm?"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#model-plot",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#model-plot",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Model plot",
    "text": "Model plot\n\n# And we can plot it\nlibrary(semPlot)\nsemPaths(fit, whatLabels = \"parameters\",\n         edge.label.cex = 1.5, rotation = 2,\n         residuals = F, sizeMan = 10, curve = 1.9,\n         edge.color=\"black\", edge.label.color=\"black\")"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#model-matrices",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#model-matrices",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Model matrices",
    "text": "Model matrices\nWe can also look at the matrices to enter in the SEM mindset\n\n\n\n#The parameters matrix\ninspect(fit)$beta\n\n   y x1 x2\ny  0  2  3\nx1 0  0  0\nx2 0  0  0\n\ninspect(fit, \"estimates\")$beta\n\n   y   x1   x2\ny  0 0.48 0.12\nx1 0 0.00 0.00\nx2 0 0.00 0.00\n\n\n\n\n#The residual var-covar matrix\ninspect(fit)$psi\n\n   y x1 x2\ny  4      \nx1 0  0   \nx2 0  0  0\n\ninspect(fit, \"estimates\")$psi\n\n       y    x1    x2\ny  0.987            \nx1 0.000 0.741      \nx2 0.000 0.014 0.988"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#basic-lavaan-syntax",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#basic-lavaan-syntax",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Basic lavaan syntax",
    "text": "Basic lavaan syntax\nAs you can see, the regression syntax of lavaan is actually the same as lm, but there is much more in lavaan. \nModel specification sintax:\n\n\n\n\n\n\n\n\nSyntax\nFunction\nExample\n\n\n\n\n~\nRegress onto\nRegress B onto A: B ~ A\n\n\n~~\nResidual (co)variance\nVariance of A: A ~~ A  Variance of A and B: A ~~ B\n\n\n=~\nDefine a reflective LV\nF1 is defined by items 1-4: F1 =~ i1 + i2 + i3 + i4\n\n\n&lt;~\nDefine a formative LV\nF1 is defined by items 1-4: F1 &lt;~ i1 + i2 + i3 + i4\n\n\n:=\nDefine non-model parameters\nu2 := x + y\n\n\n*\nLabel or fix parameter\nZ ~ b*X labels the regression as b"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#basic-lavaan-functions",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#basic-lavaan-functions",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Basic lavaan functions",
    "text": "Basic lavaan functions\n\n\n\n\n\n\n\nFunction\nCommand\n\n\n\n\nsem() / cfa()\nFit the SEM model (cfa is nested in sem…which is nested in lavaan)\n\n\nfitMeasures()\nReturn fit indices of the SEM model\n\n\ninspect()\nInspect/extract information that is stored in a fitted model\n\n\nlavPredict()\nCompute estimated latent scores\n\n\nlavTestLRT()\nCompare (nested) lavaan models\n\n\nmodificationIndices()\nCompute the modification indices of a model\n\n\nparameterEstimates()\nParameter estimates of a latent variable model\n\n\nparameterTable()\nShow the table of the parameters of a fitted model\n\n\nsimulateData()\nSimulate data starting from a lavaan model syntax"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#model-matrices-1",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#model-matrices-1",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Model matrices",
    "text": "Model matrices\n\n#The residual var-covar matrix\ninspect(fit)$psi\n\n   y x1 x2\ny  4      \nx1 0  0   \nx2 0  0  0\n\ninspect(fit, \"estimates\")$psi\n\n       y    x1    x2\ny  0.987            \nx1 0.000 0.741      \nx2 0.000 0.014 0.988"
  },
  {
    "objectID": "slides/02_path-analysis_mediation_equivalence.html#today-in-the-workflow",
    "href": "slides/02_path-analysis_mediation_equivalence.html#today-in-the-workflow",
    "title": "Path analysis & mediation",
    "section": "Today in the workflow",
    "text": "Today in the workflow\nSpecify → Identify → Estimate → Evaluate → Revise/Report\n\n\n\nToday: observed-variable path models and mediation (direct, indirect, total effects) + equivalence/pitfalls.\nNext (03): model fit & diagnostics (global vs local, residuals, MI, disciplined respecification)."
  },
  {
    "objectID": "slides/02_path-analysis_mediation_equivalence.html#learning-objectives",
    "href": "slides/02_path-analysis_mediation_equivalence.html#learning-objectives",
    "title": "Path analysis & mediation",
    "section": "Learning objectives",
    "text": "Learning objectives\nBy the end of this session you should be able to:\n\nWrite a path model as a system of regressions\nDefine direct, indirect, and total effects (and compute them in lavaan)\nExplain why indirect effects have non-normal sampling distributions\nRecognize just-identified path models (why “fit” can be uninformative)\nExplain (and fear, a little) model equivalence and causal interpretation limits"
  },
  {
    "objectID": "slides/02_path-analysis_mediation_equivalence.html#path-analysis-one-sentence",
    "href": "slides/02_path-analysis_mediation_equivalence.html#path-analysis-one-sentence",
    "title": "Path analysis & mediation",
    "section": "Path analysis (one sentence)",
    "text": "Path analysis (one sentence)\nA path model is a set of linear regressions estimated jointly, with an explicit covariance structure and with at least one variable working as mediator.\n\nAs usual, depicting the models is always the best way to understand our models."
  },
  {
    "objectID": "slides/02_path-analysis_mediation_equivalence.html#from-effects-to-equations",
    "href": "slides/02_path-analysis_mediation_equivalence.html#from-effects-to-equations",
    "title": "Path analysis & mediation",
    "section": "From “effects” to equations",
    "text": "From “effects” to equations\nA path diagram is shorthand for a system like:\n\\[\n\\begin{aligned}\nM &= i_M + aX + \\varepsilon_M\\\\\nY &= i_Y + c'X + bM + \\varepsilon_Y\n\\end{aligned}\n\\]\n\n(X) exogenous (predictor)\n(M) mediator (endogenous)\n(Y) outcome (endogenous)"
  },
  {
    "objectID": "slides/02_path-analysis_mediation_equivalence.html#mediation-three-effects",
    "href": "slides/02_path-analysis_mediation_equivalence.html#mediation-three-effects",
    "title": "Path analysis & mediation",
    "section": "Mediation: three effects",
    "text": "Mediation: three effects\n\\[\n\\text{Indirect} = ab \\qquad\n\\text{Direct} = c' \\qquad\n\\text{Total} = c = c' + ab\n\\]\nInterpretation (linear, continuous case):\n\n(a): expected change in (M) per unit change in (X)\n(b): expected change in (Y) per unit change in (M) (holding (X) fixed)\n(c’): remaining effect of (X) on (Y) after (M)"
  },
  {
    "objectID": "slides/02_path-analysis_mediation_equivalence.html#diagram-mediation-template",
    "href": "slides/02_path-analysis_mediation_equivalence.html#diagram-mediation-template",
    "title": "Path analysis & mediation",
    "section": "Diagram: mediation template",
    "text": "Diagram: mediation template\n\n\n\n“Indirect effect” is not automatically “causal mediation”. Causal language requires assumptions!"
  },
  {
    "objectID": "slides/02_path-analysis_mediation_equivalence.html#why-sem-for-mediation",
    "href": "slides/02_path-analysis_mediation_equivalence.html#why-sem-for-mediation",
    "title": "Path analysis & mediation",
    "section": "Why SEM for mediation?",
    "text": "Why SEM for mediation?\nSEM makes it easy to:\n\nestimate the system jointly (including residual covariance if justified)\ncompute functions of parameters (e.g., \\((ab)\\), totals, contrasts)\nadd covariates, multiple mediators, constraints, and (later) measurement models"
  },
  {
    "objectID": "slides/02_path-analysis_mediation_equivalence.html#indirect-effects-are-products",
    "href": "slides/02_path-analysis_mediation_equivalence.html#indirect-effects-are-products",
    "title": "Path analysis & mediation",
    "section": "Indirect effects are products",
    "text": "Indirect effects are products\nThe indirect effect is a product (ab). Even if (a) and (b) are approximately normal, the product is not.\nA common large-sample approximation (delta method):\n\\[\n\\mathrm{Var}(\\widehat{ab}) \\approx\nb^2\\mathrm{Var}(\\hat a) + a^2\\mathrm{Var}(\\hat b) + 2ab\\,\\mathrm{Cov}(\\hat a,\\hat b)\n\\]\nSobel test (same idea, historically popular):\n\\[\nz = \\frac{\\widehat{ab}}{\\sqrt{\\widehat{\\mathrm{Var}}(\\widehat{ab})}}\n\\]\n\n\n\nIn practice, bootstrap is often preferred for indirect effects (especially with small–moderate (N))."
  },
  {
    "objectID": "slides/02_path-analysis_mediation_equivalence.html#lavaan-mediation-as-a-model-defined-parameters",
    "href": "slides/02_path-analysis_mediation_equivalence.html#lavaan-mediation-as-a-model-defined-parameters",
    "title": "Path analysis & mediation",
    "section": "lavaan: mediation as a model + defined parameters",
    "text": "lavaan: mediation as a model + defined parameters\nYou already know ~ and ~~. The new piece is:\n\nlabels (a*X) and defined parameters (ind := a*b)\n\n\nlibrary(lavaan)\n\nmod_med &lt;- '\n  # structural regressions\n  M ~ a*X\n  Y ~ cprime*X + b*M\n\n  # (optional) exogenous variance\n  X ~~ X\n\n  # defined effects\n  ind := a*b\n  tot := cprime + (a*b)\n'\n\nfit &lt;- sem(mod_med, data = dat, meanstructure = TRUE)\nsummary(fit, standardized = TRUE)"
  },
  {
    "objectID": "slides/02_path-analysis_mediation_equivalence.html#bootstrap-the-indirect-effect",
    "href": "slides/02_path-analysis_mediation_equivalence.html#bootstrap-the-indirect-effect",
    "title": "Path analysis & mediation",
    "section": "Bootstrap the indirect effect",
    "text": "Bootstrap the indirect effect\n\nfit_b &lt;- sem(\n  mod_med, data = dat,\n  se = \"bootstrap\", bootstrap = 2000,\n  meanstructure = TRUE\n)\n\nparameterEstimates(fit_b, ci = TRUE, level = .95,\n                   standardized = TRUE) |&gt;\n  subset(op %in% c(\"~\", \":=\"))\n\nInterpretation:\n\nfocus on \\((ab)\\) estimate and its CI\nbootstrap CI is not magic; it’s still conditional on model assumptions"
  },
  {
    "objectID": "slides/02_path-analysis_mediation_equivalence.html#a-richer-example-multiple-indirect-paths",
    "href": "slides/02_path-analysis_mediation_equivalence.html#a-richer-example-multiple-indirect-paths",
    "title": "Path analysis & mediation",
    "section": "A richer example: multiple indirect paths",
    "text": "A richer example: multiple indirect paths\nSometimes the theory implies more than one mediated route.\n(Example structure; your variables will differ.)\n\nNotation. If there are two indirect paths:\n\\[\n\\text{ind}_1 = a_1 b_1,\n\\qquad\n\\text{ind}_2 = a_2 b_2,\n\\qquad\n\\text{total indirect} = \\text{ind}_1 + \\text{ind}_2\n\\]\nYou can define each and test/CI them separately."
  },
  {
    "objectID": "slides/02_path-analysis_mediation_equivalence.html#multiple-indirect-effects-notation",
    "href": "slides/02_path-analysis_mediation_equivalence.html#multiple-indirect-effects-notation",
    "title": "Path analysis & mediation",
    "section": "Multiple indirect effects: notation",
    "text": "Multiple indirect effects: notation\nIf there are two indirect paths:\n\\[\n\\text{ind}_1 = a_1 b_1,\n\\qquad\n\\text{ind}_2 = a_2 b_2,\n\\qquad\n\\text{total indirect} = \\text{ind}_1 + \\text{ind}_2\n\\]\nYou can define each and test/CI them separately."
  },
  {
    "objectID": "slides/02_path-analysis_mediation_equivalence.html#lavaan-multiple-indirect-effects-template",
    "href": "slides/02_path-analysis_mediation_equivalence.html#lavaan-multiple-indirect-effects-template",
    "title": "Path analysis & mediation",
    "section": "lavaan: multiple indirect effects (template)",
    "text": "lavaan: multiple indirect effects (template)\n\nmod_multi &lt;- '\n  # example: two mediators in parallel\n  M1 ~ a1*X\n  M2 ~ a2*X\n  Y  ~ cprime*X + b1*M1 + b2*M2\n\n  # optional: allow mediators to covary\n  M1 ~~ M2\n\n  ind1 := a1*b1\n  ind2 := a2*b2\n  indT := ind1 + ind2\n  tot  := cprime + indT\n'\n\nfit &lt;- sem(mod_multi, data = dat, se = \"bootstrap\", bootstrap = 2000)\nsummary(fit, standardized = TRUE)\n\n\n\n\nParallel mediators are easy to write; the hard part is interpretation (confounding, causal ordering, measurement)."
  },
  {
    "objectID": "slides/02_path-analysis_mediation_equivalence.html#standardized-vs-unstandardized-effects",
    "href": "slides/02_path-analysis_mediation_equivalence.html#standardized-vs-unstandardized-effects",
    "title": "Path analysis & mediation",
    "section": "Standardized vs unstandardized effects",
    "text": "Standardized vs unstandardized effects\n\nUnstandardized (\\(\\hat a\\), \\(\\hat b\\), \\(\\widehat{ab}\\)) are in original units → best for substantive interpretation if units matter.\nStandardized effects help compare across variables/scales.\n\nFor a simple mediation (continuous variables), a fully standardized indirect effect is:\n\\[\n(ab)_{\\text{std}} = ab \\cdot \\frac{\\sigma_X}{\\sigma_Y}\n\\]\n(because the (\\(\\sigma_M\\)) cancels)."
  },
  {
    "objectID": "slides/02_path-analysis_mediation_equivalence.html#identification-fit-can-be-perfect",
    "href": "slides/02_path-analysis_mediation_equivalence.html#identification-fit-can-be-perfect",
    "title": "Path analysis & mediation",
    "section": "Identification + “fit can be perfect”",
    "text": "Identification + “fit can be perfect”\nMany basic path/mediation models are just-identified:\n\nno degrees of freedom \\((df = 0)\\)\nthe model reproduces the sample covariance matrix exactly\nfit indices will look “perfect” even if the causal story is wrong\n\nA useful counting rule:\n\\[\ndf = \\frac{p(p+1)}{2} - t\n\\]\nwhere \\((p)\\) = observed variables, \\((t)\\) = free parameters."
  },
  {
    "objectID": "slides/02_path-analysis_mediation_equivalence.html#model-fit-what-is-being-tested-preview",
    "href": "slides/02_path-analysis_mediation_equivalence.html#model-fit-what-is-being-tested-preview",
    "title": "Path analysis & mediation",
    "section": "Model fit: what is being tested (preview)",
    "text": "Model fit: what is being tested (preview)\nThe global test compares the model-implied covariance to the sample covariance:\n\\[\nH_0:\\ \\Sigma(\\theta) = \\Sigma\n\\]\nIn ML estimation:\n\\[\n\\chi^2 = (N-1)\\,F_{ML}\n\\]\nwhere \\((F_{ML})\\) is the ML discrepancy function.\n\n\n\n\nDeck 03 is where we learn to use this information (global + local diagnostics) without worshipping cutoffs."
  },
  {
    "objectID": "slides/02_path-analysis_mediation_equivalence.html#a-meme-but-also-a-warning",
    "href": "slides/02_path-analysis_mediation_equivalence.html#a-meme-but-also-a-warning",
    "title": "Path analysis & mediation",
    "section": "A meme, but also a warning",
    "text": "A meme, but also a warning\n\n\n\n\nGood fit ≠ true model. In path analysis, equivalence is a real problem."
  },
  {
    "objectID": "slides/02_path-analysis_mediation_equivalence.html#model-equivalence-the-uncomfortable-truth",
    "href": "slides/02_path-analysis_mediation_equivalence.html#model-equivalence-the-uncomfortable-truth",
    "title": "Path analysis & mediation",
    "section": "Model equivalence: the uncomfortable truth",
    "text": "Model equivalence: the uncomfortable truth\nDifferent path diagrams can imply the same covariance matrix.\nSo:\n\nyou often cannot “prove” directionality from cross-sectional covariances alone\nmediation in SEM can be statistically identified and still be causally ambiguous\n\nPractical implication:\n\nTreat a path model as a quantitative claim under a set of assumptions, not as a discovery engine."
  },
  {
    "objectID": "slides/02_path-analysis_mediation_equivalence.html#when-can-mediation-be-interpreted-causally",
    "href": "slides/02_path-analysis_mediation_equivalence.html#when-can-mediation-be-interpreted-causally",
    "title": "Path analysis & mediation",
    "section": "When can mediation be interpreted causally?",
    "text": "When can mediation be interpreted causally?\nAt minimum, you need assumptions such as:\n\ntemporal ordering (X precedes M precedes Y)\nno unmeasured confounding for:\n\n\\((X \\rightarrow M)\\)\n\\((M \\rightarrow Y)\\)\n\\((X \\rightarrow Y)\\)\n\ncorrect model form (linearity, additivity, no omitted interactions unless modeled)\n\nWe will revisit causal interpretation when we discuss: - longitudinal designs (deck 09) - measurement error (decks 04–05)"
  },
  {
    "objectID": "slides/02_path-analysis_mediation_equivalence.html#diagnostics-what-to-check-now",
    "href": "slides/02_path-analysis_mediation_equivalence.html#diagnostics-what-to-check-now",
    "title": "Path analysis & mediation",
    "section": "Diagnostics (what to check now)",
    "text": "Diagnostics (what to check now)\nEven before learning “fit”, you should check:\n\nsign and magnitude of parameters (are they plausible?)\nstandard errors / CIs (especially for \\(ab\\))\nresidual variances (negative? huge? suspiciously tiny?)\ncollinearity among predictors/mediators (unstable estimates)\n\n\n\n\nFor mediation, your first diagnostic is often conceptual: is this ordering defensible? then statistical: is \\((ab)\\) estimated precisely?\n\n\n\n\n\n\nCan ‘sex’ be a mediator?!"
  },
  {
    "objectID": "slides/02_path-analysis_mediation_equivalence.html#exercises-lab-02",
    "href": "slides/02_path-analysis_mediation_equivalence.html#exercises-lab-02",
    "title": "Path analysis & mediation",
    "section": "Exercises (Lab 02)",
    "text": "Exercises (Lab 02)\nGo to:\n\nlabs/lab02_path-mediation.qmd\n\nYou will practice:\n\nFit a simple mediation with bootstrap CI for \\((ab)\\)\nAdd covariates (and observe what happens to \\((a)\\), \\((b)\\), and \\((c')\\))\nCompare partial vs “full” mediation (constraint \\((c'=0)\\))\nFit a parallel-mediator model and interpret \\((ind_1)\\), \\((ind_2)\\), \\((ind_T)\\)"
  },
  {
    "objectID": "slides/02_path-analysis_mediation_equivalence.html#pitfall-callout-full-mediation-is-rarely-a-good-goal",
    "href": "slides/02_path-analysis_mediation_equivalence.html#pitfall-callout-full-mediation-is-rarely-a-good-goal",
    "title": "Path analysis & mediation",
    "section": "Pitfall callout: “full mediation” is rarely a good goal",
    "text": "Pitfall callout: “full mediation” is rarely a good goal\nEven if \\((c')\\) is small/non-significant:\n\nit does not prove the direct path is zero\npower and measurement error can make \\((c')\\) hard to detect\nthe direct effect can be suppressed or masked by omitted paths\n\nBetter framing:\n\nfocus on effect sizes + uncertainty\ntest theoretically motivated constraints (and report them transparently)"
  },
  {
    "objectID": "slides/02_path-analysis_mediation_equivalence.html#take-home-3-things",
    "href": "slides/02_path-analysis_mediation_equivalence.html#take-home-3-things",
    "title": "Path analysis & mediation",
    "section": "Take-home: 3 things",
    "text": "Take-home: 3 things\n\nMediation effects are functions of parameters (\\((ab)\\), \\((c'+ab)\\)) → compute them explicitly\n\nThe indirect effect’s sampling distribution is non-normal → bootstrap is often sensible\n\nPath models are vulnerable to equivalence → fit alone cannot justify causal stories"
  },
  {
    "objectID": "slides/02_path-analysis_mediation_equivalence.html#further-reading-self-study",
    "href": "slides/02_path-analysis_mediation_equivalence.html#further-reading-self-study",
    "title": "Path analysis & mediation",
    "section": "Further reading / self-study",
    "text": "Further reading / self-study\n\nex01_power_montecarlo_sem.qmd — power and precision for indirect effects via simulation\n\n(Optional) causal inference perspective: add a short reading list in the course site resources"
  },
  {
    "objectID": "slides/02_path-analysis_mediation_equivalence.html#references",
    "href": "slides/02_path-analysis_mediation_equivalence.html#references",
    "title": "Path analysis & mediation",
    "section": "References",
    "text": "References\n(Add citations/keys once the course bibliography is finalized for the website.)"
  },
  {
    "objectID": "labs/lab02_path-mediation.html",
    "href": "labs/lab02_path-mediation.html",
    "title": "Lab 02 — Path analysis & mediation (observed variables)",
    "section": "",
    "text": "In this lab you will:\n\nFit a simple mediation model as a system of regressions in lavaan\nCompute direct, indirect, and total effects via defined parameters\nCompare delta-method vs bootstrap inference for the indirect effect\nTest a theoretically motivated constraint (full mediation: (c’ = 0))\nExtend to covariates and parallel mediators\n(Optional, advanced) See a concrete example of equivalent just-identified models"
  },
  {
    "objectID": "labs/lab02_path-mediation.html#a-write-the-model",
    "href": "labs/lab02_path-mediation.html#a-write-the-model",
    "title": "Lab 02 — Path analysis & mediation (observed variables)",
    "section": "1a) Write the model",
    "text": "1a) Write the model\n\nLabel the paths \\((a)\\), \\((b)\\), \\((c')\\)\nDefine ind := a*b and tot := cprime + a*b\n\n\n\nShow code\nmod_med &lt;- '\n  M ~ a*X\n  Y ~ cprime*X + b*M\n\n  ind := a*b\n  tot := cprime + (a*b)\n'"
  },
  {
    "objectID": "labs/lab02_path-mediation.html#b-fit-inspect",
    "href": "labs/lab02_path-mediation.html#b-fit-inspect",
    "title": "Lab 02 — Path analysis & mediation (observed variables)",
    "section": "1b) Fit + inspect",
    "text": "1b) Fit + inspect\n\n\nShow code\nfit_med &lt;- sem(mod_med, data = dat, meanstructure = TRUE)\nsummary(fit_med, standardized = TRUE)\n\n\nlavaan 0.6-19 ended normally after 1 iteration\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         7\n\n  Number of observations                           400\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  M ~                                                                   \n    X          (a)    0.463    0.049    9.521    0.000    0.463    0.430\n  Y ~                                                                   \n    X       (cprm)   -0.010    0.052   -0.185    0.853   -0.010   -0.008\n    M          (b)    0.659    0.048   13.604    0.000    0.659    0.603\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .M                -0.062    0.049   -1.248    0.212   -0.062   -0.056\n   .Y                -0.031    0.048   -0.648    0.517   -0.031   -0.026\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .M                 0.973    0.069   14.142    0.000    0.973    0.815\n   .Y                 0.914    0.065   14.142    0.000    0.914    0.641\n\nDefined Parameters:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n    ind               0.305    0.039    7.800    0.000    0.305    0.259\n    tot               0.296    0.057    5.185    0.000    0.296    0.251"
  },
  {
    "objectID": "labs/lab02_path-mediation.html#c-extract-only-the-pieces-you-need",
    "href": "labs/lab02_path-mediation.html#c-extract-only-the-pieces-you-need",
    "title": "Lab 02 — Path analysis & mediation (observed variables)",
    "section": "1c) Extract only the pieces you need",
    "text": "1c) Extract only the pieces you need\n\n\nShow code\npe &lt;- parameterEstimates(fit_med, standardized = TRUE)\npe[pe$op %in% c(\"~\",\":=\"), c(\"lhs\",\"op\",\"rhs\",\"label\",\"est\",\"se\",\"z\",\"pvalue\",\"std.all\")]\n\n\n   lhs op          rhs  label    est    se      z pvalue std.all\n1    M  ~            X      a  0.463 0.049  9.521  0.000   0.430\n2    Y  ~            X cprime -0.010 0.052 -0.185  0.853  -0.008\n3    Y  ~            M      b  0.659 0.048 13.604  0.000   0.603\n10 ind :=          a*b    ind  0.305 0.039  7.800  0.000   0.259\n11 tot := cprime+(a*b)    tot  0.296 0.057  5.185  0.000   0.251\n\n\nQuestions (answer in words)\n\nAre the estimates close to the generating values \\((a=0.50)\\), \\((b=0.60)\\), \\((c'=0.10)\\)?\nWhat is your estimate of the indirect effect \\((ab)\\)? Is it close to \\((0.30)\\)?\nWhat does lavaan use (by default) to get the SE for ind := a*b?"
  },
  {
    "objectID": "labs/lab02_path-mediation.html#compare-nested-models-lrt",
    "href": "labs/lab02_path-mediation.html#compare-nested-models-lrt",
    "title": "Lab 02 — Path analysis & mediation (observed variables)",
    "section": "Compare nested models (LRT)",
    "text": "Compare nested models (LRT)\n\n\nShow code\nanova(fit_med, fit_full)\n\n\n\nChi-Squared Difference Test\n\n         Df  AIC  BIC Chisq Chisq diff RMSEA Df diff Pr(&gt;Chisq)\nfit_med   0 2237 2265  0.00                                    \nfit_full  1 2235 2259  0.03     0.0343     0       1       0.85\n\n\nInterpretation questions\n\nWhat does a significant χ² difference imply here?\nIn this simulated world (true \\((c'=0.10)\\)), should you expect full mediation to be rejected as \\((N)\\) grows? Why?\nIn your substantive area, what theoretical arguments would justify fixing \\((c'=0)\\) (if any)?"
  },
  {
    "objectID": "labs/lab02_path-mediation.html#a-fit-without-z-misspecified-on-purpose",
    "href": "labs/lab02_path-mediation.html#a-fit-without-z-misspecified-on-purpose",
    "title": "Lab 02 — Path analysis & mediation (observed variables)",
    "section": "4a) Fit without Z (misspecified on purpose)",
    "text": "4a) Fit without Z (misspecified on purpose)\n\n\nShow code\nfit_noZ &lt;- sem(mod_med, data = dat2, meanstructure = TRUE)\nparameterEstimates(fit_noZ)[parameterEstimates(fit_noZ)$op %in% c(\"~\",\":=\"),\n                            c(\"lhs\",\"op\",\"rhs\",\"label\",\"est\",\"se\",\"pvalue\")]\n\n\n   lhs op          rhs  label    est    se pvalue\n1    M  ~            X      a  0.513 0.057  0.000\n2    Y  ~            X cprime -0.020 0.063  0.758\n3    Y  ~            M      b  0.846 0.050  0.000\n10 ind :=          a*b    ind  0.434 0.055  0.000\n11 tot := cprime+(a*b)    tot  0.415 0.075  0.000"
  },
  {
    "objectID": "labs/lab02_path-mediation.html#b-fit-with-z-included",
    "href": "labs/lab02_path-mediation.html#b-fit-with-z-included",
    "title": "Lab 02 — Path analysis & mediation (observed variables)",
    "section": "4b) Fit with Z included",
    "text": "4b) Fit with Z included\n\n\nShow code\nmod_withZ &lt;- '\n  M ~ a*X + d*Z\n  Y ~ cprime*X + b*M + e*Z\n\n  ind := a*b\n  tot := cprime + (a*b)\n'\nfit_withZ &lt;- sem(mod_withZ, data = dat2, meanstructure = TRUE)\nparameterEstimates(fit_withZ)[parameterEstimates(fit_withZ)$op %in% c(\"~\",\":=\"),\n                              c(\"lhs\",\"op\",\"rhs\",\"label\",\"est\",\"se\",\"pvalue\")]\n\n\n   lhs op          rhs  label   est    se pvalue\n1    M  ~            X      a 0.500 0.049    0.0\n2    M  ~            Z      d 0.578 0.049    0.0\n3    Y  ~            X cprime 0.097 0.059    0.1\n4    Y  ~            M      b 0.594 0.053    0.0\n5    Y  ~            Z      e 0.558 0.060    0.0\n15 ind :=          a*b    ind 0.297 0.040    0.0\n16 tot := cprime+(a*b)    tot 0.394 0.060    0.0\n\n\nQuestions\n\nCompare \\((b)\\) and \\((c')\\) from fit_noZ vs fit_withZ. Which one looks more biased and why?\nIn real research, why is “include covariates” not a magic causal fix?\nHow would you argue for including a covariate in a preregistered SEM?"
  },
  {
    "objectID": "labs/lab02_path-mediation.html#take-home-lab",
    "href": "labs/lab02_path-mediation.html#take-home-lab",
    "title": "Lab 02 — Path analysis & mediation (observed variables)",
    "section": "Take-home (lab)",
    "text": "Take-home (lab)\n\nMediation is a system of equations; the indirect effect is a defined parameter \\((ab)\\)\nFor \\((ab)\\), bootstrap CIs are often more trustworthy than normal-theory tests\nTesting “full mediation” is a constraint test—not a goal by itself\nCovariates help, but causal claims still require assumptions and design"
  },
  {
    "objectID": "slides/03_model-fit_diagnostics_respecification.html#today-in-the-workflow",
    "href": "slides/03_model-fit_diagnostics_respecification.html#today-in-the-workflow",
    "title": "Model fit & diagnostics",
    "section": "Today in the workflow",
    "text": "Today in the workflow\nSpecify → Identify → Estimate → Evaluate → Revise/Report\n\n\n\nToday: how we evaluate models: global fit + local diagnostics → disciplined respecification.\nWe keep the focus on observed-variable models; CFA-specific diagnostics come in deck 04."
  },
  {
    "objectID": "slides/03_model-fit_diagnostics_respecification.html#learning-objectives",
    "href": "slides/03_model-fit_diagnostics_respecification.html#learning-objectives",
    "title": "Model fit & diagnostics",
    "section": "Learning objectives",
    "text": "Learning objectives\nBy the end of this session you should be able to:\n\nState what “model fit” means: S vs Σ̂(θ) (exact vs approximate fit)\nDistinguish global fit from local misfit\nCompute and report core indices (χ², CFI/TLI, RMSEA + CI, SRMR) in lavaan\nUse residuals and modification indices (MI + EPC/SEPC) responsibly\nFollow a respecification protocol that avoids “fit hacking”"
  },
  {
    "objectID": "slides/03_model-fit_diagnostics_respecification.html#the-object-of-interest",
    "href": "slides/03_model-fit_diagnostics_respecification.html#the-object-of-interest",
    "title": "Model fit & diagnostics",
    "section": "The object of interest",
    "text": "The object of interest\nModel fit is about reproducing the observed covariance matrix.\n\\[\nH_0:\\ \\hat{\\Sigma}(\\theta) = \\Sigma\n\\]\n\n\n\n\n\n\nFit indices summarize “how close” the model-implied covariance structure is to the data."
  },
  {
    "objectID": "slides/03_model-fit_diagnostics_respecification.html#fit-is-a-property-of-a-model-data-estimator",
    "href": "slides/03_model-fit_diagnostics_respecification.html#fit-is-a-property-of-a-model-data-estimator",
    "title": "Model fit & diagnostics",
    "section": "Fit is a property of a model + data + estimator",
    "text": "Fit is a property of a model + data + estimator\nFit indices are not “truth meters”.\nThey depend on:\n\nsample size \\((N)\\)\nmodel degrees of freedom \\((df)\\)\nestimator and distributional assumptions (ML, robust ML, WLSMV, …)\nmodel complexity (how constrained the model is)"
  },
  {
    "objectID": "slides/03_model-fit_diagnostics_respecification.html#quick-example-dataset-same-structure-as-your-exercise-2",
    "href": "slides/03_model-fit_diagnostics_respecification.html#quick-example-dataset-same-structure-as-your-exercise-2",
    "title": "Model fit & diagnostics",
    "section": "Quick example dataset (same structure as your Exercise 2)",
    "text": "Quick example dataset (same structure as your Exercise 2)\nWe simulate data from a “true” structural model and then fit a simplified (misspecified) model to create misfit.\n\nN &lt;- 483\n\nm_true &lt;- \"\n  lifeSatisfaction ~ .05*attachment + .25*selfEsteem + .40*parentalSupport + .30*salary\n  selfEsteem       ~ .40*parentalSupport + .20*attachment\n  attachment ~~ .30*parentalSupport\n\"\n\nm_fit &lt;- \"\n  lifeSatisfaction ~ selfEsteem + salary     # omits some true predictors\n  selfEsteem       ~ parentalSupport + attachment\n  # attachment ~~ parentalSupport            # (omitted on purpose)\n\"\n\nE2 &lt;- simulateData(m_true, sample.nobs = N, seed = 12)\nfit &lt;- sem(m_fit, data = E2, meanstructure = TRUE)"
  },
  {
    "objectID": "slides/03_model-fit_diagnostics_respecification.html#families-of-fit-indices",
    "href": "slides/03_model-fit_diagnostics_respecification.html#families-of-fit-indices",
    "title": "Model fit & diagnostics",
    "section": "Families of fit indices",
    "text": "Families of fit indices\n\nχ²-based (exact-fit test)\nComparative / incremental (CFI, TLI, NFI)\nParsimony (RMSEA + CI; AIC/BIC)\nResidual-based / absolute (SRMR, RMR; and other “standalone” indices)\n\n\n\n\nYou need at least one index from each of: comparative + approximate + residual-based."
  },
  {
    "objectID": "slides/03_model-fit_diagnostics_respecification.html#χ²-test-what-it-is-and-why-it-annoys-people",
    "href": "slides/03_model-fit_diagnostics_respecification.html#χ²-test-what-it-is-and-why-it-annoys-people",
    "title": "Model fit & diagnostics",
    "section": "χ² test: what it is (and why it annoys people)",
    "text": "χ² test: what it is (and why it annoys people)\nUnder ML, the likelihood ratio test yields:\n\\[\n\\chi^2 = (N-1)\\,F_{\\mathrm{ML}}\n\\]\nwith \\((df = \\frac{p(p+1)}{2} - t)\\) (non-redundant moments minus free parameters).\nWhy it rejects so often:\n\nwith large \\((N)\\), tiny misspecifications become detectable\nreal data rarely satisfy “exact fit” assumptions"
  },
  {
    "objectID": "slides/03_model-fit_diagnostics_respecification.html#χ²-assumptions-classical-ml",
    "href": "slides/03_model-fit_diagnostics_respecification.html#χ²-assumptions-classical-ml",
    "title": "Model fit & diagnostics",
    "section": "χ² assumptions (classical ML)",
    "text": "χ² assumptions (classical ML)\nThe textbook χ² calibration relies on:\n\nindependent observations\ncorrect model form\nmultivariate normality for endogenous observed variables (in ML)\nsufficiently large \\((N)\\)\n\n…and it is sensitive to:\n\nnon-normality\nmissing data handling\nclustering (design effects)\n\n(Robust corrections and missing-data strategies come in deck 06.)"
  },
  {
    "objectID": "slides/03_model-fit_diagnostics_respecification.html#lavaan-core-fit-measures",
    "href": "slides/03_model-fit_diagnostics_respecification.html#lavaan-core-fit-measures",
    "title": "Model fit & diagnostics",
    "section": "lavaan: core fit measures",
    "text": "lavaan: core fit measures\n\nfitMeasures(fit, c(\"npar\", \"chisq\", \"df\", \"pvalue\",\n                   \"cfi\", \"tli\",\n                   \"rmsea\", \"rmsea.ci.lower\", \"rmsea.ci.upper\",\n                   \"srmr\"))\n\n\n\n\nWe will later discuss robust variants (scaled χ², robust CFI/RMSEA) and when they matter."
  },
  {
    "objectID": "slides/03_model-fit_diagnostics_respecification.html#comparative-indices-cfitli-baseline-model-logic",
    "href": "slides/03_model-fit_diagnostics_respecification.html#comparative-indices-cfitli-baseline-model-logic",
    "title": "Model fit & diagnostics",
    "section": "Comparative indices (CFI/TLI): baseline model logic",
    "text": "Comparative indices (CFI/TLI): baseline model logic\nComparative indices evaluate improvement over a baseline (independence) model.\nBaseline idea: each variable has its own variance; covariances are fixed to 0.\n\nbm &lt;- \"\n  lifeSatisfaction ~~ lifeSatisfaction\n  selfEsteem ~~ selfEsteem\n  salary ~~ salary\n  parentalSupport ~~ parentalSupport\n  attachment ~~ attachment\n\"\nfit_bm &lt;- sem(bm, data = E2, meanstructure = TRUE)"
  },
  {
    "objectID": "slides/03_model-fit_diagnostics_respecification.html#visual-intuition-baseline-vs-user-model",
    "href": "slides/03_model-fit_diagnostics_respecification.html#visual-intuition-baseline-vs-user-model",
    "title": "Model fit & diagnostics",
    "section": "Visual intuition: baseline vs user model",
    "text": "Visual intuition: baseline vs user model\n\n\nBaseline model (no covariances)\n\n\n\n\n\n\n\n\n\nchisq    df   cfi \n  277    10     0 \n\n\n\nUser model is evaluated relative to baseline.\nCFI uses the improvement in \\[\n\\delta = \\chi^2 - df\n\\] compared to baseline (and saturated).\n\n\n chisq     df    cfi \n62.984  3.000  0.725"
  },
  {
    "objectID": "slides/03_model-fit_diagnostics_respecification.html#cfi-formula-and-why-df-matters",
    "href": "slides/03_model-fit_diagnostics_respecification.html#cfi-formula-and-why-df-matters",
    "title": "Model fit & diagnostics",
    "section": "CFI formula (and why df matters)",
    "text": "CFI formula (and why df matters)\n\\[\n\\mathrm{CFI}=\\frac{\\delta(\\text{Baseline})-\\delta(\\text{User})}{\\delta(\\text{Baseline})-\\delta(\\text{Saturated})}\n\\qquad\n\\text{with}\\ \\delta=\\chi^2-df,\\ \\delta(\\text{Saturated})=0\n\\]\nImplication: \\(CFI\\)/\\(TLI\\) are functions of both misfit and \\(df\\).\nTwo models can have the same χ² but different CFI if their \\(df\\) differ.\n\nfitMeasures(fit, c(\"cfi\", \"tli\", \"nnfi\"))\n\n\n\n\nAll bounded between 0.0 and 1.0, with values closer to 1 (ONE) indicating better fit."
  },
  {
    "objectID": "slides/03_model-fit_diagnostics_respecification.html#parsimony-approximate-fit-rmsea",
    "href": "slides/03_model-fit_diagnostics_respecification.html#parsimony-approximate-fit-rmsea",
    "title": "Model fit & diagnostics",
    "section": "Parsimony & approximate fit: RMSEA",
    "text": "Parsimony & approximate fit: RMSEA\nRMSEA targets approximate (not exact) fit.\nA common ML form:\n\\[\n\\mathrm{RMSEA}=\\sqrt{\\max\\left(\\frac{\\chi^2-df}{df(N-1)},0\\right)}\n\\]\n\nprefers parsimony: penalizes low \\((df)\\) models less forgivingly\nalways report the confidence interval\n\n\nfitMeasures(fit, c(\"rmsea\", \"rmsea.ci.lower\", \"rmsea.ci.upper\"))\n\n\n\n\nIt is bounded between 0.0 and 1.0, with values closer to 0 (ZERO) indicating better fit."
  },
  {
    "objectID": "slides/03_model-fit_diagnostics_respecification.html#residual-based-fit-srmr",
    "href": "slides/03_model-fit_diagnostics_respecification.html#residual-based-fit-srmr",
    "title": "Model fit & diagnostics",
    "section": "Residual-based fit: SRMR",
    "text": "Residual-based fit: SRMR\nSRMR summarizes the average standardized residual:\n\ncompare observed correlations vs model-implied correlations\nless sensitive to \\((N)\\) than χ², but sensitive to model structure\n\n\nfitMeasures(fit, c(\"srmr\", \"rmr\"))\n\n\n\n\nSRMR is often most informative when paired with residual inspection (next slides).\n\n\n\n\n\n\nIt is bounded between 0.0 and 1.0, with values closer to 0 (ZERO) indicating better fit."
  },
  {
    "objectID": "slides/03_model-fit_diagnostics_respecification.html#what-to-report-minimum-set",
    "href": "slides/03_model-fit_diagnostics_respecification.html#what-to-report-minimum-set",
    "title": "Model fit & diagnostics",
    "section": "What to report (minimum set)",
    "text": "What to report (minimum set)\nIn manuscripts, prefer a consistent minimal bundle:\n\nestimator + missing data strategy\nχ², \\(df\\), \\(p\\)\n\\(CFI\\) and \\(TLI\\)\n\\(RMSEA\\) with 90% \\(CI\\) (and \\(SRMR\\))\nlocal diagnostics summary (what you checked, what you changed, and why)"
  },
  {
    "objectID": "slides/03_model-fit_diagnostics_respecification.html#global-vs-local-fit",
    "href": "slides/03_model-fit_diagnostics_respecification.html#global-vs-local-fit",
    "title": "Model fit & diagnostics",
    "section": "Global vs local fit",
    "text": "Global vs local fit\n\nGlobal fit: one-number summaries of overall mismatch (χ², CFI/TLI, RMSEA, SRMR)\nLocal fit: where the mismatch lives\n\nresidual covariance/correlation matrices\nstandardized residuals\nMI + EPC/SEPC\n\n\n\n\n\nGlobal fit can look “ok” while a few parameters are seriously wrong (and vice versa)."
  },
  {
    "objectID": "slides/03_model-fit_diagnostics_respecification.html#residuals-where-does-the-model-fail",
    "href": "slides/03_model-fit_diagnostics_respecification.html#residuals-where-does-the-model-fail",
    "title": "Model fit & diagnostics",
    "section": "Residuals: “where does the model fail?”",
    "text": "Residuals: “where does the model fail?”\nlavaan can return observed, implied, and residual covariances.\n\nres &lt;- lavResiduals(fit, type = \"raw\")\nnames(res)\n\n[1] \"type\"    \"cov\"     \"mean\"    \"cov.z\"   \"mean.z\"  \"summary\"\n\nres$cov     # residual covariance\n\n                 lfStsf slfEst salary prntlS attchm\nlifeSatisfaction  0.007                            \nselfEsteem        0.009  0.000                     \nsalary            0.015  0.039  0.000              \nparentalSupport   0.322  0.000  0.000  0.000       \nattachment        0.110  0.000  0.000  0.000  0.000\n\n\nIn practice you inspect:\n\nlargest residual covariances/correlations\npatterns (blocks, specific pairs, method effects)"
  },
  {
    "objectID": "slides/03_model-fit_diagnostics_respecification.html#standardized-residuals-local-z-scores",
    "href": "slides/03_model-fit_diagnostics_respecification.html#standardized-residuals-local-z-scores",
    "title": "Model fit & diagnostics",
    "section": "Standardized residuals (local z-scores)",
    "text": "Standardized residuals (local z-scores)\nStandardized residuals scale residuals by their sampling variability.\n\nres_std &lt;- residuals(fit, type = \"cor\")\nres_std$cov  # standardized residual covariances\n\n                 lfStsf slfEst salary prntlS attchm\nlifeSatisfaction  0.000                            \nselfEsteem        0.006  0.000                     \nsalary            0.012  0.037  0.000              \nparentalSupport   0.296  0.000  0.000  0.000       \nattachment        0.094  0.000  0.000  0.000  0.000\n\n\nHeuristic: large absolute standardized residuals flag local misfit.\n(We avoid “magic cutoffs”; interpret in context + patterns, but remember, you expect each of them to be \\(zero\\).)"
  },
  {
    "objectID": "slides/03_model-fit_diagnostics_respecification.html#step-5-model-modification-the-dangerous-step",
    "href": "slides/03_model-fit_diagnostics_respecification.html#step-5-model-modification-the-dangerous-step",
    "title": "Model fit & diagnostics",
    "section": "Step 5: model modification (the dangerous step)",
    "text": "Step 5: model modification (the dangerous step)\nThe goal is not “better numbers”.\nThe goal is:\n\na model that is more plausible given theory and diagnostics\nchanges that are transparent and ideally replicable"
  },
  {
    "objectID": "slides/03_model-fit_diagnostics_respecification.html#modification-indices-the-lagrange-multiplier-idea",
    "href": "slides/03_model-fit_diagnostics_respecification.html#modification-indices-the-lagrange-multiplier-idea",
    "title": "Model fit & diagnostics",
    "section": "Modification indices: the Lagrange Multiplier idea",
    "text": "Modification indices: the Lagrange Multiplier idea\nMI approximates how much χ² would decrease if a fixed parameter were freed.\n\nMI is a score test (local improvement)\nit does not tell you the direction/magnitude of the new parameter\n\nSo you inspect MI together with EPC (expected parameter change).\n\nmi &lt;- modificationIndices(fit, sort. = TRUE)\nhead(mi[, c(\"lhs\",\"op\",\"rhs\",\"mi\",\"epc\",\"sepc.all\")], 10)\n\n                lhs op              rhs     mi    epc sepc.all\n19 lifeSatisfaction  ~  parentalSupport 58.234  0.416    0.339\n18 lifeSatisfaction ~~       selfEsteem 52.562 -0.941   -0.880\n27  parentalSupport  ~ lifeSatisfaction 45.077  0.256    0.314\n21       selfEsteem  ~ lifeSatisfaction 33.931 -0.587   -0.620\n20 lifeSatisfaction  ~       attachment  5.473  0.114    0.100\n22       selfEsteem  ~           salary  0.752  0.041    0.037\n32       attachment  ~       selfEsteem  0.556  2.784    3.020\n28  parentalSupport  ~       selfEsteem  0.555 -6.106   -7.100\n24           salary  ~       selfEsteem  0.552  0.028    0.031\n23           salary  ~ lifeSatisfaction  0.524  0.073    0.086"
  },
  {
    "objectID": "slides/03_model-fit_diagnostics_respecification.html#epc-vs-sepc-why-you-want-both",
    "href": "slides/03_model-fit_diagnostics_respecification.html#epc-vs-sepc-why-you-want-both",
    "title": "Model fit & diagnostics",
    "section": "EPC vs SEPC (why you want both)",
    "text": "EPC vs SEPC (why you want both)\n\nEPC: expected unstandardized change (units matter)\nSEPC: expected standardized change (comparability)\n\nIf an MI is huge but EPC is tiny, the “improvement” may be statistically detectable but substantively trivial (especially with large \\(N\\))."
  },
  {
    "objectID": "slides/03_model-fit_diagnostics_respecification.html#a-disciplined-respecification-protocol",
    "href": "slides/03_model-fit_diagnostics_respecification.html#a-disciplined-respecification-protocol",
    "title": "Model fit & diagnostics",
    "section": "A disciplined respecification protocol",
    "text": "A disciplined respecification protocol\n\nCheck admissibility\nconvergence, Heywood cases (negative variances), huge SE, non-identified warnings\nInspect local misfit\nresiduals → standardized residuals → MI/EPC\nApply theory filter\nis the modification plausible and consistent with your construct/design? How can I justify it? What are the consequences on my theory/model?\nChange one thing at a time\nrefit, re-check, document\nValidate\nholdout sample / replication / preregistration (when feasible)"
  },
  {
    "objectID": "slides/03_model-fit_diagnostics_respecification.html#pitfall-callout-models-that-fit-are-not-necessarily-true",
    "href": "slides/03_model-fit_diagnostics_respecification.html#pitfall-callout-models-that-fit-are-not-necessarily-true",
    "title": "Model fit & diagnostics",
    "section": "Pitfall callout: “models that fit” are not necessarily true",
    "text": "Pitfall callout: “models that fit” are not necessarily true\nRemember that just because your model fits the data, you cannot conclude that your model is correct nor that the data generating process follows your hypothesized paths.\n\nopposite arrows can imply the same covariance structure (equivalence)\npost-hoc modifications capitalize on chance\nmeasurement error in observed variables contaminates estimates\n\nAs usual all models are false, but some are useful."
  },
  {
    "objectID": "slides/03_model-fit_diagnostics_respecification.html#exercises-lab-03",
    "href": "slides/03_model-fit_diagnostics_respecification.html#exercises-lab-03",
    "title": "Model fit & diagnostics",
    "section": "Exercises (Lab 03)",
    "text": "Exercises (Lab 03)\nGo to:\n\nlabs/lab03_fit-diagnostics_MI_residuals.qmd\n\nYou’ll practice:\n\nExtracting and reporting fit indices\nInspecting residual matrices (raw + standardized)\nUsing MI + EPC/SEPC to propose theory-justified modifications\nDocumenting a respecification path transparently"
  },
  {
    "objectID": "slides/03_model-fit_diagnostics_respecification.html#take-home-3-things",
    "href": "slides/03_model-fit_diagnostics_respecification.html#take-home-3-things",
    "title": "Model fit & diagnostics",
    "section": "Take-home: 3 things",
    "text": "Take-home: 3 things\n\nFit indices quantify mismatch between S and Σ̂(θ); they are not “truth”\n\nAlways pair global fit with local diagnostics (residuals + MI/EPC)\n\nRespecification is a scientific decision: theory + transparency + validation"
  },
  {
    "objectID": "slides/03_model-fit_diagnostics_respecification.html#optional-beyond-fixed-cutoffs",
    "href": "slides/03_model-fit_diagnostics_respecification.html#optional-beyond-fixed-cutoffs",
    "title": "Model fit & diagnostics",
    "section": "Optional: beyond fixed cutoffs",
    "text": "Optional: beyond fixed cutoffs\nRules like “CFI &gt; .95” or “RMSEA &lt; .06” can be misleading because fit indices depend on:\n\nmodel structure (df, factor loadings, cross-loadings, residual correlations)\ndistributional features (non-normality, ordinal data)\nestimation method and sample size\n\nExtra (later / self-study): dynamic fit indices & simulation-informed expectations\n\nGroskurth et al. (2023) — fit cutoffs depend on analysis characteristics\nMcNeish & Wolf (2023) — pushing against universal cutoffs\nDynamic fit index app (for exploring scenario-dependent thresholds)"
  },
  {
    "objectID": "slides/03_model-fit_diagnostics_respecification.html#references",
    "href": "slides/03_model-fit_diagnostics_respecification.html#references",
    "title": "Model fit & diagnostics",
    "section": "References",
    "text": "References\n(We’ll finalize citations/keys in refs/references.bib when polishing the course website.)"
  },
  {
    "objectID": "labs/lab03_fit-diagnostics_MI_residuals.html",
    "href": "labs/lab03_fit-diagnostics_MI_residuals.html",
    "title": "Lab 03 — Fit & diagnostics: residuals, MI, and disciplined respecification",
    "section": "",
    "text": "In this lab you will learn to:\n\nExtract and report core global fit indices (χ², CFI/TLI, RMSEA+CI, SRMR)\nInspect local misfit using residual matrices (raw + standardized)\nUse modification indices (MI) together with EPC / SEPC (not MI alone)\nApply a disciplined respecification protocol: one change at a time, theory filter, document\n\nImportant constraint for this lab:\nYou are not allowed to add paths “because MI says so”. Each change needs a short substantive rationale."
  },
  {
    "objectID": "labs/lab03_fit-diagnostics_MI_residuals.html#a-extract-key-indices",
    "href": "labs/lab03_fit-diagnostics_MI_residuals.html#a-extract-key-indices",
    "title": "Lab 03 — Fit & diagnostics: residuals, MI, and disciplined respecification",
    "section": "1a) Extract key indices",
    "text": "1a) Extract key indices\n\n\nShow code\nfitMeasures(\n  fit0,\n  c(\"npar\",\"chisq\",\"df\",\"pvalue\",\"cfi\",\"tli\",\n    \"rmsea\",\"rmsea.ci.lower\",\"rmsea.ci.upper\",\"srmr\")\n)\n\n\n          npar          chisq             df         pvalue            cfi \n         8.000         72.623          3.000          0.000          0.788 \n           tli          rmsea rmsea.ci.lower rmsea.ci.upper           srmr \n         0.505          0.219          0.177          0.264          0.067"
  },
  {
    "objectID": "labs/lab03_fit-diagnostics_MI_residuals.html#b-interpret",
    "href": "labs/lab03_fit-diagnostics_MI_residuals.html#b-interpret",
    "title": "Lab 03 — Fit & diagnostics: residuals, MI, and disciplined respecification",
    "section": "1b) Interpret",
    "text": "1b) Interpret\nAnswer in 3–5 sentences:\n\nDoes the model seem globally plausible?\nWhich indices are most informative here and why?\nIf χ² is significant, what are two non-mutually-exclusive reasons?"
  },
  {
    "objectID": "labs/lab03_fit-diagnostics_MI_residuals.html#a-residual-covariances",
    "href": "labs/lab03_fit-diagnostics_MI_residuals.html#a-residual-covariances",
    "title": "Lab 03 — Fit & diagnostics: residuals, MI, and disciplined respecification",
    "section": "3a) Residual covariances",
    "text": "3a) Residual covariances\n\n\nShow code\n# Play with the different 'type of residuals'\n# 'cor', 'cor.bollen', 'cor.bentler', 'raw'\nres_cov &lt;- lavResiduals(fit0)\n# res_cov$resid is S - Sigma_hat\nres_cov$cov\n\n\n                 lfStsf slfEst salary prntlS attchm\nlifeSatisfaction -0.005                            \nselfEsteem       -0.005  0.000                     \nsalary           -0.008 -0.018  0.000              \nparentalSupport   0.288  0.000  0.000  0.000       \nattachment        0.076  0.000  0.000  0.000  0.000\n\n\nTasks\n\nIdentify the top 3 largest absolute standardized residual covariances.\nFor each, propose a candidate explanation (omitted path? omitted covariance? shared cause?)."
  },
  {
    "objectID": "labs/lab03_fit-diagnostics_MI_residuals.html#a-create-model-m1-by-adding-exactly-one-theoretically-justified-parameter",
    "href": "labs/lab03_fit-diagnostics_MI_residuals.html#a-create-model-m1-by-adding-exactly-one-theoretically-justified-parameter",
    "title": "Lab 03 — Fit & diagnostics: residuals, MI, and disciplined respecification",
    "section": "5a) Create model m1 by adding exactly one theoretically justified parameter",
    "text": "5a) Create model m1 by adding exactly one theoretically justified parameter\nCommon modifications include:\n\nadding a covariance among exogenous variables (~~)\nadding a missing regression (~)\n\nCreate m1 below and refit.\n\n\nShow code\nm1 &lt;- \"\n  lifeSatisfaction ~ selfEsteem + salary\n  selfEsteem       ~ parentalSupport + attachment\n\n  # ADD ONE PARAMETER HERE (exactly one line)\n  attachment ~~ parentalSupport\n  # OR: lifeSatisfaction ~ parentalSupport\n  # OR: lifeSatisfaction ~ attachment\n\"\nfit1 &lt;- sem(m1, data = dat, meanstructure = TRUE)"
  },
  {
    "objectID": "labs/lab03_fit-diagnostics_MI_residuals.html#b-compare-global-fit",
    "href": "labs/lab03_fit-diagnostics_MI_residuals.html#b-compare-global-fit",
    "title": "Lab 03 — Fit & diagnostics: residuals, MI, and disciplined respecification",
    "section": "5b) Compare global fit",
    "text": "5b) Compare global fit\n\n\nShow code\nfitMeasures(fit0, c(\"chisq\",\"df\",\"cfi\",\"tli\",\"rmsea\",\"srmr\"))\n\n\n chisq     df    cfi    tli  rmsea   srmr \n72.623  3.000  0.788  0.505  0.219  0.067 \n\n\nShow code\nfitMeasures(fit1, c(\"chisq\",\"df\",\"cfi\",\"tli\",\"rmsea\",\"srmr\"))\n\n\n chisq     df    cfi    tli  rmsea   srmr \n72.859  5.000  0.820  0.640  0.168  0.068"
  },
  {
    "objectID": "labs/lab03_fit-diagnostics_MI_residuals.html#c-χ²-difference-test-nested-models",
    "href": "labs/lab03_fit-diagnostics_MI_residuals.html#c-χ²-difference-test-nested-models",
    "title": "Lab 03 — Fit & diagnostics: residuals, MI, and disciplined respecification",
    "section": "5c) χ² difference test (nested models)",
    "text": "5c) χ² difference test (nested models)\n\n\nShow code\nanova(fit0, fit1)\n\n\n\nChi-Squared Difference Test\n\n     Df  AIC  BIC Chisq Chisq diff RMSEA Df diff Pr(&gt;Chisq)\nfit0  3 2746 2779  72.6                                    \nfit1  5 5476 5530  72.9      0.237     0       2       0.89"
  },
  {
    "objectID": "labs/lab03_fit-diagnostics_MI_residuals.html#d-re-check-local-misfit",
    "href": "labs/lab03_fit-diagnostics_MI_residuals.html#d-re-check-local-misfit",
    "title": "Lab 03 — Fit & diagnostics: residuals, MI, and disciplined respecification",
    "section": "5d) Re-check local misfit",
    "text": "5d) Re-check local misfit\n\n\nShow code\nres1_std &lt;- residuals(fit1)$cov\nres1_std\n\n\n                 lfStsf slfEst salary prntlS attchm\nlifeSatisfaction -0.003                            \nselfEsteem       -0.003  0.000                     \nsalary           -0.005 -0.009  0.000              \nparentalSupport   0.364  0.000  0.021  0.000       \nattachment        0.098  0.000  0.006  0.000  0.000\n\n\nInterpretation questions\n\nDid the single change reduce the largest residuals you identified?\nDid it improve the global indices meaningfully?\nIs the change defensible theoretically, or did you “chase fit”?"
  },
  {
    "objectID": "labs/lab03_fit-diagnostics_MI_residuals.html#what-you-should-take-away",
    "href": "labs/lab03_fit-diagnostics_MI_residuals.html#what-you-should-take-away",
    "title": "Lab 03 — Fit & diagnostics: residuals, MI, and disciplined respecification",
    "section": "What you should take away",
    "text": "What you should take away\n\nGlobal fit summarizes mismatch; it doesn’t locate problems.\nLocal diagnostics (residuals + MI/EPC) tell you where mismatch lives.\nRespecification must be theory-filtered, done one step at a time, and reported transparently."
  },
  {
    "objectID": "labs/lab03_fit-diagnostics_MI_residuals.html#whats-next",
    "href": "labs/lab03_fit-diagnostics_MI_residuals.html#whats-next",
    "title": "Lab 03 — Fit & diagnostics: residuals, MI, and disciplined respecification",
    "section": "What’s next",
    "text": "What’s next\n\nNext we shift to measurement models (CFA), where local diagnostics include:\n\ncross-loadings (often fixed to 0)\ncorrelated errors\nweak items / low loadings"
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#today-in-the-workflow",
    "href": "slides/04_cfa_measurement_reliability.html#today-in-the-workflow",
    "title": "CFA: measurement models, identification, reliability",
    "section": "",
    "text": "Specify → Identify → Estimate → Evaluate → Revise/Report\n\n\n\n\n\n\nToday: the measurement part — CFA (and reliability from CFA).\nTwo-step mindset: measure first, then relate constructs (SEM deck 05)."
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#learning-objectives",
    "href": "slides/04_cfa_measurement_reliability.html#learning-objectives",
    "title": "CFA: measurement models, identification, reliability",
    "section": "Learning objectives",
    "text": "Learning objectives\nBy the end of this session you should be able to:\n\nExplain the difference between EFA and CFA (and why CFA is confirmatory)\nWrite the CFA measurement model in equations and matrices\nUnderstand identification & scaling (marker vs std.lv)\nFit CFA models in lavaan and interpret loadings, factor correlations, and residual variances\nUse local diagnostics in CFA (residuals, MI/EPC) without “fit hacking”\nCompute and report reliability from CFA (ω-family; and (briefly) bifactor implications)"
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#outline",
    "href": "slides/04_cfa_measurement_reliability.html#outline",
    "title": "CFA: measurement models, identification, reliability",
    "section": "Outline",
    "text": "Outline\n\nFactor analysis: what problem are we solving?\nEFA vs CFA (confirmatory stance)\nCFA model: equations, matrices, implied covariance\nIdentification and constraints (scaling + rules)\nCFA in R (lavaan) + interpretation\nReliability from CFA\nBifactor model (keep your guard up)"
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#factor-analysis",
    "href": "slides/04_cfa_measurement_reliability.html#factor-analysis",
    "title": "CFA: measurement models, identification, reliability",
    "section": "Factor analysis",
    "text": "Factor analysis\nFactor analysis models the idea that a small number of latent dimensions explain systematic covariance among many observed variables."
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#exploratory-factor-analysis-efa",
    "href": "slides/04_cfa_measurement_reliability.html#exploratory-factor-analysis-efa",
    "title": "CFA: measurement models, identification, reliability",
    "section": "Exploratory Factor Analysis (EFA)",
    "text": "Exploratory Factor Analysis (EFA)\nEFA: discover a plausible loading pattern.\n\nloadings are “free” (rotation chooses a representation)\nuseful for exploration and item development\nweak theory → strong exploration"
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#confirmatory-factor-analysis-cfa",
    "href": "slides/04_cfa_measurement_reliability.html#confirmatory-factor-analysis-cfa",
    "title": "CFA: measurement models, identification, reliability",
    "section": "Confirmatory Factor Analysis (CFA)",
    "text": "Confirmatory Factor Analysis (CFA)\nCFA: test a specific measurement hypothesis.\n\nyou specify which loadings are zero vs free\nyou can impose constraints (equal loadings, orthogonality, hierarchies)\nfit and diagnostics evaluate a theoretically constrained model\n\n\n\n\n\n\n\n\nCFA is not “EFA with nicer output”: it is a confirmatory claim with theoretical commitments."
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#general-formula-your-original",
    "href": "slides/04_cfa_measurement_reliability.html#general-formula-your-original",
    "title": "CFA: measurement models, identification, reliability",
    "section": "General formula (your original)",
    "text": "General formula (your original)\nThe general CFA model can be written as:\n\\[\n\\begin{aligned}\n\\mathbf{x} &= \\mathbf{\\Lambda}_x\\,\\mathbf{\\xi} + \\mathbf{\\delta} \\\\\n\\mathbf{y} &= \\mathbf{\\Lambda}_y\\,\\mathbf{\\eta} + \\mathbf{\\epsilon}\n\\end{aligned}\n\\]\nwhere () and () are observed variables, () and () are latent factors, and () and () are errors of measurement."
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#the-general-formula-explained-scalar-form",
    "href": "slides/04_cfa_measurement_reliability.html#the-general-formula-explained-scalar-form",
    "title": "CFA: measurement models, identification, reliability",
    "section": "The general formula explained (scalar form)",
    "text": "The general formula explained (scalar form)\n\\[\n\\begin{aligned}\ny &= b_0 + b_1 x + \\epsilon \\\\\ny_1 &= \\tau_1 + \\lambda_1\\eta + \\epsilon_1\n\\end{aligned}\n\\]\n\\[\n\\begin{bmatrix}\n  y_1 \\\\\n  y_2 \\\\\n  y_3\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n  \\tau_1 \\\\\n  \\tau_2 \\\\\n  \\tau_3\n\\end{bmatrix}\n+\n\\begin{bmatrix}\n  \\lambda_1 \\\\\n  \\lambda_2 \\\\\n  \\lambda_3\n\\end{bmatrix}\n(\\eta_1)\n+\n\\begin{bmatrix}\n  \\epsilon_1 \\\\\n  \\epsilon_2 \\\\\n  \\epsilon_3\n\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#measurement-first-implications-reflective-realism",
    "href": "slides/04_cfa_measurement_reliability.html#measurement-first-implications-reflective-realism",
    "title": "CFA: measurement models, identification, reliability",
    "section": "Measurement-first implications (reflective realism)",
    "text": "Measurement-first implications (reflective realism)\nWhen we draw () (()) from latent to observed, we assume reflective latent variables:\n\nARROWS are ARROWS: the construct affects responses\n“realist” interpretation: the latent variable is something that exists (at least as a stable attribute)\nobserved scores = construct signal + measurement error\n\nPragmatic “just a summary” interpretations are not neutral: they imply different measurement models (PCA/EGA/…)."
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#the-implied-covariance-the-single-most-important-equation",
    "href": "slides/04_cfa_measurement_reliability.html#the-implied-covariance-the-single-most-important-equation",
    "title": "CFA: measurement models, identification, reliability",
    "section": "The implied covariance (the single most important equation)",
    "text": "The implied covariance (the single most important equation)\nFor a standard CFA with latent covariance () and residual covariance ():\n\\[\n\\Sigma = \\Lambda \\Phi \\Lambda' + \\Theta\n\\]\nThis is why:\n\nloadings (()) and factor correlations (()) jointly shape observed covariances\ncorrelated residuals (off-diagonal ()) are extra covariance not explained by factors"
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#matrices-your-original-visual-slide",
    "href": "slides/04_cfa_measurement_reliability.html#matrices-your-original-visual-slide",
    "title": "CFA: measurement models, identification, reliability",
    "section": "Matrices (your original visual slide)",
    "text": "Matrices (your original visual slide)\n\n\nLambda: matrix of loadings\n\n\nPhi: latent variance-covariance matrix\n\n\nTheta: residual variance-covariance matrix"
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#cfa-model-families-you-will-see-a-lot",
    "href": "slides/04_cfa_measurement_reliability.html#cfa-model-families-you-will-see-a-lot",
    "title": "CFA: measurement models, identification, reliability",
    "section": "CFA “model families” you will see a lot",
    "text": "CFA “model families” you will see a lot\nKey design choices:\n\none factor vs multiple factors\nare factors correlated?\northogonal vs oblique\nhierarchical / second-order?\nbifactor structure?\n\nAll have statistical and theoretical consequences."
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#a-quick-visual-tour-common-cfa-structures",
    "href": "slides/04_cfa_measurement_reliability.html#a-quick-visual-tour-common-cfa-structures",
    "title": "CFA: measurement models, identification, reliability",
    "section": "A quick visual tour: common CFA structures",
    "text": "A quick visual tour: common CFA structures"
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#one-factor-model",
    "href": "slides/04_cfa_measurement_reliability.html#one-factor-model",
    "title": "CFA: measurement models, identification, reliability",
    "section": "One-factor model",
    "text": "One-factor model"
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#two-factor-model-correlated-factors",
    "href": "slides/04_cfa_measurement_reliability.html#two-factor-model-correlated-factors",
    "title": "CFA: measurement models, identification, reliability",
    "section": "Two-factor model (correlated factors)",
    "text": "Two-factor model (correlated factors)"
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#two-factor-model-orthogonal-factors",
    "href": "slides/04_cfa_measurement_reliability.html#two-factor-model-orthogonal-factors",
    "title": "CFA: measurement models, identification, reliability",
    "section": "Two-factor model (orthogonal factors)",
    "text": "Two-factor model (orthogonal factors)"
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#hierarchical-model-second-order-factor",
    "href": "slides/04_cfa_measurement_reliability.html#hierarchical-model-second-order-factor",
    "title": "CFA: measurement models, identification, reliability",
    "section": "Hierarchical model (second-order factor)",
    "text": "Hierarchical model (second-order factor)"
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#in-r-lavaan-grammar-for-cfa",
    "href": "slides/04_cfa_measurement_reliability.html#in-r-lavaan-grammar-for-cfa",
    "title": "CFA: measurement models, identification, reliability",
    "section": "In R (lavaan grammar for CFA)",
    "text": "In R (lavaan grammar for CFA)\nCore operator:\n\n=~ defines a factor from its indicators\n\n\nm &lt;- '\n  F1 =~ y1 + y2 + y3\n  F2 =~ y4 + y5 + y6\n  F1 ~~ F2          # factor covariance (oblique)\n'\n\nfit &lt;- cfa(m, data = dat)  # or sem(m, data = dat)\nsummary(fit, standardized = TRUE, fit.measures = TRUE)"
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#constraints-scaling-your-original-slide",
    "href": "slides/04_cfa_measurement_reliability.html#constraints-scaling-your-original-slide",
    "title": "CFA: measurement models, identification, reliability",
    "section": "Constraints (scaling) — your original slide",
    "text": "Constraints (scaling) — your original slide\nTo estimate latent-variable models, you must scale each factor. Two common strategies:\n\nStandardize latent variables: fix factor means to 0 and factor variances to 1 (std.lv = TRUE).\nMarker method: set one loading (()) per factor to 1 (lavaan default).\n\n\nfit &lt;- cfa(m, data = dat, std.lv = TRUE)"
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#constraints-explained-marker-vs-standardization",
    "href": "slides/04_cfa_measurement_reliability.html#constraints-explained-marker-vs-standardization",
    "title": "CFA: measurement models, identification, reliability",
    "section": "Constraints explained (marker vs standardization)",
    "text": "Constraints explained (marker vs standardization)\n\n\n\\[\n\\Sigma = \\Lambda\\Phi\\Lambda' + \\Theta\n\\]\nMarker method (fix one loading to 1)\nStandardization (fix factor variance to 1)\n(Scaling changes the metric of unstandardized loadings, not the implied covariance model.)"
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#identification-rules-your-original-framing",
    "href": "slides/04_cfa_measurement_reliability.html#identification-rules-your-original-framing",
    "title": "CFA: measurement models, identification, reliability",
    "section": "Identification rules (your original framing)",
    "text": "Identification rules (your original framing)\nFor CFA, common identification rules include:\n\nthe t-rule\nthe Three-Indicator Rule\nthe Two-Indicator Rule"
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#the-t-rule",
    "href": "slides/04_cfa_measurement_reliability.html#the-t-rule",
    "title": "CFA: measurement models, identification, reliability",
    "section": "The t-rule",
    "text": "The t-rule\nNecessary but not sufficient:\n\\[\nt \\leq \\frac{q(q+1)}{2}\n\\]\nwhere (t) is the number of free parameters and (q) the number of observed variables.\nIntuition: the number of nonredundant elements in (S) is the maximum number of “equations”; if unknowns exceed equations, identification is impossible."
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#the-three-indicator-rule",
    "href": "slides/04_cfa_measurement_reliability.html#the-three-indicator-rule",
    "title": "CFA: measurement models, identification, reliability",
    "section": "The Three-Indicator Rule",
    "text": "The Three-Indicator Rule\nA sufficient (not necessary) condition (with diagonal ()):\n\nOne-factor model: at least three indicators with nonzero loadings.\nMultifactor model is identified if:\n\n≥ 3 indicators per factor\neach row of () has one and only one nonzero element (simple structure)\n() is diagonal"
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#the-two-indicator-rule",
    "href": "slides/04_cfa_measurement_reliability.html#the-two-indicator-rule",
    "title": "CFA: measurement models, identification, reliability",
    "section": "The Two-Indicator Rule",
    "text": "The Two-Indicator Rule\nA sufficient (not necessary) condition for models with &gt;1 factor:\n\n() diagonal\neach factor scaled (one () fixed to 1, or std.lv=TRUE)\nplus:\n\n≥ 2 indicators per factor\neach row of (): one nonzero element\n() diagonal\neach row of () has at least one nonzero off-diagonal element"
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#cfa-evaluation-where-deck-03-plugs-in",
    "href": "slides/04_cfa_measurement_reliability.html#cfa-evaluation-where-deck-03-plugs-in",
    "title": "CFA: measurement models, identification, reliability",
    "section": "CFA evaluation (where deck 03 plugs in)",
    "text": "CFA evaluation (where deck 03 plugs in)\nGlobal indices are the same as in deck 03 (χ², CFI/TLI, RMSEA+CI, SRMR).\nWhat becomes CFA-specific is local misfit interpretation:\n\nbig residual correlations → local dependence / method effects / cross-loadings\nMI/EPC candidates typically propose:\n\ncross-loadings (theory-threatening)\ncorrelated residuals (requires a clear justification)\nfactor covariances / (rarely) indicator-level regressions\n\n\n\n\n\n\n\n\nFit ≠ validity. “Improving fit” can destroy the meaning of a factor model if you add substantively implausible parameters."
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#a-disciplined-cfa-respecification-mindset",
    "href": "slides/04_cfa_measurement_reliability.html#a-disciplined-cfa-respecification-mindset",
    "title": "CFA: measurement models, identification, reliability",
    "section": "A disciplined CFA respecification mindset",
    "text": "A disciplined CFA respecification mindset\n\nFirst: check items (loadings, residual variances, signs)\nThen: check patterns (blocks of residual correlations)\nMI/EPC only after you have a hypothesis for the misfit\nPrefer fewer, theory-consistent modifications over many “small fixes”\nReport the respecification path transparently (what changed and why)"
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#live-example-lavaan-holzinger-swineford-1939",
    "href": "slides/04_cfa_measurement_reliability.html#live-example-lavaan-holzinger-swineford-1939",
    "title": "CFA: measurement models, identification, reliability",
    "section": "Live example (lavaan): Holzinger & Swineford (1939)",
    "text": "Live example (lavaan): Holzinger & Swineford (1939)\n\ndat &lt;- HolzingerSwineford1939\n\nm_hs &lt;- '\n  visual  =~ x1 + x2 + x3\n  textual =~ x4 + x5 + x6\n  speed   =~ x7 + x8 + x9\n'\nfit_hs &lt;- cfa(m_hs, data = dat, std.lv = TRUE)"
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#interpret-loadings-and-factor-correlations",
    "href": "slides/04_cfa_measurement_reliability.html#interpret-loadings-and-factor-correlations",
    "title": "CFA: measurement models, identification, reliability",
    "section": "Interpret loadings and factor correlations",
    "text": "Interpret loadings and factor correlations\n\npe &lt;- parameterEstimates(fit_hs, standardized = TRUE)\npe[pe$op %in% c(\"=~\",\"~~\") & pe$lhs %in% c(\"visual\",\"textual\",\"speed\"),\n   c(\"lhs\",\"op\",\"rhs\",\"est\",\"se\",\"pvalue\",\"std.all\")]\n\n       lhs op     rhs   est    se pvalue std.all\n1   visual =~      x1 0.900 0.081      0   0.772\n2   visual =~      x2 0.498 0.077      0   0.424\n3   visual =~      x3 0.656 0.074      0   0.581\n4  textual =~      x4 0.990 0.057      0   0.852\n5  textual =~      x5 1.102 0.063      0   0.855\n6  textual =~      x6 0.917 0.054      0   0.838\n7    speed =~      x7 0.619 0.070      0   0.570\n8    speed =~      x8 0.731 0.066      0   0.723\n9    speed =~      x9 0.670 0.065      0   0.665\n19  visual ~~  visual 1.000 0.000     NA   1.000\n20 textual ~~ textual 1.000 0.000     NA   1.000\n21   speed ~~   speed 1.000 0.000     NA   1.000\n22  visual ~~ textual 0.459 0.064      0   0.459\n23  visual ~~   speed 0.471 0.073      0   0.471\n24 textual ~~   speed 0.283 0.069      0   0.283"
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#reliability-from-cfa-ω-family",
    "href": "slides/04_cfa_measurement_reliability.html#reliability-from-cfa-ω-family",
    "title": "CFA: measurement models, identification, reliability",
    "section": "Reliability from CFA (ω family)",
    "text": "Reliability from CFA (ω family)\n\nreliability(fit_hs)\n\n       visual textual speed\nalpha   0.626   0.883 0.688\nomega   0.625   0.885 0.688\nomega2  0.625   0.885 0.688\nomega3  0.612   0.885 0.686\navevar  0.371   0.721 0.424\n\n\n\n\n\n\n\n\nWe emphasize ω-family reliability because it aligns with the CFA model; α is a special (often unrealistic) case."
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#graphical-representation",
    "href": "slides/04_cfa_measurement_reliability.html#graphical-representation",
    "title": "CFA: measurement models, identification, reliability",
    "section": "Graphical representation",
    "text": "Graphical representation"
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#a-hierarchical-intelligence-example-your-original-wisc-slide",
    "href": "slides/04_cfa_measurement_reliability.html#a-hierarchical-intelligence-example-your-original-wisc-slide",
    "title": "CFA: measurement models, identification, reliability",
    "section": "A hierarchical intelligence example (your original WISC slide)",
    "text": "A hierarchical intelligence example (your original WISC slide)\nTheory: test scores are affected by specific abilities (e.g., processing speed) that are influenced by an overarching factor ((g)).\n\n\n\n\n\n\n\nIn practice, you should validate first-order abilities before jumping to a second-order model."
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#second-order-cfa-syntax-template",
    "href": "slides/04_cfa_measurement_reliability.html#second-order-cfa-syntax-template",
    "title": "CFA: measurement models, identification, reliability",
    "section": "Second-order CFA (syntax template)",
    "text": "Second-order CFA (syntax template)\n\nm2 &lt;- \"\nVCI =~ SI + VC + CO\nPRI =~ BD + PCn + MR\nWMI =~ DS + LN\nPSI =~ CD + SS\ng   =~ VCI + PRI + WMI + PSI\n\"\nfit2 &lt;- sem(m2, std.lv = TRUE, sample.cov = S, sample.nobs = N)"
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#a-second-theoretical-model-bifactor-your-original",
    "href": "slides/04_cfa_measurement_reliability.html#a-second-theoretical-model-bifactor-your-original",
    "title": "CFA: measurement models, identification, reliability",
    "section": "A second theoretical model: bifactor (your original)",
    "text": "A second theoretical model: bifactor (your original)\nParallel theories: test scores are affected by a general factor ((g)) and by specific abilities that explain remaining variance.\nAll factors are set to be orthogonal."
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#bifactor-model-in-r-your-original-structure",
    "href": "slides/04_cfa_measurement_reliability.html#bifactor-model-in-r-your-original-structure",
    "title": "CFA: measurement models, identification, reliability",
    "section": "Bifactor model in R (your original structure)",
    "text": "Bifactor model in R (your original structure)\n\nmb &lt;- \"\nVCI =~ a*SI + a*VC + a*CO\nPRI =~ b*BD + b*PCn + b*MR\nWMI =~ c*DS + c*LN\nPSI =~ d*CD + d*SS\ng   =~ SI + VC + CO + BD + PCn + MR + DS + LN + CD + SS\n\"\n\nfitb &lt;- sem(\n  mb,\n  orthogonal = TRUE,\n  std.lv = TRUE,\n  sample.cov = S,\n  sample.nobs = N\n)"
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#bifactor-interpretation-requires-diagnostics-not-just-fit",
    "href": "slides/04_cfa_measurement_reliability.html#bifactor-interpretation-requires-diagnostics-not-just-fit",
    "title": "CFA: measurement models, identification, reliability",
    "section": "Bifactor: interpretation requires diagnostics (not just fit)",
    "text": "Bifactor: interpretation requires diagnostics (not just fit)\nBifactor often improves fit by absorbing residual covariance. Before interpreting:\n\nis the general factor strong enough? (ECV / ωH / H)\nare specific factors meaningful or “junk factors”?\ndo constraints (orthogonality, equal loadings) make sense?\n\n\n# semTools helpers for bifactor diagnostics (when you fit a bifactor model)\n# bifactorIndices(fitb)\n# reliability(fitb)   # omega family; ωH is especially relevant\n\n\n\n\n\n\n\nA bifactor model that “fits” can still be a bad measurement story."
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#exercises-lab-04",
    "href": "slides/04_cfa_measurement_reliability.html#exercises-lab-04",
    "title": "CFA: measurement models, identification, reliability",
    "section": "Exercises (Lab 04)",
    "text": "Exercises (Lab 04)\nGo to:\n\nlabs/lab04_cfa_reliability_omegas.qmd\n\nYou will practice:\n\nFit and compare 1-factor vs correlated-factors CFA\nInspect local misfit (residual correlations + MI/EPC) with a theory filter\nCompute reliability (ω) from CFA and report it\n(Optional) Fit a bifactor model and evaluate interpretability (ωH / ECV)"
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#take-home-3-things",
    "href": "slides/04_cfa_measurement_reliability.html#take-home-3-things",
    "title": "CFA: measurement models, identification, reliability",
    "section": "Take-home: 3 things",
    "text": "Take-home: 3 things\n\nCFA is a confirmatory measurement claim: zeros and constraints are theory\n\nIdentification/scaling is not a nuisance—it’s the metric of your construct\n\nReliability and validity are model-based: fit helps, but fit ≠ validity"
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#further-reading-self-study",
    "href": "slides/04_cfa_measurement_reliability.html#further-reading-self-study",
    "title": "CFA: measurement models, identification, reliability",
    "section": "Further reading / self-study",
    "text": "Further reading / self-study\n\nextras/ex10_bifactor_esem_method-factors.qmd — bifactor/ESEM/method factors (advanced)\nextras/ex05_miivs_factor-score-regression.qmd — factor scores & regression (later)\nClassic SEM measurement chapters (CFA fundamentals; see course website reading list)"
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#references",
    "href": "slides/04_cfa_measurement_reliability.html#references",
    "title": "CFA: measurement models, identification, reliability",
    "section": "References",
    "text": "References\n(Add citations/keys once the course bibliography is finalized for the website.)"
  },
  {
    "objectID": "labs/lab04_cfa_reliability_omegas.html",
    "href": "labs/lab04_cfa_reliability_omegas.html",
    "title": "Lab 04 — CFA: measurement, local misfit, and ω reliability",
    "section": "",
    "text": "In this lab you will:\n\nFit and compare CFA models (1-factor vs correlated factors)\nInspect local misfit for CFA (residual correlations, MI + EPC/SEPC)\nMake theory-filtered respecification choices (and document them)\nCompute and report reliability from CFA (ω family via semTools)\n(Optional) Fit a bifactor model and evaluate interpretability (not just fit)"
  },
  {
    "objectID": "labs/lab04_cfa_reliability_omegas.html#model-1-one-general-factor",
    "href": "labs/lab04_cfa_reliability_omegas.html#model-1-one-general-factor",
    "title": "Lab 04 — CFA: measurement, local misfit, and ω reliability",
    "section": "Model 1: One general factor",
    "text": "Model 1: One general factor\n\n\nShow code\nm1 &lt;- '\n  g =~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9\n'\nfit1 &lt;- cfa(m1, data = dat, std.lv = TRUE)\nsummary(fit1, fit.measures = TRUE, standardized = TRUE)\n\n\nlavaan 0.6-19 ended normally after 18 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        18\n\n  Number of observations                           301\n\nModel Test User Model:\n                                                      \n  Test statistic                               312.264\n  Degrees of freedom                                27\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                               918.852\n  Degrees of freedom                                36\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.677\n  Tucker-Lewis Index (TLI)                       0.569\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -3851.224\n  Loglikelihood unrestricted model (H1)      -3695.092\n                                                      \n  Akaike (AIC)                                7738.448\n  Bayesian (BIC)                              7805.176\n  Sample-size adjusted Bayesian (SABIC)       7748.091\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.187\n  90 Percent confidence interval - lower         0.169\n  90 Percent confidence interval - upper         0.206\n  P-value H_0: RMSEA &lt;= 0.050                    0.000\n  P-value H_0: RMSEA &gt;= 0.080                    1.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.143\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  g =~                                                                  \n    x1                0.510    0.068    7.550    0.000    0.510    0.438\n    x2                0.259    0.071    3.649    0.000    0.259    0.220\n    x3                0.252    0.068    3.689    0.000    0.252    0.223\n    x4                0.985    0.057   17.375    0.000    0.985    0.848\n    x5                1.084    0.063   17.181    0.000    1.084    0.841\n    x6                0.917    0.054   17.092    0.000    0.917    0.838\n    x7                0.196    0.066    2.975    0.003    0.196    0.180\n    x8                0.203    0.061    3.323    0.001    0.203    0.201\n    x9                0.309    0.060    5.143    0.000    0.309    0.307\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .x1                1.098    0.092   11.895    0.000    1.098    0.808\n   .x2                1.315    0.108   12.188    0.000    1.315    0.951\n   .x3                1.212    0.099   12.186    0.000    1.212    0.950\n   .x4                0.380    0.048    7.963    0.000    0.380    0.281\n   .x5                0.486    0.059    8.193    0.000    0.486    0.293\n   .x6                0.356    0.043    8.295    0.000    0.356    0.298\n   .x7                1.145    0.094   12.215    0.000    1.145    0.967\n   .x8                0.981    0.080   12.202    0.000    0.981    0.960\n   .x9                0.919    0.076   12.105    0.000    0.919    0.906\n    g                 1.000                               1.000    1.000"
  },
  {
    "objectID": "labs/lab04_cfa_reliability_omegas.html#model-2-three-correlated-factors-the-classic-hs-structure",
    "href": "labs/lab04_cfa_reliability_omegas.html#model-2-three-correlated-factors-the-classic-hs-structure",
    "title": "Lab 04 — CFA: measurement, local misfit, and ω reliability",
    "section": "Model 2: Three correlated factors (the classic HS structure)",
    "text": "Model 2: Three correlated factors (the classic HS structure)\n\n\nShow code\nm3 &lt;- '\n  visual  =~ x1 + x2 + x3\n  textual =~ x4 + x5 + x6\n  speed   =~ x7 + x8 + x9\n'\nfit3 &lt;- cfa(m3, data = dat, std.lv = TRUE)\nsummary(fit3, fit.measures = TRUE, standardized = TRUE)\n\n\nlavaan 0.6-19 ended normally after 20 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        21\n\n  Number of observations                           301\n\nModel Test User Model:\n                                                      \n  Test statistic                                85.306\n  Degrees of freedom                                24\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                               918.852\n  Degrees of freedom                                36\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.931\n  Tucker-Lewis Index (TLI)                       0.896\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -3737.745\n  Loglikelihood unrestricted model (H1)      -3695.092\n                                                      \n  Akaike (AIC)                                7517.490\n  Bayesian (BIC)                              7595.339\n  Sample-size adjusted Bayesian (SABIC)       7528.739\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.092\n  90 Percent confidence interval - lower         0.071\n  90 Percent confidence interval - upper         0.114\n  P-value H_0: RMSEA &lt;= 0.050                    0.001\n  P-value H_0: RMSEA &gt;= 0.080                    0.840\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.065\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  visual =~                                                             \n    x1                0.900    0.081   11.128    0.000    0.900    0.772\n    x2                0.498    0.077    6.429    0.000    0.498    0.424\n    x3                0.656    0.074    8.817    0.000    0.656    0.581\n  textual =~                                                            \n    x4                0.990    0.057   17.474    0.000    0.990    0.852\n    x5                1.102    0.063   17.576    0.000    1.102    0.855\n    x6                0.917    0.054   17.082    0.000    0.917    0.838\n  speed =~                                                              \n    x7                0.619    0.070    8.903    0.000    0.619    0.570\n    x8                0.731    0.066   11.090    0.000    0.731    0.723\n    x9                0.670    0.065   10.305    0.000    0.670    0.665\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  visual ~~                                                             \n    textual           0.459    0.064    7.189    0.000    0.459    0.459\n    speed             0.471    0.073    6.461    0.000    0.471    0.471\n  textual ~~                                                            \n    speed             0.283    0.069    4.117    0.000    0.283    0.283\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .x1                0.549    0.114    4.833    0.000    0.549    0.404\n   .x2                1.134    0.102   11.146    0.000    1.134    0.821\n   .x3                0.844    0.091    9.317    0.000    0.844    0.662\n   .x4                0.371    0.048    7.779    0.000    0.371    0.275\n   .x5                0.446    0.058    7.642    0.000    0.446    0.269\n   .x6                0.356    0.043    8.277    0.000    0.356    0.298\n   .x7                0.799    0.081    9.823    0.000    0.799    0.676\n   .x8                0.488    0.074    6.573    0.000    0.488    0.477\n   .x9                0.566    0.071    8.003    0.000    0.566    0.558\n    visual            1.000                               1.000    1.000\n    textual           1.000                               1.000    1.000\n    speed             1.000                               1.000    1.000"
  },
  {
    "objectID": "labs/lab04_cfa_reliability_omegas.html#a-compare-global-fit",
    "href": "labs/lab04_cfa_reliability_omegas.html#a-compare-global-fit",
    "title": "Lab 04 — CFA: measurement, local misfit, and ω reliability",
    "section": "1a) Compare global fit",
    "text": "1a) Compare global fit\nExtract a minimal set of indices:\n\n\nShow code\nget_fit &lt;- function(f) {\n  fitMeasures(f, c(\"chisq\",\"df\",\"pvalue\",\"cfi\",\"tli\",\"rmsea\",\"rmsea.ci.lower\",\"rmsea.ci.upper\",\"srmr\"))\n}\n\nrbind(one_factor = get_fit(fit1),\n      three_factor = get_fit(fit3))\n\n\n             chisq df  pvalue   cfi   tli  rmsea rmsea.ci.lower rmsea.ci.upper\none_factor   312.3 27 0.0e+00 0.677 0.569 0.1874         0.1690          0.206\nthree_factor  85.3 24 8.5e-09 0.931 0.896 0.0921         0.0714          0.114\n               srmr\none_factor   0.1431\nthree_factor 0.0652\n\n\nQuestions\n\nWhich model fits better globally? Which indices support that conclusion?\nDo you expect the 3-factor model to always fit better? Why/why not?"
  },
  {
    "objectID": "labs/lab04_cfa_reliability_omegas.html#b-compare-with-a-χ²-difference-test-nested",
    "href": "labs/lab04_cfa_reliability_omegas.html#b-compare-with-a-χ²-difference-test-nested",
    "title": "Lab 04 — CFA: measurement, local misfit, and ω reliability",
    "section": "1b) Compare with a χ² difference test (nested?)",
    "text": "1b) Compare with a χ² difference test (nested?)\n\n\nShow code\nanova(fit1, fit3)\n\n\n\nChi-Squared Difference Test\n\n     Df  AIC  BIC Chisq Chisq diff RMSEA Df diff Pr(&gt;Chisq)    \nfit3 24 7517 7595  85.3                                        \nfit1 27 7738 7805 312.3        227 0.498       3     &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nQuestion\n\nIs this comparison a valid nested χ² test here? Why (think: is the 1-factor model nested in the 3-factor model)?\n\n\n\n\n\n\n\nEven when anova() runs, you must reason about nesting. Not every model comparison is a proper LRT."
  },
  {
    "objectID": "labs/lab04_cfa_reliability_omegas.html#a-standardized-loadings",
    "href": "labs/lab04_cfa_reliability_omegas.html#a-standardized-loadings",
    "title": "Lab 04 — CFA: measurement, local misfit, and ω reliability",
    "section": "2a) Standardized loadings",
    "text": "2a) Standardized loadings\n\n\nShow code\npe3 &lt;- parameterEstimates(fit3, standardized = TRUE)\nload3 &lt;- subset(pe3, op == \"=~\")[, c(\"lhs\",\"rhs\",\"est\",\"se\",\"pvalue\",\"std.all\")]\nload3\n\n\n      lhs rhs   est    se pvalue std.all\n1  visual  x1 0.900 0.081      0   0.772\n2  visual  x2 0.498 0.077      0   0.424\n3  visual  x3 0.656 0.074      0   0.581\n4 textual  x4 0.990 0.057      0   0.852\n5 textual  x5 1.102 0.063      0   0.855\n6 textual  x6 0.917 0.054      0   0.838\n7   speed  x7 0.619 0.070      0   0.570\n8   speed  x8 0.731 0.066      0   0.723\n9   speed  x9 0.670 0.065      0   0.665\n\n\nTasks\n\nIdentify the weakest indicator(s) by std.all.\nIdentify any signs that look strange (e.g., negative loadings, extremely low/high)."
  },
  {
    "objectID": "labs/lab04_cfa_reliability_omegas.html#b-residual-variances",
    "href": "labs/lab04_cfa_reliability_omegas.html#b-residual-variances",
    "title": "Lab 04 — CFA: measurement, local misfit, and ω reliability",
    "section": "2b) Residual variances",
    "text": "2b) Residual variances\n\n\nShow code\nresvar3 &lt;- subset(pe3, op == \"~~\" & lhs %in% vars & rhs %in% vars)[, c(\"lhs\",\"est\",\"std.all\")]\nresvar3\n\n\n   lhs   est std.all\n10  x1 0.549   0.404\n11  x2 1.134   0.821\n12  x3 0.844   0.662\n13  x4 0.371   0.275\n14  x5 0.446   0.269\n15  x6 0.356   0.298\n16  x7 0.799   0.676\n17  x8 0.488   0.477\n18  x9 0.566   0.558\n\n\nQuestion\n\nDo any residual variances look “too small” or “too large”? What might that mean substantively?"
  },
  {
    "objectID": "labs/lab04_cfa_reliability_omegas.html#c-factor-correlations",
    "href": "labs/lab04_cfa_reliability_omegas.html#c-factor-correlations",
    "title": "Lab 04 — CFA: measurement, local misfit, and ω reliability",
    "section": "2c) Factor correlations",
    "text": "2c) Factor correlations\n\n\nShow code\nphi3 &lt;- subset(pe3, op == \"~~\" & lhs %in% c(\"visual\",\"textual\",\"speed\") &\n                 rhs %in% c(\"visual\",\"textual\",\"speed\") & lhs != rhs)[, c(\"lhs\",\"rhs\",\"est\",\"std.all\")]\nphi3\n\n\n       lhs     rhs   est std.all\n22  visual textual 0.459   0.459\n23  visual   speed 0.471   0.471\n24 textual   speed 0.283   0.283\n\n\nQuestions\n\nAre factor correlations high? What would make you worry about discriminant validity?\nIn your area, what theory would justify correlated factors?"
  },
  {
    "objectID": "labs/lab04_cfa_reliability_omegas.html#take-home",
    "href": "labs/lab04_cfa_reliability_omegas.html#take-home",
    "title": "Lab 04 — CFA: measurement, local misfit, and ω reliability",
    "section": "Take-home",
    "text": "Take-home\n\nCFA is a measurement hypothesis: zeros and constraints are theory.\nPair global fit with CFA-specific local diagnostics (residual correlations + MI/EPC).\nRespecify with discipline: one change at a time, theory filter, transparent reporting.\nReliability should match your measurement model: ω from CFA is usually a better default than α."
  },
  {
    "objectID": "labs/lab05_sem_capstone_eat.html",
    "href": "labs/lab05_sem_capstone_eat.html",
    "title": "Lab 05 — SEM capstone with the EAT dataset",
    "section": "",
    "text": "This lab is a full SEM workflow exercise (measurement + structure):\n\nApply the Two-Step rule (identify/fit measurement first, then structure)\nEvaluate the model using fit indices + diagnostics (global + local)\nUse MI + EPC/SEPC to propose a theory-justified modification\nCompare a latent SEM vs a sum-score path model\n\nYou will produce: - a short “model checking log” (what you checked, what you changed, why) - a figure of your final model (R / PowerPoint / hand-drawn)"
  },
  {
    "objectID": "labs/lab05_sem_capstone_eat.html#a-specify-the-measurement-model",
    "href": "labs/lab05_sem_capstone_eat.html#a-specify-the-measurement-model",
    "title": "Lab 05 — SEM capstone with the EAT dataset",
    "section": "1a) Specify the measurement model",
    "text": "1a) Specify the measurement model\n\n\nShow code\nm_cfa &lt;- \"\n  peerPressure =~ PP1 + PP2 + PP3 + PP4\n  socialMedia  =~ SM1 + SM2 + SM3 + SM4\n  socialComparison =~ SC1 + SC2 + SC3\n  eatingDisorder =~ ED1 + ED2\n\""
  },
  {
    "objectID": "labs/lab05_sem_capstone_eat.html#b-fit-and-check-convergence",
    "href": "labs/lab05_sem_capstone_eat.html#b-fit-and-check-convergence",
    "title": "Lab 05 — SEM capstone with the EAT dataset",
    "section": "1b) Fit and check convergence",
    "text": "1b) Fit and check convergence\n\n\nShow code\nfit_cfa &lt;- sem(m_cfa, data = dE4_1, std.lv = TRUE)\nlavInspect(fit_cfa, \"converged\")\n\n\n[1] TRUE"
  },
  {
    "objectID": "labs/lab05_sem_capstone_eat.html#c-inspect-measurement-results",
    "href": "labs/lab05_sem_capstone_eat.html#c-inspect-measurement-results",
    "title": "Lab 05 — SEM capstone with the EAT dataset",
    "section": "1c) Inspect measurement results",
    "text": "1c) Inspect measurement results\n\n\nShow code\nsummary(fit_cfa, standardized = TRUE, fit.measures = TRUE)\n\n\nlavaan 0.6-19 ended normally after 30 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        32\n\n  Number of observations                          1423\n\nModel Test User Model:\n                                                      \n  Test statistic                               421.825\n  Degrees of freedom                                59\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                              3150.947\n  Degrees of freedom                                78\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.882\n  Tucker-Lewis Index (TLI)                       0.844\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)             -28616.602\n  Loglikelihood unrestricted model (H1)     -28405.690\n                                                      \n  Akaike (AIC)                               57297.204\n  Bayesian (BIC)                             57465.541\n  Sample-size adjusted Bayesian (SABIC)      57363.888\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.066\n  90 Percent confidence interval - lower         0.060\n  90 Percent confidence interval - upper         0.072\n  P-value H_0: RMSEA &lt;= 0.050                    0.000\n  P-value H_0: RMSEA &gt;= 0.080                    0.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.042\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                      Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  peerPressure =~                                                          \n    PP1                  1.016    0.036   27.977    0.000    1.016    0.821\n    PP2                  0.998    0.037   26.980    0.000    0.998    0.786\n    PP3                  0.424    0.033   12.944    0.000    0.424    0.370\n    PP4                  0.468    0.034   13.945    0.000    0.468    0.397\n  socialMedia =~                                                           \n    SM1                  0.592    0.039   15.294    0.000    0.592    0.517\n    SM2                  0.575    0.040   14.449    0.000    0.575    0.486\n    SM3                  0.554    0.039   14.234    0.000    0.554    0.479\n    SM4                  0.645    0.041   15.928    0.000    0.645    0.541\n  socialComparison =~                                                      \n    SC1                  0.881    0.038   23.042    0.000    0.881    0.662\n    SC2                  0.940    0.038   24.865    0.000    0.940    0.718\n    SC3                  0.856    0.039   22.167    0.000    0.856    0.637\n  eatingDisorder =~                                                        \n    ED1                  0.720    0.067   10.709    0.000    0.720    0.596\n    ED2                  0.671    0.064   10.491    0.000    0.671    0.547\n\nCovariances:\n                      Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  peerPressure ~~                                                          \n    socialMedia         -0.013    0.039   -0.345    0.730   -0.013   -0.013\n    socialComparsn       0.126    0.035    3.636    0.000    0.126    0.126\n    eatingDisorder      -0.035    0.042   -0.822    0.411   -0.035   -0.035\n  socialMedia ~~                                                           \n    socialComparsn       0.422    0.037   11.347    0.000    0.422    0.422\n    eatingDisorder       0.052    0.049    1.056    0.291    0.052    0.052\n  socialComparison ~~                                                      \n    eatingDisorder       0.368    0.042    8.679    0.000    0.368    0.368\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .PP1               0.500    0.053    9.365    0.000    0.500    0.326\n   .PP2               0.615    0.054   11.489    0.000    0.615    0.382\n   .PP3               1.133    0.044   25.604    0.000    1.133    0.863\n   .PP4               1.175    0.046   25.410    0.000    1.175    0.843\n   .SM1               0.958    0.048   20.116    0.000    0.958    0.733\n   .SM2               1.068    0.051   21.126    0.000    1.068    0.763\n   .SM3               1.033    0.048   21.355    0.000    1.033    0.771\n   .SM4               1.005    0.052   19.225    0.000    1.005    0.707\n   .SC1               0.993    0.054   18.400    0.000    0.993    0.561\n   .SC2               0.831    0.053   15.544    0.000    0.831    0.485\n   .SC3               1.075    0.055   19.543    0.000    1.075    0.595\n   .ED1               0.942    0.094    9.995    0.000    0.942    0.645\n   .ED2               1.052    0.085   12.310    0.000    1.052    0.700\n    peerPressure      1.000                               1.000    1.000\n    socialMedia       1.000                               1.000    1.000\n    socialComparsn    1.000                               1.000    1.000\n    eatingDisorder    1.000                               1.000    1.000\n\n\nTasks\n\nReport the standardized loadings and identify any weak items.\nCheck residual variances (Heywood cases? negative variances?).\nExtract the core fit indices: CFI, TLI, RMSEA, SRMR.\n\n\n\nShow code\nfitMeasures(fit_cfa, c(\"cfi\", \"tli\", \"rmsea\", \"srmr\"))\n\n\n  cfi   tli rmsea  srmr \n0.882 0.844 0.066 0.042"
  },
  {
    "objectID": "labs/lab05_sem_capstone_eat.html#a-add-structural-regressions-among-the-latent-variables",
    "href": "labs/lab05_sem_capstone_eat.html#a-add-structural-regressions-among-the-latent-variables",
    "title": "Lab 05 — SEM capstone with the EAT dataset",
    "section": "2a) Add structural regressions among the latent variables",
    "text": "2a) Add structural regressions among the latent variables\n\n\nShow code\nm_sem &lt;- \"\n  # CFA model\n  peerPressure =~ PP1 + PP2 + PP3 + PP4\n  socialMedia  =~ SM1 + SM2 + SM3 + SM4\n  socialComparison =~ SC1 + SC2 + SC3\n  eatingDisorder =~ ED1 + ED2\n\n  # Structural model\n  eatingDisorder ~ socialComparison\n  socialComparison ~ peerPressure + socialMedia\n\""
  },
  {
    "objectID": "labs/lab05_sem_capstone_eat.html#b-fit-and-inspect",
    "href": "labs/lab05_sem_capstone_eat.html#b-fit-and-inspect",
    "title": "Lab 05 — SEM capstone with the EAT dataset",
    "section": "2b) Fit and inspect",
    "text": "2b) Fit and inspect\n\n\nShow code\nfit_sem &lt;- sem(m_sem, data = dE4_1, std.lv = TRUE)\nsummary(fit_sem, standardized = TRUE, fit.measures = TRUE)\n\n\nlavaan 0.6-19 ended normally after 30 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        30\n\n  Number of observations                          1423\n\nModel Test User Model:\n                                                      \n  Test statistic                               430.575\n  Degrees of freedom                                61\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                              3150.947\n  Degrees of freedom                                78\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.880\n  Tucker-Lewis Index (TLI)                       0.846\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)             -28620.977\n  Loglikelihood unrestricted model (H1)     -28405.690\n                                                      \n  Akaike (AIC)                               57301.954\n  Bayesian (BIC)                             57459.770\n  Sample-size adjusted Bayesian (SABIC)      57364.470\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.065\n  90 Percent confidence interval - lower         0.060\n  90 Percent confidence interval - upper         0.071\n  P-value H_0: RMSEA &lt;= 0.050                    0.000\n  P-value H_0: RMSEA &gt;= 0.080                    0.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.044\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                      Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  peerPressure =~                                                          \n    PP1                  1.019    0.036   27.954    0.000    1.019    0.823\n    PP2                  0.996    0.037   26.873    0.000    0.996    0.785\n    PP3                  0.423    0.033   12.909    0.000    0.423    0.369\n    PP4                  0.468    0.034   13.932    0.000    0.468    0.396\n  socialMedia =~                                                           \n    SM1                  0.582    0.039   15.049    0.000    0.582    0.509\n    SM2                  0.576    0.040   14.452    0.000    0.576    0.487\n    SM3                  0.557    0.039   14.279    0.000    0.557    0.481\n    SM4                  0.653    0.041   16.062    0.000    0.653    0.548\n  socialComparison =~                                                      \n    SC1                  0.799    0.037   21.609    0.000    0.885    0.665\n    SC2                  0.847    0.037   22.797    0.000    0.937    0.716\n    SC3                  0.777    0.037   20.925    0.000    0.860    0.640\n  eatingDisorder =~                                                        \n    ED1                  0.654    0.066    9.920    0.000    0.700    0.579\n    ED2                  0.645    0.065    9.945    0.000    0.690    0.563\n\nRegressions:\n                     Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  eatingDisorder ~                                                        \n    socialComparsn      0.344    0.047    7.322    0.000    0.356    0.356\n  socialComparison ~                                                      \n    peerPressure        0.139    0.038    3.636    0.000    0.125    0.125\n    socialMedia         0.455    0.049    9.221    0.000    0.411    0.411\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  peerPressure ~~                                                       \n    socialMedia      -0.014    0.039   -0.354    0.723   -0.014   -0.014\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .PP1               0.495    0.054    9.205    0.000    0.495    0.323\n   .PP2               0.619    0.054   11.521    0.000    0.619    0.384\n   .PP3               1.134    0.044   25.612    0.000    1.134    0.864\n   .PP4               1.175    0.046   25.414    0.000    1.175    0.843\n   .SM1               0.969    0.048   20.363    0.000    0.969    0.741\n   .SM2               1.067    0.051   21.069    0.000    1.067    0.762\n   .SM3               1.030    0.048   21.257    0.000    1.030    0.768\n   .SM4               0.995    0.053   18.929    0.000    0.995    0.700\n   .SC1               0.986    0.054   18.198    0.000    0.986    0.558\n   .SC2               0.836    0.054   15.566    0.000    0.836    0.488\n   .SC3               1.068    0.055   19.361    0.000    1.068    0.591\n   .ED1               0.971    0.094   10.279    0.000    0.971    0.665\n   .ED2               1.026    0.093   11.017    0.000    1.026    0.683\n    peerPressure      1.000                               1.000    1.000\n    socialMedia       1.000                               1.000    1.000\n   .socialComparsn    1.000                               0.816    0.816\n   .eatingDisorder    1.000                               0.873    0.873\n\n\nShow code\nfitMeasures(fit_sem, c(\"cfi\", \"tli\", \"rmsea\", \"srmr\"))\n\n\n  cfi   tli rmsea  srmr \n0.880 0.846 0.065 0.044 \n\n\nQuestions\n\nAre the key hypotheses supported (sign + magnitude + uncertainty)?\nHow does fit compare to the CFA-only model? (Interpret carefully.)\n\n(Optional)\n\n\nShow code\nanova(fit_cfa, fit_sem)\n\n\n\nChi-Squared Difference Test\n\n        Df   AIC   BIC Chisq Chisq diff  RMSEA Df diff Pr(&gt;Chisq)  \nfit_cfa 59 57297 57466   422                                       \nfit_sem 61 57302 57460   431       8.75 0.0487       2      0.013 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "labs/lab05_sem_capstone_eat.html#a-standardized-residual-covariances-local-misfit",
    "href": "labs/lab05_sem_capstone_eat.html#a-standardized-residual-covariances-local-misfit",
    "title": "Lab 05 — SEM capstone with the EAT dataset",
    "section": "3a) Standardized residual covariances (local misfit)",
    "text": "3a) Standardized residual covariances (local misfit)\n\n\nShow code\nres_std &lt;- residuals(fit_sem, type = \"standardized\")$cov\nres_std\n\n\n       PP1    PP2    PP3    PP4    SM1    SM2    SM3    SM4    SC1    SC2\nPP1  0.000                                                               \nPP2  4.114  0.000                                                        \nPP3 -0.956 -1.461  0.000                                                 \nPP4 -1.782 -0.714  3.843  0.000                                          \nSM1 -0.025  0.866  0.527 -1.447  0.000                                   \nSM2 -0.201  0.135  1.297 -0.472 -0.979  0.000                            \nSM3  0.527  0.490  0.127 -0.211 -3.014  1.973  0.000                     \nSM4 -1.102 -0.389  1.354 -0.710 -2.151  1.660  2.005  0.000              \nSC1 -0.195 -0.601  0.677  0.508 -0.370 -2.178 -0.679 -0.570  0.000       \nSC2  0.298 -0.359  1.676  0.657 14.915 -1.812 -0.951 -1.042 -3.833  0.000\nSC3  0.244  0.045  1.346  1.211 -3.254 -3.230 -1.506 -2.873  4.203 -1.867\nED1 -0.693 -0.951 -2.649 -0.337 -2.138 -2.846 -1.096 -1.179  1.416 -1.514\nED2 -1.299 -2.440 -0.893 -1.020 -0.471 -0.566 -1.018  0.947  0.108 -1.475\n       SC3    ED1    ED2\nPP1                     \nPP2                     \nPP3                     \nPP4                     \nSM1                     \nSM2                     \nSM3                     \nSM4                     \nSC1                     \nSC2                     \nSC3  0.000              \nED1  1.659  0.000       \nED2  1.978  0.000  0.000\n\n\nFind the largest absolute residual covariances:\n\n\nShow code\nR &lt;- res_std\ndiag(R) &lt;- NA\ntop_res &lt;- as.data.frame(as.table(R))\ntop_res &lt;- top_res[order(abs(top_res$Freq), decreasing = TRUE), ]\nhead(top_res, 10)\n\n\n    Var1 Var2  Freq\n122  SM1  SC2 14.92\n62   SC2  SM1 14.92\n115  SC3  SC1  4.20\n139  SC1  SC3  4.20\n2    PP2  PP1  4.11\n14   PP1  PP2  4.11\n30   PP4  PP3  3.84\n42   PP3  PP4  3.84\n114  SC2  SC1 -3.83\n126  SC1  SC2 -3.83"
  },
  {
    "objectID": "labs/lab05_sem_capstone_eat.html#b-modification-indices-mi-effect-size-epcsepc",
    "href": "labs/lab05_sem_capstone_eat.html#b-modification-indices-mi-effect-size-epcsepc",
    "title": "Lab 05 — SEM capstone with the EAT dataset",
    "section": "3b) Modification indices (MI) + effect size (EPC/SEPC)",
    "text": "3b) Modification indices (MI) + effect size (EPC/SEPC)\n\n\nShow code\nmi &lt;- modificationIndices(fit_sem, sort. = TRUE)\nhead(mi[, c(\"lhs\",\"op\",\"rhs\",\"mi\",\"epc\",\"sepc.all\")], 15)\n\n\n                 lhs op rhs     mi    epc sepc.all\n120              SM1 ~~ SC2 328.97  0.565    0.628\n49       socialMedia =~ SC2  56.91  0.378    0.289\n57  socialComparison =~ SM1  54.67  0.292    0.283\n121              SM1 ~~ SC3  51.71 -0.235   -0.231\n50       socialMedia =~ SC3  30.54 -0.277   -0.206\n119              SM1 ~~ SC1  22.07 -0.151   -0.154\n143              SC1 ~~ SC3  19.17  0.293    0.285\n74               PP1 ~~ PP2  18.34  0.665    1.201\n97               PP3 ~~ PP4  15.33  0.126    0.109\n58  socialComparison =~ SM2  13.08 -0.146   -0.137\n142              SC1 ~~ SC2  12.91 -0.277   -0.304\n138              SM4 ~~ SC2   9.69 -0.101   -0.110\n117              SM1 ~~ SM3   8.09 -0.112   -0.112\n51       socialMedia =~ ED1   8.02 -0.130   -0.108\n105              PP3 ~~ ED1   7.86 -0.091   -0.087\n\n\nTasks\n\nDo the top residual pairs match the top MI suggestions?\nPick one candidate modification that you can justify substantively.\nWrite a 1–2 sentence justification (content overlap? method effect? plausible local dependence?)."
  },
  {
    "objectID": "labs/lab05_sem_capstone_eat.html#a-add-one-residual-correlation-and-refit",
    "href": "labs/lab05_sem_capstone_eat.html#a-add-one-residual-correlation-and-refit",
    "title": "Lab 05 — SEM capstone with the EAT dataset",
    "section": "4a) Add one residual correlation and refit",
    "text": "4a) Add one residual correlation and refit\n\n\nShow code\nm_sem_mod &lt;- \"\n  # CFA model\n  peerPressure =~ PP1 + PP2 + PP3 + PP4\n  socialMedia  =~ SM1 + SM2 + SM3 + SM4\n  socialComparison =~ SC1 + SC2 + SC3\n  eatingDisorder =~ ED1 + ED2\n\n  # Structural model\n  eatingDisorder ~ socialComparison\n  socialComparison ~ peerPressure + socialMedia\n\n  # Residual correlation (one modification)\n  SM1 ~~ SC2\n\"\nfit_sem_mod &lt;- sem(m_sem_mod, data = dE4_1, std.lv = TRUE)"
  },
  {
    "objectID": "labs/lab05_sem_capstone_eat.html#b-compare-fit-nested-test",
    "href": "labs/lab05_sem_capstone_eat.html#b-compare-fit-nested-test",
    "title": "Lab 05 — SEM capstone with the EAT dataset",
    "section": "4b) Compare fit + nested test",
    "text": "4b) Compare fit + nested test\n\n\nShow code\nrbind(\n  original = fitMeasures(fit_sem, c(\"cfi\",\"tli\",\"rmsea\",\"srmr\")),\n  modified = fitMeasures(fit_sem_mod, c(\"cfi\",\"tli\",\"rmsea\",\"srmr\"))\n)\n\n\n           cfi   tli  rmsea   srmr\noriginal 0.880 0.846 0.0653 0.0440\nmodified 0.995 0.994 0.0130 0.0233\n\n\nShow code\nanova(fit_sem, fit_sem_mod)\n\n\n\nChi-Squared Difference Test\n\n            Df   AIC   BIC Chisq Chisq diff RMSEA Df diff Pr(&gt;Chisq)    \nfit_sem_mod 60 56948 57111  74.4                                        \nfit_sem     61 57302 57460 430.6        356   0.5       1     &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "labs/lab05_sem_capstone_eat.html#c-re-check-diagnostics",
    "href": "labs/lab05_sem_capstone_eat.html#c-re-check-diagnostics",
    "title": "Lab 05 — SEM capstone with the EAT dataset",
    "section": "4c) Re-check diagnostics",
    "text": "4c) Re-check diagnostics\n\n\nShow code\nmi_mod &lt;- modificationIndices(fit_sem_mod, sort. = TRUE)\nhead(mi_mod[, c(\"lhs\",\"op\",\"rhs\",\"mi\",\"epc\",\"sepc.all\")], 10)\n\n\n               lhs op            rhs    mi    epc sepc.all\n75             PP1 ~~            PP2 19.27  0.679    1.226\n98             PP3 ~~            PP4 15.29  0.126    0.109\n106            PP3 ~~            ED1  8.04 -0.092   -0.089\n51     socialMedia =~            SC3  7.89 -0.127   -0.094\n120            SM1 ~~            SC1  5.37  0.075    0.074\n52     socialMedia =~            ED1  4.89 -0.092   -0.076\n129            SM2 ~~            ED1  4.21 -0.068   -0.068\n160   peerPressure  ~ eatingDisorder  3.99 -0.090   -0.097\n153   peerPressure ~~ eatingDisorder  3.99 -0.090   -0.090\n69  eatingDisorder =~            SM2  3.93 -0.077   -0.070\n\n\nDocumentation (write these down in your log)\n\nWhat did you change and why?\nWhat evidence supported it (residuals? MI+EPC?)?\nDoes the modification change interpretation of the constructs or paths?"
  },
  {
    "objectID": "labs/lab05_sem_capstone_eat.html#a-compare-key-standardized-structural-coefficients",
    "href": "labs/lab05_sem_capstone_eat.html#a-compare-key-standardized-structural-coefficients",
    "title": "Lab 05 — SEM capstone with the EAT dataset",
    "section": "7a) Compare key standardized structural coefficients",
    "text": "7a) Compare key standardized structural coefficients\nExtract standardized regressions from both models:\n\n\nShow code\npe_lat &lt;- parameterEstimates(fit_sem_mod, standardized = TRUE)\nlat_paths &lt;- subset(pe_lat, op == \"~\" &\n                      lhs %in% c(\"eatingDisorder\",\"socialComparison\"))[, \n                    c(\"lhs\",\"rhs\",\"est\",\"se\",\"pvalue\",\"std.all\")]\nlat_paths\n\n\n                lhs              rhs   est    se pvalue std.all\n14   eatingDisorder socialComparison 0.377 0.049      0   0.371\n15 socialComparison     peerPressure 0.133 0.036      0   0.126\n16 socialComparison      socialMedia 0.324 0.045      0   0.306\n\n\n\n\nShow code\npe_sum &lt;- parameterEstimates(fit_path, standardized = TRUE)\nsum_paths &lt;- subset(pe_sum, op == \"~\")[, c(\"lhs\",\"rhs\",\"est\",\"se\",\"pvalue\",\"std.all\")]\nsum_paths\n\n\n               lhs              rhs   est    se pvalue std.all\n1   eatingDisorder socialComparison 0.139 0.016      0   0.223\n2 socialComparison     peerPressure 0.097 0.023      0   0.106\n3 socialComparison      socialMedia 0.258 0.026      0   0.253"
  },
  {
    "objectID": "labs/lab05_sem_capstone_eat.html#b-discussion-write-a-short-paragraph",
    "href": "labs/lab05_sem_capstone_eat.html#b-discussion-write-a-short-paragraph",
    "title": "Lab 05 — SEM capstone with the EAT dataset",
    "section": "7b) Discussion (write a short paragraph)",
    "text": "7b) Discussion (write a short paragraph)\n\nWhich paths change the most (magnitude / uncertainty)?\nDoes the pattern of support for hypotheses change?\nOffer at least two measurement-driven explanations for differences:\n\nunequal loadings / reliability differences\ncorrelated residuals / local dependence\nattenuation / error-in-variables logic\nfactor correlation vs sum-score correlation differences"
  },
  {
    "objectID": "labs/lab05_sem_capstone_eat.html#deliverables",
    "href": "labs/lab05_sem_capstone_eat.html#deliverables",
    "title": "Lab 05 — SEM capstone with the EAT dataset",
    "section": "Deliverables",
    "text": "Deliverables\n\nA 1-page model-checking log:\n\nCFA fit + key issues\nSEM fit + key issues\ndiagnostics used (residuals, MI/EPC)\nwhat you modified and why\n\nA diagram of the final SEM\nA short comparison of latent vs sum-score conclusions"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#today-in-the-workflow",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#today-in-the-workflow",
    "title": "Structural Equation Models",
    "section": "Today in the workflow",
    "text": "Today in the workflow\nSpecify → Identify → Estimate → Evaluate → Revise/Report\n\n\n\nToday: full SEM = measurement model (CFA) + structural model (paths among latent variables).\nWe will repeat fit/diagnostics on purpose: by now it should become a habit (global + local)."
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#learning-objectives",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#learning-objectives",
    "title": "Structural Equation Models",
    "section": "Learning objectives",
    "text": "Learning objectives\nBy the end of this session you should be able to:\n\nConnect the CFA measurement model to the SEM structural model (two-step mindset)\nUnderstand how SEM is represented in matrices (Λ, B, Γ, Φ, Ψ, Θ)\nFit a full SEM in lavaan and interpret parameters + fit indices + diagnostics\nCompare plausible SEMs (nested comparisons) and justify modifications transparently"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#outline",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#outline",
    "title": "Structural Equation Models",
    "section": "Outline",
    "text": "Outline\n\nIntroduction\nIdentification\nExample\nExercise\nResults"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#structural-equation-models",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#structural-equation-models",
    "title": "Structural Equation Models",
    "section": "Structural equation models",
    "text": "Structural equation models\nUp to now, we have seen how to model the relationship between different variables/constructs at the same time (path analysis) and how to build a measurement model with one or more latent variables.\nA complete SEM takes both of these things and put them together"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#the-two-parts-of-a-sem",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#the-two-parts-of-a-sem",
    "title": "Structural Equation Models",
    "section": "The two parts of a SEM",
    "text": "The two parts of a SEM\n\nThe measurement model \\[\n\\begin{aligned}\nx = \\Lambda_x\\xi + \\delta\ny =\\Lambda_y\\eta + \\epsilon\n\\end{aligned}\n\\]\nThe structural model \\[\n\\begin{aligned}\n\\eta = B\\eta + \\Gamma\\xi + \\zeta\n\\end{aligned}\n\\]\n\nalready seen in the first slides"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#matrices",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#matrices",
    "title": "Structural Equation Models",
    "section": "Matrices",
    "text": "Matrices\nThese models (can) have all the possible matrices: - Loadings and coefficients matrices \\[\n\\begin{aligned}\n\\Lambda^x &  - relation among  \\xi  and  x\n    \\Lambda^y &  - relation among  \\eta  and  y\n    B &  - relation among  \\eta  and  \\eta\n    \\Gamma &  - relation among  \\xi  and  \\eta\n\\end{aligned}\n\\] - Covariance matrices \\[\n\\begin{aligned}\n\\Theta^\\delta &  -  x  errors\n    \\Theta^\\epsilon &  -  y  errors\n    \\Psi &  -  \\eta  errors\n    \\Phi &  - relations among  \\eta\n\\end{aligned}\n\\] Different models are allowew based on the way we define relationships among variables"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#lavaan-matrices",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#lavaan-matrices",
    "title": "Structural Equation Models",
    "section": "… lavaan matrices",
    "text": "… lavaan matrices\nlavaan does not distinguish between endogenous and exogenous variables. This leads to an easier parametrization and to four matrices only: 1. \\(\\Lambda\\) factor loadings matrix \\([p x m]\\) 1. \\(\\Theta\\) measurement residual errors covariance matrix \\([p x p]\\) 1. \\(B\\) regression coefficients matrix \\([m x m]\\) 1. \\(\\Psi\\) residual structural errors covariance matrix \\([m x m]\\) With p being the number of manifest variables and m being the number of latent variables."
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#the-lavaan-matrices",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#the-lavaan-matrices",
    "title": "Structural Equation Models",
    "section": "The lavaan matrices",
    "text": "The lavaan matrices\n{Lambda: matrix of loadings}\n\n{Beta: regression coefficients}\n\n{Psi: residual structural errors matrix}\n\n{Theta: observed variance-covariance matrix}"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#a-sem-example---simulation",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#a-sem-example---simulation",
    "title": "Structural Equation Models",
    "section": "A SEM example - simulation",
    "text": "A SEM example - simulation\n\nlibrary(lavaan)\ndSEM &lt;- simulateData(\"xi =~ .74*x1 + .65*x2\n                      eta =~ .56*y1 + .75*y2\n                      eta ~ .30*xi\n                     \", sample.nobs = 1000)"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#a-sem-example---specification-and-constraints",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#a-sem-example---specification-and-constraints",
    "title": "Structural Equation Models",
    "section": "A SEM example - specification and constraints",
    "text": "A SEM example - specification and constraints\n\nfit &lt;- sem(model = \"xi =~ x1 + x2\n                     eta =~ y1 + y2\n                     eta ~ xi\", data = dSEM)\n\nConstraints\nTo estimate the model we need to set constraints: - the sem or cfa functions default is setting to 1 one loading for each latent variable - an alternative is to standardized latent variables using the std.lv = TRUE option"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#constraints-default",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#constraints-default",
    "title": "Structural Equation Models",
    "section": "Constraints: default",
    "text": "Constraints: default\n\n\n[...]\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  xi =~                                                                 \n    x1                1.000                               0.727    0.570\n    x2                1.004    0.304    3.297    0.001    0.730    0.602\n  eta =~                                                                \n    y1                1.000                               0.440    0.372\n    y2                2.324    1.063    2.186    0.029    1.021    0.799\n\n[...]\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .x1                1.102    0.168    6.570    0.000    1.102    0.676\n   .x2                0.937    0.167    5.613    0.000    0.937    0.637\n   .y1                1.204    0.103   11.701    0.000    1.204    0.862\n   .y2                0.592    0.474    1.249    0.212    0.592    0.362\n    xi                0.529    0.169    3.129    0.002    1.000    1.000\n   .eta               0.181    0.083    2.173    0.030    0.937    0.937\n\n[...]"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#constraints-std.lvt",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#constraints-std.lvt",
    "title": "Structural Equation Models",
    "section": "Constraints: std.lv=T",
    "text": "Constraints: std.lv=T\n\n\n[...]\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  xi =~                                                                 \n    x1                0.727    0.116    6.258    0.000    0.727    0.570\n    x2                0.730    0.116    6.298    0.000    0.730    0.602\n  eta =~                                                                \n    y1                0.425    0.098    4.346    0.000    0.440    0.372\n    y2                0.988    0.239    4.127    0.000    1.021    0.799\n\n[...]\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .x1                1.102    0.168    6.570    0.000    1.102    0.676\n   .x2                0.937    0.167    5.613    0.000    0.937    0.637\n   .y1                1.204    0.103   11.701    0.000    1.204    0.862\n   .y2                0.592    0.474    1.249    0.212    0.592    0.362\n    xi                1.000                               1.000    1.000\n   .eta               1.000                               0.937    0.937\n\n[...]"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#lavaan-matrices-1",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#lavaan-matrices-1",
    "title": "Structural Equation Models",
    "section": "lavaan matrices",
    "text": "lavaan matrices\n\ninspect(fit, \"std\") # OR \"est\"\n\n\n\n$lambda\n      xi   eta\nx1 0.570 0.000\nx2 0.602 0.000\ny1 0.000 0.372\ny2 0.000 0.799\n\n$theta\n      x1    x2    y1    y2\nx1 0.676                  \nx2 0.000 0.637            \ny1 0.000 0.000 0.862      \ny2 0.000 0.000 0.000 0.362\n\n\n\n\n$psi\n       xi   eta\nxi  1.000      \neta 0.000 0.937\n\n$beta\n       xi eta\nxi  0.000   0\neta 0.252   0"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#sem-identification",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#sem-identification",
    "title": "Structural Equation Models",
    "section": "SEM identification",
    "text": "SEM identification\nOnce again, remember that identification is a topic relevant to all structural equation models.\nIf an unknown parameter in \\(\\theta\\) can be written as a function of one or more elements of \\(\\Sigma\\), that parameter is identified.\nIf all unknown parameters in \\(\\theta\\) are identified, the model is identified. - the t-rule (again) - the Two-Steps rule"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#two-steps-rule",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#two-steps-rule",
    "title": "Structural Equation Models",
    "section": "Two-Steps rule",
    "text": "Two-Steps rule\n\nStep 1. Treat the model as a confirmatory factor analysis: view the original \\(x\\) and \\(y\\) as \\(x\\) variables and the original \\(\\xi\\) and \\(\\eta\\) as \\(\\xi\\) variables. The only relationship between latent variables of interest are their variance and covariance \\(Phi\\). That is, ignore the \\(B\\), \\(\\Gamma\\), and \\(\\Psi\\) elements.\n\\(\\rightarrow\\) apply CFA identification rules\nStep 2. Examine the latent variable equation of the original model (\\(\\eta = B\\eta + \\Gamma\\xi + \\zeta\\)), assuming that each latent variable is an observed variable that is perfectly measured."
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#two-steps-rule-1",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#two-steps-rule-1",
    "title": "Structural Equation Models",
    "section": "Two-Steps rule",
    "text": "Two-Steps rule\nSummary\nIf the first step shows that the measurement parameters are identified and the second step shows that the latent variable model parameters also are identified, then this is suficient to identify the whole model."
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#political-democracy-dataset",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#political-democracy-dataset",
    "title": "Structural Equation Models",
    "section": "Political democracy dataset",
    "text": "Political democracy dataset\nBollen (1989) studied the relation between industrialization in 1960 and political democracy of developing countries in 1960 and 1965.\nWe have 11 variables\n\n\n    y1  y2    y3  y4   y5   y6    y7   y8   x1   x2   x3\n1 2.50 0.0  3.33 0.0 1.25 0.00  3.73 3.33 4.44 3.64 2.56\n2 1.25 0.0  3.33 0.0 6.25 1.10  6.67 0.74 5.38 5.06 3.57\n3 7.50 8.8 10.00 9.2 8.75 8.09 10.00 8.21 5.96 6.26 5.22\n\n\nA first latent variable, Industrialization (\\(I = x_1 + x_2 + x_3\\))\nA second latent variable, political democracy in 1960 (\\(D60 = y_1 + y_2 + y_3 + y_4\\))\nA third latent variable, political democracy in 1965 (\\(D65 = y_5 + y_6 + y_7 + y_8\\)).\nLET'S APLLY THE TWO-STEPS RULE"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#step-1---model-plot",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#step-1---model-plot",
    "title": "Structural Equation Models",
    "section": "Step 1 - model plot",
    "text": "Step 1 - model plot\nThe CFA model"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#step-1---model-specification-and-results",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#step-1---model-specification-and-results",
    "title": "Structural Equation Models",
    "section": "Step 1 - model specification and results",
    "text": "Step 1 - model specification and results\nThe CFA model\n\nm &lt;- \"I =~ x1 + x2 + x3\nD60 =~ y1 + y2 + y3 + y4\nD65 =~ y5 + y6 + y7 + y8\n\"\n\n\nfit1 &lt;- sem(m, data = PoliticalDemocracy)\nfit1@Fit@converged\n\n[1] TRUE\n\n\nPARAMETERS ARE ALL IDENTIFIED. LET'S GO TO STEP 2"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#step-2---model-plot",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#step-2---model-plot",
    "title": "Structural Equation Models",
    "section": "Step 2 - model plot",
    "text": "Step 2 - model plot\nThe structural model"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#step-2---model-specification-and-results",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#step-2---model-specification-and-results",
    "title": "Structural Equation Models",
    "section": "Step 2 - model specification and results",
    "text": "Step 2 - model specification and results\nThe structural model\n\nm2 &lt;- \"I =~ x1 + x2 + x3\nD60 =~ y1 + y2 + y3 + y4\nD65 =~ y5 + y6 + y7 + y8\nD65 ~ I + D60\nD60 ~ I\n\"\n\n\nfit2 &lt;- sem(m2, data = PoliticalDemocracy)\nfit2@Fit@converged\n\n[1] TRUE\n\n\nSTRUCTURAL PARAMETERS ARE ALSO IDENTIFIED.\nLET'S DEFINE THE MODEL CONSIDERING LONGITUDINAL MEASURES"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#final-model",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#final-model",
    "title": "Structural Equation Models",
    "section": "Final model",
    "text": "Final model\nThe modified model"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#final-model-specification",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#final-model-specification",
    "title": "Structural Equation Models",
    "section": "Final model specification",
    "text": "Final model specification\nThe modified model\n\nm3 &lt;- \"I =~ x1 + x2 + x3\nD60 =~ y1 + y2 + y3 + y4\nD65 =~ y5 + y6 + y7 + y8\nD65 ~ I + D60\nD60 ~ I\ny1 ~~ y5\ny2 ~~ y6\ny3 ~~ y7\ny4 ~~ y8\n\"\n\nSAME ITEMS AT DIFFERENT TIME POINTS HAVE CORRELATED RESIDUALS"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#final-model-results",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#final-model-results",
    "title": "Structural Equation Models",
    "section": "Final model results",
    "text": "Final model results\nThe modified model\n\n(fit3 &lt;- sem(m3, data = PoliticalDemocracy))\n\nlavaan 0.6-19 ended normally after 58 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        29\n\n  Number of observations                            75\n\nModel Test User Model:\n                                                      \n  Test statistic                                50.835\n  Degrees of freedom                                37\n  P-value (Chi-square)                           0.064\n\ninspect(fit3, what = \"fitmeasures\")[\n  c(\"cfi\", \"srmr\", \"rmsea\")]\n\n       cfi       srmr      rmsea \n0.97952316 0.05011528 0.07060935 \n\n\nMODEL FIT IS GOOD!"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#model-comparisons",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#model-comparisons",
    "title": "Structural Equation Models",
    "section": "Model comparisons",
    "text": "Model comparisons\n\nanova(fit1,fit2,fit3)\n\nWarning: lavaan-&gt;lavTestLRT():  \n   some models have the same degrees of freedom\n\n\n\nChi-Squared Difference Test\n\n     Df    AIC    BIC  Chisq Chisq diff   RMSEA Df diff Pr(&gt;Chisq)    \nfit3 37 3166.3 3233.5 50.835                                          \nfit1 41 3179.9 3237.9 72.462     21.626 0.24239       4  0.0002378 ***\nfit2 41 3179.9 3237.9 72.462      0.000 0.00000       0               \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#model-comparisons-1",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#model-comparisons-1",
    "title": "Structural Equation Models",
    "section": "Model comparisons",
    "text": "Model comparisons\nWe can also compare the models using fit indices:\n\n\n\n\n\n\nchisq\ndf\ncfi\ntli\nsrmr\nrmsea\naic\nbic\n\n\n\n\nmodel1\n72.462\n41\n0.953\n0.938\n0.055\n0.101\n3179.918\n3237.855\n\n\nmodel2\n72.462\n41\n0.953\n0.938\n0.055\n0.101\n3179.918\n3237.855\n\n\nmodel3\n50.835\n37\n0.980\n0.970\n0.050\n0.071\n3166.292\n3233.499\n\n\n\n\n\nWHAT IS THE BEST MODEL? QUESTIONS? COMMENTS?"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#the-eat-dataset",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#the-eat-dataset",
    "title": "Structural Equation Models",
    "section": "The EAT dataset",
    "text": "The EAT dataset\nThe dataset includes 13 items that measure ‘peer pressure’, ‘social media use’, ‘social comparison’, and ‘eating disorders’.\n\nload(\"../data/Exercise4_1.Rdata\")\nround(head(dE4_1),2)\n\n    PP1   PP2   PP3   PP4   SM1   SM2   SM3   SM4   SC1   SC2   SC3   ED1   ED2\n1  0.23  1.91  0.59 -0.70  2.31  1.06  1.43 -0.77  1.18  2.20  0.18 -0.38  1.61\n2 -0.65 -3.18 -0.84 -0.43  0.69  0.10  1.24  0.51 -1.87 -1.17 -1.23 -1.74 -1.73\n3  0.26 -1.46 -0.43 -0.05 -0.21 -0.46 -0.02  1.26  1.39  1.03  0.90  1.07  2.04\n4 -0.68 -0.29 -0.08 -2.24 -0.64  0.47 -0.76  0.58  1.22  0.97  2.73  0.71  0.32\n5 -0.06  0.89  0.04 -0.41  0.17  1.02  0.18  0.61  3.74  1.38  1.85  1.25  0.66\n6 -0.29 -2.74 -0.52  2.58  0.15 -1.08  1.08  0.99  1.32 -0.24  0.93 -0.97 -0.68"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#the-theoretical-model",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#the-theoretical-model",
    "title": "Structural Equation Models",
    "section": "The theoretical model",
    "text": "The theoretical model"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#the-exercise",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#the-exercise",
    "title": "Structural Equation Models",
    "section": "The exercise",
    "text": "The exercise\n\nApply the two-step rule:\n\nTest the CFA model\nTest the structural model\n\nInspect model results and fit indices\n\nAre the hypotheses confirmed?\nDoes the model fit the data well?\n\nIf the model is not satisfactory, understand why and change it\nDraw the model (in R, ppt, or with a pencil)\nTry to fit a simple path model using sum scores instead of latent scores"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#model-specification",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#model-specification",
    "title": "Structural Equation Models",
    "section": "Model specification",
    "text": "Model specification\nSTEP 1 and 2\n\nm1 &lt;- \"\n # CFA model\n peerPressure =~ PP1 + PP2 + PP3 + PP4\n socialMedia =~ SM1 + SM2 + SM3 + SM4\n socialComparison =~ SC1 + SC2 + SC3\n eatingDisorder =~ ED1 + ED2\n\"\nfit1 &lt;- sem(m1, data = dE4_1, std.lv=T)\nfit1@Fit@converged\nm2 &lt;- \"\n [...]\n # Structural model\n eatingDisorder ~ socialComparison\n socialComparison ~ peerPressure + socialMedia\"\nfit2 &lt;- sem(m2, data = dE4_1, std.lv=T)\nfit2@Fit@converged\n\nOK?"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#results-and-fit",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#results-and-fit",
    "title": "Structural Equation Models",
    "section": "Results and fit",
    "text": "Results and fit\n\nsummary(fitE4_1, std=T)\n\n\n\n[...]\nRegressions:\n                     Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  eatingDisorder ~                                                        \n    socialComparsn      0.344    0.047    7.322    0.000    0.356    0.356\n  socialComparison ~                                                      \n    peerPressure        0.139    0.038    3.636    0.000    0.125    0.125\n    socialMedia         0.455    0.049    9.221    0.000    0.411    0.411\n\n[...]\n\n\n\nfitmeasures(fitE4_1, \n            fit.measures = \n            c(\"cfi\", \"tli\", \"srmr\", \"rmsea\"))\n\n  cfi   tli  srmr rmsea \n0.880 0.846 0.044 0.065"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#model-modification",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#model-modification",
    "title": "Structural Equation Models",
    "section": "Model modification",
    "text": "Model modification\n\nmodificationIndices(fitE4_1, sort. = T)[1:10,]\n\n                 lhs op rhs      mi    epc sepc.lv sepc.all sepc.nox\n120              SM1 ~~ SC2 328.967  0.565   0.565    0.628    0.628\n49       socialMedia =~ SC2  56.910  0.378   0.378    0.289    0.289\n57  socialComparison =~ SM1  54.668  0.292   0.323    0.283    0.283\n121              SM1 ~~ SC3  51.713 -0.235  -0.235   -0.231   -0.231\n50       socialMedia =~ SC3  30.539 -0.277  -0.277   -0.206   -0.206\n119              SM1 ~~ SC1  22.069 -0.151  -0.151   -0.154   -0.154\n143              SC1 ~~ SC3  19.170  0.293   0.293    0.285    0.285\n74               PP1 ~~ PP2  18.341  0.665   0.665    1.201    1.201\n97               PP3 ~~ PP4  15.333  0.126   0.126    0.109    0.109\n58  socialComparison =~ SM2  13.081 -0.146  -0.162   -0.137   -0.137\n\n\n\nm2.1 &lt;- \"\n[...]\n# Residual correlations\nSM1 ~~ SC2\n\"\nfitmeasures(fit2.1, ...)\n\n\n\n  cfi   tli  srmr rmsea \n0.995 0.994 0.023 0.013"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#why-sum-scores-can-mislead-measurement-error-attenuation",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#why-sum-scores-can-mislead-measurement-error-attenuation",
    "title": "Structural Equation Models",
    "section": "Why sum scores can mislead (measurement error → attenuation)",
    "text": "Why sum scores can mislead (measurement error → attenuation)\nIf an observed score (X) is a noisy measure of a latent (X^*), measurement error tends to attenuate associations.\nA classic intuition (simple linear setting):\n\\[\n\\hat\\beta_{\\text{observed}} \\approx \\hat\\beta_{\\text{latent}} \\times \\rho_{xx}\n\\]\nwhere (_{xx}) is reliability of (X).\n\n\n\nThis is exactly why latent-variable SEM can change “structural” conclusions even when factor scores correlate highly with sum scores."
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#sum-scores",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#sum-scores",
    "title": "Structural Equation Models",
    "section": "Sum scores",
    "text": "Sum scores\n\nd2 &lt;- data.frame(\n  peerPressure = dE4_1$PP1 + dE4_1$PP2 + dE4_1$PP3 + dE4_1$PP4, \n  socialMedia = dE4_1$SM1 + dE4_1$SM2 + dE4_1$SM3 + dE4_1$SM4,\n  socialComparison = dE4_1$SC1 + dE4_1$SC2 + dE4_1$SC3,\n  eatingDisorder = dE4_1$ED1 + dE4_1$ED2)\npath &lt;- \"\neatingDisorder ~ socialComparison\nsocialComparison ~ peerPressure + socialMedia\"\nfitP &lt;- sem(path, d2)\nfitmeasures(fitP, fit.measures = \n              c(\"cfi\", \"tli\", \"srmr\", \"rmsea\"))\n\n  cfi   tli  srmr rmsea \n0.978 0.946 0.019 0.037"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#sum-scores-vs-latent-scores",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#sum-scores-vs-latent-scores",
    "title": "Structural Equation Models",
    "section": "Sum scores VS latent scores",
    "text": "Sum scores VS latent scores\nHowever, the debate is still open:\n\nThinking twice about sum scores\n\nThinking thrice about sum scores, and then some more about measurement and analysis\n\nPsychometric properties of sum scores and factor scores differ even when their correlation is 0.98: A response to Widaman and Revelle\n\nOr some more Schimmack:\n\nSchimmack vs Gelman 1\nSchimmack vs Gelman 2"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#the-ground-truth",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#the-ground-truth",
    "title": "Structural Equation Models",
    "section": "The ground truth",
    "text": "The ground truth\n\n# peer pressure AND social media -&gt; social comparison -&gt; eating disorder\nmE4_1 &lt;- \"\n # CFA model\n peerPressure =~ .75*PP1 + .72*PP2 + .59*PP3 + .65*PP4\n socialMedia =~ .45*SM1 + .55*SM2 + .59*SM3 + .65*SM4\n socialComparison =~ .81*SC1 + .75*SC2 + .86*SC3\n eatingDisorder =~ .70*ED1 + .65*ED2\n \n # Structural model\n eatingDisorder ~ .37*socialComparison\n socialComparison ~ .23*peerPressure + .41*socialMedia\n \n # Misspecifications\n # within construct\n PP1 ~~ .43*PP2\n # between construct\n SM1 ~~ .53*SC2\n\""
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#sum-scores-vs-latent-scores-1",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#sum-scores-vs-latent-scores-1",
    "title": "Structural Equation Models",
    "section": "Sum scores VS latent scores",
    "text": "Sum scores VS latent scores\nHowever, the debate is still open:\n\nThinking twice about sum scores\n\nThinking thrice about sum scores, and then some more about measurement and analysis\n\nPsychometric properties of sum scores and factor scores differ even when their correlation is 0.98: A response to Widaman and Revelle\n\nOr some more Schimmack:\n\nSchimmack vs Gelman 1\nSchimmack vs Gelman 2"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#the-indifference-of-the-indicator",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#the-indifference-of-the-indicator",
    "title": "Structural Equation Models",
    "section": "The indifference of the indicator",
    "text": "The indifference of the indicator\n\nHow many indicators do we need?\nHow should I select them?\n… LET'S SEE THE ADDITIONAL CODE"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#take-home-3-things",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#take-home-3-things",
    "title": "Structural Equation Models",
    "section": "Take-home: 3 things",
    "text": "Take-home: 3 things\n\nSEM is measurement + structure — structural paths do not rescue poor measurement\n\nTreat fit indices and diagnostics as routine checks (global + local), not as a one-time hurdle\n\nComparing models is scientific: theory → constraints → estimation → evaluation → transparent revision"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#references",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#references",
    "title": "Structural Equation Models",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#model-evaluation",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#model-evaluation",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "4) Model evaluation",
    "text": "4) Model evaluation\nIs the model adequate? Do our parameter generate a theoretical matrix (\\(\\boldsymbol{\\Sigma}\\)) which is close to the empirical covariance matrix \\(\\boldsymbol{S}\\)?\n\nGlobal fit: is the overall model plausible?\nLocal fit: where does the model misfit?\n\n\n\n\nWe’ll do this properly in deck 03. Today: just remember that fit ≠ truth.\n\n\n\nFormally:\n\\[\nH_0 : \\boldsymbol{\\hat{\\Sigma}}(\\theta) = \\boldsymbol{\\Sigma}\n\\]\nwhere \\(\\boldsymbol{\\Sigma}\\) is the true covariance matrix among model variables, \\(\\theta\\) the parameters vector, and \\(\\boldsymbol{\\hat{\\Sigma}}\\) the reproduced covariance matrix."
  },
  {
    "objectID": "slides/02_path-analysis_mediation_equivalence.html#path-analysis",
    "href": "slides/02_path-analysis_mediation_equivalence.html#path-analysis",
    "title": "Path analysis & mediation",
    "section": "Path analysis",
    "text": "Path analysis\nA path model is a set of linear regressions estimated jointly, with an explicit covariance structure and with at least one variable working as mediator.\n\nAs usual, depicting the models is always the best way to understand our models.\n\n\n\nActually, this looks like a full SEM. Why? And why it isn’t, given the way latent variables should be represented?."
  },
  {
    "objectID": "slides/02_path-analysis_mediation_equivalence.html#indirect-effects-are-just-products",
    "href": "slides/02_path-analysis_mediation_equivalence.html#indirect-effects-are-just-products",
    "title": "Path analysis & mediation",
    "section": "Indirect effects are just products",
    "text": "Indirect effects are just products\nThe indirect effect is a product \\((ab)\\). Even if \\((\\hat a)\\) and \\((\\hat b)\\) are approximately normal, the product is not.\nA common large-sample approximation (delta method):\n\\[\n\\mathrm{Var}(\\widehat{ab}) \\approx\nb^2\\mathrm{Var}(\\hat a) + a^2\\mathrm{Var}(\\hat b) + 2ab\\,\\mathrm{Cov}(\\hat a,\\hat b)\n\\]\nSobel test (same idea, historically popular):\n\\[\nz = \\frac{\\widehat{ab}}{\\sqrt{\\widehat{\\mathrm{Var}}(\\widehat{ab})}}\n\\]\n\n\n\nIn practice, bootstrap is often preferred for indirect effects (especially with small–moderate \\(N\\))."
  },
  {
    "objectID": "slides/03_model-fit_diagnostics_respecification.html#quick-example-dataset",
    "href": "slides/03_model-fit_diagnostics_respecification.html#quick-example-dataset",
    "title": "Model fit & diagnostics",
    "section": "Quick example dataset",
    "text": "Quick example dataset\nWe simulate data from a “true” structural model and then fit a simplified (misspecified) model to create misfit.\n\nN &lt;- 483\n\nm_true &lt;- \"\n  lifeSatisfaction ~ .05*attachment + .25*selfEsteem + .40*parentalSupport + .30*salary\n  selfEsteem       ~ .40*parentalSupport + .20*attachment\n  attachment ~~ .30*parentalSupport\n\"\n\nm_fit &lt;- \"\n  lifeSatisfaction ~ selfEsteem + salary     # omits some true predictors\n  selfEsteem       ~ parentalSupport + attachment\n  # attachment ~~ parentalSupport            # (omitted on purpose)\n\"\n\nE2 &lt;- simulateData(m_true, sample.nobs = N, seed = 12)\nfit &lt;- sem(m_fit, data = E2, meanstructure = TRUE)"
  },
  {
    "objectID": "slides/03_model-fit_diagnostics_respecification.html#step-5-model-modification-the-dangerousmagic-step",
    "href": "slides/03_model-fit_diagnostics_respecification.html#step-5-model-modification-the-dangerousmagic-step",
    "title": "Model fit & diagnostics",
    "section": "Step 5: model modification (the dangerous/magic step)",
    "text": "Step 5: model modification (the dangerous/magic step)\n\n\n\nWHERE QRPs HAPPEN\n\n\n\nThe goal is not “better numbers”.\nThe goal is:\n\na model that is more plausible given theory and diagnostics\nchanges that are transparent and ideally replicable"
  },
  {
    "objectID": "slides/03_model-fit_diagnostics_respecification.html#oh-no-my-p-values",
    "href": "slides/03_model-fit_diagnostics_respecification.html#oh-no-my-p-values",
    "title": "Model fit & diagnostics",
    "section": "Oh NO, my p values!",
    "text": "Oh NO, my p values!"
  },
  {
    "objectID": "slides/03_model-fit_diagnostics_respecification.html#modification-indices",
    "href": "slides/03_model-fit_diagnostics_respecification.html#modification-indices",
    "title": "Model fit & diagnostics",
    "section": "Modification indices",
    "text": "Modification indices\nMI approximates how much χ² would decrease if a fixed parameter were freed.\n\nMI is a score test (local improvement)\nit does not tell you the direction/magnitude of the new parameter\n\nSo you inspect MI together with EPC (expected parameter change).\n\nmi &lt;- modificationIndices(fit, sort. = TRUE)\nhead(mi[, c(\"lhs\",\"op\",\"rhs\",\"mi\",\"epc\",\"sepc.all\")], 10)\n\n                lhs op              rhs     mi    epc sepc.all\n19 lifeSatisfaction  ~  parentalSupport 58.234  0.416    0.339\n18 lifeSatisfaction ~~       selfEsteem 52.562 -0.941   -0.880\n27  parentalSupport  ~ lifeSatisfaction 45.077  0.256    0.314\n21       selfEsteem  ~ lifeSatisfaction 33.931 -0.587   -0.620\n20 lifeSatisfaction  ~       attachment  5.473  0.114    0.100\n22       selfEsteem  ~           salary  0.752  0.041    0.037\n32       attachment  ~       selfEsteem  0.556  2.784    3.020\n28  parentalSupport  ~       selfEsteem  0.555 -6.106   -7.100\n24           salary  ~       selfEsteem  0.552  0.028    0.031\n23           salary  ~ lifeSatisfaction  0.524  0.073    0.086"
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#workflow-map",
    "href": "slides/06_robustness_missing_reporting.html#workflow-map",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Workflow map",
    "text": "Workflow map\nSpecify → Identify → Estimate → Evaluate → Report\nToday we practice a sensitivity mindset:\n\nSame model, different reasonable choices → does the conclusion change?"
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#learning-objectives",
    "href": "slides/06_robustness_missing_reporting.html#learning-objectives",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Learning objectives",
    "text": "Learning objectives\nBy the end of today you can:\n\nDistinguish MCAR / MAR / MNAR and what FIML assumes\nExplain what MLR corrects (robust SE + scaled test statistic)\nDecide when bootstrap CIs are needed (and when they’re overkill)\nCombine global + local diagnostics without fishing\nWrite a defensible reporting paragraph"
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#plan-for-today",
    "href": "slides/06_robustness_missing_reporting.html#plan-for-today",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Plan for today",
    "text": "Plan for today\n\nSimulate a “realistic messy” dataset (skewness + MAR missingness)\n\nFit the same SEM under different choices\n\nCompare conclusions (parameters, SE, CIs, fit, local misfit)\n\nTurn results into reporting decisions\n\n\nAdd figure: one pipeline diagram showing “Same model → different estimation choices → compare conclusions”."
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#why-simulate",
    "href": "slides/06_robustness_missing_reporting.html#why-simulate",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Why simulate?",
    "text": "Why simulate?\nReal SEM work is rarely “clean”:\n\nindicators are skewed\nresiduals are non-normal\nmissingness is not random\nindirect effects are asymmetric\n\nWe simulate this so we can see what changes and what doesn’t."
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#setup",
    "href": "slides/06_robustness_missing_reporting.html#setup",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Setup",
    "text": "Setup\n\nlibrary(lavaan)\n\nset.seed(1234)\nN &lt;- 600"
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#population-model-measurement-structural",
    "href": "slides/06_robustness_missing_reporting.html#population-model-measurement-structural",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Population model (measurement + structural)",
    "text": "Population model (measurement + structural)\nA simple measurement-first SEM:\n\npeer pressure → social comparison\n\nsocial media → social comparison\n\nsocial comparison → eating disorder symptoms\n\n\nmodel_pop &lt;- \"\n# Measurement\npeer  =~ 0.80*p1 + 0.70*p2 + 0.60*p3 + 0.70*p4\nmedia =~ 0.70*m1 + 0.80*m2 + 0.60*m3 + 0.70*m4\ncomp  =~ 0.70*c1 + 0.70*c2 + 0.60*c3\neat   =~ 0.70*e1 + 0.60*e2\n\n# Structural\ncomp ~ 0.40*peer + 0.50*media\neat  ~ 0.35*comp\n\"\ndat &lt;- simulateData(model_pop, sample.nobs = N)"
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#make-indicators-skewed",
    "href": "slides/06_robustness_missing_reporting.html#make-indicators-skewed",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Make indicators skewed",
    "text": "Make indicators skewed\nWe “Likert-ify” some indicators by applying a monotone transform (skewness).\n\nskew_vars &lt;- c(\"p1\",\"p2\",\"m1\",\"m2\",\"c1\")\nfor (v in skew_vars) dat[[v]] &lt;- exp(dat[[v]] / 2)"
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#quick-distribution-check",
    "href": "slides/06_robustness_missing_reporting.html#quick-distribution-check",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Quick distribution check",
    "text": "Quick distribution check\n\nhist(dat$p1, main = \"Skewed indicator: p1\", xlab = \"p1\")\n\n\n\nAdd conceptual graphic: normal vs skewed distributions with same mean/variance but different tails."
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#add-heavy-tails-non-normal-residual-behavior",
    "href": "slides/06_robustness_missing_reporting.html#add-heavy-tails-non-normal-residual-behavior",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Add heavy tails (non-normal residual behavior)",
    "text": "Add heavy tails (non-normal residual behavior)\nWe inject a small number of outliers in two indicators (a common real-life pattern).\n\nset.seed(1234)\nix &lt;- sample(seq_len(N), size = round(0.03*N))  # ~3% outliers\ndat$m4[ix] &lt;- dat$m4[ix] + rnorm(length(ix), mean = 0, sd = 4)\ndat$c3[ix] &lt;- dat$c3[ix] + rnorm(length(ix), mean = 0, sd = 4)"
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#a-simple-non-normality-summary-no-extra-packages",
    "href": "slides/06_robustness_missing_reporting.html#a-simple-non-normality-summary-no-extra-packages",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "A simple non-normality summary (no extra packages)",
    "text": "A simple non-normality summary (no extra packages)\n\nskew &lt;- function(x) {\n  x &lt;- x[is.finite(x)]\n  m &lt;- mean(x); s &lt;- sd(x)\n  mean((x - m)^3) / s^3\n}\nkurt_excess &lt;- function(x) {\n  x &lt;- x[is.finite(x)]\n  m &lt;- mean(x); s &lt;- sd(x)\n  mean((x - m)^4) / s^4 - 3\n}\n\nround(c(skew = skew(dat$p1), kurt_excess = kurt_excess(dat$p1)), 2)\n\n       skew kurt_excess \n       2.83       14.79"
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#create-mar-missingness-20",
    "href": "slides/06_robustness_missing_reporting.html#create-mar-missingness-20",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Create MAR missingness (~20%)",
    "text": "Create MAR missingness (~20%)\nMissingness depends on an observed variable (MAR), not on the missing value itself.\nWe make e1 and m3 more likely to be missing when peer pressure is high.\n\nset.seed(1234)\n\n# a proxy observed score for peer (in real life: a sum score, previous wave, etc.)\npeer_obs &lt;- rowMeans(dat[, c(\"p1\",\"p2\",\"p3\",\"p4\")])\n\np_miss &lt;- plogis(scale(peer_obs))            # 0..1\nmiss   &lt;- runif(N) &lt; (p_miss * 0.45)         # tune to ~20%\n\ndat$e1[miss] &lt;- NA\ndat$m3[miss] &lt;- NA\n\nround(colMeans(is.na(dat)), 3)\n\n p1  p2  p3  p4  m1  m2  m3  m4  c1  c2  c3  e1  e2 \n0.0 0.0 0.0 0.0 0.0 0.0 0.2 0.0 0.0 0.0 0.0 0.2 0.0"
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#missingness-what-would-you-check",
    "href": "slides/06_robustness_missing_reporting.html#missingness-what-would-you-check",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Missingness: what would you check?",
    "text": "Missingness: what would you check?\n\n% missing per variable\npatterns (is it concentrated in a subset?)\nassociation between missingness and observed variables (supports MAR plausibility)\n\n\nAdd small schematic: MCAR vs MAR vs MNAR (arrows from observed/unobserved to missingness indicator R)."
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#the-analysis-model-same-model-throughout",
    "href": "slides/06_robustness_missing_reporting.html#the-analysis-model-same-model-throughout",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "The analysis model (same model throughout)",
    "text": "The analysis model (same model throughout)\n\nmodel_sem &lt;- \"\n# Measurement\npeer  =~ p1 + p2 + p3 + p4\nmedia =~ m1 + m2 + m3 + m4\ncomp  =~ c1 + c2 + c3\neat   =~ e1 + e2\n\n# Structural\ncomp ~ peer + media\neat  ~ comp\n\""
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#a-helper-extract-the-same-key-parameters-each-time",
    "href": "slides/06_robustness_missing_reporting.html#a-helper-extract-the-same-key-parameters-each-time",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "A helper: extract the same key parameters each time",
    "text": "A helper: extract the same key parameters each time\nWe track the same hypotheses in every fit:\n\npeer → comp\nmedia → comp\ncomp → eat\n\n\nkey_paths &lt;- function(fit) {\n  pe &lt;- parameterEstimates(fit)\n  pe &lt;- pe[pe$op == \"~\" & pe$lhs %in% c(\"comp\",\"eat\"), ]\n  pe[pe$rhs %in% c(\"peer\",\"media\",\"comp\"),\n     c(\"lhs\",\"op\",\"rhs\",\"est\",\"se\",\"z\",\"pvalue\")]\n}"
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#concepts-technical-but-actionable",
    "href": "slides/06_robustness_missing_reporting.html#concepts-technical-but-actionable",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Concepts (technical, but actionable)",
    "text": "Concepts (technical, but actionable)\n\nMCAR: missingness unrelated to observed/unobserved → listwise unbiased (but inefficient)\nMAR: missingness depends on observed variables → FIML OK (under correct model)\nMNAR: missingness depends on unobserved/missing values → both listwise & FIML can be biased\n\nKey point:\n\nFIML is not “imputation”. It’s likelihood-based estimation using all available cases assuming MAR."
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#fit-1-ml-default-missing-handling-listwise",
    "href": "slides/06_robustness_missing_reporting.html#fit-1-ml-default-missing-handling-listwise",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Fit 1 — ML, default missing handling (listwise)",
    "text": "Fit 1 — ML, default missing handling (listwise)\n\nfit_list &lt;- sem(model_sem, data = dat)  # default: listwise deletion\nfitMeasures(fit_list, c(\"nobs\",\"chisq\",\"df\",\"cfi\",\"tli\",\"rmsea\",\"srmr\"))\n\n chisq     df    cfi    tli  rmsea   srmr \n56.219 61.000  1.000  1.009  0.000  0.030"
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#fit-2-ml-fiml",
    "href": "slides/06_robustness_missing_reporting.html#fit-2-ml-fiml",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Fit 2 — ML + FIML",
    "text": "Fit 2 — ML + FIML\n\nfit_fiml &lt;- sem(model_sem, data = dat, missing = \"fiml\")\nfitMeasures(fit_fiml, c(\"nobs\",\"chisq\",\"df\",\"cfi\",\"tli\",\"rmsea\",\"srmr\"))\n\n chisq     df    cfi    tli  rmsea   srmr \n54.717 61.000  1.000  1.010  0.000  0.027"
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#sensitivity-check-did-the-conclusion-change",
    "href": "slides/06_robustness_missing_reporting.html#sensitivity-check-did-the-conclusion-change",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Sensitivity check: did the conclusion change?",
    "text": "Sensitivity check: did the conclusion change?\n\nrbind(\n  listwise = key_paths(fit_list),\n  fiml     = key_paths(fit_fiml)\n)\n\n             lhs op   rhs   est    se     z pvalue\nlistwise.14 comp  ~  peer 0.362 0.103 3.523  0.000\nlistwise.15 comp  ~ media 0.424 0.093 4.578  0.000\nlistwise.16  eat  ~  comp 0.430 0.125 3.436  0.001\nfiml.14     comp  ~  peer 0.409 0.089 4.592  0.000\nfiml.15     comp  ~ media 0.450 0.085 5.280  0.000\nfiml.16      eat  ~  comp 0.427 0.124 3.442  0.001\n\n\n\n\n\n\n\n\nInterpretation rule of thumb (today)\n\n\nIf your substantive conclusion changes under a reasonable alternative (e.g., listwise → FIML), treat the result as fragile and investigate why."
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#what-mlr-does-the-technical-version",
    "href": "slides/06_robustness_missing_reporting.html#what-mlr-does-the-technical-version",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "What MLR does (the technical version)",
    "text": "What MLR does (the technical version)\nMLR (robust ML) typically:\n\nkeeps similar point estimates\nadjusts standard errors using a “sandwich” (empirical) correction\nreports a scaled test statistic (robust χ²) and robust fit indices\n\nUse case:\n\nnon-normality (skewness, heavy tails)\nmild misspecification\n“psychology-shaped” data"
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#fit-3-mlr-fiml",
    "href": "slides/06_robustness_missing_reporting.html#fit-3-mlr-fiml",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Fit 3 — MLR + FIML",
    "text": "Fit 3 — MLR + FIML\n\nfit_mlr &lt;- sem(model_sem, data = dat,\n               missing = \"fiml\",\n               estimator = \"MLR\")\nfitMeasures(fit_mlr, c(\"nobs\",\"chisq\",\"df\",\"cfi\",\"tli\",\"rmsea\",\"srmr\"))\n\n chisq     df    cfi    tli  rmsea   srmr \n54.717 61.000  1.000  1.010  0.000  0.027"
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#sensitivity-check-do-se-p-values-change",
    "href": "slides/06_robustness_missing_reporting.html#sensitivity-check-do-se-p-values-change",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Sensitivity check: do SE / p-values change?",
    "text": "Sensitivity check: do SE / p-values change?\n\nrbind(\n  fiml_ML  = key_paths(fit_fiml),\n  fiml_MLR = key_paths(fit_mlr)\n)\n\n             lhs op   rhs   est    se     z pvalue\nfiml_ML.14  comp  ~  peer 0.409 0.089 4.592  0.000\nfiml_ML.15  comp  ~ media 0.450 0.085 5.280  0.000\nfiml_ML.16   eat  ~  comp 0.427 0.124 3.442  0.001\nfiml_MLR.14 comp  ~  peer 0.409 0.091 4.496  0.000\nfiml_MLR.15 comp  ~ media 0.450 0.146 3.085  0.002\nfiml_MLR.16  eat  ~  comp 0.427 0.125 3.430  0.001\n\n\n\n\n\n\n\n\nPitfall\n\n\nDon’t mix-and-match reporting: - If you estimate MLR, report robust fit statistics (scaled χ², robust RMSEA/CFI/TLI). - Don’t copy/paste the ML χ² from another run."
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#why-bootstrap-is-special-for-indirect-effects",
    "href": "slides/06_robustness_missing_reporting.html#why-bootstrap-is-special-for-indirect-effects",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Why bootstrap is special for indirect effects",
    "text": "Why bootstrap is special for indirect effects\nIndirect effects are products of coefficients:\n[ ab = a b ]\nEven if (a) and (b) are roughly normal, (ab) is often skewed → normal-theory CIs can be misleading."
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#optional-add-an-indirect-effect-to-the-model",
    "href": "slides/06_robustness_missing_reporting.html#optional-add-an-indirect-effect-to-the-model",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "(Optional) Add an indirect effect to the model",
    "text": "(Optional) Add an indirect effect to the model\n\nmodel_sem_ind &lt;- paste0(model_sem, \"\\n\\n# Indirect effect\\nind_peer := (comp~peer)*(eat~comp)\\n\")\n\n\nIf lavaan complains about label reuse depending on version, label paths explicitly (a* and b) and redefine ind := ab."
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#fit-4-bootstrap-seci-keep-small-for-live-teaching",
    "href": "slides/06_robustness_missing_reporting.html#fit-4-bootstrap-seci-keep-small-for-live-teaching",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Fit 4 — Bootstrap SE/CI (keep small for live teaching)",
    "text": "Fit 4 — Bootstrap SE/CI (keep small for live teaching)\nFor live demos keep bootstrap modest (e.g., 300–800).\nFor papers, use ~2000+.\n\nfit_boot &lt;- sem(model_sem, data = dat,\n                missing = \"fiml\",\n                se = \"bootstrap\",\n                bootstrap = 500)"
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#compare-ci-for-key-paths-normal-vs-bootstrap",
    "href": "slides/06_robustness_missing_reporting.html#compare-ci-for-key-paths-normal-vs-bootstrap",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Compare CI for key paths (normal vs bootstrap)",
    "text": "Compare CI for key paths (normal vs bootstrap)\n\npe_norm &lt;- parameterEstimates(fit_fiml, ci = TRUE)\npe_boot &lt;- parameterEstimates(fit_boot, ci = TRUE, boot.ci.type = \"perc\")\n\nsel &lt;- function(pe) {\n  pe[pe$op == \"~\" & pe$lhs %in% c(\"comp\",\"eat\") &\n       pe$rhs %in% c(\"peer\",\"media\",\"comp\"),\n     c(\"lhs\",\"op\",\"rhs\",\"est\",\"ci.lower\",\"ci.upper\")]\n}\n\nlist(\n  normal_CI = sel(pe_norm),\n  boot_CI   = sel(pe_boot)\n)\n\n$normal_CI\n    lhs op   rhs   est ci.lower ci.upper\n14 comp  ~  peer 0.409    0.235    0.584\n15 comp  ~ media 0.450    0.283    0.616\n16  eat  ~  comp 0.427    0.184    0.670\n\n$boot_CI\n    lhs op   rhs   est ci.lower ci.upper\n14 comp  ~  peer 0.409    0.236    0.601\n15 comp  ~ media 0.450    0.242    0.801\n16  eat  ~  comp 0.427    0.188    0.692\n\n\n\n\n\n\n\n\nDecision heuristic (today)\n\n\nBootstrap is most valuable when: - your target parameter is a product (indirect effects), - distributions are skewed / small N, - normal CIs would be suspect."
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#global-fit-quick-recap",
    "href": "slides/06_robustness_missing_reporting.html#global-fit-quick-recap",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Global fit (quick recap)",
    "text": "Global fit (quick recap)\nGlobal fit indices summarize average discrepancy:\n\nχ² (sample-size sensitive)\nCFI/TLI (incremental)\nRMSEA (+ CI; small df behavior)\nSRMR (residual-based)\n\nBut:\n\nGood global fit does not guarantee good measurement or correct structure."
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#local-fit-residuals-and-mi",
    "href": "slides/06_robustness_missing_reporting.html#local-fit-residuals-and-mi",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Local fit: residuals and MI",
    "text": "Local fit: residuals and MI\n\n# Residual correlations (a small block)\nresid(fit_mlr, type = \"cor\")$cov[1:6, 1:6]\n\n              p1            p2           p3            p4            m1\np1 -2.220446e-16  2.260205e-02 -0.027764125 -1.156267e-02 -5.688705e-02\np2  2.260205e-02  2.220446e-16  0.008962091 -1.205551e-02  3.437288e-03\np3 -2.776412e-02  8.962091e-03  0.000000000  2.145905e-02 -1.029635e-02\np4 -1.156267e-02 -1.205551e-02  0.021459052 -1.110223e-16  3.037465e-02\nm1 -5.688705e-02  3.437288e-03 -0.010296345  3.037465e-02  2.220446e-16\nm2  1.572566e-02  3.943457e-02  0.010333999 -2.492806e-02  1.005055e-02\n            m2\np1  0.01572566\np2  0.03943457\np3  0.01033400\np4 -0.02492806\nm1  0.01005055\nm2  0.00000000\n\n\n\nmodificationIndices(fit_mlr, sort. = TRUE)[1:10, c(\"lhs\",\"op\",\"rhs\",\"mi\",\"epc\")]\n\n     lhs op rhs    mi    epc\n132   p4 ~~  e2 4.658  0.116\n147   m2 ~~  e2 4.044 -0.074\n94    p1 ~~  m1 3.794 -0.047\n84   eat =~  m1 3.541  0.124\n109   p2 ~~  c1 3.434 -0.042\n125   p4 ~~  m2 3.237 -0.064\n85   eat =~  m2 3.024 -0.113\n56  peer =~  c1 2.961 -0.207\n96    p1 ~~  m3 2.841 -0.061\n101   p1 ~~  e1 2.573  0.065\n\n\n\nAdd schematic: “CFI looks fine” but highlight a single large residual correlation and its substantive interpretation."
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#a-disciplined-respecification-rule",
    "href": "slides/06_robustness_missing_reporting.html#a-disciplined-respecification-rule",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "A disciplined respecification rule",
    "text": "A disciplined respecification rule\nOnly consider modifications that are:\n\ntheoretically defensible\n\nconsistent with measurement-first logic\n\nreported transparently (what was changed and why)\n\n\n\n\n\n\n\nPitfall: “MI shopping”\n\n\nIf you add correlated errors because they “fix RMSEA”, you can end up fitting noise."
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#what-you-must-report-minimum",
    "href": "slides/06_robustness_missing_reporting.html#what-you-must-report-minimum",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "What you must report (minimum)",
    "text": "What you must report (minimum)\n\nModel specification (measurement + structural)\nEstimator (ML / MLR / DWLS / ULS / …)\nMissing data handling (listwise / FIML / …) + assumption (MAR)\nχ²(df), p (robust/scaled if applicable)\nCFI, TLI, RMSEA (+ CI), SRMR\nAny respecifications (with theory rationale)\nIf bootstrap: type + number of draws + CI type"
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#example-reporting-paragraph-template",
    "href": "slides/06_robustness_missing_reporting.html#example-reporting-paragraph-template",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Example reporting paragraph (template)",
    "text": "Example reporting paragraph (template)\n\nThe SEM was estimated in lavaan using robust maximum likelihood (MLR) with FIML for missing data under a MAR assumption. Model fit was evaluated using the scaled χ² test and robust fit indices (CFI, TLI, RMSEA with 90% CI, SRMR). Key parameters were interpreted based on standardized estimates and robust standard errors. Where relevant, confidence intervals were obtained via bootstrap percentile CIs (B = 500 for teaching; ≥ 2000 for publication)."
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#take-home-the-sensitivity-mindset",
    "href": "slides/06_robustness_missing_reporting.html#take-home-the-sensitivity-mindset",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Take-home: the sensitivity mindset",
    "text": "Take-home: the sensitivity mindset\nFor any important claim, ask:\n\nDoes it survive FIML vs listwise?\nDoes it survive ML vs MLR?\nDoes it survive bootstrap vs normal CI (when relevant)?\nDoes it survive local diagnostics (residuals/MI)?\n\nIf not, don’t panic—learn what the data are telling you."
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#exercises-lab-6",
    "href": "slides/06_robustness_missing_reporting.html#exercises-lab-6",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Exercises → Lab 6",
    "text": "Exercises → Lab 6\nIn the lab you will:\n\nIncrease missingness to ~40% and re-run the sensitivity checks\n\nSimulate MNAR and compare to MAR\n\nIdentify 1–2 large MIs, justify (or reject) a modification\n\nWrite a short “Methods + Results” reporting paragraph\n\n\nLink placeholder: add a direct link to /labs/06_robustness_lab.qmd once created."
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#things-to-remember",
    "href": "slides/06_robustness_missing_reporting.html#things-to-remember",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "3 things to remember",
    "text": "3 things to remember\n\nMissing data handling can change conclusions — check sensitivity\n\nRobust SE protect against inflated significance — don’t trust ML by default\n\nFit indices are diagnostics, not verdicts — always check local fit"
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#further-reading-optional",
    "href": "slides/06_robustness_missing_reporting.html#further-reading-optional",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Further reading (optional)",
    "text": "Further reading (optional)\n\nMissing data in SEM (FIML, MAR assumptions)\nRobust estimation (MLR/MLM and non-normality)\nBootstrap inference for indirect effects\nReporting standards for SEM in psychology\n\n\nAdd 2–3 concrete citations once we confirm keys in refs/references.bib."
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#references",
    "href": "slides/06_robustness_missing_reporting.html#references",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#workflow-map",
    "href": "slides/06_missing-data_robustness_reporting.html#workflow-map",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Workflow map",
    "text": "Workflow map"
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#learning-objectives",
    "href": "slides/06_missing-data_robustness_reporting.html#learning-objectives",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Learning objectives",
    "text": "Learning objectives\nBy the end of today you can:\n\nDistinguish MCAR / MAR / MNAR and what FIML assumes\nExplain what MLR corrects (robust SE + scaled test statistic)\nDecide when bootstrap CIs are needed (and when they’re overkill)\nCombine global + local diagnostics without fishing\nWrite a defensible reporting paragraph"
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#plan-for-today",
    "href": "slides/06_missing-data_robustness_reporting.html#plan-for-today",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Plan for today",
    "text": "Plan for today\n\nSimulate a “realistic messy” dataset (skewness + MAR missingness)\n\nFit the same SEM under different choices\n\nCompare conclusions (parameters, SE, CIs, fit, local misfit)\n\nTurn results into reporting decisions\n\n\nAdd figure: one pipeline diagram showing “Same model → different estimation choices → compare conclusions”."
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#why-simulate",
    "href": "slides/06_missing-data_robustness_reporting.html#why-simulate",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Why simulate?",
    "text": "Why simulate?\nReal SEM work is rarely “clean”:\n\nindicators are skewed\nresiduals are non-normal\nmissingness is not random\nindirect effects are asymmetric\n\nWe simulate this so we can see what changes and what doesn’t."
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#setup",
    "href": "slides/06_missing-data_robustness_reporting.html#setup",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Setup",
    "text": "Setup\n\nlibrary(lavaan)\n\nset.seed(1234)\nN &lt;- 600"
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#population-model-measurement-structural",
    "href": "slides/06_missing-data_robustness_reporting.html#population-model-measurement-structural",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Population model (measurement + structural)",
    "text": "Population model (measurement + structural)\nA simple measurement-first SEM:\n\npeer pressure → social comparison\n\nsocial media → social comparison\n\nsocial comparison → eating disorder symptoms\n\n\nmodel_pop &lt;- \"\n# Measurement\npeer  =~ 0.80*p1 + 0.70*p2 + 0.60*p3 + 0.70*p4\nmedia =~ 0.70*m1 + 0.80*m2 + 0.60*m3 + 0.70*m4\ncomp  =~ 0.70*c1 + 0.70*c2 + 0.60*c3\neat   =~ 0.70*e1 + 0.60*e2\n\n# Structural\ncomp ~ 0.40*peer + 0.50*media\neat  ~ 0.35*comp\n\"\ndat &lt;- simulateData(model_pop, sample.nobs = N)"
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#make-indicators-skewed",
    "href": "slides/06_missing-data_robustness_reporting.html#make-indicators-skewed",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Make indicators skewed",
    "text": "Make indicators skewed\nWe “Likert-ify” some indicators by applying a monotone transform (skewness).\n\nskew_vars &lt;- c(\"p1\",\"p2\",\"m1\",\"m2\",\"c1\")\nfor (v in skew_vars) dat[[v]] &lt;- exp(dat[[v]] / 2)"
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#quick-distribution-check",
    "href": "slides/06_missing-data_robustness_reporting.html#quick-distribution-check",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Quick distribution check",
    "text": "Quick distribution check\n\nhist(dat$p1, main = \"Skewed indicator: p1\", xlab = \"p1\")\n\n\n\nAdd conceptual graphic: normal vs skewed distributions with same mean/variance but different tails."
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#add-heavy-tails-non-normal-residual-behavior",
    "href": "slides/06_missing-data_robustness_reporting.html#add-heavy-tails-non-normal-residual-behavior",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Add heavy tails (non-normal residual behavior)",
    "text": "Add heavy tails (non-normal residual behavior)\nWe inject a small number of outliers in two indicators (a common real-life pattern).\n\nset.seed(1234)\nix &lt;- sample(seq_len(N), size = round(0.03*N))  # ~3% outliers\ndat$m4[ix] &lt;- dat$m4[ix] + rnorm(length(ix), mean = 0, sd = 4)\ndat$c3[ix] &lt;- dat$c3[ix] + rnorm(length(ix), mean = 0, sd = 4)"
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#a-simple-non-normality-summary-no-extra-packages",
    "href": "slides/06_missing-data_robustness_reporting.html#a-simple-non-normality-summary-no-extra-packages",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "A simple non-normality summary (no extra packages)",
    "text": "A simple non-normality summary (no extra packages)\n\nskew &lt;- function(x) {\n  x &lt;- x[is.finite(x)]\n  m &lt;- mean(x); s &lt;- sd(x)\n  mean((x - m)^3) / s^3\n}\nkurt_excess &lt;- function(x) {\n  x &lt;- x[is.finite(x)]\n  m &lt;- mean(x); s &lt;- sd(x)\n  mean((x - m)^4) / s^4 - 3\n}\n\nround(c(skew = skew(dat$p1), kurt_excess = kurt_excess(dat$p1)), 2)\n\n       skew kurt_excess \n       2.83       14.79"
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#create-mar-missingness-20",
    "href": "slides/06_missing-data_robustness_reporting.html#create-mar-missingness-20",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Create MAR missingness (~20%)",
    "text": "Create MAR missingness (~20%)\nMissingness depends on an observed variable (MAR), not on the missing value itself.\nWe make e1 and m3 more likely to be missing when peer pressure is high.\n\nset.seed(1234)\n\n# a proxy observed score for peer (in real life: a sum score, previous wave, etc.)\npeer_obs &lt;- rowMeans(dat[, c(\"p1\",\"p2\",\"p3\",\"p4\")])\n\np_miss &lt;- plogis(scale(peer_obs))            # 0..1\nmiss   &lt;- runif(N) &lt; (p_miss * 0.45)         # tune to ~20%\n\ndat$e1[miss] &lt;- NA\ndat$m3[miss] &lt;- NA\n\nround(colMeans(is.na(dat)), 3)\n\n p1  p2  p3  p4  m1  m2  m3  m4  c1  c2  c3  e1  e2 \n0.0 0.0 0.0 0.0 0.0 0.0 0.2 0.0 0.0 0.0 0.0 0.2 0.0"
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#missingness-what-would-you-check",
    "href": "slides/06_missing-data_robustness_reporting.html#missingness-what-would-you-check",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Missingness: what would you check?",
    "text": "Missingness: what would you check?\n\n% missing per variable\npatterns (is it concentrated in a subset?)\nassociation between missingness and observed variables (supports MAR plausibility)\n\n\nAdd small schematic: MCAR vs MAR vs MNAR (arrows from observed/unobserved to missingness indicator R)."
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#the-analysis-model-same-model-throughout",
    "href": "slides/06_missing-data_robustness_reporting.html#the-analysis-model-same-model-throughout",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "The analysis model (same model throughout)",
    "text": "The analysis model (same model throughout)\n\nmodel_sem &lt;- \"\n# Measurement\npeer  =~ p1 + p2 + p3 + p4\nmedia =~ m1 + m2 + m3 + m4\ncomp  =~ c1 + c2 + c3\neat   =~ e1 + e2\n\n# Structural\ncomp ~ peer + media\neat  ~ comp\n\""
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#a-helper-extract-the-same-key-parameters-each-time",
    "href": "slides/06_missing-data_robustness_reporting.html#a-helper-extract-the-same-key-parameters-each-time",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "A helper: extract the same key parameters each time",
    "text": "A helper: extract the same key parameters each time\nWe track the same hypotheses in every fit:\n\npeer → comp\nmedia → comp\ncomp → eat\n\n\nkey_paths &lt;- function(fit) {\n  pe &lt;- parameterEstimates(fit)\n  pe &lt;- pe[pe$op == \"~\" & pe$lhs %in% c(\"comp\",\"eat\"), ]\n  pe[pe$rhs %in% c(\"peer\",\"media\",\"comp\"),\n     c(\"lhs\",\"op\",\"rhs\",\"est\",\"se\",\"z\",\"pvalue\")]\n}"
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#concepts-technical-but-actionable",
    "href": "slides/06_missing-data_robustness_reporting.html#concepts-technical-but-actionable",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Concepts (technical, but actionable)",
    "text": "Concepts (technical, but actionable)\n\nMCAR: missingness unrelated to observed/unobserved → listwise unbiased (but inefficient)\nMAR: missingness depends on observed variables → FIML OK (under correct model)\nMNAR: missingness depends on unobserved/missing values → both listwise & FIML can be biased\n\nKey point:\n\nFIML is not “imputation”. It’s likelihood-based estimation using all available cases assuming MAR."
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#fit-1-ml-default-missing-handling-listwise",
    "href": "slides/06_missing-data_robustness_reporting.html#fit-1-ml-default-missing-handling-listwise",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Fit 1 — ML, default missing handling (listwise)",
    "text": "Fit 1 — ML, default missing handling (listwise)\n\nfit_list &lt;- sem(model_sem, data = dat)  # default: listwise deletion\nfitMeasures(fit_list, c(\"nobs\",\"chisq\",\"df\",\"cfi\",\"tli\",\"rmsea\",\"srmr\"))\n\n chisq     df    cfi    tli  rmsea   srmr \n56.219 61.000  1.000  1.009  0.000  0.030"
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#fit-2-ml-fiml",
    "href": "slides/06_missing-data_robustness_reporting.html#fit-2-ml-fiml",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Fit 2 — ML + FIML",
    "text": "Fit 2 — ML + FIML\n\nfit_fiml &lt;- sem(model_sem, data = dat, missing = \"fiml\")\nfitMeasures(fit_fiml, c(\"nobs\",\"chisq\",\"df\",\"cfi\",\"tli\",\"rmsea\",\"srmr\"))\n\n chisq     df    cfi    tli  rmsea   srmr \n54.717 61.000  1.000  1.010  0.000  0.027"
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#sensitivity-check-did-the-conclusion-change",
    "href": "slides/06_missing-data_robustness_reporting.html#sensitivity-check-did-the-conclusion-change",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Sensitivity check: did the conclusion change?",
    "text": "Sensitivity check: did the conclusion change?\n\nrbind(\n  listwise = key_paths(fit_list),\n  fiml     = key_paths(fit_fiml)\n)\n\n             lhs op   rhs   est    se     z pvalue\nlistwise.14 comp  ~  peer 0.362 0.103 3.523  0.000\nlistwise.15 comp  ~ media 0.424 0.093 4.578  0.000\nlistwise.16  eat  ~  comp 0.430 0.125 3.436  0.001\nfiml.14     comp  ~  peer 0.409 0.089 4.592  0.000\nfiml.15     comp  ~ media 0.450 0.085 5.280  0.000\nfiml.16      eat  ~  comp 0.427 0.124 3.442  0.001\n\n\n\n\n\n\n\n\nInterpretation rule of thumb (today)\n\n\nIf your substantive conclusion changes under a reasonable alternative (e.g., listwise → FIML), treat the result as fragile and investigate why."
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#what-mlr-does-the-technical-version",
    "href": "slides/06_missing-data_robustness_reporting.html#what-mlr-does-the-technical-version",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "What MLR does (the technical version)",
    "text": "What MLR does (the technical version)\nMLR (robust ML) typically:\n\nkeeps similar point estimates\nadjusts standard errors using a “sandwich” (empirical) correction\nreports a scaled test statistic (robust χ²) and robust fit indices\n\nUse case:\n\nnon-normality (skewness, heavy tails)\nmild misspecification\n“psychology-shaped” data"
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#fit-3-mlr-fiml",
    "href": "slides/06_missing-data_robustness_reporting.html#fit-3-mlr-fiml",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Fit 3 — MLR + FIML",
    "text": "Fit 3 — MLR + FIML\n\nfit_mlr &lt;- sem(model_sem, data = dat,\n               missing = \"fiml\",\n               estimator = \"MLR\")\nfitMeasures(fit_mlr, c(\"nobs\",\"chisq\",\"df\",\"cfi\",\"tli\",\"rmsea\",\"srmr\"))\n\n chisq     df    cfi    tli  rmsea   srmr \n54.717 61.000  1.000  1.010  0.000  0.027"
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#sensitivity-check-do-se-p-values-change",
    "href": "slides/06_missing-data_robustness_reporting.html#sensitivity-check-do-se-p-values-change",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Sensitivity check: do SE / p-values change?",
    "text": "Sensitivity check: do SE / p-values change?\n\nrbind(\n  fiml_ML  = key_paths(fit_fiml),\n  fiml_MLR = key_paths(fit_mlr)\n)\n\n             lhs op   rhs   est    se     z pvalue\nfiml_ML.14  comp  ~  peer 0.409 0.089 4.592  0.000\nfiml_ML.15  comp  ~ media 0.450 0.085 5.280  0.000\nfiml_ML.16   eat  ~  comp 0.427 0.124 3.442  0.001\nfiml_MLR.14 comp  ~  peer 0.409 0.091 4.496  0.000\nfiml_MLR.15 comp  ~ media 0.450 0.146 3.085  0.002\nfiml_MLR.16  eat  ~  comp 0.427 0.125 3.430  0.001\n\n\n\n\n\n\n\n\nPitfall\n\n\nDon’t mix-and-match reporting: - If you estimate MLR, report robust fit statistics (scaled χ², robust RMSEA/CFI/TLI). - Don’t copy/paste the ML χ² from another run."
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#why-bootstrap-is-special-for-indirect-effects",
    "href": "slides/06_missing-data_robustness_reporting.html#why-bootstrap-is-special-for-indirect-effects",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Why bootstrap is special for indirect effects",
    "text": "Why bootstrap is special for indirect effects\nIndirect effects are products of coefficients:\n\\(ab = a \\times b\\)\nEven if \\((a)\\) and \\((b)\\) are roughly normal, \\((ab)\\) is often skewed → normal-theory CIs can be misleading."
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#optional-add-an-indirect-effect-to-the-model",
    "href": "slides/06_missing-data_robustness_reporting.html#optional-add-an-indirect-effect-to-the-model",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "(Optional) Add an indirect effect to the model",
    "text": "(Optional) Add an indirect effect to the model\n\nmodel_sem_ind &lt;- paste0(model_sem, \"\\n\\n# Indirect effect\\nind_peer := (comp~peer)*(eat~comp)\\n\")\n\n\nIf lavaan complains about label reuse depending on version, label paths explicitly (a* and b) and redefine ind := ab."
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#fit-4-bootstrap-seci-keep-small-for-live-teaching",
    "href": "slides/06_missing-data_robustness_reporting.html#fit-4-bootstrap-seci-keep-small-for-live-teaching",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Fit 4 — Bootstrap SE/CI (keep small for live teaching)",
    "text": "Fit 4 — Bootstrap SE/CI (keep small for live teaching)\nFor live demos keep bootstrap modest (e.g., 300–800).\nFor papers, use ~2000+.\n\nfit_boot &lt;- sem(model_sem, data = dat,\n                missing = \"fiml\",\n                se = \"bootstrap\",\n                bootstrap = 500)"
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#compare-ci-for-key-paths-normal-vs-bootstrap",
    "href": "slides/06_missing-data_robustness_reporting.html#compare-ci-for-key-paths-normal-vs-bootstrap",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Compare CI for key paths (normal vs bootstrap)",
    "text": "Compare CI for key paths (normal vs bootstrap)\n\npe_norm &lt;- parameterEstimates(fit_fiml, ci = TRUE)\npe_boot &lt;- parameterEstimates(fit_boot, ci = TRUE, boot.ci.type = \"perc\")\n\nsel &lt;- function(pe) {\n  pe[pe$op == \"~\" & pe$lhs %in% c(\"comp\",\"eat\") &\n       pe$rhs %in% c(\"peer\",\"media\",\"comp\"),\n     c(\"lhs\",\"op\",\"rhs\",\"est\",\"ci.lower\",\"ci.upper\")]\n}\n\nlist(\n  normal_CI = sel(pe_norm),\n  boot_CI   = sel(pe_boot)\n)\n\n$normal_CI\n    lhs op   rhs   est ci.lower ci.upper\n14 comp  ~  peer 0.409    0.235    0.584\n15 comp  ~ media 0.450    0.283    0.616\n16  eat  ~  comp 0.427    0.184    0.670\n\n$boot_CI\n    lhs op   rhs   est ci.lower ci.upper\n14 comp  ~  peer 0.409    0.236    0.601\n15 comp  ~ media 0.450    0.242    0.801\n16  eat  ~  comp 0.427    0.188    0.692\n\n\n\n\n\n\n\n\nDecision heuristic (today)\n\n\nBootstrap is most valuable when: - your target parameter is a product (indirect effects), - distributions are skewed / small N, - normal CIs would be suspect."
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#global-fit-quick-recap",
    "href": "slides/06_missing-data_robustness_reporting.html#global-fit-quick-recap",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Global fit (quick recap)",
    "text": "Global fit (quick recap)\nGlobal fit indices summarize average discrepancy:\n\nχ² (sample-size sensitive)\nCFI/TLI (incremental)\nRMSEA (+ CI; small df behavior)\nSRMR (residual-based)\n\nBut:\n\nGood global fit does not guarantee good measurement or correct structure."
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#local-fit-residuals-and-mi",
    "href": "slides/06_missing-data_robustness_reporting.html#local-fit-residuals-and-mi",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Local fit: residuals and MI",
    "text": "Local fit: residuals and MI\n\n# Residual correlations (a small block)\nresid(fit_mlr, type = \"cor\")$cov[1:6, 1:6]\n\n              p1            p2           p3            p4            m1\np1 -2.220446e-16  2.260205e-02 -0.027764125 -1.156267e-02 -5.688705e-02\np2  2.260205e-02  2.220446e-16  0.008962091 -1.205551e-02  3.437288e-03\np3 -2.776412e-02  8.962091e-03  0.000000000  2.145905e-02 -1.029635e-02\np4 -1.156267e-02 -1.205551e-02  0.021459052 -1.110223e-16  3.037465e-02\nm1 -5.688705e-02  3.437288e-03 -0.010296345  3.037465e-02  2.220446e-16\nm2  1.572566e-02  3.943457e-02  0.010333999 -2.492806e-02  1.005055e-02\n            m2\np1  0.01572566\np2  0.03943457\np3  0.01033400\np4 -0.02492806\nm1  0.01005055\nm2  0.00000000\n\n\n\nmodificationIndices(fit_mlr, sort. = TRUE)[1:10, c(\"lhs\",\"op\",\"rhs\",\"mi\",\"epc\")]\n\n     lhs op rhs    mi    epc\n132   p4 ~~  e2 4.658  0.116\n147   m2 ~~  e2 4.044 -0.074\n94    p1 ~~  m1 3.794 -0.047\n84   eat =~  m1 3.541  0.124\n109   p2 ~~  c1 3.434 -0.042\n125   p4 ~~  m2 3.237 -0.064\n85   eat =~  m2 3.024 -0.113\n56  peer =~  c1 2.961 -0.207\n96    p1 ~~  m3 2.841 -0.061\n101   p1 ~~  e1 2.573  0.065\n\n\n\nAdd schematic: “CFI looks fine” but highlight a single large residual correlation and its substantive interpretation."
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#a-disciplined-respecification-rule",
    "href": "slides/06_missing-data_robustness_reporting.html#a-disciplined-respecification-rule",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "A disciplined respecification rule",
    "text": "A disciplined respecification rule\nOnly consider modifications that are:\n\ntheoretically defensible\n\nconsistent with measurement-first logic\n\nreported transparently (what was changed and why)\n\n\n\n\n\n\n\nPitfall: “MI shopping”\n\n\nIf you add correlated errors because they “fix RMSEA”, you can end up fitting noise."
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#what-you-must-report-minimum",
    "href": "slides/06_missing-data_robustness_reporting.html#what-you-must-report-minimum",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "What you must report (minimum)",
    "text": "What you must report (minimum)\n\nModel specification (measurement + structural)\nEstimator (ML / MLR / DWLS / ULS / …)\nMissing data handling (listwise / FIML / …) + assumption (MAR)\nχ²(df), p (robust/scaled if applicable)\nCFI, TLI, RMSEA (+ CI), SRMR\nAny respecifications (with theory rationale)\nIf bootstrap: type + number of draws + CI type"
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#example-reporting-paragraph-template",
    "href": "slides/06_missing-data_robustness_reporting.html#example-reporting-paragraph-template",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Example reporting paragraph (template)",
    "text": "Example reporting paragraph (template)\n\nThe SEM was estimated in lavaan using robust maximum likelihood (MLR) with FIML for missing data under a MAR assumption. Model fit was evaluated using the scaled χ² test and robust fit indices (CFI, TLI, RMSEA with 90% CI, SRMR). Key parameters were interpreted based on standardized estimates and robust standard errors. Where relevant, confidence intervals were obtained via bootstrap percentile CIs (B = 500 for teaching; ≥ 2000 for publication)."
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#take-home-the-sensitivity-mindset",
    "href": "slides/06_missing-data_robustness_reporting.html#take-home-the-sensitivity-mindset",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Take-home: the sensitivity mindset",
    "text": "Take-home: the sensitivity mindset\nFor any important claim, ask:\n\nDoes it survive FIML vs listwise?\nDoes it survive ML vs MLR?\nDoes it survive bootstrap vs normal CI (when relevant)?\nDoes it survive local diagnostics (residuals/MI)?\n\nIf not, don’t panic—learn what the data are telling you."
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#exercises-lab-6",
    "href": "slides/06_missing-data_robustness_reporting.html#exercises-lab-6",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Exercises → Lab 6",
    "text": "Exercises → Lab 6\nIn the lab you will:\n\nIncrease missingness to ~40% and re-run the sensitivity checks\n\nSimulate MNAR and compare to MAR\n\nIdentify 1–2 large MIs, justify (or reject) a modification\n\nWrite a short “Methods + Results” reporting paragraph\n\n\nLink placeholder: add a direct link to /labs/06_robustness_lab.qmd once created."
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#things-to-remember",
    "href": "slides/06_missing-data_robustness_reporting.html#things-to-remember",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "3 things to remember",
    "text": "3 things to remember\n\nMissing data handling can change conclusions — check sensitivity\n\nRobust SE protect against inflated significance — don’t trust ML by default\n\nFit indices are diagnostics, not verdicts — always check local fit"
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#further-reading-optional",
    "href": "slides/06_missing-data_robustness_reporting.html#further-reading-optional",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Further reading (optional)",
    "text": "Further reading (optional)\n\nMissing data in SEM (FIML, MAR assumptions)\nRobust estimation (MLR/MLM and non-normality)\nBootstrap inference for indirect effects\nReporting standards for SEM in psychology\n\n\nAdd 2–3 concrete citations once we confirm keys in refs/references.bib."
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#references",
    "href": "slides/06_missing-data_robustness_reporting.html#references",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#today",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#today",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Today",
    "text": "Today\n\nWhy measurement invariance is a prerequisite for group comparisons\nThe MG-CFA ladder (configural → metric → scalar → strict)\nHow to evaluate invariance (Δ fit + local diagnostics)\nPartial invariance: what to free, how to justify it\n(Briefly) structural invariance: variances/covariances/means\n\n\n\n\n\n\n\nTip\n\n\nKeep one “workflow map” slide that reappears in every deck."
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#workflow-map-where-we-are",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#workflow-map-where-we-are",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Workflow map (where we are)",
    "text": "Workflow map (where we are)\nSpecify → Identify → Estimate → Evaluate → Revise / Report\nToday we focus on:\n\nEvaluate: “Does the same measurement model hold across groups?”\nReport: “What level of invariance supports which claims?”"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#learning-objectives",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#learning-objectives",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Learning objectives",
    "text": "Learning objectives\nBy the end of this lesson you can:\n\nExplain configural / metric / scalar / strict invariance in plain language\nFit MG-CFA models in lavaan using group.equal\nCompare nested models using ΔCFI / ΔRMSEA / Δχ² (and know the limits)\nUse score tests / modification indices to diagnose non-invariance\nImplement partial invariance via group.partial\nState which inferences are valid under each invariance level"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#a-hot-topic",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#a-hot-topic",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "A hot topic",
    "text": "A hot topic"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#introduction",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#introduction",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Introduction",
    "text": "Introduction"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#the-importance-of-measurement-invariance",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#the-importance-of-measurement-invariance",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "The importance of Measurement Invariance",
    "text": "The importance of Measurement Invariance\n\nResearchers often compare groups on psychological constructs, assuming instruments measure the same latent variables across groups.\nThis assumption is often untested.\nMeasurement invariance is a prerequisite for meaningful comparisons across groups (and across time)."
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#invariance-of-a-structural-equation-model",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#invariance-of-a-structural-equation-model",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Invariance of a Structural Equation Model",
    "text": "Invariance of a Structural Equation Model\nMore generally, testing invariance evaluates to what extent a hypothesized SEM can be considered invariant (same parameters) across groups.\nInvariance is commonly used for comparisons across:\n\ngender\nage groups\nclinical vs non-clinical\nculture / language / nationality\ntime (longitudinal invariance)"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#some-applications",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#some-applications",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "(Some) applications",
    "text": "(Some) applications\nInvariance is commonly used for comparisons across:\n\ngender\nage groups\nclinical vs non-clinical\nculture / language / nationality\ntime (longitudinal invariance)"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#assessing-invariance-the-multi-group-analysis",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#assessing-invariance-the-multi-group-analysis",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Assessing invariance: the multi-group analysis",
    "text": "Assessing invariance: the multi-group analysis\n\nMulti-group analysis is the most widely used method to assess invariance.\nIn this lesson we focus on CFA models (MG-CFA).\nLogic: estimate the same model in multiple groups, then add equality constraints and check what breaks."
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#the-starting-point-mg-cfa",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#the-starting-point-mg-cfa",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "The starting point (MG-CFA)",
    "text": "The starting point (MG-CFA)"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#the-idea-constraints-ladder",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#the-idea-constraints-ladder",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "The idea (constraints ladder)",
    "text": "The idea (constraints ladder)\n\nStart with the same model in all groups (baseline: all structural parameters are free to vary across groups)\n\nAdd constraints (more restrictive models: loadings, intercepts, residual variances, … fixed to be equal)\n\nCompare fit: does the constraint produce a meaningful worsening?"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#invariance-steps-measurement-ladder",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#invariance-steps-measurement-ladder",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Invariance steps (measurement ladder)",
    "text": "Invariance steps (measurement ladder)\n\nConfigural: same factor structure (same “form”)\nMetric / weak: equal loadings (Λ)\nScalar / strong: equal intercepts (τ)\nStrict: equal residual variances (Θ)\n\n\nScalar invariance (full or partial) is the gateway to latent mean comparisons."
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#what-level-do-you-need-for-which-claim",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#what-level-do-you-need-for-which-claim",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "What level do you need for which claim?",
    "text": "What level do you need for which claim?\n\n\n\n\n\n\n\nClaim / Comparison\nMinimum invariance\n\n\n\n\nSame factor structure (same “form”)\nConfigural\n\n\nCompare relations (regressions/correlations)\nMetric (often)\n\n\nCompare latent means\nScalar (often partial scalar)\n\n\nCompare observed means directly\nNot recommended without invariance evidence"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#step-by-step-guide-summary",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#step-by-step-guide-summary",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Step-by-step guide (summary)",
    "text": "Step-by-step guide (summary)\n\n\n\n\n\n\n\n\n\nStep\nModel\nConstrain\nCompare to\n\n\n\n\n0\nSeparate CFAs\n—\n—\n\n\n1\nConfigural\n—\n—\n\n\n2\nMetric\nloadings\nconfigural\n\n\n3\nScalar\nloadings + intercepts\nmetric\n\n\n4\nStrict\n+ residual variances\nscalar\n\n\n5–7\nStructural invariance\nlv variances/covariances/means\nprevious"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#mg-cfa-scheme-steps-14",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#mg-cfa-scheme-steps-14",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "MG-CFA scheme (steps 1–4)",
    "text": "MG-CFA scheme (steps 1–4)\n\nSlide stolen from Psicostat’s meeting by Enrico Perinelli."
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#visual-ladder-legacy-diagrams",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#visual-ladder-legacy-diagrams",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Visual ladder (legacy diagrams)",
    "text": "Visual ladder (legacy diagrams)\n\n\nStep 0 (separate models)\n\n\nStep 1 (configural)"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#visual-ladder-continued",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#visual-ladder-continued",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Visual ladder (continued)",
    "text": "Visual ladder (continued)\n\n\nStep 2 (metric)\n\n\nStep 3 (scalar)"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#visual-ladder-strict-structural",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#visual-ladder-strict-structural",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Visual ladder (strict + structural)",
    "text": "Visual ladder (strict + structural)\n\n\nStep 4 (strict)\n\n\nStructural steps (5–7)"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#evaluation-global-comparison",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#evaluation-global-comparison",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Evaluation: global comparison",
    "text": "Evaluation: global comparison\nCommon ingredients:\n\nModel fit in the more constrained model (χ², RMSEA, CFI/TLI, SRMR)\nChange in fit vs less constrained model:\n\nΔχ² (highly N-sensitive)\nΔCFI (often used)\nΔRMSEA / ΔSRMR (sometimes used)\nΔBIC (information criteria)\n\n\nA marked worsening of fit indices indicates that the considered invariance model is too restrictive and thus must be rejected.\n\n\n\n\n\n\nWarning\n\n\n\nmake a comprehensive evaluation based on different fit indices, rather than on a single fit criterion."
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#practical-comparison-rules-legacy-modern-caution",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#practical-comparison-rules-legacy-modern-caution",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Practical comparison rules (legacy + modern caution)",
    "text": "Practical comparison rules (legacy + modern caution)\nLet MOD-A be a reference model and MOD-B a more restrictive model.\n\nΔχ² = χ²(B) − χ²(A) (N-sensitive; use with caution)\nΔCFI = CFI(B) − CFI(A)\n\nheuristic: accept if ΔCFI &gt; −.01\n\nΔBIC = BIC(B) − BIC(A)\n\nnegative values favor B\n\n\n\n\n\n\n\n\nWarning\n\n\nPitfall: with robust estimators (e.g., MLR/WLSMV), the χ² difference test is not always the plain anova() test."
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#partial-invariance-what-it-is",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#partial-invariance-what-it-is",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Partial invariance (what it is)",
    "text": "Partial invariance (what it is)\nWhen invariance is untenable at some level (metric/scalar/strict), you can allow some parameters to differ:\n\nFree non-invariant loadings/intercepts/residual variances\nKeep most constraints to preserve comparability\n\nOptions (in practice):\n\nFree a small number of parameters (theory-driven)\nArgue differences are negligible (rarely convincing)\nRemove problematic indicators (last resort)\nConclude constructs are not comparable with the current instrument or theoretically (sometimes correct!)"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#how-do-we-choose-what-to-free",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#how-do-we-choose-what-to-free",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "How do we choose what to free?",
    "text": "How do we choose what to free?\n\nInspect parameters by group (largest differences)\nInspect score tests / modification indices for constrained parameters\nFree one at a time and re-evaluate\nAlways justify based on theory and measurement logic\n\n\n\n\n\n\n\nWarning\n\n\n\nPitfall: “MI shopping” can overfit noise. Partial invariance must remain interpretable."
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#cfa-model-toy",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#cfa-model-toy",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "CFA model (toy)",
    "text": "CFA model (toy)"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#step-0-separate-models-sanity-check",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#step-0-separate-models-sanity-check",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Step 0 — Separate models (sanity check)",
    "text": "Step 0 — Separate models (sanity check)\nThis is not configural invariance. It’s only: “Does the model work in each group?”\n\nm0 &lt;- cfa(m, data = d[d$Group == 0, ])\nm1 &lt;- cfa(m, data = d[d$Group == 1, ])\n\nfitMeasures(m0, fi)\n\n     cfi      tli     srmr    rmsea      bic      aic \n   1.000    1.021    0.034    0.000 5214.258 5162.428 \n\nfitMeasures(m1, fi)\n\n     cfi      tli     srmr    rmsea      bic      aic \n   0.945    0.910    0.040    0.050 7899.949 7841.867"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#step-1-configural-invariance",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#step-1-configural-invariance",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Step 1: Configural invariance",
    "text": "Step 1: Configural invariance"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#step-2-metric-invariance-equal-loadings",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#step-2-metric-invariance-equal-loadings",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Step 2 — Metric invariance (equal loadings)",
    "text": "Step 2 — Metric invariance (equal loadings)\n\nm_metr &lt;- cfa(m, data = d, group = \"Group\",\n             group.equal = \"loadings\")\n\nfitMeasures(m_metr, fi)\n\n      cfi       tli      srmr     rmsea       bic       aic \n    0.976     0.967     0.038     0.032 13198.034 13027.276 \n\n# Compare to configural\nanova(m_metr, m_conf)\n\n\nChi-Squared Difference Test\n\n       Df   AIC   BIC  Chisq Chisq diff RMSEA Df diff Pr(&gt;Chisq)\nm_conf 26 13032 13225 35.392                                    \nm_metr 31 13027 13198 40.373     4.9804     0       5     0.4183\n\nfitMeasures(m_metr, \"cfi\") - fitMeasures(m_conf, \"cfi\")\n\ncfi \n  0 \n\nfitMeasures(m_metr, \"bic\") - fitMeasures(m_conf, \"bic\")\n\n    bic \n-26.912"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#step-2-diagnostics-what-breaks",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#step-2-diagnostics-what-breaks",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Step 2 diagnostics (what breaks?)",
    "text": "Step 2 diagnostics (what breaks?)\n\n# Score tests for equality constraints\nlavTestScore(m_metr)$uni |&gt; head(10)\n\n\nunivariate score tests:\n\n   lhs op   rhs    X2 df p.value\n1 .p2. == .p28. 2.336  1   0.126\n2 .p3. == .p29. 0.310  1   0.578\n3 .p4. == .p30. 0.877  1   0.349\n4 .p6. == .p32. 1.798  1   0.180\n5 .p7. == .p33. 0.227  1   0.634\n\n# Parameter table (useful for mapping constraint ids)\nparameterTable(m_metr)[1:15, c(\"lhs\",\"op\",\"rhs\",\"group\",\"free\",\"ustart\")]\n\n   lhs op rhs group free ustart\n1   f1 =~  x1     1    0      1\n2   f1 =~  x2     1    1     NA\n3   f1 =~  x3     1    2     NA\n4   f1 =~  x4     1    3     NA\n5   f2 =~  x5     1    0      1\n6   f2 =~  x6     1    4     NA\n7   f2 =~  x7     1    5     NA\n8   x1 ~~  x1     1    6     NA\n9   x2 ~~  x2     1    7     NA\n10  x3 ~~  x3     1    8     NA\n11  x4 ~~  x4     1    9     NA\n12  x5 ~~  x5     1   10     NA\n13  x6 ~~  x6     1   11     NA\n14  x7 ~~  x7     1   12     NA\n15  f1 ~~  f1     1   13     NA"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#step-3-scalar-invariance-loadings-intercepts",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#step-3-scalar-invariance-loadings-intercepts",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Step 3 — Scalar invariance (loadings + intercepts)",
    "text": "Step 3 — Scalar invariance (loadings + intercepts)\n\nm_scal &lt;- cfa(m, data = d, group = \"Group\",\n             group.equal = c(\"loadings\",\"intercepts\"))\n\nfitMeasures(m_scal, fi)\n\n      cfi       tli      srmr     rmsea       bic       aic \n    0.984     0.981     0.039     0.024 13168.052 13019.185 \n\nanova(m_scal, m_metr)\n\n\nChi-Squared Difference Test\n\n       Df   AIC   BIC  Chisq Chisq diff RMSEA Df diff Pr(&gt;Chisq)\nm_metr 31 13027 13198 40.373                                    \nm_scal 36 13019 13168 42.283     1.9096     0       5     0.8615\n\nfitMeasures(m_scal, \"cfi\") - fitMeasures(m_metr, \"cfi\")\n\n  cfi \n0.008"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#partial-invariance-in-lavaan",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#partial-invariance-in-lavaan",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Partial invariance in lavaan",
    "text": "Partial invariance in lavaan\ngroup.partial allows selected parameters to differ.\nExample: After the inspection of MI, we decided to estimate a model of partial metric invariance in which the loading of the item x5 is free to vary between groups::\n\nm_metr_p &lt;- cfa(m, data = d, group = \"Group\",\n               group.equal = \"loadings\",\n               group.partial = \"f2 =~ x5\")\n\nfitMeasures(m_metr_p, fi)\n\n      cfi       tli      srmr     rmsea       bic       aic \n    0.976     0.967     0.038     0.032 13198.034 13027.276 \n\n\n\nWhich model should we compare this to, and why? How to we interpret the results of such a model?"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#common-mistakes-invariance",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#common-mistakes-invariance",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Common mistakes (invariance)",
    "text": "Common mistakes (invariance)\n\nComparing latent means without (partial) scalar invariance\nFreeing many parameters without theoretical rationale (“MI fishing”)\nIgnoring identification choices (scaling, reference indicators, factor means)\nUsing automated helpers as a black box"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#the-case-study-dataset",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#the-case-study-dataset",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "The case study dataset",
    "text": "The case study dataset\n\nload(\"../data/dmg.RData\")\nstr(dmg)\n\n'data.frame':   300 obs. of  10 variables:\n $ id       : int  1 2 3 4 5 6 7 8 9 10 ...\n $ diagnosis: Factor w/ 2 levels \"manic\",\"norming\": 1 1 1 1 1 1 1 1 1 1 ...\n $ Info     : num  8.95 11.94 5.8 14.69 6 ...\n $ Sim      : num  9.34 9.93 6.64 17.72 6.56 ...\n $ Vocab    : num  12.39 4.57 6.03 13.21 7.83 ...\n $ Comp     : num  11.61 8.86 5.03 13.38 5.77 ...\n $ PicComp  : num  11.15 4.95 8.02 11.54 8.84 ...\n $ PicArr   : num  15.7 5.46 7.65 12.06 5.39 ...\n $ BlkDsgn  : num  11.45 3.43 9.28 10.46 7.39 ...\n $ ObjAsmb  : num  15.54 3.8 8.63 14.38 9.92 ...\n\n\n\n\n\n\n\n\nImportant\n\n\n\nSEM work with variance-covariance matrices. For this reason, it is sufficient to find it in the original articles to use their “data”! The data we will use have been generated based on the parameters provided in the article, modifying the sample size."
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#model-legacy",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#model-legacy",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Model (legacy)",
    "text": "Model (legacy)\n\nmodel &lt;- \"\ngc =~ Info + Sim + Vocab + Comp\ngv =~ PicComp + PicArr + BlkDsgn + ObjAsmb\n\""
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#step-0-separate-models-legacy",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#step-0-separate-models-legacy",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Step 0 — Separate models (legacy)",
    "text": "Step 0 — Separate models (legacy)\n\nm_man &lt;- cfa(model, data = dmg[dmg$diagnosis == \"manic\", ])\nm_nor &lt;- cfa(model, data = dmg[dmg$diagnosis == \"norming\", ])\n\nfitMeasures(m_man, c(\"chisq\",\"df\",\"rmsea\",\"cfi\",\"tli\"))\n\n chisq     df  rmsea    cfi    tli \n54.052 19.000  0.111  0.949  0.924 \n\nfitMeasures(m_nor, c(\"chisq\",\"df\",\"rmsea\",\"cfi\",\"tli\"))\n\n chisq     df  rmsea    cfi    tli \n18.151 19.000  0.000  1.000  1.003"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#step-1-configural-legacy",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#step-1-configural-legacy",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Step 1 — Configural (legacy)",
    "text": "Step 1 — Configural (legacy)\n\nm_conf2 &lt;- cfa(model, data = dmg, group = \"diagnosis\")\nfitMeasures(m_conf2, c(\"chisq\",\"df\",\"rmsea\",\"cfi\",\"tli\"))\n\n chisq     df  rmsea    cfi    tli \n72.203 38.000  0.077  0.971  0.957 \n\n\nANY COMMENTS?"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#step-2-metric-legacy",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#step-2-metric-legacy",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Step 2 — Metric (legacy)",
    "text": "Step 2 — Metric (legacy)\n\nm_metr2 &lt;- cfa(model, data = dmg, group = \"diagnosis\",\n              group.equal = \"loadings\")\n\nfitMeasures(m_metr2, c(\"chisq\",\"df\",\"rmsea\",\"cfi\",\"tli\"))\n\n chisq     df  rmsea    cfi    tli \n88.153 44.000  0.082  0.963  0.952 \n\nanova(m_metr2, m_conf2)\n\n\nChi-Squared Difference Test\n\n        Df   AIC   BIC  Chisq Chisq diff   RMSEA Df diff Pr(&gt;Chisq)  \nm_conf2 38 11239 11424 72.203                                        \nm_metr2 44 11243 11406 88.153      15.95 0.10515       6    0.01402 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nfitMeasures(m_metr2, \"cfi\") - fitMeasures(m_conf2, \"cfi\")\n\n   cfi \n-0.008 \n\nfitMeasures(m_metr2, \"bic\") - fitMeasures(m_conf2, \"bic\")\n\n    bic \n-18.272"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#step-3-scalar-legacy-and-partial-scalar",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#step-3-scalar-legacy-and-partial-scalar",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Step 3 — Scalar (legacy) and partial scalar",
    "text": "Step 3 — Scalar (legacy) and partial scalar\n\nm_scal2 &lt;- cfa(model, data = dmg, group = \"diagnosis\",\n              group.equal = c(\"loadings\",\"intercepts\"))\n\nfitMeasures(m_scal2, c(\"chisq\",\"df\",\"rmsea\",\"cfi\",\"tli\"))\n\n  chisq      df   rmsea     cfi     tli \n144.667  50.000   0.112   0.920   0.910 \n\n\nCOMMENTS"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#what-does-partial-scalar-mean-interpretation",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#what-does-partial-scalar-mean-interpretation",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "What does partial scalar mean (interpretation)?",
    "text": "What does partial scalar mean (interpretation)?\n\nMost intercepts are comparable across groups\nA small subset is not (e.g., Sim)\nLatent mean comparisons can be more defensible under partial scalar, but interpret non-invariant indicators substantively\n\n\nWhich item behaves differently across groups, and what could it reflect?"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#structural-invariance-what-comes-after-measurement",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#structural-invariance-what-comes-after-measurement",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Structural invariance (what comes after measurement)",
    "text": "Structural invariance (what comes after measurement)\nOnce measurement invariance is at least partially established, you can test:\n\nlatent variances\nlatent covariances\nlatent means\nregression paths (structural relations)"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#exercise-connect-to-the-lab",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#exercise-connect-to-the-lab",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Exercise (connect to the lab)",
    "text": "Exercise (connect to the lab)\n\n\n\n\n\n\nImportant\n\n\n\nTry it (15–25 min)\n1. Fit configural, metric, scalar on the toy dataset d.\n2. Decide whether scalar is acceptable using ΔCFI + theory.\n3. If scalar fails, free one intercept using group.partial.\n4. Write 3–4 sentences: what is comparable now, and what is not?\n\n\n\nLab link placeholder: add a direct link to the invariance lab once created (e.g., ../labs/lab04_invariance.qmd)."
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#take-home-3-things",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#take-home-3-things",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Take-home: 3 things",
    "text": "Take-home: 3 things\n\nInvariance is about comparability\n\nScalar (full/partial) is the key for latent mean comparisons.\n\nPartial invariance is legitimate, but must be disciplined + theory-driven."
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#further-reading-extras",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#further-reading-extras",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Further reading (extras)",
    "text": "Further reading (extras)\n\nPartial invariance strategies and interpretability\n\nInvariance with ordinal indicators (thresholds first)\n\nRobust difference testing with MLR / WLSMV\n\n\nAdd links to extras/ modules when we create them."
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#references",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#references",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#today-in-the-workflow",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#today-in-the-workflow",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "",
    "text": "Specify → Identify → Estimate → Evaluate → Revise/Report\n\n\n\n\n\n\nToday we focus on:\n\nEvaluate: “Does the same measurement model hold across groups?”\nReport: “What level of invariance supports which claims?”\n\n\n\n\nIn particular:\n\nWhy measurement invariance is a prerequisite for group comparisons\nThe MG-CFA ladder (configural → metric → scalar → strict)\nHow to evaluate invariance (Δ fit + local diagnostics)\nPartial invariance: what to free, how to justify it\n(Briefly) structural invariance: variances/covariances/means"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#invariance-steps-measurement",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#invariance-steps-measurement",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Invariance steps (measurement)",
    "text": "Invariance steps (measurement)\n\nConfigural: same factor structure (same “form”)\nMetric / weak: equal loadings (Λ)\nScalar / strong: equal intercepts (τ)\nStrict: equal residual variances (Θ)\n\n\nScalar invariance (full or partial) is the gateway to latent mean comparisons."
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#step-0-separate-models",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#step-0-separate-models",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Step 0 — Separate models",
    "text": "Step 0 — Separate models\n\nm_man &lt;- cfa(model, data = dmg[dmg$diagnosis == \"manic\", ])\nm_nor &lt;- cfa(model, data = dmg[dmg$diagnosis == \"norming\", ])\n\nfitMeasures(m_man, c(\"chisq\",\"df\",\"rmsea\",\"cfi\",\"tli\"))\n\n chisq     df  rmsea    cfi    tli \n54.052 19.000  0.111  0.949  0.924 \n\nfitMeasures(m_nor, c(\"chisq\",\"df\",\"rmsea\",\"cfi\",\"tli\"))\n\n chisq     df  rmsea    cfi    tli \n18.151 19.000  0.000  1.000  1.003"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#step-1-configural",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#step-1-configural",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Step 1 — Configural",
    "text": "Step 1 — Configural\n\nm_conf2 &lt;- cfa(model, data = dmg, group = \"diagnosis\")\nfitMeasures(m_conf2, c(\"chisq\",\"df\",\"rmsea\",\"cfi\",\"tli\"))\n\n chisq     df  rmsea    cfi    tli \n72.203 38.000  0.077  0.971  0.957 \n\n\nANY COMMENTS?"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#step-2-metric",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#step-2-metric",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Step 2 — Metric",
    "text": "Step 2 — Metric\n\nm_metr2 &lt;- cfa(model, data = dmg, group = \"diagnosis\",\n              group.equal = \"loadings\")\n\nfitMeasures(m_metr2, c(\"chisq\",\"df\",\"rmsea\",\"cfi\",\"tli\"))\n\n chisq     df  rmsea    cfi    tli \n88.153 44.000  0.082  0.963  0.952"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#step-3-scalar",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#step-3-scalar",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Step 3 (scalar)",
    "text": "Step 3 (scalar)"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#step-0-separate-models-for-each-group",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#step-0-separate-models-for-each-group",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Step 0: Separate models for each group",
    "text": "Step 0: Separate models for each group"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#step-1-configural-non-invariance",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#step-1-configural-non-invariance",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Step 1: Configural (non-)invariance",
    "text": "Step 1: Configural (non-)invariance\nConfigural invariance means that the “form” of the models is the same in the groups of interest. Form entails both the number of latent variables and whether the loadings are non-zero to begin with."
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#step-2-metric-invariance",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#step-2-metric-invariance",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Step 2: Metric invariance",
    "text": "Step 2: Metric invariance"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#step-2-metric-non-invariance",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#step-2-metric-non-invariance",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Step 2: Metric (non-)invariance",
    "text": "Step 2: Metric (non-)invariance\nMetric invariance means that for each item, the loading of the factor on the item is the same in the two groups (or, again more precisely, that we cannot reject the hypothesis that the loadings are the same)."
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#step-2-metric-non-invariance-1",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#step-2-metric-non-invariance-1",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Step 2: Metric (non-)invariance",
    "text": "Step 2: Metric (non-)invariance\nThe source of group differences does not come from the latent variable!"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#step-3-scalar-invariance",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#step-3-scalar-invariance",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Step 3: Scalar invariance",
    "text": "Step 3: Scalar invariance"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#step-3-scalar-invariance-1",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#step-3-scalar-invariance-1",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Step 3: Scalar invariance",
    "text": "Step 3: Scalar invariance\nScalar invariance means that for each item, the intercept is the same. This means that group differences in the item responses are fully accounted for by group differences in the latent construct."
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#step-4-invariance-of-observed-residual-variances",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#step-4-invariance-of-observed-residual-variances",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Step 4: Invariance of observed residual variances",
    "text": "Step 4: Invariance of observed residual variances\nResidual invariance means that for each item, the residual variance—the variance of the ominous E pointing into the items—is the same. We can again phrase this statistically: if we regressed the item scores on the factor, then the variance of the remaining residual would be the same in the groups (i.e., there would be homoscedasticity)."
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#step-4-invariance-of-observed-residual-variances-1",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#step-4-invariance-of-observed-residual-variances-1",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Step 4: Invariance of observed residual variances",
    "text": "Step 4: Invariance of observed residual variances\n\nThe thing about the residual is that it captures everything that’s not explained in the model, and explaining changes in the amount of unexplained things seems a bit futile. Residual invariance is often not tested because it’s not necessary for latent mean comparisons. It’s a bit of an anticlimactic level to end on."
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#step-5-invariance-of-latent-variances",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#step-5-invariance-of-latent-variances",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Step 5: Invariance of latent variances",
    "text": "Step 5: Invariance of latent variances"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#step-6-invariance-of-latent-covariances",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#step-6-invariance-of-latent-covariances",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Step 6: Invariance of latent covariances",
    "text": "Step 6: Invariance of latent covariances"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#step-7-invariance-of-latent-means",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#step-7-invariance-of-latent-means",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Step 7: Invariance of latent means",
    "text": "Step 7: Invariance of latent means"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#step-1-configural-invariance-1",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#step-1-configural-invariance-1",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Step 1 — Configural invariance",
    "text": "Step 1 — Configural invariance\n\nm_all &lt;- cfa(m, data = d)\nfitMeasures(m_all, fi)\n\n      cfi       tli      srmr     rmsea       bic       aic \n    1.000     1.007     0.021     0.000 13070.106 13004.430 \n\n\n\nm_conf &lt;- cfa(m, data = d, group = \"Group\")\nfitMeasures(m_conf, fi)\n\n      cfi       tli      srmr     rmsea       bic       aic \n    0.976     0.961     0.034     0.035 13224.946 13032.295"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#to-read",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#to-read",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "TO READ",
    "text": "TO READ\nAll the next slides are inspired in large part from the following blog post"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#practical-comparison-rules",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#practical-comparison-rules",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Practical comparison rules",
    "text": "Practical comparison rules\nLet MOD-A be a reference model and MOD-B a more restrictive model.\n\nΔχ² = χ²(B) − χ²(A) (N-sensitive; use with caution)\nΔCFI = CFI(B) − CFI(A)\n\nheuristic: accept if ΔCFI &gt; −.01\n\nΔBIC = BIC(B) − BIC(A)\n\nnegative values favor B\n\n\n\n\n\n\n\n\nWarning\n\n\n\nPitfall: with robust estimators (e.g., MLR/WLSMV), the χ² difference test is not always the plain anova() test."
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#what-can-we-fix",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#what-can-we-fix",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "What can we fix?",
    "text": "What can we fix?\nThrough the option group.equal , it is possible to constrain groups of parameters to be equal across groups in order to assess increasingly restrictive invariance hypotheses:\n\n\n\nConstrained parameters\nIn R\n\n\n\n\nFactor loadings\nloadings\n\n\nIntercepts of manifest variables\nintercepts\n\n\nResidual variances of manifest variables\nresiduals\n\n\nResidual covariances of manifest variables\nresidual.covariances\n\n\nResidual variances of latent variables\nlv.variances\n\n\nResidual covariances of latent variable\nlv.covariances\n\n\nIntercepts/means of latent variables\nmeans\n\n\nAll regression coefficients\nregressions\n\n\nThresholds\nthresholds"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#step-2-metric-1",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#step-2-metric-1",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Step 2 — Metric",
    "text": "Step 2 — Metric\n\nanova(m_metr2, m_conf2)\n\n\nChi-Squared Difference Test\n\n        Df   AIC   BIC  Chisq Chisq diff   RMSEA Df diff Pr(&gt;Chisq)  \nm_conf2 38 11239 11424 72.203                                        \nm_metr2 44 11243 11406 88.153      15.95 0.10515       6    0.01402 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nfitMeasures(m_metr2, \"cfi\") - fitMeasures(m_conf2, \"cfi\")\n\n   cfi \n-0.008 \n\nfitMeasures(m_metr2, \"bic\") - fitMeasures(m_conf2, \"bic\")\n\n    bic \n-18.272"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#step-3-scalar-legacy-and-partial-scalar-1",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#step-3-scalar-legacy-and-partial-scalar-1",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Step 3 — Scalar (legacy) and partial scalar",
    "text": "Step 3 — Scalar (legacy) and partial scalar\n\nanova(m_scal2, m_metr2)\n\n\nChi-Squared Difference Test\n\n        Df   AIC   BIC   Chisq Chisq diff   RMSEA Df diff Pr(&gt;Chisq)    \nm_metr2 44 11243 11406  88.153                                          \nm_scal2 50 11287 11428 144.667     56.513 0.23691       6  2.292e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nfitMeasures(m_scal2, \"cfi\") - fitMeasures(m_metr2, \"cfi\")\n\n   cfi \n-0.043"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#step-3-inspection-of-equality-constraints",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#step-3-inspection-of-equality-constraints",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Step 3 — Inspection of equality constraints",
    "text": "Step 3 — Inspection of equality constraints\n\n# Identify the worst constraints\nlavTestScore(m_scal2)$uni |&gt; head(10)\n\n\nunivariate score tests:\n\n     lhs op   rhs     X2 df p.value\n1   .p2. == .p31.  0.419  1   0.517\n2   .p3. == .p32.  0.335  1   0.563\n3   .p4. == .p33.  2.389  1   0.122\n4   .p6. == .p35.  7.026  1   0.008\n5   .p7. == .p36.  0.072  1   0.789\n6   .p8. == .p37.  0.000  1   0.988\n7  .p20. == .p49.  8.342  1   0.004\n8  .p21. == .p50. 42.173  1   0.000\n9  .p22. == .p51.  2.691  1   0.101\n10 .p23. == .p52. 11.089  1   0.001\n\n\n\nparameterTable(m_scal2)"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#step-3-partial-scalar-invariance",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#step-3-partial-scalar-invariance",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Step 3 — Partial scalar invariance",
    "text": "Step 3 — Partial scalar invariance\n\n# Example: free the intercept of Sim\nm_scal2_p &lt;- cfa(model, data = dmg, group = \"diagnosis\",\n                group.equal = c(\"loadings\",\"intercepts\"),\n                group.partial = \"Sim ~ 1\")\nfitMeasures(m_scal2_p, c(\"chisq\",\"df\",\"rmsea\",\"cfi\",\"tli\"))\n\n  chisq      df   rmsea     cfi     tli \n100.174  49.000   0.083   0.957   0.950"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#step-3-partial-scalar-invariance-1",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#step-3-partial-scalar-invariance-1",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Step 3 — Partial scalar invariance",
    "text": "Step 3 — Partial scalar invariance\n\nanova(m_scal2_p, m_metr2)\n\n\nChi-Squared Difference Test\n\n          Df   AIC   BIC   Chisq Chisq diff    RMSEA Df diff Pr(&gt;Chisq)  \nm_metr2   44 11243 11406  88.153                                         \nm_scal2_p 49 11245 11389 100.174     12.021 0.096752       5     0.0345 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nfitMeasures(m_scal2_p, \"cfi\") - fitMeasures(m_metr2, \"cfi\")\n\n   cfi \n-0.006"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#invariance-of-residuals-of-observed-variables1",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#invariance-of-residuals-of-observed-variables1",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Invariance of Residuals of observed variables(1)",
    "text": "Invariance of Residuals of observed variables(1)\n\n# Note: parameter \"Sim~1\" remains free\nm.rvo=cfa(model,dmg,group=\"diagnosis\",\n          group.equal=c(\"loadings\",\"intercepts\",\"residuals\"),\n          group.partial=\"Sim~1\") #Note that this is still here\n# Inspection of fit indices\nfitMeasures(m.rvo,c(\"chisq\",\"df\",\"rmsea\",\"cfi\",\"nnfi\"))\n\n  chisq      df   rmsea     cfi    nnfi \n127.344  57.000   0.091   0.940   0.941"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#invariance-of-residuals-of-observed-variables-2",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#invariance-of-residuals-of-observed-variables-2",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Invariance of Residuals of observed variables (2)",
    "text": "Invariance of Residuals of observed variables (2)\n\nanova(m.rvo,m_scal2_p) # Note: Comparison model Partial Scalar invariance\n\n\nChi-Squared Difference Test\n\n          Df   AIC   BIC  Chisq Chisq diff   RMSEA Df diff Pr(&gt;Chisq)    \nm_scal2_p 49 11245 11389 100.17                                          \nm.rvo     57 11256 11371 127.34     27.169 0.12639       8  0.0006609 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nfitMeasures(m.rvo,\"cfi\")-fitMeasures(m_scal2_p,\"cfi\")\n\n   cfi \n-0.016 \n\nfitMeasures(m.rvo,\"bic\")-fitMeasures(m_scal2_p,\"bic\")\n\n    bic \n-18.461 \n\n# The Invariance of Residuals of observed variables\n#   is not satisfactory. Let's take a look at equality constraints"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#inspection-of-equality-constraints",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#inspection-of-equality-constraints",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Inspection of equality constraints",
    "text": "Inspection of equality constraints\n\nlavTestScore(m.rvo)$uni |&gt; head(10)\n\n\nunivariate score tests:\n\n     lhs op   rhs     X2 df p.value\n1   .p2. == .p31.  4.802  1   0.028\n2   .p3. == .p32.  1.156  1   0.282\n3   .p4. == .p33.  0.138  1   0.710\n4   .p6. == .p35.  7.948  1   0.005\n5   .p7. == .p36.  0.099  1   0.753\n6   .p8. == .p37.  0.020  1   0.888\n7   .p9. == .p38.  0.107  1   0.744\n8  .p10. == .p39.  0.108  1   0.743\n9  .p11. == .p40.  0.504  1   0.478\n10 .p12. == .p41. 12.169  1   0.000\n\n\n\n# (... see complete output )\n# From a first analysis, we can see that\n#  the residuals of variables  “Comp” and “PicComp”\n#  have Modification indices that are\n#  particularly high, so let's free them"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#invariance-of-residuals-of-observed-variables-1",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#invariance-of-residuals-of-observed-variables-1",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Invariance of Residuals of observed variables (1)",
    "text": "Invariance of Residuals of observed variables (1)\n\nm.rvo.P=cfa(model,dmg,group=\"diagnosis\",\n            group.equal=c(\"loadings\",\"intercepts\",\"residuals\"),\n            group.partial=c(\"Sim~1\",\"PicComp~~PicComp\",\"Comp~~Comp\"))\n# Fit indices\nfitMeasures(m.rvo.P,c(\"chisq\",\"df\",\"rmsea\",\"cfi\",\"nnfi\"))\n\n  chisq      df   rmsea     cfi    nnfi \n102.420  55.000   0.076   0.960   0.959"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#partial-invariance-of-residuals-of-observed-variables-2",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#partial-invariance-of-residuals-of-observed-variables-2",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Partial Invariance of Residuals of observed variables (2)",
    "text": "Partial Invariance of Residuals of observed variables (2)\n\n# Evaluation of Partial Invariance of Residuals of observed variables\nanova(m.rvo.P,m_scal2_p) # Note: Comparison model Partial Scalar invariance\n\n\nChi-Squared Difference Test\n\n          Df   AIC   BIC  Chisq Chisq diff RMSEA Df diff Pr(&gt;Chisq)\nm_scal2_p 49 11245 11389 100.17                                    \nm.rvo.P   55 11235 11357 102.42     2.2458     0       6     0.8958\n\nfitMeasures(m.rvo.P,\"cfi\")-fitMeasures(m_scal2_p,\"cfi\")\n\n  cfi \n0.003 \n\nfitMeasures(m.rvo.P,\"bic\")-fitMeasures(m_scal2_p,\"bic\")\n\n    bic \n-31.977 \n\n# Paartial Invariance of Residuals of observed variables is satisfactory.\n# Question: What can we say about overall\n# Measurement Invariance of the baseline theoretical model?"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#invariance-of-variance-of-latent-variables-1",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#invariance-of-variance-of-latent-variables-1",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Invariance of Variance of latent variables (1)",
    "text": "Invariance of Variance of latent variables (1)\n\nm.vvl=cfa(model,dmg,group=\"diagnosis\",\n          group.equal=c(\"loadings\",\"intercepts\",\"residuals\",\n                        \"lv.variances\"),\n          group.partial=c(\"Sim~1\",\"PicComp~~PicComp\",\"Comp~~Comp\"))\n# Fit indices\nfitMeasures(m.vvl,c(\"chisq\",\"df\",\"rmsea\",\"cfi\",\"nnfi\"))\n\n  chisq      df   rmsea     cfi    nnfi \n105.825  57.000   0.076   0.959   0.959"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#invariance-of-variance-of-latent-variables-2",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#invariance-of-variance-of-latent-variables-2",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Invariance of Variance of latent variables (2)",
    "text": "Invariance of Variance of latent variables (2)\n\nanova(m.vvl,m.rvo.P)\n\n\nChi-Squared Difference Test\n\n        Df   AIC   BIC  Chisq Chisq diff    RMSEA Df diff Pr(&gt;Chisq)\nm.rvo.P 55 11235 11357 102.42                                       \nm.vvl   57 11234 11349 105.83     3.4056 0.068449       2     0.1822\n\nfitMeasures(m.vvl,\"cfi\")-fitMeasures(m.rvo.P,\"cfi\")\n\n   cfi \n-0.001 \n\nfitMeasures(m.vvl,\"bic\")-fitMeasures(m.rvo.P,\"bic\")\n\n   bic \n-8.002 \n\n# OK, this looks good!"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#invariance-of-covariance-of-latent-variables-1",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#invariance-of-covariance-of-latent-variables-1",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Invariance of Covariance of latent variables (1)",
    "text": "Invariance of Covariance of latent variables (1)\n\nm.cvl=cfa(model,dmg,group=\"diagnosis\",\n          group.equal=c(\"loadings\",\"intercepts\"\n                        ,\"residuals\",\"lv.variances\",\"lv.covariances\"),\n          group.partial=c(\"Sim~1\",\"PicComp~~PicComp\",\"Comp~~Comp\"))\n# Fit indices\nfitMeasures(m.cvl,c(\"chisq\",\"df\",\"rmsea\",\"cfi\",\"nnfi\"))\n\n  chisq      df   rmsea     cfi    nnfi \n106.412  58.000   0.075   0.959   0.960"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#invariance-of-covariance-of-latent-variables2",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#invariance-of-covariance-of-latent-variables2",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Invariance of Covariance of latent variables(2)",
    "text": "Invariance of Covariance of latent variables(2)\n\nanova(m.cvl,m.vvl)\n\n\nChi-Squared Difference Test\n\n      Df   AIC   BIC  Chisq Chisq diff RMSEA Df diff Pr(&gt;Chisq)\nm.vvl 57 11234 11349 105.83                                    \nm.cvl 58 11233 11344 106.41    0.58642     0       1     0.4438\n\nfitMeasures(m.cvl,\"cfi\")-fitMeasures(m.vvl,\"cfi\")\n\ncfi \n  0 \n\nfitMeasures(m.cvl,\"bic\")-fitMeasures(m.vvl,\"bic\")\n\n   bic \n-5.117 \n\n# OK, we're almost there!"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#invariance-of-means-of-latent-variables-1",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#invariance-of-means-of-latent-variables-1",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Invariance of Means of latent variables (1)",
    "text": "Invariance of Means of latent variables (1)\n\n# last step\nm.med=cfa(model,dmg,group=\"diagnosis\",\n          group.equal=c(\"loadings\",\"intercepts\"\n                        ,\"residuals\",\"lv.variances\",\"lv.covariances\",\n                        \"means\"),\n          group.partial=c(\"Sim~1\",\"PicComp~~PicComp\",\"Comp~~Comp\"))\n# Fit indices\nfitMeasures(m.med,c(\"chisq\",\"df\",\"rmsea\",\"cfi\",\"nnfi\"))\n\n  chisq      df   rmsea     cfi    nnfi \n110.933  60.000   0.075   0.957   0.960"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#invariance-of-means-of-latent-variables-2",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#invariance-of-means-of-latent-variables-2",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Invariance of Means of latent variables (2)",
    "text": "Invariance of Means of latent variables (2)\n\nanova(m.med,m.cvl)\n\n\nChi-Squared Difference Test\n\n      Df   AIC   BIC  Chisq Chisq diff    RMSEA Df diff Pr(&gt;Chisq)\nm.cvl 58 11233 11344 106.41                                       \nm.med 60 11234 11337 110.93     4.5212 0.091673       2     0.1043\n\nfitMeasures(m.med,\"cfi\")-fitMeasures(m.cvl,\"cfi\")\n\n   cfi \n-0.002 \n\nfitMeasures(m.med,\"bic\")-fitMeasures(m.cvl,\"bic\")\n\n   bic \n-6.886 \n\n# This last model is also satisfactory\n# ANY COMMENTS?"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#summing-up",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#summing-up",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Summing up",
    "text": "Summing up\n\n\n\n\n\nModels\nnpar\ndf\nchisq\ncfi\ntli\nnnfi\nagfi\nsrmr\nrmsea\nbic\naic\n\n\n\n\nManics\n17\n19\n54.05\n0.95\n0.92\n0.92\n0.84\n0.05\n0.11\n5590.65\n5539.47\n\n\nNorming\n17\n19\n18.15\n1\n1\n1\n0.94\n0.03\n0\n5718.64\n5667.46\n\n\nConfigural\n50\n38\n72.2\n0.97\n0.96\n0.96\n0.98\n0.04\n0.08\n11424.11\n11238.93\n\n\nMetric\n44\n44\n88.15\n0.96\n0.95\n0.95\n0.98\n0.06\n0.08\n11405.84\n11242.88\n\n\nScalar\n38\n50\n144.67\n0.92\n0.91\n0.91\n0.97\n0.08\n0.11\n11428.13\n11287.39\n\n\nScalar Partial\n39\n49\n100.17\n0.96\n0.95\n0.95\n0.98\n0.07\n0.08\n11389.34\n11244.9\n\n\nResidual Variances\n31\n57\n127.34\n0.94\n0.94\n0.94\n0.98\n0.08\n0.09\n11370.88\n11256.07\n\n\nResidual Variances Partial\n33\n55\n102.42\n0.96\n0.96\n0.96\n0.98\n0.07\n0.08\n11357.37\n11235.14\n\n\nLatent Variances\n31\n57\n105.83\n0.96\n0.96\n0.96\n0.98\n0.09\n0.08\n11349.36\n11234.55\n\n\nLatent Covariances\n30\n58\n106.41\n0.96\n0.96\n0.96\n0.98\n0.09\n0.07\n11344.25\n11233.13\n\n\nLatent Means\n28\n60\n110.93\n0.96\n0.96\n0.96\n0.98\n0.09\n0.08\n11337.36\n11233.66"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#model",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#model",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Model",
    "text": "Model\n\nmodel &lt;- \"\ngc =~ Info + Sim + Vocab + Comp\ngv =~ PicComp + PicArr + BlkDsgn + ObjAsmb\n\""
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#step-3-scalar-and-partial-scalar",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#step-3-scalar-and-partial-scalar",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Step 3 — Scalar and partial scalar",
    "text": "Step 3 — Scalar and partial scalar\n\nm_scal2 &lt;- cfa(model, data = dmg, group = \"diagnosis\",\n              group.equal = c(\"loadings\",\"intercepts\"))\n\nfitMeasures(m_scal2, c(\"chisq\",\"df\",\"rmsea\",\"cfi\",\"tli\"))\n\n  chisq      df   rmsea     cfi     tli \n144.667  50.000   0.112   0.920   0.910 \n\n\nCOMMENTS"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#step-3-scalar-and-partial-scalar-1",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#step-3-scalar-and-partial-scalar-1",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Step 3 — Scalar and partial scalar",
    "text": "Step 3 — Scalar and partial scalar\n\nanova(m_scal2, m_metr2)\n\n\nChi-Squared Difference Test\n\n        Df   AIC   BIC   Chisq Chisq diff   RMSEA Df diff Pr(&gt;Chisq)    \nm_metr2 44 11243 11406  88.153                                          \nm_scal2 50 11287 11428 144.667     56.513 0.23691       6  2.292e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nfitMeasures(m_scal2, \"cfi\") - fitMeasures(m_metr2, \"cfi\")\n\n   cfi \n-0.043"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html#structural-invariance",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html#structural-invariance",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "Structural invariance",
    "text": "Structural invariance\nTest of multigroup invariance can also be used to compare differences in the regression coefficients of two or more groups (interactions)."
  },
  {
    "objectID": "labs/lab07_invariance_mgcfa.html",
    "href": "labs/lab07_invariance_mgcfa.html",
    "title": "Lab 07 — Invariance (MG-CFA)",
    "section": "",
    "text": "By the end of this lab, you can:\n\nFit a multi-group CFA in lavaan\nRun the invariance ladder (configural → metric → scalar → strict)\nDecide when partial invariance is defensible (and how to implement it)\nMap common claims (paths / latent means) to the minimum invariance level needed"
  },
  {
    "objectID": "labs/lab07_invariance_mgcfa.html#references",
    "href": "labs/lab07_invariance_mgcfa.html#references",
    "title": "Lab 07 — Invariance (MG-CFA)",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "labs/lab06_missing_fiml_mi_robust.html",
    "href": "labs/lab06_missing_fiml_mi_robust.html",
    "title": "Lab 06 — Missing data, FIML, MI, and robust estimation",
    "section": "",
    "text": "By the end of this lab, you can:\n\nDiagnose what kind of missingness you likely have (MCAR/MAR/MNAR)\nFit the same SEM under different defensible choices (listwise vs FIML; ML vs MLR)\nRun multiple imputation (MI) and compare with FIML\nWrite a minimal, defensible reporting paragraph for a SEM with missing and non-normal data"
  },
  {
    "objectID": "labs/lab06_missing_fiml_mi_robust.html#simulate-a-messy-but-realistic-dataset",
    "href": "labs/lab06_missing_fiml_mi_robust.html#simulate-a-messy-but-realistic-dataset",
    "title": "Lab 06 — Missing data, FIML, MI, and robust estimation",
    "section": "Simulate a “messy but realistic” dataset",
    "text": "Simulate a “messy but realistic” dataset\nWe reuse the same model as in Lesson 6 (measurement + structural), then we add:\n\nskewness (monotone transforms of some indicators)\nheavy tails/outliers (a small proportion of extreme values)\nMAR missingness (missingness depends on an observed proxy)\n\n\n\nShow code\nsimulate_sem_data &lt;- function(N = 600, seed = 1234,\n                              add_skew = TRUE,\n                              add_outliers = TRUE) {\n  set.seed(seed)\n\n  model_pop &lt;- \"\n  # Measurement\n  peer  =~ 0.80*p1 + 0.70*p2 + 0.60*p3 + 0.70*p4\n  media =~ 0.70*m1 + 0.80*m2 + 0.60*m3 + 0.70*m4\n  comp  =~ 0.70*c1 + 0.70*c2 + 0.60*c3\n  eat   =~ 0.70*e1 + 0.60*e2\n\n  # Structural\n  comp ~ 0.40*peer + 0.50*media\n  eat  ~ 0.35*comp\n  \"\n\n  dat &lt;- simulateData(model_pop, sample.nobs = N)\n\n  if (add_skew) {\n    skew_vars &lt;- c(\"p1\",\"p2\",\"m1\",\"m2\",\"c1\")\n    for (v in skew_vars) dat[[v]] &lt;- exp(dat[[v]] / 2)\n  }\n\n  if (add_outliers) {\n    set.seed(seed)\n    ix &lt;- sample(seq_len(N), size = round(0.03 * N))  # ~3% outliers\n    dat$m4[ix] &lt;- dat$m4[ix] + rnorm(length(ix), mean = 0, sd = 4)\n    dat$c3[ix] &lt;- dat$c3[ix] + rnorm(length(ix), mean = 0, sd = 4)\n  }\n\n  dat\n}\n\nmake_missing_mar &lt;- function(dat, prop = 0.20, seed = 1234,\n                             vars = c(\"e1\",\"m3\")) {\n  set.seed(seed)\n\n  # Observed proxy for the latent 'peer' factor (think: sum score, previous wave, etc.)\n  peer_obs &lt;- rowMeans(dat[, c(\"p1\",\"p2\",\"p3\",\"p4\")], na.rm = TRUE)\n\n  # Base MAR mechanism: higher peer_obs -&gt; higher missingness probability\n  p_base &lt;- plogis(as.numeric(scale(peer_obs)))  # in (0,1), mean ~ 0.5\n\n  # Calibrate to hit approx prop missing (cap to avoid p &gt; 1)\n  k &lt;- min(0.95, prop / mean(p_base))\n  p_miss &lt;- pmin(p_base * k, 0.95)\n\n  miss &lt;- runif(nrow(dat)) &lt; p_miss\n\n  for (v in vars) dat[[v]][miss] &lt;- NA\n\n  attr(dat, \"missing_mechanism\") &lt;- list(type = \"MAR\", prop_target = prop, vars = vars)\n  dat\n}\n\n# Build the dataset used throughout the lab\ndat &lt;- simulate_sem_data(N = 600, seed = 1234)\ndat &lt;- make_missing_mar(dat, prop = 0.20, seed = 1234)\n\nround(colMeans(is.na(dat)), 3)\n\n\n   p1    p2    p3    p4    m1    m2    m3    m4    c1    c2    c3    e1    e2 \n0.000 0.000 0.000 0.000 0.000 0.000 0.175 0.000 0.000 0.000 0.000 0.175 0.000"
  },
  {
    "objectID": "labs/lab06_missing_fiml_mi_robust.html#references",
    "href": "labs/lab06_missing_fiml_mi_robust.html#references",
    "title": "Lab 06 — Missing data, FIML, MI, and robust estimation",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "slides/07_invariance_mgcfa_partialinvariance.html",
    "href": "slides/07_invariance_mgcfa_partialinvariance.html",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group CFA",
    "section": "",
    "text": "Specify → Identify → Estimate → Evaluate → Revise/Report\n\n\n\n\n\n\nToday we focus on:\n\nEvaluate: “Does the same measurement model hold across groups?”\nReport: “What level of invariance supports which claims?”\n\n\n\n\nIn particular:\n\nWhy measurement invariance is a prerequisite for group comparisons\nThe MG-CFA ladder (configural → metric → scalar → strict)\nHow to evaluate invariance (Δ fit + local diagnostics)\nPartial invariance: what to free, how to justify it\n(Briefly) structural invariance: variances/covariances/means"
  },
  {
    "objectID": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#today-in-the-workflow",
    "href": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#today-in-the-workflow",
    "title": "SEM with ordinal variables",
    "section": "Today in the workflow",
    "text": "Today in the workflow\nSpecify → Identify → Estimate → Evaluate → Revise/Report\n\n\n\nToday: extending SEM to ordinal (ordered-categorical) indicators:\nthresholds, polychoric correlations, DWLS/WLSMV (and ULS), and what changes in model fit and invariance."
  },
  {
    "objectID": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#learning-objectives",
    "href": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#learning-objectives",
    "title": "SEM with ordinal variables",
    "section": "Learning objectives",
    "text": "Learning objectives\nBy the end of this session you should be able to:\n\nExplain the latent-response view of ordinal items and the role of thresholds\nKnow when treating Likert items as continuous is risky (few categories / skewed distributions)\nFit ordinal CFA/SEM in lavaan using ordered= and appropriate estimators (DWLS/WLSMV/ULS)\nUnderstand how (and why) global fit indices behave differently with ordinal data\nRun MG-CFA invariance with ordinal indicators (thresholds first, then loadings)"
  },
  {
    "objectID": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#credits",
    "href": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#credits",
    "title": "SEM with ordinal variables",
    "section": "Credits",
    "text": "Credits\nCredits to Prof. Massimiliano Pastore for the original slides."
  },
  {
    "objectID": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#outline",
    "href": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#outline",
    "title": "SEM with ordinal variables",
    "section": "Outline",
    "text": "Outline\n\nIntroduction\nIn lavaan\nModel fit\nMG-CFA with ordinal data"
  },
  {
    "objectID": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#introduction",
    "href": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#introduction",
    "title": "SEM with ordinal variables",
    "section": "Introduction",
    "text": "Introduction\nIn psychology we rarely have data that are normally distributed or that follow a continuous distribution. Our data are probably ordinal or the consequence of ordinal/dichotomous processes:\n\nset.seed(42); n=10000; items = 30;\nscore &lt;- rbinom(n,items, rnorm(n,.80,.10))\n\n\nCOMMENTS?"
  },
  {
    "objectID": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#introduction-1",
    "href": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#introduction-1",
    "title": "SEM with ordinal variables",
    "section": "Introduction",
    "text": "Introduction\nHowever, we postulate that they are generated from continuous normal latent distributions\n\nCOMMENTS?"
  },
  {
    "objectID": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#likert-scales",
    "href": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#likert-scales",
    "title": "SEM with ordinal variables",
    "section": "Likert scales",
    "text": "Likert scales\nThis also applies to Liker scales, where the difference between reporting a score of 1 or 2, and the difference between reporting a score of 2 or 3 is not the same!"
  },
  {
    "objectID": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#the-adaptability-data",
    "href": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#the-adaptability-data",
    "title": "SEM with ordinal variables",
    "section": "The adaptability data",
    "text": "The adaptability data\nAnd in real data they are often not normally distributed"
  },
  {
    "objectID": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#wrong-correlations",
    "href": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#wrong-correlations",
    "title": "SEM with ordinal variables",
    "section": "Wrong correlations",
    "text": "Wrong correlations\nUnfortunately, when we use data that follow discrete distributions and treat them as they were continuous, we can fail to recreate true correlation matrices accurately. That’s why you usually use polychoric correlations with dichotomous or ordinal variables.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData were generated from a multivariate normal distribution using MASS::mvrnorm and then manually truncated on a 3-point scale\n\n\n\nThis, of course, has consequences on SEM parameters, which are based on covariance"
  },
  {
    "objectID": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#in-lavaan-and-sem",
    "href": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#in-lavaan-and-sem",
    "title": "SEM with ordinal variables",
    "section": "In lavaan and SEM",
    "text": "In lavaan and SEM\nTo estimate a model treating items/observations as ordinal data, we need to change the estimationd method\n\nML is not always accurate with ordinal data (especially with few categories)\nlavaan, when ordered is TRUE, automatically use WLSMV (diagonally weighted least squares)\nA great alternative is ULS, but has more convergence problems\nWe can also use robust ML alternatives, like MLR\nOther available estimators: lavaan tutorial on estimators (see here)"
  },
  {
    "objectID": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#how-to-fit-a-cfa-with-ordinal-data",
    "href": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#how-to-fit-a-cfa-with-ordinal-data",
    "title": "SEM with ordinal variables",
    "section": "How to fit a CFA with ordinal data",
    "text": "How to fit a CFA with ordinal data\n\nlibrary(lavaan)\n\n\n# THE MODEL IS SPECIFIED AS USUAL\nmOrd &lt;- \"\ncb =~ Adaptability_1 + Adaptability_2 + Adaptability_3 + \n      Adaptability_4 + Adaptability_5 + Adaptability_6\nem =~ Adaptability_7 + Adaptability_8 + Adaptability_9\nem ~~ cb\n\"\n# WE JUST NEED TO ADD\nfitOrd &lt;- sem(mOrd, D.ad, std.lv=T,\n              estimator = \"ULS\", # optional\n              ordered = colnames(D.ad)) # the list of ord vars\n#             ordered = T) # or just \"TRUE\" if all ordered"
  },
  {
    "objectID": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#results-1",
    "href": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#results-1",
    "title": "SEM with ordinal variables",
    "section": "Results (1)",
    "text": "Results (1)\n\ntemp = capture.output(summary(fitOrd, std=T))\ncat(c(temp[1:21], \"[...]\"), sep = \"\\n\")\n\nlavaan 0.6-19 ended normally after 16 iterations\n\n  Estimator                                        ULS\n  Optimization method                           NLMINB\n  Number of model parameters                        64\n\n                                                  Used       Total\n  Number of observations                          1044        1083\n\nModel Test User Model:\n                                                      \n  Test statistic                                73.746\n  Degrees of freedom                                26\n  P-value (Unknown)                                 NA\n\nParameter Estimates:\n\n  Parameterization                               Delta\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model        Unstructured\n[...]"
  },
  {
    "objectID": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#results-2",
    "href": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#results-2",
    "title": "SEM with ordinal variables",
    "section": "Results (2)",
    "text": "Results (2)\n\n\n[...]\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  cb =~                                                                 \n    Adaptability_1    0.659    0.021   30.831    0.000    0.659    0.659\n    Adaptability_2    0.659    0.021   30.841    0.000    0.659    0.659\n    Adaptability_3    0.664    0.021   30.983    0.000    0.664    0.664\n    Adaptability_4    0.551    0.020   26.957    0.000    0.551    0.551\n    Adaptability_5    0.619    0.021   29.486    0.000    0.619    0.619\n    Adaptability_6    0.553    0.020   27.012    0.000    0.553    0.553\n  em =~                                                                 \n    Adaptability_7    0.642    0.026   24.949    0.000    0.642    0.642\n    Adaptability_8    0.671    0.026   25.513    0.000    0.671    0.671\n    Adaptability_9    0.699    0.027   25.983    0.000    0.699    0.699\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  cb ~~                                                                 \n    em                0.587    0.022   26.729    0.000    0.587    0.587\n[...]"
  },
  {
    "objectID": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#results-3",
    "href": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#results-3",
    "title": "SEM with ordinal variables",
    "section": "Results (3)",
    "text": "Results (3)\n\n\n[...]\n\nThresholds:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n    Adaptblty_1|t1   -2.114    0.031  -68.285    0.000   -2.114   -2.114\n    Adaptblty_1|t2   -1.647    0.031  -53.181    0.000   -1.647   -1.647\n    Adaptblty_1|t3   -1.056    0.031  -34.089    0.000   -1.056   -1.056\n    Adaptblty_1|t4   -0.320    0.031  -10.331    0.000   -0.320   -0.320\n    Adaptblty_1|t5    0.495    0.031   15.982    0.000    0.495    0.495\n    Adaptblty_1|t6    1.181    0.031   38.145    0.000    1.181    1.181\n    Adaptblty_2|t1   -2.071    0.031  -66.899    0.000   -2.071   -2.071\n    Adaptblty_2|t2   -1.421    0.031  -45.908    0.000   -1.421   -1.421\n    Adaptblty_2|t3   -0.794    0.031  -25.642    0.000   -0.794   -0.794\n    Adaptblty_2|t4   -0.188    0.031   -6.084    0.000   -0.188   -0.188\n    Adaptblty_2|t5    0.492    0.031   15.895    0.000    0.492    0.492\n    Adaptblty_2|t6    1.257    0.031   40.590    0.000    1.257    1.257\n    Adaptblty_3|t1   -1.930    0.031  -62.322    0.000   -1.930   -1.930\n    Adaptblty_3|t2   -1.415    0.031  -45.696    0.000   -1.415   -1.415\n    Adaptblty_3|t3   -0.858    0.031  -27.715    0.000   -0.858   -0.858\n    Adaptblty_3|t4   -0.250    0.031   -8.070    0.000   -0.250   -0.250\n    Adaptblty_3|t5    0.350    0.031   11.316    0.000    0.350    0.350\n    Adaptblty_3|t6    1.162    0.031   37.529    0.000    1.162    1.162\n[...]"
  },
  {
    "objectID": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#results-4",
    "href": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#results-4",
    "title": "SEM with ordinal variables",
    "section": "Results (4)",
    "text": "Results (4)\n\n\n[...]\n    Adaptblty_4|t1   -1.962    0.031  -63.351    0.000   -1.962   -1.962\n    Adaptblty_4|t2   -1.476    0.031  -47.680    0.000   -1.476   -1.476\n    Adaptblty_4|t3   -0.817    0.031  -26.393    0.000   -0.817   -0.817\n    Adaptblty_4|t4   -0.257    0.031   -8.310    0.000   -0.257   -0.257\n    Adaptblty_4|t5    0.295    0.031    9.518    0.000    0.295    0.295\n    Adaptblty_4|t6    1.094    0.031   35.332    0.000    1.094    1.094\n    Adaptblty_5|t1   -1.978    0.031  -63.891    0.000   -1.978   -1.978\n    Adaptblty_5|t2   -1.408    0.031  -45.486    0.000   -1.408   -1.408\n    Adaptblty_5|t3   -0.781    0.031  -25.219    0.000   -0.781   -0.781\n    Adaptblty_5|t4   -0.196    0.031   -6.321    0.000   -0.196   -0.196\n    Adaptblty_5|t5    0.397    0.031   12.812    0.000    0.397    0.397\n    Adaptblty_5|t6    1.081    0.031   34.912    0.000    1.081    1.081\n    Adaptblty_6|t1   -1.705    0.031  -55.076    0.000   -1.705   -1.705\n    Adaptblty_6|t2   -1.186    0.031  -38.302    0.000   -1.186   -1.186\n    Adaptblty_6|t3   -0.654    0.031  -21.106    0.000   -0.654   -0.654\n    Adaptblty_6|t4   -0.055    0.031   -1.784    0.074   -0.055   -0.055\n    Adaptblty_6|t5    0.519    0.031   16.776    0.000    0.519    0.519\n    Adaptblty_6|t6    1.211    0.031   39.097    0.000    1.211    1.211\n[...]\n[...]"
  },
  {
    "objectID": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#thresholds-1",
    "href": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#thresholds-1",
    "title": "SEM with ordinal variables",
    "section": "Thresholds (1)",
    "text": "Thresholds (1)\n\nWe can assume that a discrete variable \\(x\\) (expressed with \\(k\\) ordered categories) represents an approximation of a continuous latent variable \\(\\xi\\), normally distributed with mean 0.\nTherefore, when we observe \\(x = i\\), it means that the true corresponding value \\(\\xi\\) is ranging between two values, i.e.\n\n\\[\n\\alpha_{i-1} &lt; \\xi \\leq \\alpha_i\n\\] where \\(\\alpha_0 = - \\infty, \\alpha_1 &lt; \\alpha_2 &lt; \\dots &lt; \\alpha_{k-1}\\) e \\(\\alpha_k = +\\infty\\) are the thresholds - Consequenlty we will have that, given a discrete ordered variable with \\(k\\) possible values, there are \\(k - 1\\) unknown thresholds."
  },
  {
    "objectID": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#thresholds-2",
    "href": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#thresholds-2",
    "title": "SEM with ordinal variables",
    "section": "Thresholds (2)",
    "text": "Thresholds (2)\nThresholds represent the link between the (continuous) latent variable \\(\\xi\\) and the observed values (on a discrete scale).\nFor example, the item Adaptability_1\n\n\n[1] -2.11 -1.65 -1.06 -0.32  0.49  1.18\n\n\nThat we can manually compute as:\n\nround(qnorm(cumsum(table(D.ad$Adaptability_1)) /\n             sum(table(D.ad$Adaptability_1))),2)\n\n    1     2     3     4     5     6     7 \n-2.12 -1.65 -1.06 -0.32  0.49  1.18   Inf"
  },
  {
    "objectID": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#results-5",
    "href": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#results-5",
    "title": "SEM with ordinal variables",
    "section": "Results (5)",
    "text": "Results (5)\n\n\n[...]\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .Adaptability_1    0.566                               0.566    0.566\n   .Adaptability_2    0.565                               0.565    0.565\n   .Adaptability_3    0.559                               0.559    0.559\n   .Adaptability_4    0.696                               0.696    0.696\n   .Adaptability_5    0.616                               0.616    0.616\n   .Adaptability_6    0.695                               0.695    0.695\n   .Adaptability_7    0.588                               0.588    0.588\n   .Adaptability_8    0.550                               0.550    0.550\n   .Adaptability_9    0.511                               0.511    0.511\n    cb                1.000                               1.000    1.000\n    em                1.000                               1.000    1.000\n\n[...]"
  },
  {
    "objectID": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#model-fit",
    "href": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#model-fit",
    "title": "SEM with ordinal variables",
    "section": "Model fit",
    "text": "Model fit\nThis works as usual\n\nfi &lt;- c(\"npar\", \"df\", \"chisq\", \n        \"cfi\", \"tli\", \"nnfi\", \"agfi\", \n        \"srmr\", \"rmsea\", \"bic\", \"aic\")\nfitmeasures(fitOrd, fit.measures = fi)\n# OR inspect(fitOrd, \"fit\")[fi]\n\n\n\n    npar       df    chisq \n64.00000 26.00000 73.74574 \n\n\n      cfi       tli      nnfi      agfi \n0.9883022 0.9838030 0.9838030 0.9964375 \n\n\n      srmr      rmsea        bic        aic \n0.03963876 0.04196029         NA         NA \n\n\nBUT YOU CANNOT INTERPRET THEM AS WE USED TO DO!"
  },
  {
    "objectID": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#model-fit-references",
    "href": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#model-fit-references",
    "title": "SEM with ordinal variables",
    "section": "Model fit, references",
    "text": "Model fit, references\nSome references for model fit with ordinal data:\n\nRMSEA (doi:10.1080/10705511.2019.1611434) tends to reject models with large datasets and 5-point scales\nCFI and TLI tend to overestimate model fit\nSRMR seems to be less biased\n\nBut there are many contradictory suggestions and it is not easy to navigate them. Look for what you need as simulation studies depend on many variables.\nThis (doi:10.1027/2698-1866/a000034) might be a helpful summary/reflection."
  },
  {
    "objectID": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#reviewer-2",
    "href": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#reviewer-2",
    "title": "SEM with ordinal variables",
    "section": "Reviewer 2",
    "text": "Reviewer 2"
  },
  {
    "objectID": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#prerequisites",
    "href": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#prerequisites",
    "title": "SEM with ordinal variables",
    "section": "Prerequisites",
    "text": "Prerequisites\nWhen we test multigroup invariance with ordinal data we assume that the THRESHOLDS are also equal between the two groups, but before running the analysis, remember:\n\nthe number of parameters is higher than with continuous data…and you split the data in two or more parts! Be sure you have enough data in each group\nall the observed indicators hold the same categories in each group, otherwise you cannot fit the model"
  },
  {
    "objectID": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#steps",
    "href": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#steps",
    "title": "SEM with ordinal variables",
    "section": "Steps",
    "text": "Steps\nThe steps that you should follow fo MG-CFA with ordinal data are slightly different:\n\nBaseline model, as the configural model\nEqual thresholds model, you should start by forcing the thresholds to be equal across groups\nEqual loadings and thresholds model, only now you can fix the loadings to be equal across groups"
  },
  {
    "objectID": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#in-r",
    "href": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#in-r",
    "title": "SEM with ordinal variables",
    "section": "In R",
    "text": "In R\nI use again the adaptability items. I manually added a group variable.\n\nD.ad$group &lt;- c(rep(\"G1\", 428), rep(\"G2\", 1083-428))\n# 1. FIT THE BASELINE/CONFIGURAL MODEL\nfConf &lt;- sem(mOrd, D.ad, std.lv=T, estimator = \"ULS\",\n             ordered = T, group = \"group\")\n# 2. FIT THE FIXED THRESHOLDS MODEL\nfTresh&lt;- sem(mOrd, D.ad, std.lv=T, estimator = \"ULS\",\n             ordered = T, group = \"group\",\n             group.equal = c(\"thresholds\"))\n# 3. FIT THE FIXED LOADINGS MODEL\nfLoad &lt;- sem(mOrd, D.ad, std.lv=T, estimator = \"ULS\",\n             ordered = T, group = \"group\",\n             group.equal = c(\"thresholds\", \"loadings\"))"
  },
  {
    "objectID": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#model-fit-comparison",
    "href": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#model-fit-comparison",
    "title": "SEM with ordinal variables",
    "section": "Model fit comparison",
    "text": "Model fit comparison\n\nfitTable &lt;- rbind(fitmeasures(fConf, fi),\n                  fitmeasures(fTresh, fi),\n                  fitmeasures(fLoad, fi))\n\n\n\n\n\nnpar\ndf\nchisq\ncfi\ntli\nnnfi\nagfi\nsrmr\nrmsea\nbic\naic\n\n\n\n\nbaseline\n128\n52\n91.652\n0.990\n0.987\n0.987\n0.996\n0.044\n0.038\nNA\nNA\n\n\nthresholds\n85\n95\n166.552\n0.983\n0.987\n0.987\n0.996\n0.044\n0.038\nNA\nNA\n\n\nloadings\n78\n102\n173.785\n0.983\n0.988\n0.988\n0.996\n0.046\n0.037\nNA\nNA"
  },
  {
    "objectID": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#model-results",
    "href": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#model-results",
    "title": "SEM with ordinal variables",
    "section": "Model results",
    "text": "Model results\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGroup 1\n\n\n\nGroup 2\n\n\n\nlhs\nop\nrhs\nest\n||\nlhs\nop\nrhs\nest\n\n\n\n\nLoadings\n\n\ncb\n=~\nAdaptability_1\n0.69\n||\ncb\n=~\nAdaptability_1\n0.64\n\n\ncb\n=~\nAdaptability_2\n0.69\n||\ncb\n=~\nAdaptability_2\n0.64\n\n\ncb\n=~\nAdaptability_3\n0.70\n||\ncb\n=~\nAdaptability_3\n0.64\n\n\ncb\n=~\nAdaptability_4\n0.54\n||\ncb\n=~\nAdaptability_4\n0.56\n\n\ncb\n=~\nAdaptability_5\n0.66\n||\ncb\n=~\nAdaptability_5\n0.59\n\n\ncb\n=~\nAdaptability_6\n0.65\n||\ncb\n=~\nAdaptability_6\n0.49\n\n\nem\n=~\nAdaptability_7\n0.66\n||\nem\n=~\nAdaptability_7\n0.63\n\n\nem\n=~\nAdaptability_8\n0.67\n||\nem\n=~\nAdaptability_8\n0.67\n\n\nem\n=~\nAdaptability_9\n0.73\n||\nem\n=~\nAdaptability_9\n0.67\n\n\nLatent covariance\n\n\ncb\n~~\nem\n0.62\n||\ncb\n~~\nem\n0.56\n\n\nThresholds\n\n\nAdaptability_1\n|\nt1\n-2.13\n||\nAdaptability_1\n|\nt1\n-2.11\n\n\nAdaptability_1\n|\nt2\n-1.69\n||\nAdaptability_1\n|\nt2\n-1.62\n\n\nAdaptability_1\n|\nt3\n-1.06\n||\nAdaptability_1\n|\nt3\n-1.05\n\n\nAdaptability_1\n|\nt4\n-0.36\n||\nAdaptability_1\n|\nt4\n-0.30\n\n\nAdaptability_1\n|\nt5\n0.52\n||\nAdaptability_1\n|\nt5\n0.48\n\n\nAdaptability_1\n|\nt6\n1.14\n||\nAdaptability_1\n|\nt6\n1.21"
  },
  {
    "objectID": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#additional-materials",
    "href": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#additional-materials",
    "title": "SEM with ordinal variables",
    "section": "Additional materials",
    "text": "Additional materials\n\nSvetina et al. (doi:10.1080/10705511.2019.1602776) tutorial, suggestions, and model fit recommendations for MG-CFA with ordinal data\nEnrico Perinelli held a psicostat meeting on the topic following Svetina et al.’s code"
  },
  {
    "objectID": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#exercises-lab",
    "href": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#exercises-lab",
    "title": "SEM with ordinal variables",
    "section": "Exercises → Lab",
    "text": "Exercises → Lab\nOpen and work through:\n\nlabs/lab08_ordinal_sem_invariance.qmd\n\nFocus on:\n\nfitting the same CFA/SEM treating items as continuous vs ordered\ninspecting thresholds and (polychoric) correlations\nMG-CFA steps with ordinal indicators (thresholds → thresholds + loadings)"
  },
  {
    "objectID": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#take-home-summary",
    "href": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#take-home-summary",
    "title": "SEM with ordinal variables",
    "section": "Take-home summary",
    "text": "Take-home summary\nThree things to remember:\n\nOrdinal items are usually modeled via an underlying continuous latent response + thresholds\nEstimation changes (DWLS/WLSMV/ULS), and fit indices are not “plug-and-play” as in ML for continuous data\nWith ordinal MG-CFA, threshold invariance is a key early step (often before loadings)"
  },
  {
    "objectID": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#further-reading",
    "href": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#further-reading",
    "title": "SEM with ordinal variables",
    "section": "Further reading",
    "text": "Further reading\n\nSvetina et al. tutorial + simulation-based guidance for ordinal MG-CFA\n\nSimulation papers on fit indices with ordinal data (RMSEA/CFI/TLI/SRMR)\n\n(See the “Additional materials” slide for links.)"
  },
  {
    "objectID": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#references",
    "href": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#references",
    "title": "SEM with ordinal variables",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#data-quality-checks-before-fitting",
    "href": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#data-quality-checks-before-fitting",
    "title": "SEM with ordinal variables",
    "section": "Data quality checks (before fitting)",
    "text": "Data quality checks (before fitting)\nBefore you run WLSMV / ordinal CFA, check:\n\nCategory frequencies\nAny category with very few responses? (e.g., &lt; 5% or tiny counts)\nEmpty / near-empty pairs\nSome item pairs may have empty cells in their K×K tables → unstable polychorics\nExtreme skew / floor–ceiling\nItems with almost everyone in the same category carry little information\nToo many categories for N\nMany categories + modest sample size → sparse tables and unstable estimation\n\n\n\n\nIf you see sparse categories, consider collapsing adjacent categories (with a substantive rationale)."
  },
  {
    "objectID": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#quick-checks-in-r-copypaste",
    "href": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#quick-checks-in-r-copypaste",
    "title": "SEM with ordinal variables",
    "section": "Quick checks in R (copy/paste)",
    "text": "Quick checks in R (copy/paste)\n\nvars &lt;- c(\"item1\",\"item2\",\"item3\",\"item4\")   # ordered items\n\n# 1) Univariate category counts\nlapply(dat[vars], table)\n\n# 2) Univariate proportions\nlapply(dat[vars], prop.table)\n\n# 3) Flag sparse categories (e.g., &lt; 5% per category)\nsparse &lt;- lapply(dat[vars], function(x) prop.table(table(x)) &lt; .05)\nsparse\n\n# 4) Pairwise contingency tables for suspicious item pairs\n# (Pick a few pairs; don’t do all pairs if you have many items.)\ntable(dat$item1, dat$item2)\ntable(dat$item3, dat$item4)\n\nWhat to do if categories are sparse\nOptions (in order of “least invasive”):\n\nCollapse adjacent categories (e.g., merge 1–2 or 4–5)\n\ndo it consistently across groups/time if you’ll test invariance\n\nDrop an item that is essentially constant or unusable\nCollect more data (sparse tables are fundamentally a sample-size problem)\n\n\n\n\nAvoid “data-driven collapsing” that changes the construct meaning. Document the decision clearly."
  },
  {
    "objectID": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#what-to-do-if-categories-are-sparse",
    "href": "slides/08_ordinal-sem_thresholds_wlsmv_ordinal-invariance.html#what-to-do-if-categories-are-sparse",
    "title": "SEM with ordinal variables",
    "section": "What to do if categories are sparse",
    "text": "What to do if categories are sparse\nOptions (in order of “least invasive”):\n\nCollapse adjacent categories (e.g., merge 1–2 or 4–5)\n\ndo it consistently across groups/time if you’ll test invariance\n\nDrop an item that is essentially constant or unusable\nCollect more data (sparse tables are fundamentally a sample-size problem)\n\n\n\n\nAvoid “data-driven collapsing” that changes the construct meaning. Document the decision clearly."
  },
  {
    "objectID": "labs/lab08_ordinal_sem_invariance.html",
    "href": "labs/lab08_ordinal_sem_invariance.html",
    "title": "Lab 08 — Ordinal CFA/SEM: thresholds, WLSMV, and ordinal invariance",
    "section": "",
    "text": "In this lab you will:\n\nCreate an ordinal version of a familiar CFA dataset\nFit a CFA treating items as continuous (wrong-on-purpose) vs ordinal (WLSMV)\nInterpret thresholds and why ordinal models replace intercepts with thresholds\nUse CFA diagnostics (residuals + MI/EPC) in the ordinal setting\nTest a simple ordinal measurement invariance ladder across groups"
  },
  {
    "objectID": "labs/lab08_ordinal_sem_invariance.html#a-continuous-ml-on-ordinal-codes-wrong-on-purpose",
    "href": "labs/lab08_ordinal_sem_invariance.html#a-continuous-ml-on-ordinal-codes-wrong-on-purpose",
    "title": "Lab 08 — Ordinal CFA/SEM: thresholds, WLSMV, and ordinal invariance",
    "section": "1a) Continuous (ML) on ordinal codes (wrong-on-purpose)",
    "text": "1a) Continuous (ML) on ordinal codes (wrong-on-purpose)\n\n\nShow code\nfit_cont &lt;- cfa(m3, data = dat_ord_num, std.lv = TRUE)  # ML default\nfitMeasures(fit_cont, c(\"chisq\",\"df\",\"cfi\",\"tli\",\"rmsea\",\"srmr\"))\n\n\n chisq     df    cfi    tli  rmsea   srmr \n79.046 24.000  0.928  0.891  0.087  0.060"
  },
  {
    "objectID": "labs/lab08_ordinal_sem_invariance.html#b-ordinal-wlsmv-with-thresholds",
    "href": "labs/lab08_ordinal_sem_invariance.html#b-ordinal-wlsmv-with-thresholds",
    "title": "Lab 08 — Ordinal CFA/SEM: thresholds, WLSMV, and ordinal invariance",
    "section": "1b) Ordinal (WLSMV) with thresholds",
    "text": "1b) Ordinal (WLSMV) with thresholds\n\n\nShow code\nfit_ord &lt;- cfa(\n  m3,\n  data = dat_ord,\n  ordered = vars,              # tells lavaan these are ordinal\n  std.lv = TRUE,\n  parameterization = \"theta\"   # common choice for categorical indicators\n  # estimator is set automatically to WLSMV when ordered= is used\n)\n\nfitMeasures(fit_ord, c(\"chisq\",\"df\",\"cfi\",\"tli\",\"rmsea\",\"srmr\"))\n\n\n chisq     df    cfi    tli  rmsea   srmr \n56.708 24.000  0.987  0.980  0.067  0.065 \n\n\nQuestions (answer in words)\n\nWhich fit indices change the most between the two analyses?\nDo standardized loadings change meaningfully? Why might they?\nWhat is the conceptual mistake of treating ordinal codes as if they were continuous?"
  },
  {
    "objectID": "labs/lab08_ordinal_sem_invariance.html#a-standardized-residuals",
    "href": "labs/lab08_ordinal_sem_invariance.html#a-standardized-residuals",
    "title": "Lab 08 — Ordinal CFA/SEM: thresholds, WLSMV, and ordinal invariance",
    "section": "4a) Standardized residuals",
    "text": "4a) Standardized residuals\n\n\nShow code\nres_std &lt;- residuals(fit_ord, type = \"cor\")$cov\nres_std\n\n\n       x1     x2     x3     x4     x5     x6     x7     x8     x9\nx1  0.000                                                        \nx2 -0.052  0.000                                                 \nx3 -0.006  0.101  0.000                                          \nx4  0.090  0.050 -0.079  0.000                                   \nx5 -0.016  0.020 -0.133 -0.004  0.000                            \nx6  0.017 -0.001 -0.048 -0.012  0.010  0.000                     \nx7 -0.144 -0.165 -0.073  0.056 -0.013  0.001  0.000              \nx8 -0.065 -0.043  0.008 -0.058 -0.054 -0.033  0.161  0.000       \nx9  0.068  0.032  0.150  0.046  0.061 -0.028 -0.074 -0.072  0.000\n\n\nFind the largest absolute residuals:\n\n\nShow code\nR &lt;- res_std\ndiag(R) &lt;- NA\ntop_res &lt;- as.data.frame(as.table(R))\ntop_res &lt;- top_res[order(abs(top_res$Freq), decreasing = TRUE), ]\nhead(top_res, 10)\n\n\n   Var1 Var2   Freq\n16   x7   x2 -0.165\n56   x2   x7 -0.165\n62   x8   x7  0.161\n70   x7   x8  0.161\n27   x9   x3  0.150\n75   x3   x9  0.150\n7    x7   x1 -0.144\n55   x1   x7 -0.144\n23   x5   x3 -0.133\n39   x3   x5 -0.133"
  },
  {
    "objectID": "labs/lab08_ordinal_sem_invariance.html#b-modification-indices-epcsepc",
    "href": "labs/lab08_ordinal_sem_invariance.html#b-modification-indices-epcsepc",
    "title": "Lab 08 — Ordinal CFA/SEM: thresholds, WLSMV, and ordinal invariance",
    "section": "4b) Modification indices + EPC/SEPC",
    "text": "4b) Modification indices + EPC/SEPC\n\n\nShow code\nmi &lt;- modificationIndices(fit_ord, sort. = TRUE)\nhead(mi[, c(\"lhs\",\"op\",\"rhs\",\"mi\",\"epc\",\"sepc.all\")], 15)\n\n\n        lhs op rhs    mi    epc sepc.all\n133      x7 ~~  x8 29.83 -0.651   -0.651\n87   visual =~  x9 29.44 -1.156   -0.662\n135      x8 ~~  x9 12.48  1.043    1.043\n85   visual =~  x7 12.04  0.348    0.295\n90  textual =~  x3 11.41  0.338    0.280\n120      x3 ~~  x9  9.73 -0.446   -0.446\n112      x2 ~~  x7  7.30  0.239    0.239\n105      x1 ~~  x7  7.03  0.407    0.407\n93  textual =~  x9  6.51 -0.314   -0.180\n86   visual =~  x8  5.60  0.309    0.239\n88  textual =~  x1  5.60 -0.496   -0.273\n134      x7 ~~  x9  5.50  0.522    0.522\n116      x3 ~~  x5  5.10  0.413    0.413\n96    speed =~  x3  4.72 -0.242   -0.201\n92  textual =~  x8  4.30  0.158    0.122\n\n\nQuestions\n\nDo residuals and MI point to the same problematic pairs?\nIn an ordinal CFA, which modifications are most common?\n\ncorrelated residuals (local dependence / method)\ncross-loadings (threaten simple structure)\nfreeing thresholds/loadings across groups (invariance context)"
  },
  {
    "objectID": "labs/lab08_ordinal_sem_invariance.html#a-configural-model-same-pattern-of-loadings",
    "href": "labs/lab08_ordinal_sem_invariance.html#a-configural-model-same-pattern-of-loadings",
    "title": "Lab 08 — Ordinal CFA/SEM: thresholds, WLSMV, and ordinal invariance",
    "section": "5a) Configural model (same pattern of loadings)",
    "text": "5a) Configural model (same pattern of loadings)\n\n\nShow code\ndat_ord_g &lt;- dat_ord\ndat_ord_g$school &lt;- dat_full$school  # keep group variable\n\nfit_g0 &lt;- cfa(\n  m3, data = dat_ord_g,\n  group = \"school\",\n  ordered = vars,\n  std.lv = TRUE,\n  parameterization = \"theta\"\n)\n\nfitMeasures(fit_g0, c(\"cfi\",\"tli\",\"rmsea\",\"srmr\"))\n\n\n  cfi   tli rmsea  srmr \n0.988 0.982 0.062 0.073"
  },
  {
    "objectID": "labs/lab08_ordinal_sem_invariance.html#b-threshold-invariance-equal-thresholds",
    "href": "labs/lab08_ordinal_sem_invariance.html#b-threshold-invariance-equal-thresholds",
    "title": "Lab 08 — Ordinal CFA/SEM: thresholds, WLSMV, and ordinal invariance",
    "section": "5b) Threshold invariance (equal thresholds)",
    "text": "5b) Threshold invariance (equal thresholds)\n\n\nShow code\nfit_g1 &lt;- cfa(\n  m3, data = dat_ord_g,\n  group = \"school\",\n  group.equal = c(\"thresholds\"),\n  ordered = vars,\n  std.lv = TRUE,\n  parameterization = \"theta\"\n)\n\nfitMeasures(fit_g1, c(\"cfi\",\"tli\",\"rmsea\",\"srmr\"))\n\n\n  cfi   tli rmsea  srmr \n0.970 0.970 0.082 0.075"
  },
  {
    "objectID": "labs/lab08_ordinal_sem_invariance.html#c-threshold-loading-invariance-often-the-key-step",
    "href": "labs/lab08_ordinal_sem_invariance.html#c-threshold-loading-invariance-often-the-key-step",
    "title": "Lab 08 — Ordinal CFA/SEM: thresholds, WLSMV, and ordinal invariance",
    "section": "5c) Threshold + loading invariance (often the key step)",
    "text": "5c) Threshold + loading invariance (often the key step)\n\n\nShow code\nfit_g2 &lt;- cfa(\n  m3, data = dat_ord_g,\n  group = \"school\",\n  group.equal = c(\"thresholds\", \"loadings\"),\n  ordered = vars,\n  std.lv = TRUE,\n  parameterization = \"theta\"\n)\n\nfitMeasures(fit_g2, c(\"cfi\",\"tli\",\"rmsea\",\"srmr\"))\n\n\n  cfi   tli rmsea  srmr \n0.972 0.974 0.076 0.075"
  },
  {
    "objectID": "labs/lab08_ordinal_sem_invariance.html#d-compare-nested-models-wlsmv-difference-tests",
    "href": "labs/lab08_ordinal_sem_invariance.html#d-compare-nested-models-wlsmv-difference-tests",
    "title": "Lab 08 — Ordinal CFA/SEM: thresholds, WLSMV, and ordinal invariance",
    "section": "5d) Compare nested models (WLSMV difference tests)",
    "text": "5d) Compare nested models (WLSMV difference tests)\n\n\nShow code\nlavTestLRT(fit_g0, fit_g1, fit_g2)\n\n\n\nScaled Chi-Squared Difference Test (method = \"satorra.2000\")\n\nlavaan-&gt;lavTestLRT():  \n   lavaan NOTE: The \"Chisq\" column contains standard test statistics, not the \n   robust test that should be reported per model. A robust difference test is \n   a function of two standard (not robust) statistics.\n       Df AIC BIC Chisq Chisq diff Df diff Pr(&gt;Chisq)    \nfit_g0 48          75.7                                  \nfit_g1 72         143.7       93.7      24    3.4e-10 ***\nfit_g2 78         144.6        1.0       6       0.98    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nInterpretation tasks\n\nDoes adding equal thresholds worsen fit meaningfully?\nDoes adding equal loadings (on top of thresholds) worsen fit meaningfully?\nBased on this ladder, what comparisons would you feel comfortable making?\n\nfactor structure? (configural)\nrelations among factors? (threshold+loading invariance often needed)\nlatent means? (typically needs at least thresholds+loadings; and later we discuss partial invariance)"
  },
  {
    "objectID": "labs/lab08_ordinal_sem_invariance.html#deliverables",
    "href": "labs/lab08_ordinal_sem_invariance.html#deliverables",
    "title": "Lab 08 — Ordinal CFA/SEM: thresholds, WLSMV, and ordinal invariance",
    "section": "Deliverables",
    "text": "Deliverables\n\nA short paragraph: continuous-vs-ordinal CFA — what changed and why?\nA table (or bullet list) summarizing:\n\ntop thresholds for one item\ntop residual pairs + what you think they represent\n\nInvariance summary across school: configural vs thresholds vs thresholds+loadings"
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#today-in-the-workflow",
    "href": "slides/06_missing-data_robustness_reporting.html#today-in-the-workflow",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Today in the workflow",
    "text": "Today in the workflow\nSpecify → Identify → Estimate → Evaluate → Revise/Report\n\n\n\nToday we practice a sensitivity mindset: Same model, different reasonable choices → does the conclusion change?"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#today-in-the-workflow",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#today-in-the-workflow",
    "title": "Multilevel Confirmatory Factor Analysis",
    "section": "Today in the workflow",
    "text": "Today in the workflow\nSpecify → Identify → Estimate → Evaluate → Revise / Report\n\n\n\nFocus today: what changes when data are clustered (schools/teams) or repeated (ESM / within-person).\nKey idea: with clustering we need to model two covariance structures (within & between)."
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#learning-objectives",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#learning-objectives",
    "title": "Multilevel Confirmatory Factor Analysis",
    "section": "Learning objectives",
    "text": "Learning objectives\nBy the end you should be able to:\n\nDiagnose non-independence (clusters / repeated measures) and why it matters\nExplain within vs between covariance (and how to compute them)\nFit a two-level CFA in lavaan (level: blocks + cluster=)\nRead level-specific fit (especially srmr_within vs srmr_between)\nUnderstand cross-level invariance and its link to construct meaning (e.g., traits as distributions of states)"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#outline-come-nel-pdf",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#outline-come-nel-pdf",
    "title": "Multilevel / clustered-data strategy",
    "section": "Outline (come nel PDF)",
    "text": "Outline (come nel PDF)\n\nSEM, CFA e razionale della CFA multilivello\n\nHandZone: come condurre una CFA multilivello con lavaan\n\nEsempio pratico: Gruppi e individui\n\nEsempi pratici: Misure ripetute\n\nInvarianza cross-livello: dalla pratica alla teoria"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#multilevel-what",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#multilevel-what",
    "title": "Multilevel Confirmatory Factor Analysis",
    "section": "Multilevel what!?",
    "text": "Multilevel what!?\nSEM = multivariate linear models formalized as systems of equations.\n\n\nlinear models\n\\(\\text{PERF}=\\beta_1\\text{IQ}+\\beta_2\\text{ANX}+\\epsilon\\)\n\n\n\n\n\n\nSEM system\n\\[\n\\begin{aligned}\n\\text{ANX} &= \\beta_1\\text{SEFF} + \\epsilon_2\\\\\n\\text{PERF} &= \\beta_2\\text{SEFF} + \\beta_3\\text{ANX} + \\epsilon_3\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#le-due-parti-fondamentali-di-un-sem",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#le-due-parti-fondamentali-di-un-sem",
    "title": "Multilevel / clustered-data strategy",
    "section": "Le due parti fondamentali di un SEM",
    "text": "Le due parti fondamentali di un SEM\nUn SEM include generalmente:\n\nModello strutturale: relazioni “regression-like” tra (latenti o osservate)\n\nModello di misurazione: relazioni tra latenti e indicatori (CFA)\n\n[INSERIRE FIGURA: “Le due parti fondamentali” (schema SEM dal PDF)]"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#analisi-fattoriale-confermativa-cfa",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#analisi-fattoriale-confermativa-cfa",
    "title": "Multilevel / clustered-data strategy",
    "section": "Analisi fattoriale confermativa (CFA)",
    "text": "Analisi fattoriale confermativa (CFA)\nUna CFA include solo il modello di misurazione:\n\ndefinisce i fattori (latenti) e quali indicatori li misurano\nstima saturazioni, varianze residue, (co)varianze tra fattori\nvaluta l’adattamento del modello a partire da (S) e (())\n\n[INSERIRE FIGURA: “CFA” / “Struttura fattoriale” dal PDF]"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#punto-di-partenza-la-matrice-di-covarianza",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#punto-di-partenza-la-matrice-di-covarianza",
    "title": "Multilevel / clustered-data strategy",
    "section": "Punto di partenza: la matrice di covarianza",
    "text": "Punto di partenza: la matrice di covarianza\nSEM/CFA partono dalla matrice di covarianza osservata (S):\n\\[\n\\mathrm{cov}(x,y) = \\frac{\\sum (x_i-\\bar x)(y_i-\\bar y)}{N}\n\\]\nIl modello stima parametri () tali che:\n\nla matrice implicata (()) “assomigli” a (S)\nla differenza tra (S) e () guida fit e diagnostica"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#e-se-i-dati-sono-multilivello",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#e-se-i-dati-sono-multilivello",
    "title": "Multilevel / clustered-data strategy",
    "section": "E se i dati sono multilivello?",
    "text": "E se i dati sono multilivello?\nQuando le osservazioni sono nidificate (cluster) o ripetute:\n\nsi creano dipendenze locali (osservazioni nello stesso cluster più simili)\nsi viola l’assunto di indipendenza\nignorare la struttura può alterare SE e inferenza (e a volte anche stime)\n\nEsempi: - persone entro scuole/classi/team - misure ripetute entro persone (ESM, longitudinali intensivi)"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#scomposizione-within-vs-between-intuizione",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#scomposizione-within-vs-between-intuizione",
    "title": "Multilevel / clustered-data strategy",
    "section": "Scomposizione within vs between (intuizione)",
    "text": "Scomposizione within vs between (intuizione)\nPossiamo decomporre la (co)varianza in:\n\nBetween (L2): covarianza tra le medie dei cluster\n\nWithin (L1): covarianza tra gli scarti dalla media del cluster\n\nInterpretazione: - Between: cluster con media alta su X hanno media alta su Y? - Within: unità “sopra la media del proprio cluster” su X sono anche sopra su Y?"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#come-si-ottengono-pseudo-codice",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#come-si-ottengono-pseudo-codice",
    "title": "Multilevel / clustered-data strategy",
    "section": "Come si ottengono (pseudo-codice)",
    "text": "Come si ottengono (pseudo-codice)\n\n# df: long data, cluster = id_cluster\nwide &lt;- aggregate(cbind(x1, x2) ~ cluster, data = df, FUN = mean)  # between means\ndf &lt;- merge(df, wide, by = \"cluster\", suffixes = c(\"\", \".b\"))\ndf$x1.w &lt;- df$x1 - df$x1.b\ndf$x2.w &lt;- df$x2 - df$x2.b\n\nS_between &lt;- cov(wide[, c(\"x1\",\"x2\")])\nS_within  &lt;- cov(df[, c(\"x1.w\",\"x2.w\")])"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#multilevel-cfa-idea",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#multilevel-cfa-idea",
    "title": "Multilevel / clustered-data strategy",
    "section": "Multilevel CFA (idea)",
    "text": "Multilevel CFA (idea)\nLa MCFA usa due strutture:\n\nfattori e residui a livello within\nfattori e residui a livello between\n\nObiettivo: capire se la struttura di misura è coerente a entrambi i livelli e valutare: - saturazioni livello-specifiche - varianze residue livello-specifiche - fit livello-specifico\n[INSERIRE FIGURA: “Multilevel CFA” (schema within/between) dal PDF]"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#handzone-cfa-con-lavaan-recap-veloce",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#handzone-cfa-con-lavaan-recap-veloce",
    "title": "Multilevel / clustered-data strategy",
    "section": "HandZone: CFA con lavaan (recap veloce)",
    "text": "HandZone: CFA con lavaan (recap veloce)\n\ndata(HolzingerSwineford1939, package = \"lavaan\")\n\nm3 &lt;- '\n  visual  =~ x1 + x2 + x3\n  textual =~ x4 + x5 + x6\n  speed   =~ x7 + x8 + x9\n'\nm1 &lt;- 'general =~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9'\n\nfit3 &lt;- cfa(m3, data = HolzingerSwineford1939)\nfit1 &lt;- cfa(m1, data = HolzingerSwineford1939)"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#fit-e-confronto-tra-modelli-recap",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#fit-e-confronto-tra-modelli-recap",
    "title": "Multilevel / clustered-data strategy",
    "section": "Fit e confronto tra modelli (recap)",
    "text": "Fit e confronto tra modelli (recap)\n\nlavInspect(fit3, \"fit\")[c(\"chisq\",\"df\",\"rmsea\",\"cfi\",\"tli\",\"srmr\")]\nlavInspect(fit1, \"fit\")[c(\"chisq\",\"df\",\"rmsea\",\"cfi\",\"tli\",\"srmr\")]\n\n[INSERIRE FIGURA/TABELLA: confronto fit (come nel PDF)]"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#multilevel-cfa-in-lavaan-sintassi",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#multilevel-cfa-in-lavaan-sintassi",
    "title": "Multilevel / clustered-data strategy",
    "section": "Multilevel CFA in lavaan: sintassi",
    "text": "Multilevel CFA in lavaan: sintassi\nDue ingredienti:\n\nblocchi level: 1 e level: 2\nargomento cluster = \"ID\" in cfa() / sem()\n\n\nm2l &lt;- '\n  level: 1\n    TD_w =~ d1 + d2 + d3 + d4\n  level: 2\n    TD_b =~ d1 + d2 + d3 + d4\n'\n\nfit2l &lt;- cfa(m2l, data = ESMdata, cluster = \"ID\")\n\n[INSERIRE FIGURA: “MCFA con R (ESM)” / esempio HandZone dal PDF]"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#fit-livello-specifico-punto-chiave-pratico",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#fit-livello-specifico-punto-chiave-pratico",
    "title": "Multilevel / clustered-data strategy",
    "section": "Fit livello-specifico (punto chiave pratico)",
    "text": "Fit livello-specifico (punto chiave pratico)\nIn MCFA:\n\nRMSEA/CFI/TLI sono spesso guidati dal within (molte più osservazioni a L1)\nSRMR è disponibile separatamente:\n\nsrmr_within\nsrmr_between (molto informativo per L2)\n\n\n\nlavInspect(fit2l, \"fit\")[c(\"rmsea\",\"cfi\",\"tli\",\"srmr_within\",\"srmr_between\")]"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#parametri-livello-specifici",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#parametri-livello-specifici",
    "title": "Multilevel / clustered-data strategy",
    "section": "Parametri livello-specifici",
    "text": "Parametri livello-specifici\n\n# within loadings (indicativo: righe iniziali)\nstandardizedSolution(fit2l)[1:4, ]\n\n# between loadings (indicativo: righe successive)\nstandardizedSolution(fit2l)[15:18, ]\n\n\n\n\nNel PDF: nota che spesso le saturazioni between risultano più forti (Hox, 2010)."
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#esempio-gruppi-soggetti-nidificati-entro-scuoleteam",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#esempio-gruppi-soggetti-nidificati-entro-scuoleteam",
    "title": "Multilevel / clustered-data strategy",
    "section": "Esempio (gruppi): soggetti nidificati entro scuole/team",
    "text": "Esempio (gruppi): soggetti nidificati entro scuole/team\nQuando soggetti sono reclutati in scuole/classi/organizzazioni:\n\ncorrelazioni più forti entro gruppo\npossibile componente “shared” (contesto / composizione)\ndomanda: il costrutto esiste anche a livello gruppo?\n\n[INSERIRE SLIDE: descrizione dataset “participation” (campione + 4 item) dal PDF]"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#single-level-cfa-mlr-vs-wlsmv",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#single-level-cfa-mlr-vs-wlsmv",
    "title": "Multilevel / clustered-data strategy",
    "section": "Single-level CFA (MLR vs WLSMV)",
    "text": "Single-level CFA (MLR vs WLSMV)\n[INSERIRE FIGURA: “Single-level CFA (MLR vs WLSMV)” dal PDF]"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#modello-preliminare-l1-pooled-within-hox-2010",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#modello-preliminare-l1-pooled-within-hox-2010",
    "title": "Multilevel / clustered-data strategy",
    "section": "Modello preliminare L1: pooled-within (Hox, 2010)",
    "text": "Modello preliminare L1: pooled-within (Hox, 2010)\nIdea: fit della CFA sulla matrice pooled-within prima di passare al two-level.\n\nlwd &lt;- na.omit(edudata[, c(\"schoolID\", paste0(\"p\",2:5))])\n\nms &lt;- data.frame(\n  p2 = ave(lwd$p2, lwd$schoolID),\n  p3 = ave(lwd$p3, lwd$schoolID),\n  p4 = ave(lwd$p4, lwd$schoolID),\n  p5 = ave(lwd$p5, lwd$schoolID)\n)\n\ncs &lt;- lwd[, 2:ncol(lwd)] - ms\n\npw.cov &lt;- (cov(cs) * (nrow(lwd) - 1)) / (nrow(lwd) - nlevels(lwd$schoolID))\n\nm1 &lt;- 'EP =~ p2 + p3 + p4 + p5'\nfit_pw &lt;- cfa(m1, sample.cov = pw.cov, sample.nobs = nrow(lwd))\nlavInspect(fit_pw, \"fit\")[c(\"chisq\",\"df\",\"rmsea\",\"cfi\",\"tli\",\"srmr\")]"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#modelli-preliminari-l2-benchmark",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#modelli-preliminari-l2-benchmark",
    "title": "Multilevel / clustered-data strategy",
    "section": "Modelli preliminari L2: benchmark",
    "text": "Modelli preliminari L2: benchmark\nBenchmark models (Hox):\n\nNull (L2): nessuna varianza a L2 (se va bene → poca struttura between)\nIndependence (L2): solo varianze, niente covarianze\nSaturated (L2): L2 saturo (se necessario per fit → la struttura factor L2 non spiega bene)\n\n\nm_null &lt;- '\n  level: 1\n    p.w =~ p2 + p3 + p4 + p5\n  level: 2\n    p2 ~~ 0*p2\n    p3 ~~ 0*p3\n    p4 ~~ 0*p4\n    p5 ~~ 0*p5\n'\n\nm_ind &lt;- '\n  level: 1\n    p.w =~ p2 + p3 + p4 + p5\n  level: 2\n    p2 ~~ p2\n    p3 ~~ p3\n    p4 ~~ p4\n    p5 ~~ p5\n'\n\nm_sat &lt;- '\n  level: 1\n    p.w =~ p2 + p3 + p4 + p5\n  level: 2\n    p2 ~~ p2 + p3 + p4 + p5\n    p3 ~~ p3 + p4 + p5\n    p4 ~~ p4 + p5\n    p5 ~~ p5\n'"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#mcfa-modello-ipotizzato-1-fattore-a-entrambi-i-livelli",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#mcfa-modello-ipotizzato-1-fattore-a-entrambi-i-livelli",
    "title": "Multilevel / clustered-data strategy",
    "section": "MCFA: modello ipotizzato (1 fattore a entrambi i livelli)",
    "text": "MCFA: modello ipotizzato (1 fattore a entrambi i livelli)\n\nm_mcfa &lt;- '\n  level: 1\n    p.w =~ p2 + p3 + p4 + p5\n  level: 2\n    p.b =~ p2 + p3 + p4 + p5\n'\n\nfit_mcfa &lt;- cfa(m_mcfa, data = edudata, cluster = \"schoolID\", estimator = \"MLR\")\n\n[INSERIRE FIGURA: “MCFA: modello ipotizzato” dal PDF]"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#saturazioni-livello-specifiche-ω-idea-dal-pdf",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#saturazioni-livello-specifiche-ω-idea-dal-pdf",
    "title": "Multilevel / clustered-data strategy",
    "section": "Saturazioni livello-specifiche + ω (idea dal PDF)",
    "text": "Saturazioni livello-specifiche + ω (idea dal PDF)\n\nsl &lt;- standardizedSolution(fit_mcfa)[c(1:4, 15:18), 1:6]\n\nsl.w &lt;- sl[1:4, \"est.std\"]; re.w &lt;- 1 - sl.w^2\nomega_w &lt;- sum(sl.w)^2 / (sum(sl.w)^2 + sum(re.w))\n\nsl.b &lt;- sl[5:8, \"est.std\"]; re.b &lt;- 1 - sl.b^2\nomega_b &lt;- sum(sl.b)^2 / (sum(sl.b)^2 + sum(re.b))\n\nround(c(omega_within = omega_w, omega_between = omega_b), 2)"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#misure-ripetute-entro-persona-esm-stressor-strain",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#misure-ripetute-entro-persona-esm-stressor-strain",
    "title": "Multilevel / clustered-data strategy",
    "section": "Misure ripetute entro persona (ESM): stressor & strain",
    "text": "Misure ripetute entro persona (ESM): stressor & strain\nDati ESM (misure ripetute):\n\nwithin-person = fluttuazioni “state”\nbetween-person = differenze stabili “trait-like”\n\n[INSERIRE FIGURA: “stressor e strain” (design ESM) dal PDF]"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#strutture-alternative-withinbetween-più-fattori",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#strutture-alternative-withinbetween-più-fattori",
    "title": "Multilevel / clustered-data strategy",
    "section": "Strutture alternative within/between (più fattori)",
    "text": "Strutture alternative within/between (più fattori)\nIdea: confrontare dimensionalità diversa tra livelli (3×3, 2×3, 2×2, 3×2).\n\nm3x3 &lt;- '\n  level: 1\n    NV_w =~ v1 + v2 + v3\n    TA_w =~ t1 + t2 + t3\n    FA_w =~ f1 + f2 + f3\n  level: 2\n    NV_b =~ v1 + v2 + v3\n    TA_b =~ t1 + t2 + t3\n    FA_b =~ f1 + f2 + f3\n'\n\nm2x3 &lt;- '\n  level: 1\n    NV_w =~ v1 + v2 + v3\n    TA_w =~ t1 + t2 + t3\n    FA_w =~ f1 + f2 + f3\n  level: 2\n    NV_b =~ v1 + v2 + v3 + t1 + t2 + t3\n    FA_b =~ f1 + f2 + f3\n'\n\nm2x2 &lt;- '\n  level: 1\n    NV_w =~ v1 + v2 + v3 + t1 + t2 + t3\n    FA_w =~ f1 + f2 + f3\n  level: 2\n    NV_b =~ v1 + v2 + v3 + t1 + t2 + t3\n    FA_b =~ f1 + f2 + f3\n'\n\nm3x2 &lt;- '\n  level: 1\n    NV_w =~ v1 + v2 + v3 + t1 + t2 + t3\n    FA_w =~ f1 + f2 + f3\n  level: 2\n    NV_b =~ v1 + v2 + v3\n    TA_b =~ t1 + t2 + t3\n    FA_b =~ f1 + f2 + f3\n'\n\n[INSERIRE FIGURA: “MCFA con più di un fattore / strutture alternative” dal PDF]"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#varianze-negative-a-livello-2-heywood-cases",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#varianze-negative-a-livello-2-heywood-cases",
    "title": "Multilevel / clustered-data strategy",
    "section": "Varianze negative a livello 2 (Heywood cases)",
    "text": "Varianze negative a livello 2 (Heywood cases)\nNel two-level CFA possono apparire varianze residue negative a L2:\n\nspesso perché la varianza residua vera è ~0 a L2\noppure per misspecification / campione piccolo a livello cluster\n\nNel PDF: discussione + citazione (Kolenikov & Bollen, 2012).\n\np &lt;- parameterEstimates(fit3x3)\np[p$op == \"~~\" & p$ci.lower &lt; 0, ]\n\n[INSERIRE SLIDE: “Analisi casi influenti” dal PDF (lista ID rimossi)]"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#invarianza-cross-livello-idea",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#invarianza-cross-livello-idea",
    "title": "Multilevel / clustered-data strategy",
    "section": "Invarianza cross-livello (idea)",
    "text": "Invarianza cross-livello (idea)\nCon molti cluster, la MG-CFA classica è impraticabile.\nSi può testare se la misura è “simile” tra within e between: cross-level invariance.\n[INSERIRE FIGURE: “Invarianza tra gruppi / tra cluster!?” dal PDF]"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#cross-level-invariance-configurale",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#cross-level-invariance-configurale",
    "title": "Multilevel / clustered-data strategy",
    "section": "Cross-level invariance: configurale",
    "text": "Cross-level invariance: configurale\nStessa struttura fattoriale a livello 1 e 2.\n\nconf &lt;- '\n  level: 1\n    NV_w =~ v1 + v2 + v3\n    TA_w =~ t1 + t2 + t3\n    FA_w =~ f1 + f2 + f3\n  level: 2\n    NV_b =~ v1 + v2 + v3\n    TA_b =~ t1 + t2 + t3\n    FA_b =~ f1 + f2 + f3\n'"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#cross-level-invariance-debole-loadings-uguali",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#cross-level-invariance-debole-loadings-uguali",
    "title": "Multilevel / clustered-data strategy",
    "section": "Cross-level invariance: debole (loadings uguali)",
    "text": "Cross-level invariance: debole (loadings uguali)\n\nweak &lt;- '\n  level: 1\n    NV_w =~ a*v1 + b*v2 + c*v3\n    TA_w =~ d*t1 + e*t2 + f*t3\n    FA_w =~ g*f1 + h*f2 + i*f3\n  level: 2\n    NV_b =~ a*v1 + b*v2 + c*v3\n    TA_b =~ d*t1 + e*t2 + f*t3\n    FA_b =~ g*f1 + h*f2 + i*f3\n'"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#cross-level-invariance-forte-nota-dal-pdf",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#cross-level-invariance-forte-nota-dal-pdf",
    "title": "Multilevel / clustered-data strategy",
    "section": "Cross-level invariance: “forte” (nota dal PDF)",
    "text": "Cross-level invariance: “forte” (nota dal PDF)\nNel deck originale: oltre ai loadings uguali, residui L2 fissati a 0 (attendibilità perfetta).\nIn psicologia spesso è un benchmark teorico più che un default.\n\nstrong &lt;- '\n  level: 1\n    NV_w =~ a*v1 + b*v2 + c*v3\n    TA_w =~ d*t1 + e*t2 + f*t3\n    FA_w =~ g*f1 + h*f2 + i*f3\n  level: 2\n    NV_b =~ a*v1 + b*v2 + c*v3\n    TA_b =~ d*t1 + e*t2 + f*t3\n    FA_b =~ g*f1 + h*f2 + i*f3\n\n    v1 ~~ 0*v1; v2 ~~ 0*v2; v3 ~~ 0*v3\n    t1 ~~ 0*t1; t2 ~~ 0*t2; t3 ~~ 0*t3\n    f1 ~~ 0*f1; f2 ~~ 0*f2; f3 ~~ 0*f3\n'"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#confronto-modelli-fit",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#confronto-modelli-fit",
    "title": "Multilevel / clustered-data strategy",
    "section": "Confronto modelli (fit)",
    "text": "Confronto modelli (fit)\n\nfit.conf   &lt;- cfa(conf,   clean, cluster = \"ID\")\nfit.weak   &lt;- cfa(weak,   clean, cluster = \"ID\")\nfit.strong &lt;- cfa(strong, clean, cluster = \"ID\")\n\nf &lt;- c(\"df\",\"rmsea\",\"cfi\",\"srmr_within\",\"srmr_between\")\nround(rbind(\n  conf   = lavInspect(fit.conf,   \"fit\")[f],\n  weak   = lavInspect(fit.weak,   \"fit\")[f],\n  strong = lavInspect(fit.strong, \"fit\")[f]\n), 3)\n\n[INSERIRE FIGURA/TABELLA: confronto modelli (come nel PDF)]"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#costrutti-multilivello-e-omologia-cross-livello",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#costrutti-multilivello-e-omologia-cross-livello",
    "title": "Multilevel / clustered-data strategy",
    "section": "Costrutti multilivello e omologia cross-livello",
    "text": "Costrutti multilivello e omologia cross-livello\nMessaggio finale del PDF:\n\nwithin e between possono rappresentare “lo stesso” costrutto (omologia) oppure costrutti differenti\nl’invarianza cross-livello aiuta a sostenere interpretazioni trait/state\n\n[INSERIRE FIGURE FINALI: costrutti multilivello, tratti/stati, workaholism (dal PDF)]"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#exercises-lab-10",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#exercises-lab-10",
    "title": "Multilevel Confirmatory Factor Analysis",
    "section": "Exercises → Lab 10",
    "text": "Exercises → Lab 10\nGo to: labs/lab10_multilevel_robustse_twolevelcfa.qmd\n\nfit a two-level CFA with level: + cluster=\ncompare alternative within/between structures and interpret SRMR\ndiagnose (potential) Heywood cases at Level 2\ntest (optional) cross-level invariance and partial invariance"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#take-home-3-things",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#take-home-3-things",
    "title": "Multilevel Confirmatory Factor Analysis",
    "section": "Take-home: 3 things",
    "text": "Take-home: 3 things\n\nWith clustered/repeated data, always think within vs between (two covariance structures).\n\nIn MCFA, global fit can hide L2 misspecification — check SRMR_between.\n\nCross-level invariance connects estimation constraints to construct interpretation (trait/state, aggregation, homology)."
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#further-reading",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#further-reading",
    "title": "Multilevel Confirmatory Factor Analysis",
    "section": "Further reading",
    "text": "Further reading\n[ADD the corresponding bib entries + citation keys in refs/references.bib]\n\nHox (2010), Multilevel Analysis (SEM/MCFA chapter)\n\nRyu & West (2009) on level-specific fit, SRMR\n\nHsu et al. (2015) on level-specific fit in MCFA\n\nKolenikov & Bollen (2012) on improper solutions / negative variances\n\nJak & Jorgensen (2017) on cross-level invariance\n\nStapleton et al. (2016) on multilevel constructs\n\nChen et al. (2005) on cross-level homology"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#references",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#references",
    "title": "Multilevel Confirmatory Factor Analysis",
    "section": "References",
    "text": "References\n[Replace the red TODOs with proper [@key] citations once the bib entries are in place.]"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#outline",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#outline",
    "title": "Multilevel Confirmatory Factor Analysis",
    "section": "Outline",
    "text": "Outline\n\nSEM vs CFA (quick refresher)\nFrom single-level CFA to multilevel CFA\nExample A: individuals nested within groups (schools/teams)\nExample B: repeated measures nested within persons (ESM)\nCross-level invariance and cross-level homology"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#the-two-fundamental-parts-of-a-sem",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#the-two-fundamental-parts-of-a-sem",
    "title": "Multilevel Confirmatory Factor Analysis",
    "section": "The two fundamental parts of a SEM",
    "text": "The two fundamental parts of a SEM\n\nStructural model: relations among variables (latent/observed)\n\nMeasurement model: indicators → latent variables (CFA)"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#confirmatory-factor-analysis-cfa",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#confirmatory-factor-analysis-cfa",
    "title": "Multilevel Confirmatory Factor Analysis",
    "section": "Confirmatory factor analysis (CFA)",
    "text": "Confirmatory factor analysis (CFA)\nCFA is the measurement model:\n\nnumber of factors (1, 2, …, k)\nwhich indicators load on which factor\n(co)variances among factors and residual variances"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#factor-structure-concept",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#factor-structure-concept",
    "title": "Multilevel Confirmatory Factor Analysis",
    "section": "Factor structure (concept)",
    "text": "Factor structure (concept)\n\n\nA factor structure is one possible configuration of relations between a set of observed variables and one or more latent factors, defining:\n\nthe number of latent variables (1-factor, 2-factor, …, k-factor model)\n\nthe pattern of relations between each observed variable and its factor (loading pattern)\n\n\n\n\n\n\n\n\nStarting from the covariance matrix of observed variables, CFA tests the fit of one or more hypothesized factor structures and estimates the corresponding loadings."
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#the-starting-point-variancecovariance-matrix",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#the-starting-point-variancecovariance-matrix",
    "title": "Multilevel Confirmatory Factor Analysis",
    "section": "The starting point: variance–covariance matrix",
    "text": "The starting point: variance–covariance matrix\nSEM is about reproducing the observed covariance matrix.\n\\[\nH_0:\\ \\hat{\\Sigma}(\\theta) = \\Sigma\n\\]\n\n\n\n\n\n\nFit indices summarize “how close” the model-implied covariance structure is to the data."
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#what-if-data-are-multilevel",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#what-if-data-are-multilevel",
    "title": "Multilevel Confirmatory Factor Analysis",
    "section": "What if data are multilevel?",
    "text": "What if data are multilevel?\nWhen observations are nested (e.g., students in classes; employees in teams) or repeated (ESM):\n\nlocal dependence: units in the same cluster/person are more similar\n\nindependence assumption fails\n\nignoring clustering can bias standard errors and sometimes distort inference\n\n\n\n\n# toy long dataset\ndf &lt;- data.frame(\n  cluster = rep(1:4, each = 6),\n  x1 = rnorm(24),\n  x2 = rnorm(24)\n)\n\n\n\ndf[1:10,]\n\n   cluster          x1         x2\n1        1 -0.56047565 -0.6250393\n2        1 -0.23017749 -1.6866933\n3        1  1.55870831  0.8377870\n4        1  0.07050839  0.1533731\n5        1  0.12928774 -1.1381369\n6        1  1.71506499  1.2538149\n7        2  0.46091621  0.4264642\n8        2 -1.26506123 -0.2950715\n9        2 -0.68685285  0.8951257\n10       2 -0.44566197  0.8781335"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#decomposing-covariance-within-vs-between",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#decomposing-covariance-within-vs-between",
    "title": "Multilevel Confirmatory Factor Analysis",
    "section": "Decomposing (co)variance: within vs between",
    "text": "Decomposing (co)variance: within vs between\nWe decompose the covariance structure into:\n\n\n\nBetween (L2): covariance among cluster means\n\n\nwide &lt;- aggregate(\n  cbind(x1, x2) ~ cluster, \n  data = df, FUN = mean)\nnames(wide)[2:3] &lt;- c(\"x1.b\",\"x2.b\")\n\nhead(wide)\n\n  cluster        x1.b        x2.b\n1       1  0.44715272 -0.20081574\n2       2 -0.05879404  0.56914554\n3       3  0.04562658 -0.18284200\n4       4 -0.46868830  0.01981214\n\n\n\n\n\ndo clusters with higher mean \\((X)\\) also have higher mean \\((Y)\\)?\n\n\n\n\n\nWithin (L1): covariance among deviations from cluster means\n\n\ndf2 &lt;- merge(df, wide, by = \"cluster\")\ndf2$x1.w &lt;- df2$x1 - df2$x1.b\ndf2$x2.w &lt;- df2$x2 - df2$x2.b\n\nround(head(df2),2)\n\n  cluster    x1    x2 x1.b x2.b  x1.w  x2.w\n1       1 -0.56 -0.63 0.45 -0.2 -1.01 -0.42\n2       1 -0.23 -1.69 0.45 -0.2 -0.68 -1.49\n3       1  1.56  0.84 0.45 -0.2  1.11  1.04\n4       1  0.07  0.15 0.45 -0.2 -0.38  0.35\n5       1  0.13 -1.14 0.45 -0.2 -0.32 -0.94\n6       1  1.72  1.25 0.45 -0.2  1.27  1.45\n\n\n\n\n\nWithin: when a unit is above its cluster mean on \\((X)\\), is it also above on \\((Y)\\)?"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#computing-withinbetween-didactic-example",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#computing-withinbetween-didactic-example",
    "title": "Multilevel Confirmatory Factor Analysis",
    "section": "Computing within/between (didactic example)",
    "text": "Computing within/between (didactic example)\n\n\n\nBetween (L2): covariance among cluster means\n\n\nS_between &lt;- cov(wide[, c(\"x1.b\",\"x2.b\")])\nS_between\n\n            x1.b        x2.b\nx1.b  0.14161724 -0.04636824\nx2.b -0.04636824  0.12918010\n\n\n\n\n\ndo clusters with higher mean \\((X)\\) also have higher mean \\((Y)\\)?\n\n\n\n\n\nWithin (L1): covariance among deviations from cluster means\n\n\nS_within  &lt;- cov(df2[, c(\"x1.w\",\"x2.w\")])\nS_within\n\n          x1.w      x2.w\nx1.w 0.8085842 0.1428157\nx2.w 0.1428157 0.7787649\n\n\n\n\n\nWithin: when a unit is above its cluster mean on \\((X)\\), is it also above on \\((Y)\\)?"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#level-specific-covariance-matrices",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#level-specific-covariance-matrices",
    "title": "Multilevel Confirmatory Factor Analysis",
    "section": "Level-specific covariance matrices",
    "text": "Level-specific covariance matrices"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#multilevel-cfa-mcfa",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#multilevel-cfa-mcfa",
    "title": "Multilevel Confirmatory Factor Analysis",
    "section": "Multilevel CFA (MCFA)",
    "text": "Multilevel CFA (MCFA)\n\n\nMCFA estimates measurement structure at both levels and matches both matrices:\n\nwithin-level factor model\n\n\\((S_\\text{within}\\) vs \\(\\hat{\\Sigma}_\\text{within})\\)\n\nbetween-level factor model\n\n\\((S_\\text{between}\\) vs \\(\\hat{\\Sigma}_\\text{between})\\)\n\n\nThat is why we need level-specific fit and level-specific parameters.\n\n\n\n\n\n\n\n\n\nAnd we can ask:\n\nare loadings stronger at L2?\nis fit acceptable within and between?\nis the construct “the same” across levels? (cross-level invariance)"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#cfa-with-lavaan-data-model-specification",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#cfa-with-lavaan-data-model-specification",
    "title": "Multilevel Confirmatory Factor Analysis",
    "section": "CFA with lavaan: data + model specification",
    "text": "CFA with lavaan: data + model specification\n\n\n\ndata(HolzingerSwineford1939, package = \"lavaan\")\n\nm3 &lt;- '\n  visual  =~ x1 + x2 + x3\n  textual =~ x4 + x5 + x6\n  speed   =~ x7 + x8 + x9\n'\n\nm1 &lt;- 'general =~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9'\n\nfit3 &lt;- cfa(m3, data = HolzingerSwineford1939)\nfit1 &lt;- cfa(m1, data = HolzingerSwineford1939)"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#cfa-with-lavaan-fit-indices-and-model-comparison",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#cfa-with-lavaan-fit-indices-and-model-comparison",
    "title": "Multilevel Confirmatory Factor Analysis",
    "section": "CFA with lavaan: fit indices and model comparison",
    "text": "CFA with lavaan: fit indices and model comparison\n\nround(lavInspect(fit3, \"fit\")[c(\"chisq\",\"df\",\"rmsea\",\"cfi\",\"tli\",\"srmr\")], 3)\n\n chisq     df  rmsea    cfi    tli   srmr \n85.306 24.000  0.092  0.931  0.896  0.065 \n\nround(lavInspect(fit1, \"fit\")[c(\"chisq\",\"df\",\"rmsea\",\"cfi\",\"tli\",\"srmr\")], 3)\n\n  chisq      df   rmsea     cfi     tli    srmr \n312.264  27.000   0.187   0.677   0.569   0.143 \n\n\n\n# Optional model weights (if MuMIn installed)\nlibrary(MuMIn)\nWeights(AIC(fit3, fit1))\nWeights(BIC(fit3, fit1))"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#cfa-with-lavaan-estimated-parameters",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#cfa-with-lavaan-estimated-parameters",
    "title": "Multilevel Confirmatory Factor Analysis",
    "section": "CFA with lavaan: estimated parameters",
    "text": "CFA with lavaan: estimated parameters\n\nparameterEstimates(fit3)[1:10, ]\n\n       lhs op rhs   est    se      z pvalue ci.lower ci.upper\n1   visual =~  x1 1.000 0.000     NA     NA    1.000    1.000\n2   visual =~  x2 0.554 0.100  5.554      0    0.358    0.749\n3   visual =~  x3 0.729 0.109  6.685      0    0.516    0.943\n4  textual =~  x4 1.000 0.000     NA     NA    1.000    1.000\n5  textual =~  x5 1.113 0.065 17.014      0    0.985    1.241\n6  textual =~  x6 0.926 0.055 16.703      0    0.817    1.035\n7    speed =~  x7 1.000 0.000     NA     NA    1.000    1.000\n8    speed =~  x8 1.180 0.165  7.152      0    0.857    1.503\n9    speed =~  x9 1.082 0.151  7.155      0    0.785    1.378\n10      x1 ~~  x1 0.549 0.114  4.833      0    0.326    0.772\n\nstandardizedSolution(fit3)[1:10, c(\"lhs\",\"op\",\"rhs\",\"est.std\")]\n\n       lhs op rhs est.std\n1   visual =~  x1   0.772\n2   visual =~  x2   0.424\n3   visual =~  x3   0.581\n4  textual =~  x4   0.852\n5  textual =~  x5   0.855\n6  textual =~  x6   0.838\n7    speed =~  x7   0.570\n8    speed =~  x8   0.723\n9    speed =~  x9   0.665\n10      x1 ~~  x1   0.404"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#cfa-with-lavaan-but-items-are-ordinal",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#cfa-with-lavaan-but-items-are-ordinal",
    "title": "Multilevel Confirmatory Factor Analysis",
    "section": "CFA with lavaan: but items are ordinal 🙂",
    "text": "CFA with lavaan: but items are ordinal 🙂\n\nfit3_ord &lt;- cfa(m3, data = HolzingerSwineford1939, ordered = TRUE) # WLSMV default\nlavInspect(fit3_ord, \"fit\")[c(\"rmsea\",\"cfi\",\"tli\",\"srmr\")]"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#mcfa-in-lavaan-syntax",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#mcfa-in-lavaan-syntax",
    "title": "Multilevel Confirmatory Factor Analysis",
    "section": "MCFA in lavaan: syntax",
    "text": "MCFA in lavaan: syntax\nTwo key ingredients:\n\nlevel: 1 and level: 2 blocks\n\ncluster = \"cluster_id\" in cfa() / sem()\n\n\nm2l &lt;- '\n  level: 1\n    TD_w =~ d1 + d2 + d3 + d4\n  level: 2\n    TD_b =~ d1 + d2 + d3 + d4\n'\nfit2l &lt;- cfa(m2l, data = dat, cluster = \"ID\")"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#simulate-an-esm-like-dataset-task-demand",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#simulate-an-esm-like-dataset-task-demand",
    "title": "Multilevel Confirmatory Factor Analysis",
    "section": "Simulate an ESM-like dataset (Task Demand)",
    "text": "Simulate an ESM-like dataset (Task Demand)\n\n139 individuals\n21 measurements each (3 days × 7 prompts/day)\n4 Likert indicators of “Task Demand”\n\n\n\n\nn_id &lt;- 139\nn_rep &lt;- 21\nN &lt;- n_id * n_rep\nID &lt;- rep(sprintf(\"S%03d\", 1:n_id), \n          each = n_rep)\n\n# Between-person factor\neta_b &lt;- rnorm(n_id, 0, 0.7)\neta_b_long &lt;- rep(eta_b, each = n_rep)\n\n# Within-person factor\neta_w &lt;- rnorm(N, 0, 1.0)\n\nlambda &lt;- c(0.80, 0.70, 0.75, 0.65)\neps_sd &lt;- c(0.70, 0.80, 0.75, 0.85)\n\ny_cont &lt;- sapply(seq_along(lambda), \n                 function(j) {\n  lambda[j]*(eta_b_long + eta_w) + \n                 rnorm(N, 0, eps_sd[j])\n})\n\n\n\nESMdata &lt;- data.frame(\n  ID = ID,\n  day = rep(rep(1:3, length.out = n_rep), \n            times = n_id),\n  d1 = cut_likert(y_cont[,1]),\n  d2 = cut_likert(y_cont[,2]),\n  d3 = cut_likert(y_cont[,3]),\n  d4 = cut_likert(y_cont[,4])\n)\nhead(ESMdata, 12)\n\n     ID day d1 d2 d3 d4\n1  S001   1  4  5  2  1\n2  S001   2  4  4  5  4\n3  S001   3  3  2  4  2\n4  S001   1  4  4  5  5\n5  S001   2  4  3  4  4\n6  S001   3  2  4  4  3\n7  S001   1  2  2  3  4\n8  S001   2  2  4  1  5\n9  S001   3  5  5  3  5\n10 S001   1  4  5  4  5\n11 S001   2  1  2  2  1\n12 S001   3  2  3  2  2"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#multilevel-cfa-fit-the-model",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#multilevel-cfa-fit-the-model",
    "title": "Multilevel Confirmatory Factor Analysis",
    "section": "Multilevel CFA: fit the model",
    "text": "Multilevel CFA: fit the model\n\nm_td &lt;- '\n  level: 1\n    TD_w =~ d1 + d2 + d3 + d4\n  level: 2\n    TD_b =~ d1 + d2 + d3 + d4\n'\nfit_td &lt;- cfa(m_td, data = ESMdata, cluster = \"ID\", estimator = \"MLR\")"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#multilevel-cfa-level-specific-fit-indices",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#multilevel-cfa-level-specific-fit-indices",
    "title": "Multilevel Confirmatory Factor Analysis",
    "section": "Multilevel CFA: level-specific fit indices",
    "text": "Multilevel CFA: level-specific fit indices\nGlobal fit is often dominated by the within-level.\nSRMR is available by level:\n\nsrmr_within\nsrmr_between (key for L2 misspecification)\n\n\nround(lavInspect(fit_td, \"fit\")[\n  c(\"rmsea.robust\",\"cfi.robust\",\"tli.robust\",\n    \"srmr_within\",\"srmr_between\")\n  ], 3)\n\nrmsea.robust   cfi.robust   tli.robust  srmr_within srmr_between \n       0.000        1.000        1.003        0.008        0.002 \n\n\n[ADD REFERENCES: Ryu & West (2009); Hsu et al. (2015) → add bib entries]"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#multilevel-cfa-level-specific-parameters",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#multilevel-cfa-level-specific-parameters",
    "title": "Multilevel Confirmatory Factor Analysis",
    "section": "Multilevel CFA: level-specific parameters",
    "text": "Multilevel CFA: level-specific parameters\n\n# within loadings (first block)\nstandardizedSolution(fit_td)[1:4, c(\"lhs\",\"op\",\"rhs\",\"est.std\")]\n\n   lhs op rhs est.std\n1 TD_w =~  d1   0.731\n2 TD_w =~  d2   0.632\n3 TD_w =~  d3   0.662\n4 TD_w =~  d4   0.554\n\n\n\n# between loadings (later block)\nstandardizedSolution(fit_td)[15:18, c(\"lhs\",\"op\",\"rhs\",\"est.std\")]\n\n    lhs op rhs est.std\n15 TD_b =~  d1   1.012\n16 TD_b =~  d2   0.986\n17 TD_b =~  d3   1.016\n18 TD_b =~  d4   1.010\n\n\n\n\n\nNote: Loadings are typically stronger at the between level because measurement error tends to accumulate at Level 1 (Hox, 2010).\n\n\n\n[ADD REFERENCES: Hox, 2010 → add bib entries]"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#multilevel-cfa-but-items-are-ordinal",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#multilevel-cfa-but-items-are-ordinal",
    "title": "Multilevel Confirmatory Factor Analysis",
    "section": "Multilevel CFA: but items are ordinal",
    "text": "Multilevel CFA: but items are ordinal\n\nfit_td_ord &lt;- cfa(m_td, data = ESMdata, cluster = \"ID\",\n                  ordered = c(\"d1\",\"d2\",\"d3\",\"d4\"))\n\nError: lavaan-&gt;lav_lavaan_step02_options():  \n   categorical + clustered is not supported yet."
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#subjects-nested-within-groups",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#subjects-nested-within-groups",
    "title": "Multilevel Confirmatory Factor Analysis",
    "section": "Subjects nested within groups",
    "text": "Subjects nested within groups\nWhen participants belong to many groups (schools/classes/teams):\n\nobservations are not independent\nyou can still fit a single-level model, but SEs/inference can be wrong\nmultilevel CFA allows separate within and between measurement models"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#example-individual-vs-team-participation-simulated",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#example-individual-vs-team-participation-simulated",
    "title": "Multilevel Confirmatory Factor Analysis",
    "section": "Example: individual vs team participation (simulated)",
    "text": "Example: individual vs team participation (simulated)\n\nn_school &lt;- 68\nn_i &lt;- 608\nschoolID &lt;- sample(seq_len(n_school), size = n_i, replace = TRUE)\n# Between-school factor\neta_school &lt;- rnorm(n_school, 0, 0.6)\neta_b &lt;- eta_school[schoolID]\n# Within-person factor\neta_w &lt;- rnorm(n_i, 0, 1.0)\n\nlam_p &lt;- c(0.80, 0.75, 0.70, 0.65)\neps_p &lt;- c(0.80, 0.85, 0.90, 0.95)\np_cont &lt;- sapply(seq_along(lam_p), function(j) {\n  lam_p[j] * (eta_b + eta_w) + rnorm(n_i, 0, eps_p[j])\n})\n\nedudata &lt;- data.frame(\n  schoolID = schoolID,\n  p2 = cut_likert(p_cont[,1]),\n  p3 = cut_likert(p_cont[,2]),\n  p4 = cut_likert(p_cont[,3]),\n  p5 = cut_likert(p_cont[,4])\n)\nhead(edudata, 4)\n\n  schoolID p2 p3 p4 p5\n1       28  5  5  5  5\n2        8  5  3  4  5\n3       18  1  2  1  2\n4       26  2  1  4  2"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#distributions-of-items-ordinal",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#distributions-of-items-ordinal",
    "title": "Multilevel Confirmatory Factor Analysis",
    "section": "Distributions of items (ordinal)",
    "text": "Distributions of items (ordinal)\n\n[IF THIS IMAGE IS MISSING: copy partin.png into assets/images/]"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#single-level-cfa",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#single-level-cfa",
    "title": "Multilevel Confirmatory Factor Analysis",
    "section": "Single-level CFA",
    "text": "Single-level CFA\n\nm_ep &lt;- 'EP =~ p2 + p3 + p4 + p5'\n\nfit_mlr &lt;- cfa(m_ep, edudata, estimator = \"MLR\")\nround(lavInspect(fit_mlr, \"fit\")[\n  c(\"chisq\",\"df\",\"rmsea.robust\",\"cfi.robust\",\"srmr\")\n  ], 3)\n\n       chisq           df rmsea.robust   cfi.robust         srmr \n       5.837        2.000        0.055        0.994        0.017 \n\n\n\n# Ordinal estimator (single-level)\nfit_wlsmv &lt;- cfa(m_ep, edudata, \n                 ordered = c(\"p2\",\"p3\",\"p4\",\"p5\"))  # WLSMV default\nround(lavInspect(fit_wlsmv, \"fit\")[\n  c(\"chisq\",\"df\",\"rmsea\",\"cfi\",\"tli\",\"srmr\")\n  ], 3)\n\nchisq    df rmsea   cfi   tli  srmr \n1.136 2.000 0.000 1.000 1.002 0.012"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#multilevel-cfa-preliminary-models-level-1",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#multilevel-cfa-preliminary-models-level-1",
    "title": "Multilevel Confirmatory Factor Analysis",
    "section": "Multilevel CFA: preliminary models (Level 1)",
    "text": "Multilevel CFA: preliminary models (Level 1)\nHox (2010) suggests a preliminary check:\n\nfit CFA on the pooled-within covariance matrix (within-cluster centered scores)\n\n\nlwd &lt;- na.omit(edudata[, c(\"schoolID\", paste0(\"p\",2:5))])\n\nms &lt;- data.frame(\n  p2 = ave(lwd$p2, lwd$schoolID),\n  p3 = ave(lwd$p3, lwd$schoolID),\n  p4 = ave(lwd$p4, lwd$schoolID),\n  p5 = ave(lwd$p5, lwd$schoolID)\n)\ncs &lt;- lwd[, 2:ncol(lwd)] - ms\n\npw.cov &lt;- (cov(cs) * (nrow(lwd) - 1)) / (nrow(lwd) - nlevels(lwd$schoolID))\n\nfit_pw &lt;- cfa(m_ep, sample.cov = pw.cov, sample.nobs = nrow(lwd))\nround(lavInspect(fit_pw, \"fit\")[c(\"chisq\",\"df\",\"rmsea\",\"cfi\",\"tli\",\"srmr\")], 3)\n\nchisq    df rmsea   cfi   tli  srmr \n5.856 2.000 0.056 0.991 0.973 0.019"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#multilevel-cfa-preliminary-models-level-2",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#multilevel-cfa-preliminary-models-level-2",
    "title": "Multilevel Confirmatory Factor Analysis",
    "section": "Multilevel CFA: preliminary models (Level 2)",
    "text": "Multilevel CFA: preliminary models (Level 2)\nAt Level 2 (between), fit benchmark models:\n\nNull: No structure at Level 2. If it fits well, there is no clear structure at Level 2 (classic CFA is better: no between variability)\n\nIndependence: Fit a model with variances only. If it fits well, there is probably a structure at Level 2, but not an interesting structural model (the pooled within matrix is better)\n\nSaturated: Fit a saturated model with variances and covariances. If it fits well, then the construct ‘exist’ only at Level 1, while covariances at Level 2 are spurious."
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#multilevel-cfa-the-hypothesized-model",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#multilevel-cfa-the-hypothesized-model",
    "title": "Multilevel Confirmatory Factor Analysis",
    "section": "Multilevel CFA: the hypothesized model",
    "text": "Multilevel CFA: the hypothesized model\n\nm_mcfa &lt;- '\n  level: 1\n    p.w =~ p2 + p3 + p4 + p5\n  level: 2\n    p.b =~ p2 + p3 + p4 + p5\n'\nfit_mcfa &lt;- cfa(m_mcfa, edudata, cluster = \"schoolID\", estimator = \"MLR\")\n\nWarning: lavaan-&gt;lav_data_full():  \n   Level-1 variable \"p4\" has no variance within some clusters . The cluster \n   ids with zero within variance are: 58.\n\n\nWarning: lavaan-&gt;lav_data_full():  \n   Level-1 variable \"p5\" has no variance within some clusters . The cluster \n   ids with zero within variance are: 5.\n\n\nWarning: lavaan-&gt;lav_object_post_check():  \n   some estimated ov variances are negative\n\nround(rbind(\n  null = lavInspect(fit_null,\"fit\")[f],\n  ind  = lavInspect(fit_ind,\"fit\")[f],\n  sat  = lavInspect(fit_sat,\"fit\")[f],\n  mcfa = lavInspect(fit_mcfa,\"fit\")[f]\n), 3)\n\n     df rmsea.robust cfi.robust srmr_within srmr_between\nnull 12        0.085      0.908       0.057           NA\nind   8        0.105      0.907       0.058        0.763\nsat   2        0.000      1.000       0.019        0.004\nmcfa  4        0.000      1.000       0.019        0.005"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#level-specific-loadings",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#level-specific-loadings",
    "title": "Multilevel Confirmatory Factor Analysis",
    "section": "Level-specific loadings",
    "text": "Level-specific loadings\n\nstandardizedSolution(fit_mcfa)[c(1:4, 15:18), c(\"lhs\",\"op\",\"rhs\",\"est.std\")]\n\n   lhs op rhs est.std\n1  p.w =~  p2   0.707\n2  p.w =~  p3   0.638\n3  p.w =~  p4   0.563\n4  p.w =~  p5   0.572\n15 p.b =~  p2   1.020\n16 p.b =~  p3   1.030\n17 p.b =~  p4   0.967\n18 p.b =~  p5   1.118\n\n\n\n\n\nRemember: Loadings are typically stronger at the between level because measurement error tends to accumulate at Level 1 (Hox, 2010)."
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#esm-intensive-longitudinal-designs",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#esm-intensive-longitudinal-designs",
    "title": "Multilevel Confirmatory Factor Analysis",
    "section": "ESM / intensive longitudinal designs",
    "text": "ESM / intensive longitudinal designs\nIn ESM:\n\nLevel 2 (between): stable differences across persons (“trait-like”)\nLevel 1 (within): momentary fluctuations within a person (“state-like”)\n\n\nSee Menghini, Pastore & Balducci (2023) https://doi.org/10.1027/1015-5759/a000725"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#multiple-factor-mcfa-compare-structures",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#multiple-factor-mcfa-compare-structures",
    "title": "Multilevel Confirmatory Factor Analysis",
    "section": "Multiple-factor MCFA (compare structures)",
    "text": "Multiple-factor MCFA (compare structures)\nSome constructs show different dimensionality within vs between."
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#simulate-a-3-factor-mcfa-dataset-nv-ta-fa",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#simulate-a-3-factor-mcfa-dataset-nv-ta-fa",
    "title": "Multilevel Confirmatory Factor Analysis",
    "section": "Simulate a 3-factor MCFA dataset (NV, TA, FA)",
    "text": "Simulate a 3-factor MCFA dataset (NV, TA, FA)\nWe simulate 9 ordinal items (3 per factor), repeated within persons.\n\nn_id &lt;- 139\nn_rep &lt;- 21\nN &lt;- n_id * n_rep\nID &lt;- rep(sprintf(\"S%03d\", 1:n_id), each = n_rep)\n\n# between factors (person-level)\nEtaB &lt;- matrix(rnorm(n_id * 3), ncol = 3)\ncolnames(EtaB) &lt;- c(\"NV_b\",\"TA_b\",\"FA_b\")\nEtaB_long &lt;- EtaB[match(ID, sprintf(\"S%03d\", 1:n_id)), ]\n\n# within factors (occasion-level)\nEtaW &lt;- matrix(rnorm(N * 3), ncol = 3)\ncolnames(EtaW) &lt;- c(\"NV_w\",\"TA_w\",\"FA_w\")\n\nlam &lt;- c(0.80, 0.70, 0.75)\n\nmake_items &lt;- function(f_w, f_b, prefix) {\n  out &lt;- sapply(1:3, function(j) lam[j] * (f_w + f_b) + rnorm(N, 0, 0.9))\n  colnames(out) &lt;- paste0(prefix, 1:3)\n  out\n}\n\nV &lt;- make_items(EtaW[,\"NV_w\"], EtaB_long[,\"NV_b\"], \"v\")\nT &lt;- make_items(EtaW[,\"TA_w\"], EtaB_long[,\"TA_b\"], \"t\")\nF &lt;- make_items(EtaW[,\"FA_w\"], EtaB_long[,\"FA_b\"], \"f\")\n\nESM3 &lt;- data.frame(\n  ID = ID,\n  v1 = cut_likert(V[,1]), v2 = cut_likert(V[,2]), v3 = cut_likert(V[,3]),\n  t1 = cut_likert(T[,1]), t2 = cut_likert(T[,2]), t3 = cut_likert(T[,3]),\n  f1 = cut_likert(F[,1]), f2 = cut_likert(F[,2]), f3 = cut_likert(F[,3])\n)\nhead(ESM3, 4)\n\n    ID v1 v2 v3 t1 t2 t3 f1 f2 f3\n1 S001  2  2  4  1  4  3  2  4  5\n2 S001  3  2  4  4  3  2  5  2  4\n3 S001  5  2  3  2  1  1  5  5  5\n4 S001  2  1  1  2  2  2  3  5  5"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#specify-alternative-structures-as-in-luca",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#specify-alternative-structures-as-in-luca",
    "title": "Multilevel Confirmatory Factor Analysis",
    "section": "Specify alternative structures (as in Luca)",
    "text": "Specify alternative structures (as in Luca)\n\nm3x3 &lt;- '\n  level: 1\n    NV_w =~ v1 + v2 + v3\n    TA_w =~ t1 + t2 + t3\n    FA_w =~ f1 + f2 + f3\n  level: 2\n    NV_b =~ v1 + v2 + v3\n    TA_b =~ t1 + t2 + t3\n    FA_b =~ f1 + f2 + f3\n'\n\nm2x3 &lt;- '\n  level: 1\n    NV_w =~ v1 + v2 + v3\n    TA_w =~ t1 + t2 + t3\n    FA_w =~ f1 + f2 + f3\n  level: 2\n    NV_b =~ v1 + v2 + v3 + t1 + t2 + t3\n    FA_b =~ f1 + f2 + f3\n'\n\nm2x2 &lt;- '\n  level: 1\n    NV_w =~ v1 + v2 + v3 + t1 + t2 + t3\n    FA_w =~ f1 + f2 + f3\n  level: 2\n    NV_b =~ v1 + v2 + v3 + t1 + t2 + t3\n    FA_b =~ f1 + f2 + f3\n'\n\nm3x2 &lt;- '\n  level: 1\n    NV_w =~ v1 + v2 + v3 + t1 + t2 + t3\n    FA_w =~ f1 + f2 + f3\n  level: 2\n    NV_b =~ v1 + v2 + v3\n    TA_b =~ t1 + t2 + t3\n    FA_b =~ f1 + f2 + f3\n'"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#fit-and-compare",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#fit-and-compare",
    "title": "Multilevel Confirmatory Factor Analysis",
    "section": "Fit and compare",
    "text": "Fit and compare\n\nfit2x2 &lt;- cfa(m2x2, ESM3, cluster = \"ID\", estimator = \"MLR\")\nfit3x2 &lt;- cfa(m3x2, ESM3, cluster = \"ID\", estimator = \"MLR\")\nfit2x3 &lt;- cfa(m2x3, ESM3, cluster = \"ID\", estimator = \"MLR\")\nfit3x3 &lt;- cfa(m3x3, ESM3, cluster = \"ID\", estimator = \"MLR\")\n\nf2 &lt;- c(\"df\",\"rmsea.robust\",\"cfi.robust\",\"srmr_within\",\"srmr_between\")\nround(rbind(\n  `2x2` = lavInspect(fit2x2,\"fit\")[f2],\n  `3x2` = lavInspect(fit3x2,\"fit\")[f2],\n  `2x3` = lavInspect(fit2x3,\"fit\")[f2],\n  `3x3` = lavInspect(fit3x3,\"fit\")[f2]\n), 3)\n\n    df rmsea.robust cfi.robust srmr_within srmr_between\n2x2 52        0.100      0.682       0.094        0.257\n3x2 50        0.081      0.802       0.094        0.020\n2x3 50        0.060      0.891       0.012        0.257\n3x3 48        0.000      1.000       0.012        0.020"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#negative-level-2-variances-heywood-cases",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#negative-level-2-variances-heywood-cases",
    "title": "Multilevel Confirmatory Factor Analysis",
    "section": "Negative Level-2 variances (Heywood cases)",
    "text": "Negative Level-2 variances (Heywood cases)\nNegative residual variances at Level 2 are common in MCFA because:\n\nerror tends to accumulate at Level 1\n\nLevel-2 loadings can be very strong → residual variances close to 0\n\nsampling fluctuations around ~0 can produce negative estimates\n\n\n\np &lt;- parameterEstimates(fit3x3)\np[p$op == \"~~\" & p$ci.lower &lt; 0, ]\n\n    lhs op  rhs block level    est    se      z pvalue ci.lower ci.upper\n22 NV_w ~~ TA_w     1     1  0.003 0.017  0.202  0.840   -0.030    0.037\n23 NV_w ~~ FA_w     1     1 -0.013 0.017 -0.772  0.440   -0.047    0.020\n24 TA_w ~~ FA_w     1     1 -0.016 0.017 -0.942  0.346   -0.050    0.017\n46   v1 ~~   v1     2     2 -0.016 0.008 -2.001  0.045   -0.032    0.000\n47   v2 ~~   v2     2     2  0.007 0.009  0.827  0.408   -0.010    0.024\n48   v3 ~~   v3     2     2  0.011 0.008  1.420  0.156   -0.004    0.027\n49   t1 ~~   t1     2     2  0.007 0.009  0.730  0.465   -0.011    0.025\n50   t2 ~~   t2     2     2 -0.013 0.008 -1.654  0.098   -0.028    0.002\n51   t3 ~~   t3     2     2 -0.002 0.008 -0.216  0.829   -0.017    0.014\n52   f1 ~~   f1     2     2  0.002 0.008  0.294  0.769   -0.013    0.018\n53   f2 ~~   f2     2     2 -0.005 0.007 -0.630  0.529   -0.019    0.010\n54   f3 ~~   f3     2     2 -0.007 0.008 -0.979  0.328   -0.022    0.007\n58 NV_b ~~ TA_b     2     2 -0.034 0.057 -0.596  0.551   -0.145    0.077\n59 NV_b ~~ FA_b     2     2 -0.013 0.054 -0.248  0.804   -0.120    0.093\n60 TA_b ~~ FA_b     2     2 -0.030 0.051 -0.598  0.550   -0.130    0.069\n\n\n[ADD REFERENCE: Hox (2010); Kolenikov & Bollen (2012) → add bib entries]"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#negative-variances-and-influential-case-analysis",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#negative-variances-and-influential-case-analysis",
    "title": "Multilevel Confirmatory Factor Analysis",
    "section": "Negative variances and influential-case analysis",
    "text": "Negative variances and influential-case analysis\nIf misspecification is unlikely, one pragmatic strategy is influential-case analysis:\n\nremove clusters (persons) that drive the improper solution\n\nrefit until the negative variance becomes ~0\n\ncompare substantive conclusions\n\n\n# Example template: replace IDs with the clusters you find influential\nclean &lt;- subset(ESM3, !ID %in% c(\"S017\",\"S035\",\"S139\",\"S008\",\n                                 \"S106\",\"S142\",\"S067\"))\nfit3x3_c &lt;- cfa(m3x3, clean, cluster = \"ID\", estimator = \"MLR\")"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#invariance-across-groups-reminder",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#invariance-across-groups-reminder",
    "title": "Multilevel Confirmatory Factor Analysis",
    "section": "Invariance across groups (reminder)",
    "text": "Invariance across groups (reminder)\nQuestion: are we measuring the same construct across groups?\nTypical approach: multi-group CFA with a sequence of constraints (configural → metric → scalar → …)."
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#invariance-across-clusters",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#invariance-across-clusters",
    "title": "Multilevel Confirmatory Factor Analysis",
    "section": "Invariance across clusters!?",
    "text": "Invariance across clusters!?\nMulti-group CFA becomes impractical with many clusters (e.g., 139 persons).\nMultilevel logic: treat clusters as random effects and focus on cross-level invariance.\n\n[ADD REFERENCE: Jak & Jorgensen (2017) → add bib entry]"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#cross-level-invariance-configural",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#cross-level-invariance-configural",
    "title": "Multilevel Confirmatory Factor Analysis",
    "section": "Cross-level invariance: configural",
    "text": "Cross-level invariance: configural\nSame factor structure at both levels.\n\nconf &lt;- '\n  level: 1\n    NV_w =~ v1 + v2 + v3\n    TA_w =~ t1 + t2 + t3\n    FA_w =~ f1 + f2 + f3\n  level: 2\n    NV_b =~ v1 + v2 + v3\n    TA_b =~ t1 + t2 + t3\n    FA_b =~ f1 + f2 + f3\n'"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#cross-level-invariance-weak-equal-loadings",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#cross-level-invariance-weak-equal-loadings",
    "title": "Multilevel Confirmatory Factor Analysis",
    "section": "Cross-level invariance: weak (equal loadings)",
    "text": "Cross-level invariance: weak (equal loadings)\nSame structure + equal (unstandardized) loadings across levels.\n\nweak &lt;- '\n  level: 1\n    NV_w =~ a*v1 + b*v2 + c*v3\n    TA_w =~ d*t1 + e*t2 + f*t3\n    FA_w =~ g*f1 + h*f2 + i*f3\n  level: 2\n    NV_b =~ a*v1 + b*v2 + c*v3\n    TA_b =~ d*t1 + e*t2 + f*t3\n    FA_b =~ g*f1 + h*f2 + i*f3\n'"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#cross-level-invariance-strong-as-in-lucas-slide",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#cross-level-invariance-strong-as-in-lucas-slide",
    "title": "Multilevel Confirmatory Factor Analysis",
    "section": "Cross-level invariance: “strong” (as in Luca’s slide)",
    "text": "Cross-level invariance: “strong” (as in Luca’s slide)\nLuca’s “strong” adds zero residual variances at Level 2 (“perfect reliability”).\n\n\n\nWith psychological data, this is rarely realistic. Treat it as a theoretical benchmark, not a default.\n\n\n\n\nstrong &lt;- '\n  level: 1\n    NV_w =~ a*v1 + b*v2 + c*v3\n    TA_w =~ d*t1 + e*t2 + f*t3\n    FA_w =~ g*f1 + h*f2 + i*f3\n  level: 2\n    NV_b =~ a*v1 + b*v2 + c*v3\n    TA_b =~ d*t1 + e*t2 + f*t3\n    FA_b =~ g*f1 + h*f2 + i*f3\n\n    v1 ~~ 0*v1; v2 ~~ 0*v2; v3 ~~ 0*v3\n    t1 ~~ 0*t1; t2 ~~ 0*t2; t3 ~~ 0*t3\n    f1 ~~ 0*f1; f2 ~~ 0*f2; f3 ~~ 0*f3\n'"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#compare-invariance-models",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#compare-invariance-models",
    "title": "Multilevel Confirmatory Factor Analysis",
    "section": "Compare invariance models",
    "text": "Compare invariance models\n\nfit.conf   &lt;- cfa(conf,   ESM3, cluster = \"ID\", estimator = \"MLR\")\nfit.weak   &lt;- cfa(weak,   ESM3, cluster = \"ID\", estimator = \"MLR\")\nfit.strong &lt;- cfa(strong, ESM3, cluster = \"ID\", estimator = \"MLR\")\n\nround(rbind(\n  conf   = lavInspect(fit.conf,   \"fit\")[f2],\n  weak   = lavInspect(fit.weak,   \"fit\")[f2],\n  strong = lavInspect(fit.strong, \"fit\")[f2]\n), 3)\n\n       df rmsea.robust cfi.robust srmr_within srmr_between\nconf   48            0          1       0.012        0.020\nweak   54            0          1       0.013        0.019\nstrong 63            0          1       0.013        0.020"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#try-with-the-participation-data",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#try-with-the-participation-data",
    "title": "Multilevel Confirmatory Factor Analysis",
    "section": "Try with the participation data",
    "text": "Try with the participation data\n\nconf_p &lt;- '\n  level: 1\n    p.w =~ p2 + p3 + p4 + p5\n  level: 2\n    p.b =~ p2 + p3 + p4 + p5\n'\n\nweak_p &lt;- '\n  level: 1\n    p.w =~ a*p2 + b*p3 + c*p4 + d*p5\n  level: 2\n    p.b =~ a*p2 + b*p3 + c*p4 + d*p5\n'\n\nfit.conf_p &lt;- cfa(conf_p, edudata, cluster = \"schoolID\", estimator = \"MLR\")\nfit.weak_p &lt;- cfa(weak_p, edudata, cluster = \"schoolID\", estimator = \"MLR\")\n\nf3 &lt;- c(\"df\",\"rmsea.robust\",\"cfi.robust\",\"srmr_within\",\"srmr_between\")\nround(rbind(\n  conf = lavInspect(fit.conf_p, \"fit\")[f3],\n  weak = lavInspect(fit.weak_p, \"fit\")[f3]\n), 3)\n\n     df rmsea.robust cfi.robust srmr_within srmr_between\nconf  4            0          1       0.019        0.005\nweak  7            0          1       0.020        0.008"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#multilevel-constructs-and-cross-level-invariance",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#multilevel-constructs-and-cross-level-invariance",
    "title": "Multilevel Confirmatory Factor Analysis",
    "section": "Multilevel constructs and cross-level invariance",
    "text": "Multilevel constructs and cross-level invariance\nCross-level invariance is not only “fit”—it’s about construct meaning.\n\n[ADD REFERENCE: Stapleton et al. (2016) → add bib entry]"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#traits-as-distributions-of-states",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#traits-as-distributions-of-states",
    "title": "Multilevel Confirmatory Factor Analysis",
    "section": "Traits as distributions of states",
    "text": "Traits as distributions of states\nSome theories treat traits as distributions of states.\nThis implicitly assumes at least weak cross-level invariance."
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#lucas-real-data-example-slides",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#lucas-real-data-example-slides",
    "title": "Multilevel Confirmatory Factor Analysis",
    "section": "Luca’s real-data example (slides)",
    "text": "Luca’s real-data example (slides)"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#simulate-a-workaholism-esm-dataset-2-factors-6-items",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#simulate-a-workaholism-esm-dataset-2-factors-6-items",
    "title": "Multilevel Confirmatory Factor Analysis",
    "section": "Simulate a workaholism ESM dataset (2 factors, 6 items)",
    "text": "Simulate a workaholism ESM dataset (2 factors, 6 items)\n\nn_id &lt;- 135\nn_rep &lt;- 30\nN &lt;- n_id * n_rep\nID &lt;- rep(sprintf(\"P%03d\", 1:n_id), each = n_rep)\n# Between factors\nWE_b &lt;- rnorm(n_id, 0, 0.6)\nWC_b &lt;- rnorm(n_id, 0, 0.6)\nWE_b_long &lt;- rep(WE_b, each = n_rep)\nWC_b_long &lt;- rep(WC_b, each = n_rep)\n# Within factors\nWE_w &lt;- rnorm(N, 0, 1.0)\nWC_w &lt;- rnorm(N, 0, 1.0)\n# Loadings within\nlam_WE_w &lt;- c(0.8, 0.7, 0.75)   # items 1,3,5\nlam_WC_w &lt;- c(0.75, 0.70, 0.65) # items 2,4,6\n# Loadings between (slight violation on item1)\nlam_WE_b &lt;- c(0.60, 0.70, 0.75)\nlam_WC_b &lt;- lam_WC_w\n\nWH1 &lt;- lam_WE_w[1]*WE_w + lam_WE_b[1]*WE_b_long + rnorm(N, 0, 0.9)\nWH3 &lt;- lam_WE_w[2]*WE_w + lam_WE_b[2]*WE_b_long + rnorm(N, 0, 0.9)\nWH5 &lt;- lam_WE_w[3]*WE_w + lam_WE_b[3]*WE_b_long + rnorm(N, 0, 0.9)\n\nWH2 &lt;- lam_WC_w[1]*WC_w + lam_WC_b[1]*WC_b_long + rnorm(N, 0, 0.9)\nWH4 &lt;- lam_WC_w[2]*WC_w + lam_WC_b[2]*WC_b_long + rnorm(N, 0, 0.9)\nWH6 &lt;- lam_WC_w[3]*WC_w + lam_WC_b[3]*WC_b_long + rnorm(N, 0, 0.9)\n\ndat_wh &lt;- data.frame(\n  ID = ID,\n  WHLSM1 = cut_likert(WH1),\n  WHLSM2 = cut_likert(WH2),\n  WHLSM3 = cut_likert(WH3),\n  WHLSM4 = cut_likert(WH4),\n  WHLSM5 = cut_likert(WH5),\n  WHLSM6 = cut_likert(WH6)\n)\nhead(dat_wh, 4)\n\n    ID WHLSM1 WHLSM2 WHLSM3 WHLSM4 WHLSM5 WHLSM6\n1 P001      1      4      2      5      1      4\n2 P001      1      5      1      5      1      4\n3 P001      2      4      1      5      1      4\n4 P001      4      1      1      4      1      2"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#cross-level-invariance-configural-vs-weak",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#cross-level-invariance-configural-vs-weak",
    "title": "Multilevel Confirmatory Factor Analysis",
    "section": "Cross-level invariance: configural vs weak",
    "text": "Cross-level invariance: configural vs weak\n\nconf_wh &lt;- '\n  level: 1\n    sWE =~ WHLSM1 + WHLSM3 + WHLSM5\n    sWC =~ WHLSM2 + WHLSM4 + WHLSM6\n  level: 2\n    tWE =~ WHLSM1 + WHLSM3 + WHLSM5\n    tWC =~ WHLSM2 + WHLSM4 + WHLSM6\n'\n\nweak_wh &lt;- '\n  level: 1\n    sWE =~ a*WHLSM1 + b*WHLSM3 + c*WHLSM5\n    sWC =~ d*WHLSM2 + e*WHLSM4 + f*WHLSM6\n  level: 2\n    tWE =~ a*WHLSM1 + b*WHLSM3 + c*WHLSM5\n    tWC =~ d*WHLSM2 + e*WHLSM4 + f*WHLSM6\n'\n\nfit.conf_wh &lt;- cfa(conf_wh, dat_wh, cluster = \"ID\", estimator = \"MLR\")\nfit.weak_wh &lt;- cfa(weak_wh, dat_wh, cluster = \"ID\", estimator = \"MLR\")\n\nround(rbind(\n  conf = lavInspect(fit.conf_wh, \"fit\")[c(\"df\",\"rmsea.robust\",\"cfi.robust\",\"srmr_within\",\"srmr_between\")],\n  weak = lavInspect(fit.weak_wh, \"fit\")[c(\"df\",\"rmsea.robust\",\"cfi.robust\",\"srmr_within\",\"srmr_between\")]\n), 3)\n\n     df rmsea.robust cfi.robust srmr_within srmr_between\nconf 16        0.014      0.996       0.014        0.046\nweak 20        0.018      0.992       0.015        0.046"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#partial-invariance",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#partial-invariance",
    "title": "Multilevel Confirmatory Factor Analysis",
    "section": "Partial invariance?",
    "text": "Partial invariance?\nUse modification indices to find which equality constraint is most problematic.\n\nmi &lt;- modificationIndices(fit.weak_wh)\nmi[order(mi$mi, decreasing = TRUE), ][1:6, c(\"lhs\",\"op\",\"rhs\",\"mi\")]\n\n      lhs op    rhs     mi\n83 WHLSM3 ~~ WHLSM5 18.185\n62 WHLSM3 ~~ WHLSM5 17.976\n1     sWE =~ WHLSM1 17.796\n24    tWE =~ WHLSM1 17.795\n53    sWE =~ WHLSM6 10.478\n82 WHLSM1 ~~ WHLSM6  6.599\n\n\nThen free one loading across levels (partial weak invariance):\n\nweak_part_wh &lt;- '\n  level: 1\n    sWE =~ WHLSM1 + b*WHLSM3 + c*WHLSM5\n    sWC =~ d*WHLSM2 + e*WHLSM4 + f*WHLSM6\n  level: 2\n    tWE =~ WHLSM1 + b*WHLSM3 + c*WHLSM5\n    tWC =~ d*WHLSM2 + e*WHLSM4 + f*WHLSM6\n'\nfit.weak_part_wh &lt;- cfa(weak_part_wh, dat_wh, cluster = \"ID\", estimator = \"MLR\")"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#beyond-invariance-homology",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#beyond-invariance-homology",
    "title": "Multilevel Confirmatory Factor Analysis",
    "section": "Beyond invariance: homology",
    "text": "Beyond invariance: homology\nIf cross-level invariance holds (conceptually and empirically), we can test whether the construct has a similar nomological network across levels (cross-level homology).\n\n[ADD REFERENCE: Chen et al. (2005) → add bib entries]"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#computing-withinbetween-covariance",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#computing-withinbetween-covariance",
    "title": "Multilevel Confirmatory Factor Analysis",
    "section": "Computing within/between covariance",
    "text": "Computing within/between covariance\n\n\n\nBetween (L2): covariance among cluster means\n\n\nS_between &lt;- cov(wide[, c(\"x1.b\",\"x2.b\")])\nS_between\n\n            x1.b        x2.b\nx1.b  0.14161724 -0.04636824\nx2.b -0.04636824  0.12918010\n\n\n\n\n\ndo clusters with higher mean \\((X)\\) also have higher mean \\((Y)\\)?\n\n\n\n\n\nWithin (L1): covariance among deviations from cluster means\n\n\nS_within  &lt;- cov(df2[, c(\"x1.w\",\"x2.w\")])\nS_within\n\n          x1.w      x2.w\nx1.w 0.8085842 0.1428157\nx2.w 0.1428157 0.7787649\n\n\n\n\n\nWithin: when a unit is above its cluster mean on \\((X)\\), is it also above on \\((Y)\\)?"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#simulate-an-esm-like-dataset",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#simulate-an-esm-like-dataset",
    "title": "Multilevel Confirmatory Factor Analysis",
    "section": "Simulate an ESM-like dataset",
    "text": "Simulate an ESM-like dataset\n\n139 individuals\n21 measurements each (3 days × 7 prompts/day)\n4 Likert indicators of “Task Demand”\n\n\n\n\nn_id &lt;- 139\nn_rep &lt;- 21\nN &lt;- n_id * n_rep\nID &lt;- rep(sprintf(\"S%03d\", 1:n_id), \n          each = n_rep)\n# Between-person factor\neta_b &lt;- rnorm(n_id, 0, 0.7)\neta_b_long &lt;- rep(eta_b, each = n_rep)\n# Within-person factor\neta_w &lt;- rnorm(N, 0, 1.0)\n\nlambda &lt;- c(0.80, 0.70, 0.75, 0.65)\neps_sd &lt;- c(0.70, 0.80, 0.75, 0.85)\n\ny_cont &lt;- sapply(seq_along(lambda), \n                 function(j) {\n  lambda[j]*(eta_b_long + eta_w) + \n                 rnorm(N, 0, eps_sd[j])\n})\n\n\n\nESMdata &lt;- data.frame(\n  ID = ID,\n  day = rep(rep(1:3, length.out = n_rep), \n            times = n_id),\n  d1 = cut_likert(y_cont[,1]),\n  d2 = cut_likert(y_cont[,2]),\n  d3 = cut_likert(y_cont[,3]),\n  d4 = cut_likert(y_cont[,4])\n)\nhead(ESMdata, 12)\n\n     ID day d1 d2 d3 d4\n1  S001   1  4  5  2  1\n2  S001   2  4  4  5  4\n3  S001   3  3  2  4  2\n4  S001   1  4  4  5  5\n5  S001   2  4  3  4  4\n6  S001   3  2  4  4  3\n7  S001   1  2  2  3  4\n8  S001   2  2  4  1  5\n9  S001   3  5  5  3  5\n10 S001   1  4  5  4  5\n11 S001   2  1  2  2  1\n12 S001   3  2  3  2  2"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#multilevel-cfa-preliminary-models-level-2-1",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#multilevel-cfa-preliminary-models-level-2-1",
    "title": "Multilevel Confirmatory Factor Analysis",
    "section": "Multilevel CFA: preliminary models (Level 2)",
    "text": "Multilevel CFA: preliminary models (Level 2)\n\n\n\nm_null &lt;- '\n  level: 1\n    p.w =~ p2 + p3 + p4 + p5\n  level: 2\n    p2 ~~ 0*p2\n    p3 ~~ 0*p3\n    p4 ~~ 0*p4\n    p5 ~~ 0*p5\n'\n\nm_ind &lt;- '\n  level: 1\n    p.w =~ p2 + p3 + p4 + p5\n  level: 2\n    p2 ~~ p2\n    p3 ~~ p3\n    p4 ~~ p4\n    p5 ~~ p5\n'\n\n\n\nm_sat &lt;- '\n  level: 1\n    p.w =~ p2 + p3 + p4 + p5\n  level: 2\n    p2 ~~ p2 + p3 + p4 + p5\n    p3 ~~ p3 + p4 + p5\n    p4 ~~ p4 + p5\n    p5 ~~ p5\n'\n\nfit_null &lt;- cfa(m_null, edudata, \n                cluster = \"schoolID\", \n                estimator = \"MLR\")\nfit_ind  &lt;- cfa(m_ind,  edudata, \n                cluster = \"schoolID\", \n                estimator = \"MLR\")\nfit_sat  &lt;- cfa(m_sat,  edudata, \n                cluster = \"schoolID\", \n                estimator = \"MLR\")\n\n\n\n     df rmsea.robust cfi.robust srmr_within srmr_between\nnull 12        0.085      0.908       0.057           NA\nind   8        0.105      0.907       0.058        0.763\nsat   2        0.000      1.000       0.019        0.004"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#specify-alternative-structures",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa.html#specify-alternative-structures",
    "title": "Multilevel Confirmatory Factor Analysis",
    "section": "Specify alternative structures",
    "text": "Specify alternative structures\n\n\n\nm3x3 &lt;- '\n  level: 1\n    NV_w =~ v1 + v2 + v3\n    TA_w =~ t1 + t2 + t3\n    FA_w =~ f1 + f2 + f3\n  level: 2\n    NV_b =~ v1 + v2 + v3\n    TA_b =~ t1 + t2 + t3\n    FA_b =~ f1 + f2 + f3\n'\n\nm2x3 &lt;- '\n  level: 1\n    NV_w =~ v1 + v2 + v3\n    TA_w =~ t1 + t2 + t3\n    FA_w =~ f1 + f2 + f3\n  level: 2\n    NV_b =~ v1 + v2 + v3 + t1 + t2 + t3\n    FA_b =~ f1 + f2 + f3\n'\n\n\n\nm2x2 &lt;- '\n  level: 1\n    NV_w =~ v1 + v2 + v3 + t1 + t2 + t3\n    FA_w =~ f1 + f2 + f3\n  level: 2\n    NV_b =~ v1 + v2 + v3 + t1 + t2 + t3\n    FA_b =~ f1 + f2 + f3\n'\n\nm3x2 &lt;- '\n  level: 1\n    NV_w =~ v1 + v2 + v3 + t1 + t2 + t3\n    FA_w =~ f1 + f2 + f3\n  level: 2\n    NV_b =~ v1 + v2 + v3\n    TA_b =~ t1 + t2 + t3\n    FA_b =~ f1 + f2 + f3\n'"
  },
  {
    "objectID": "labs/lab10_multilevel_robustse_twolevelcfa.html",
    "href": "labs/lab10_multilevel_robustse_twolevelcfa.html",
    "title": "Lab 10 — Multilevel CFA (clustered / repeated data) in lavaan",
    "section": "",
    "text": "By the end of this lab, you can:\n\nRecognize when non-independence (clusters / repeated measures) matters\nDecompose variability into within vs between components (conceptually + via lavaan)\nFit a two-level CFA in lavaan using level: blocks and cluster=\nRead level-specific fit, especially srmr_within and srmr_between\nDiagnose (and think through) Heywood cases / negative level-2 variances\n(Optional) test cross-level invariance of loadings (and partial invariance)"
  },
  {
    "objectID": "labs/lab10_multilevel_robustse_twolevelcfa.html#packages",
    "href": "labs/lab10_multilevel_robustse_twolevelcfa.html#packages",
    "title": "Lab 10 — Multilevel CFA (clustered / repeated data) in lavaan",
    "section": "Packages",
    "text": "Packages\n\n\nShow code\nlibrary(lavaan)\nlibrary(semTools)"
  },
  {
    "objectID": "labs/lab10_multilevel_robustse_twolevelcfa.html#helper-discretize-to-likert",
    "href": "labs/lab10_multilevel_robustse_twolevelcfa.html#helper-discretize-to-likert",
    "title": "Lab 10 — Multilevel CFA (clustered / repeated data) in lavaan",
    "section": "Helper: discretize to Likert",
    "text": "Helper: discretize to Likert\n\n\nShow code\ncut_likert &lt;- function(x, k = 5) {\n  qs &lt;- quantile(x, probs = seq(0, 1, length.out = k + 1), na.rm = TRUE)\n  as.integer(cut(x, breaks = unique(qs), include.lowest = TRUE, labels = FALSE))\n}"
  },
  {
    "objectID": "labs/lab10_multilevel_robustse_twolevelcfa.html#your-task",
    "href": "labs/lab10_multilevel_robustse_twolevelcfa.html#your-task",
    "title": "Lab 10 — Multilevel CFA (clustered / repeated data) in lavaan",
    "section": "Your task",
    "text": "Your task\n\nCheck the marginal distributions of d1–d4 (are categories used?).\nCompute the number of clusters and average cluster size.\n\n\n\nShow code\n# Write your code here"
  },
  {
    "objectID": "labs/lab10_multilevel_robustse_twolevelcfa.html#your-task-1",
    "href": "labs/lab10_multilevel_robustse_twolevelcfa.html#your-task-1",
    "title": "Lab 10 — Multilevel CFA (clustered / repeated data) in lavaan",
    "section": "Your task",
    "text": "Your task\n\nFit the model with estimator = \"MLR\" and cluster = \"ID\".\nExtract these fit measures: rmsea.robust, cfi.robust, tli.robust, srmr_within, srmr_between.\nInterpret what it would mean if srmr_between were much worse than srmr_within.\n\n\n\nShow code\n# Write your code here"
  },
  {
    "objectID": "labs/lab10_multilevel_robustse_twolevelcfa.html#your-task-2",
    "href": "labs/lab10_multilevel_robustse_twolevelcfa.html#your-task-2",
    "title": "Lab 10 — Multilevel CFA (clustered / repeated data) in lavaan",
    "section": "Your task",
    "text": "Your task\n\nFit a single-level CFA to the same ordinal indicators (no cluster=).\nCompare the story you would tell about fit vs the two-level fit.\n(Conceptual) What is the risk of relying on the single-level fit here?\n\n\n\nShow code\n# Write your code here"
  },
  {
    "objectID": "labs/lab10_multilevel_robustse_twolevelcfa.html#your-task-3",
    "href": "labs/lab10_multilevel_robustse_twolevelcfa.html#your-task-3",
    "title": "Lab 10 — Multilevel CFA (clustered / repeated data) in lavaan",
    "section": "Your task",
    "text": "Your task\n\nExtract standardized loadings at Level 1 and Level 2.\nDo you see stronger loadings at Level 2? Why could that happen?\n\n\n\nShow code\n# Write your code here"
  },
  {
    "objectID": "labs/lab10_multilevel_robustse_twolevelcfa.html#your-task-4",
    "href": "labs/lab10_multilevel_robustse_twolevelcfa.html#your-task-4",
    "title": "Lab 10 — Multilevel CFA (clustered / repeated data) in lavaan",
    "section": "Your task",
    "text": "Your task\n\nFit the same two-level CFA on ESMdata2.\nCompare srmr_within and srmr_between to the original dataset.\nPropose one model modification at Level 2 that could improve srmr_between.\n\n\n\nShow code\n# Write your code here"
  },
  {
    "objectID": "labs/lab10_multilevel_robustse_twolevelcfa.html#your-task-5",
    "href": "labs/lab10_multilevel_robustse_twolevelcfa.html#your-task-5",
    "title": "Lab 10 — Multilevel CFA (clustered / repeated data) in lavaan",
    "section": "Your task",
    "text": "Your task\n\nCheck the estimated variances at Level 2 for ESMdata2.\nIf any variance is negative or near 0, list two possible explanations (substantive/statistical).\n\n\n\nShow code\n# Write your code here"
  },
  {
    "objectID": "labs/lab10_multilevel_robustse_twolevelcfa.html#your-task-6",
    "href": "labs/lab10_multilevel_robustse_twolevelcfa.html#your-task-6",
    "title": "Lab 10 — Multilevel CFA (clustered / repeated data) in lavaan",
    "section": "Your task",
    "text": "Your task\n\nFit conf and weak on the original dataset (ESMdata) and compare fit (focus on srmr_between).\nIf the weak model fits worse, inspect modification indices and propose a partial invariance model.\n\n\n\nShow code\n# Write your code here"
  },
  {
    "objectID": "labs/lab10_multilevel_robustse_twolevelcfa.html#what-you-should-be-able-to-say-now",
    "href": "labs/lab10_multilevel_robustse_twolevelcfa.html#what-you-should-be-able-to-say-now",
    "title": "Lab 10 — Multilevel CFA (clustered / repeated data) in lavaan",
    "section": "What you should be able to say now",
    "text": "What you should be able to say now\n\n“This dataset has a within covariance structure and a between covariance structure.”\n“My MCFA fits within/between simultaneously; SRMR tells me where misfit is.”\n“Cross-level invariance connects modeling constraints to construct interpretation.”"
  },
  {
    "objectID": "labs/lab10_multilevel_robustse_twolevelcfa.html#next-steps",
    "href": "labs/lab10_multilevel_robustse_twolevelcfa.html#next-steps",
    "title": "Lab 10 — Multilevel CFA (clustered / repeated data) in lavaan",
    "section": "Next steps",
    "text": "Next steps\n\nMigrate the key citations into refs/references.bib and cite them in the slides/lab.\n(If you want a true ordinal data-generating model) simulate via latent response + thresholds and fit with WLSMV."
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html",
    "title": "Multilevel / clustered-data strategy",
    "section": "",
    "text": "Specify → Identify → Estimate → Evaluate → Revise/Report\n\n\n\n\n\n\nToday: cosa cambia quando i dati sono nidificati (cluster) o ripetuti (entro persona).\nIdea chiave: SEM/CFA partono da una matrice di covarianza; con dati clustered abbiamo within e between."
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#today-in-the-workflow",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#today-in-the-workflow",
    "title": "Multilevel / clustered-data strategy",
    "section": "",
    "text": "Specify → Identify → Estimate → Evaluate → Revise/Report\n\n\n\n\n\n\nToday: cosa cambia quando i dati sono nidificati (cluster) o ripetuti (entro persona).\nIdea chiave: SEM/CFA partono da una matrice di covarianza; con dati clustered abbiamo within e between."
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#learning-objectives",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#learning-objectives",
    "title": "Multilevel / clustered-data strategy",
    "section": "Learning objectives",
    "text": "Learning objectives\n\nRiconoscere quando l’indipendenza è violata (cluster/repeated) e cosa succede se la ignori\n\nCapire la decomposizione within vs between della (co)varianza\n\nSpecificare e stimare una two-level CFA in lavaan (level: + cluster=)\n\nLeggere fit livello-specifici (SRMR within vs between)\n\nCapire la logica dell’invarianza cross-livello (e i suoi limiti)"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#outline-come-nel-pdf",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#outline-come-nel-pdf",
    "title": "Multilevel / clustered-data strategy",
    "section": "Outline (come nel PDF)",
    "text": "Outline (come nel PDF)\n\nSEM, CFA e razionale della CFA multilivello\n\nHandZone: come condurre una CFA multilivello con lavaan\n\nEsempio pratico: Gruppi e individui\n\nEsempi pratici: Misure ripetute\n\nInvarianza cross-livello: dalla pratica alla teoria"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#multilevel-what",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#multilevel-what",
    "title": "Multilevel / clustered-data strategy",
    "section": "Multilevel what!?",
    "text": "Multilevel what!?\n[INSERIRE FIGURA: “Multilevel what!?” (schema introduttivo dal PDF)]\nIdea: SEM = sistema di equazioni stimate simultaneamente.\nEsempio (regressione “standard”):\n\\[\n\\text{PERF} = \\beta_1 \\text{IQ} + \\beta_2 \\text{ANX} + \\epsilon\n\\]\nEsempio (sistema SEM):\n\\[\n\\begin{aligned}\n\\text{ANX} &= \\beta_1 \\text{SEFF} + \\epsilon_2\\\\\n\\text{PERF} &= \\beta_2 \\text{SEFF} + \\beta_3 \\text{ANX} + \\epsilon_3\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#le-due-parti-fondamentali-di-un-sem",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#le-due-parti-fondamentali-di-un-sem",
    "title": "Multilevel / clustered-data strategy",
    "section": "Le due parti fondamentali di un SEM",
    "text": "Le due parti fondamentali di un SEM\nUn SEM include generalmente:\n\nModello strutturale: relazioni “regression-like” tra (latenti o osservate)\n\nModello di misurazione: relazioni tra latenti e indicatori (CFA)\n\n[INSERIRE FIGURA: “Le due parti fondamentali” (schema SEM dal PDF)]"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#analisi-fattoriale-confermativa-cfa",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#analisi-fattoriale-confermativa-cfa",
    "title": "Multilevel / clustered-data strategy",
    "section": "Analisi fattoriale confermativa (CFA)",
    "text": "Analisi fattoriale confermativa (CFA)\nUna CFA include solo il modello di misurazione:\n\ndefinisce i fattori (latenti) e quali indicatori li misurano\nstima saturazioni, varianze residue, (co)varianze tra fattori\nvaluta l’adattamento del modello a partire da (S) e (())\n\n[INSERIRE FIGURA: “CFA” / “Struttura fattoriale” dal PDF]"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#punto-di-partenza-la-matrice-di-covarianza",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#punto-di-partenza-la-matrice-di-covarianza",
    "title": "Multilevel / clustered-data strategy",
    "section": "Punto di partenza: la matrice di covarianza",
    "text": "Punto di partenza: la matrice di covarianza\nSEM/CFA partono dalla matrice di covarianza osservata (S):\n\\[\n\\mathrm{cov}(x,y) = \\frac{\\sum (x_i-\\bar x)(y_i-\\bar y)}{N}\n\\]\nIl modello stima parametri () tali che:\n\nla matrice implicata (()) “assomigli” a (S)\nla differenza tra (S) e () guida fit e diagnostica"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#e-se-i-dati-sono-multilivello",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#e-se-i-dati-sono-multilivello",
    "title": "Multilevel / clustered-data strategy",
    "section": "E se i dati sono multilivello?",
    "text": "E se i dati sono multilivello?\nQuando le osservazioni sono nidificate (cluster) o ripetute:\n\nsi creano dipendenze locali (osservazioni nello stesso cluster più simili)\nsi viola l’assunto di indipendenza\nignorare la struttura può alterare SE e inferenza (e a volte anche stime)\n\nEsempi: - persone entro scuole/classi/team - misure ripetute entro persone (ESM, longitudinali intensivi)"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#scomposizione-within-vs-between-intuizione",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#scomposizione-within-vs-between-intuizione",
    "title": "Multilevel / clustered-data strategy",
    "section": "Scomposizione within vs between (intuizione)",
    "text": "Scomposizione within vs between (intuizione)\nPossiamo decomporre la (co)varianza in:\n\nBetween (L2): covarianza tra le medie dei cluster\n\nWithin (L1): covarianza tra gli scarti dalla media del cluster\n\nInterpretazione: - Between: cluster con media alta su X hanno media alta su Y? - Within: unità “sopra la media del proprio cluster” su X sono anche sopra su Y?"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#come-si-ottengono-pseudo-codice",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#come-si-ottengono-pseudo-codice",
    "title": "Multilevel / clustered-data strategy",
    "section": "Come si ottengono (pseudo-codice)",
    "text": "Come si ottengono (pseudo-codice)\n\n# df: long data, cluster = id_cluster\nwide &lt;- aggregate(cbind(x1, x2) ~ cluster, data = df, FUN = mean)  # between means\ndf &lt;- merge(df, wide, by = \"cluster\", suffixes = c(\"\", \".b\"))\ndf$x1.w &lt;- df$x1 - df$x1.b\ndf$x2.w &lt;- df$x2 - df$x2.b\n\nS_between &lt;- cov(wide[, c(\"x1\",\"x2\")])\nS_within  &lt;- cov(df[, c(\"x1.w\",\"x2.w\")])"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#multilevel-cfa-idea",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#multilevel-cfa-idea",
    "title": "Multilevel / clustered-data strategy",
    "section": "Multilevel CFA (idea)",
    "text": "Multilevel CFA (idea)\nLa MCFA usa due strutture:\n\nfattori e residui a livello within\nfattori e residui a livello between\n\nObiettivo: capire se la struttura di misura è coerente a entrambi i livelli e valutare: - saturazioni livello-specifiche - varianze residue livello-specifiche - fit livello-specifico\n[INSERIRE FIGURA: “Multilevel CFA” (schema within/between) dal PDF]"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#handzone-cfa-con-lavaan-recap-veloce",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#handzone-cfa-con-lavaan-recap-veloce",
    "title": "Multilevel / clustered-data strategy",
    "section": "HandZone: CFA con lavaan (recap veloce)",
    "text": "HandZone: CFA con lavaan (recap veloce)\n\ndata(HolzingerSwineford1939, package = \"lavaan\")\n\nm3 &lt;- '\n  visual  =~ x1 + x2 + x3\n  textual =~ x4 + x5 + x6\n  speed   =~ x7 + x8 + x9\n'\nm1 &lt;- 'general =~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9'\n\nfit3 &lt;- cfa(m3, data = HolzingerSwineford1939)\nfit1 &lt;- cfa(m1, data = HolzingerSwineford1939)"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#fit-e-confronto-tra-modelli-recap",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#fit-e-confronto-tra-modelli-recap",
    "title": "Multilevel / clustered-data strategy",
    "section": "Fit e confronto tra modelli (recap)",
    "text": "Fit e confronto tra modelli (recap)\n\nlavInspect(fit3, \"fit\")[c(\"chisq\",\"df\",\"rmsea\",\"cfi\",\"tli\",\"srmr\")]\nlavInspect(fit1, \"fit\")[c(\"chisq\",\"df\",\"rmsea\",\"cfi\",\"tli\",\"srmr\")]\n\n[INSERIRE FIGURA/TABELLA: confronto fit (come nel PDF)]"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#multilevel-cfa-in-lavaan-sintassi",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#multilevel-cfa-in-lavaan-sintassi",
    "title": "Multilevel / clustered-data strategy",
    "section": "Multilevel CFA in lavaan: sintassi",
    "text": "Multilevel CFA in lavaan: sintassi\nDue ingredienti:\n\nblocchi level: 1 e level: 2\nargomento cluster = \"ID\" in cfa() / sem()\n\n\nm2l &lt;- '\n  level: 1\n    TD_w =~ d1 + d2 + d3 + d4\n  level: 2\n    TD_b =~ d1 + d2 + d3 + d4\n'\n\nfit2l &lt;- cfa(m2l, data = ESMdata, cluster = \"ID\")\n\n[INSERIRE FIGURA: “MCFA con R (ESM)” / esempio HandZone dal PDF]"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#fit-livello-specifico-punto-chiave-pratico",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#fit-livello-specifico-punto-chiave-pratico",
    "title": "Multilevel / clustered-data strategy",
    "section": "Fit livello-specifico (punto chiave pratico)",
    "text": "Fit livello-specifico (punto chiave pratico)\nIn MCFA:\n\nRMSEA/CFI/TLI sono spesso guidati dal within (molte più osservazioni a L1)\nSRMR è disponibile separatamente:\n\nsrmr_within\nsrmr_between (molto informativo per L2)\n\n\n\nlavInspect(fit2l, \"fit\")[c(\"rmsea\",\"cfi\",\"tli\",\"srmr_within\",\"srmr_between\")]"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#parametri-livello-specifici",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#parametri-livello-specifici",
    "title": "Multilevel / clustered-data strategy",
    "section": "Parametri livello-specifici",
    "text": "Parametri livello-specifici\n\n# within loadings (indicativo: righe iniziali)\nstandardizedSolution(fit2l)[1:4, ]\n\n# between loadings (indicativo: righe successive)\nstandardizedSolution(fit2l)[15:18, ]\n\n\n\n\n\n\n\nNel PDF: nota che spesso le saturazioni between risultano più forti (Hox, 2010)."
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#esempio-gruppi-soggetti-nidificati-entro-scuoleteam",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#esempio-gruppi-soggetti-nidificati-entro-scuoleteam",
    "title": "Multilevel / clustered-data strategy",
    "section": "Esempio (gruppi): soggetti nidificati entro scuole/team",
    "text": "Esempio (gruppi): soggetti nidificati entro scuole/team\nQuando soggetti sono reclutati in scuole/classi/organizzazioni:\n\ncorrelazioni più forti entro gruppo\npossibile componente “shared” (contesto / composizione)\ndomanda: il costrutto esiste anche a livello gruppo?\n\n[INSERIRE SLIDE: descrizione dataset “participation” (campione + 4 item) dal PDF]"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#single-level-cfa-mlr-vs-wlsmv",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#single-level-cfa-mlr-vs-wlsmv",
    "title": "Multilevel / clustered-data strategy",
    "section": "Single-level CFA (MLR vs WLSMV)",
    "text": "Single-level CFA (MLR vs WLSMV)\n[INSERIRE FIGURA: “Single-level CFA (MLR vs WLSMV)” dal PDF]"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#modello-preliminare-l1-pooled-within-hox-2010",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#modello-preliminare-l1-pooled-within-hox-2010",
    "title": "Multilevel / clustered-data strategy",
    "section": "Modello preliminare L1: pooled-within (Hox, 2010)",
    "text": "Modello preliminare L1: pooled-within (Hox, 2010)\nIdea: fit della CFA sulla matrice pooled-within prima di passare al two-level.\n\nlwd &lt;- na.omit(edudata[, c(\"schoolID\", paste0(\"p\",2:5))])\n\nms &lt;- data.frame(\n  p2 = ave(lwd$p2, lwd$schoolID),\n  p3 = ave(lwd$p3, lwd$schoolID),\n  p4 = ave(lwd$p4, lwd$schoolID),\n  p5 = ave(lwd$p5, lwd$schoolID)\n)\n\ncs &lt;- lwd[, 2:ncol(lwd)] - ms\n\npw.cov &lt;- (cov(cs) * (nrow(lwd) - 1)) / (nrow(lwd) - nlevels(lwd$schoolID))\n\nm1 &lt;- 'EP =~ p2 + p3 + p4 + p5'\nfit_pw &lt;- cfa(m1, sample.cov = pw.cov, sample.nobs = nrow(lwd))\nlavInspect(fit_pw, \"fit\")[c(\"chisq\",\"df\",\"rmsea\",\"cfi\",\"tli\",\"srmr\")]"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#modelli-preliminari-l2-benchmark",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#modelli-preliminari-l2-benchmark",
    "title": "Multilevel / clustered-data strategy",
    "section": "Modelli preliminari L2: benchmark",
    "text": "Modelli preliminari L2: benchmark\nBenchmark models (Hox):\n\nNull (L2): nessuna varianza a L2 (se va bene → poca struttura between)\nIndependence (L2): solo varianze, niente covarianze\nSaturated (L2): L2 saturo (se necessario per fit → la struttura factor L2 non spiega bene)\n\n\nm_null &lt;- '\n  level: 1\n    p.w =~ p2 + p3 + p4 + p5\n  level: 2\n    p2 ~~ 0*p2\n    p3 ~~ 0*p3\n    p4 ~~ 0*p4\n    p5 ~~ 0*p5\n'\n\nm_ind &lt;- '\n  level: 1\n    p.w =~ p2 + p3 + p4 + p5\n  level: 2\n    p2 ~~ p2\n    p3 ~~ p3\n    p4 ~~ p4\n    p5 ~~ p5\n'\n\nm_sat &lt;- '\n  level: 1\n    p.w =~ p2 + p3 + p4 + p5\n  level: 2\n    p2 ~~ p2 + p3 + p4 + p5\n    p3 ~~ p3 + p4 + p5\n    p4 ~~ p4 + p5\n    p5 ~~ p5\n'"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#mcfa-modello-ipotizzato-1-fattore-a-entrambi-i-livelli",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#mcfa-modello-ipotizzato-1-fattore-a-entrambi-i-livelli",
    "title": "Multilevel / clustered-data strategy",
    "section": "MCFA: modello ipotizzato (1 fattore a entrambi i livelli)",
    "text": "MCFA: modello ipotizzato (1 fattore a entrambi i livelli)\n\nm_mcfa &lt;- '\n  level: 1\n    p.w =~ p2 + p3 + p4 + p5\n  level: 2\n    p.b =~ p2 + p3 + p4 + p5\n'\n\nfit_mcfa &lt;- cfa(m_mcfa, data = edudata, cluster = \"schoolID\", estimator = \"MLR\")\n\n[INSERIRE FIGURA: “MCFA: modello ipotizzato” dal PDF]"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#saturazioni-livello-specifiche-ω-idea-dal-pdf",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#saturazioni-livello-specifiche-ω-idea-dal-pdf",
    "title": "Multilevel / clustered-data strategy",
    "section": "Saturazioni livello-specifiche + ω (idea dal PDF)",
    "text": "Saturazioni livello-specifiche + ω (idea dal PDF)\n\nsl &lt;- standardizedSolution(fit_mcfa)[c(1:4, 15:18), 1:6]\n\nsl.w &lt;- sl[1:4, \"est.std\"]; re.w &lt;- 1 - sl.w^2\nomega_w &lt;- sum(sl.w)^2 / (sum(sl.w)^2 + sum(re.w))\n\nsl.b &lt;- sl[5:8, \"est.std\"]; re.b &lt;- 1 - sl.b^2\nomega_b &lt;- sum(sl.b)^2 / (sum(sl.b)^2 + sum(re.b))\n\nround(c(omega_within = omega_w, omega_between = omega_b), 2)"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#misure-ripetute-entro-persona-esm-stressor-strain",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#misure-ripetute-entro-persona-esm-stressor-strain",
    "title": "Multilevel / clustered-data strategy",
    "section": "Misure ripetute entro persona (ESM): stressor & strain",
    "text": "Misure ripetute entro persona (ESM): stressor & strain\nDati ESM (misure ripetute):\n\nwithin-person = fluttuazioni “state”\nbetween-person = differenze stabili “trait-like”\n\n[INSERIRE FIGURA: “stressor e strain” (design ESM) dal PDF]"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#strutture-alternative-withinbetween-più-fattori",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#strutture-alternative-withinbetween-più-fattori",
    "title": "Multilevel / clustered-data strategy",
    "section": "Strutture alternative within/between (più fattori)",
    "text": "Strutture alternative within/between (più fattori)\nIdea: confrontare dimensionalità diversa tra livelli (3×3, 2×3, 2×2, 3×2).\n\nm3x3 &lt;- '\n  level: 1\n    NV_w =~ v1 + v2 + v3\n    TA_w =~ t1 + t2 + t3\n    FA_w =~ f1 + f2 + f3\n  level: 2\n    NV_b =~ v1 + v2 + v3\n    TA_b =~ t1 + t2 + t3\n    FA_b =~ f1 + f2 + f3\n'\n\nm2x3 &lt;- '\n  level: 1\n    NV_w =~ v1 + v2 + v3\n    TA_w =~ t1 + t2 + t3\n    FA_w =~ f1 + f2 + f3\n  level: 2\n    NV_b =~ v1 + v2 + v3 + t1 + t2 + t3\n    FA_b =~ f1 + f2 + f3\n'\n\nm2x2 &lt;- '\n  level: 1\n    NV_w =~ v1 + v2 + v3 + t1 + t2 + t3\n    FA_w =~ f1 + f2 + f3\n  level: 2\n    NV_b =~ v1 + v2 + v3 + t1 + t2 + t3\n    FA_b =~ f1 + f2 + f3\n'\n\nm3x2 &lt;- '\n  level: 1\n    NV_w =~ v1 + v2 + v3 + t1 + t2 + t3\n    FA_w =~ f1 + f2 + f3\n  level: 2\n    NV_b =~ v1 + v2 + v3\n    TA_b =~ t1 + t2 + t3\n    FA_b =~ f1 + f2 + f3\n'\n\n[INSERIRE FIGURA: “MCFA con più di un fattore / strutture alternative” dal PDF]"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#varianze-negative-a-livello-2-heywood-cases",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#varianze-negative-a-livello-2-heywood-cases",
    "title": "Multilevel / clustered-data strategy",
    "section": "Varianze negative a livello 2 (Heywood cases)",
    "text": "Varianze negative a livello 2 (Heywood cases)\nNel two-level CFA possono apparire varianze residue negative a L2:\n\nspesso perché la varianza residua vera è ~0 a L2\noppure per misspecification / campione piccolo a livello cluster\n\nNel PDF: discussione + citazione (Kolenikov & Bollen, 2012).\n\np &lt;- parameterEstimates(fit3x3)\np[p$op == \"~~\" & p$ci.lower &lt; 0, ]\n\n[INSERIRE SLIDE: “Analisi casi influenti” dal PDF (lista ID rimossi)]"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#invarianza-cross-livello-idea",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#invarianza-cross-livello-idea",
    "title": "Multilevel / clustered-data strategy",
    "section": "Invarianza cross-livello (idea)",
    "text": "Invarianza cross-livello (idea)\nCon molti cluster, la MG-CFA classica è impraticabile.\nSi può testare se la misura è “simile” tra within e between: cross-level invariance.\n[INSERIRE FIGURE: “Invarianza tra gruppi / tra cluster!?” dal PDF]"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#cross-level-invariance-configurale",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#cross-level-invariance-configurale",
    "title": "Multilevel / clustered-data strategy",
    "section": "Cross-level invariance: configurale",
    "text": "Cross-level invariance: configurale\nStessa struttura fattoriale a livello 1 e 2.\n\nconf &lt;- '\n  level: 1\n    NV_w =~ v1 + v2 + v3\n    TA_w =~ t1 + t2 + t3\n    FA_w =~ f1 + f2 + f3\n  level: 2\n    NV_b =~ v1 + v2 + v3\n    TA_b =~ t1 + t2 + t3\n    FA_b =~ f1 + f2 + f3\n'"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#cross-level-invariance-debole-loadings-uguali",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#cross-level-invariance-debole-loadings-uguali",
    "title": "Multilevel / clustered-data strategy",
    "section": "Cross-level invariance: debole (loadings uguali)",
    "text": "Cross-level invariance: debole (loadings uguali)\n\nweak &lt;- '\n  level: 1\n    NV_w =~ a*v1 + b*v2 + c*v3\n    TA_w =~ d*t1 + e*t2 + f*t3\n    FA_w =~ g*f1 + h*f2 + i*f3\n  level: 2\n    NV_b =~ a*v1 + b*v2 + c*v3\n    TA_b =~ d*t1 + e*t2 + f*t3\n    FA_b =~ g*f1 + h*f2 + i*f3\n'"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#cross-level-invariance-forte-nota-dal-pdf",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#cross-level-invariance-forte-nota-dal-pdf",
    "title": "Multilevel / clustered-data strategy",
    "section": "Cross-level invariance: “forte” (nota dal PDF)",
    "text": "Cross-level invariance: “forte” (nota dal PDF)\nNel deck originale: oltre ai loadings uguali, residui L2 fissati a 0 (attendibilità perfetta).\nIn psicologia spesso è un benchmark teorico più che un default.\n\nstrong &lt;- '\n  level: 1\n    NV_w =~ a*v1 + b*v2 + c*v3\n    TA_w =~ d*t1 + e*t2 + f*t3\n    FA_w =~ g*f1 + h*f2 + i*f3\n  level: 2\n    NV_b =~ a*v1 + b*v2 + c*v3\n    TA_b =~ d*t1 + e*t2 + f*t3\n    FA_b =~ g*f1 + h*f2 + i*f3\n\n    v1 ~~ 0*v1; v2 ~~ 0*v2; v3 ~~ 0*v3\n    t1 ~~ 0*t1; t2 ~~ 0*t2; t3 ~~ 0*t3\n    f1 ~~ 0*f1; f2 ~~ 0*f2; f3 ~~ 0*f3\n'"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#confronto-modelli-fit",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#confronto-modelli-fit",
    "title": "Multilevel / clustered-data strategy",
    "section": "Confronto modelli (fit)",
    "text": "Confronto modelli (fit)\n\nfit.conf   &lt;- cfa(conf,   clean, cluster = \"ID\")\nfit.weak   &lt;- cfa(weak,   clean, cluster = \"ID\")\nfit.strong &lt;- cfa(strong, clean, cluster = \"ID\")\n\nf &lt;- c(\"df\",\"rmsea\",\"cfi\",\"srmr_within\",\"srmr_between\")\nround(rbind(\n  conf   = lavInspect(fit.conf,   \"fit\")[f],\n  weak   = lavInspect(fit.weak,   \"fit\")[f],\n  strong = lavInspect(fit.strong, \"fit\")[f]\n), 3)\n\n[INSERIRE FIGURA/TABELLA: confronto modelli (come nel PDF)]"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#costrutti-multilivello-e-omologia-cross-livello",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#costrutti-multilivello-e-omologia-cross-livello",
    "title": "Multilevel / clustered-data strategy",
    "section": "Costrutti multilivello e omologia cross-livello",
    "text": "Costrutti multilivello e omologia cross-livello\nMessaggio finale del PDF:\n\nwithin e between possono rappresentare “lo stesso” costrutto (omologia) oppure costrutti differenti\nl’invarianza cross-livello aiuta a sostenere interpretazioni trait/state\n\n[INSERIRE FIGURE FINALI: costrutti multilivello, tratti/stati, workaholism (dal PDF)]"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#exercises-lab-10",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#exercises-lab-10",
    "title": "Multilevel / clustered-data strategy",
    "section": "Exercises → Lab 10",
    "text": "Exercises → Lab 10\nVai a:\n\nlabs/lab10_multilevel_robustse_twolevelcfa.qmd\n\nCose che farai:\n\nSpecificare un modello 2-livelli (level: + cluster=)\n\nConfrontare strutture alternative within/between\n\nLeggere srmr_within vs srmr_between e diagnosticare Heywood a livello 2\n\n(Opzionale) impostare cross-level invariance e confrontare modelli"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#take-home-3-things",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#take-home-3-things",
    "title": "Multilevel / clustered-data strategy",
    "section": "Take-home: 3 things",
    "text": "Take-home: 3 things\n\nCon dati nidificati, pensa sempre within vs between (decomposizione della covarianza)\n\nIn MCFA, usa indici livello-specifici (spec. SRMR_between) e controlla Heywood cases a lv2\n\nL’invarianza cross-livello collega pratica (fit) e teoria (che cosa “è” il costrutto a lv2)"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#further-reading",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#further-reading",
    "title": "Multilevel / clustered-data strategy",
    "section": "Further reading",
    "text": "Further reading\n\nHox, J. (2010). Multilevel Analysis (cap. su SEM/MCFA)\n\nStapleton et al. (2016) su costrutti multilivello e cross-level invariance\n\nKolenikov & Bollen (2012) su varianze negative / soluzioni improprie in MCFA"
  },
  {
    "objectID": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#references",
    "href": "slides/10_multilevel_clustered-data_robustse_twolevel-cfa22.html#references",
    "title": "Multilevel / clustered-data strategy",
    "section": "References",
    "text": "References\n[INSERIRE: citazioni dal PDF in refs/references.bib]"
  },
  {
    "objectID": "slides/09_longitudinal-sem_growth_invariance-over-time.html#title",
    "href": "slides/09_longitudinal-sem_growth_invariance-over-time.html#title",
    "title": "Longitudinal SEM: Growth + Invariance Over Time",
    "section": "Title",
    "text": "Title\n\n\nLongitudinal SEM\nInvariance over time → Latent Growth Models\n\nMeasurement-first, two-step mindset\n\nFit ≠ truth (especially over time)\n\nGrowth is a latent variable model with time-coded loadings"
  },
  {
    "objectID": "slides/09_longitudinal-sem_growth_invariance-over-time.html#workflow-map",
    "href": "slides/09_longitudinal-sem_growth_invariance-over-time.html#workflow-map",
    "title": "Longitudinal SEM: Growth + Invariance Over Time",
    "section": "Workflow map",
    "text": "Workflow map\n\n\n\n\n\n\nNote\n\n\nSEM workflow: Specify → Identify → Estimate → Evaluate → Revise/Report\nToday we highlight Evaluate (and the disciplined loop back to Revise/Report).\n\n\n\n\n[ADD IMAGE] A simple workflow diagram (Specify→Identify→Estimate→Evaluate→Revise/Report) with “Evaluate” highlighted for Lesson 09. Save as: assets/images/workflow_map_evaluate.png"
  },
  {
    "objectID": "slides/09_longitudinal-sem_growth_invariance-over-time.html#learning-objectives",
    "href": "slides/09_longitudinal-sem_growth_invariance-over-time.html#learning-objectives",
    "title": "Longitudinal SEM: Growth + Invariance Over Time",
    "section": "Learning objectives",
    "text": "Learning objectives\nBy the end of today you can:\n\nFit and justify measurement invariance over time (longitudinal CFA).\nSpecify and estimate latent growth curve models (LGM) in SEM form.\nInterpret growth parameters (means, variances, covariances) and understand time coding.\nUse global + local diagnostics to decide on disciplined respecification."
  },
  {
    "objectID": "slides/09_longitudinal-sem_growth_invariance-over-time.html#what-question-are-we-asking",
    "href": "slides/09_longitudinal-sem_growth_invariance-over-time.html#what-question-are-we-asking",
    "title": "Longitudinal SEM: Growth + Invariance Over Time",
    "section": "What question are we asking?",
    "text": "What question are we asking?\nLongitudinal SEM is not one model, but a family of models.\n\n\n\n\n\n\nTip\n\n\nChoose the model family from the scientific question:\n\nGrowth (LGM): “How do people change on average? How do trajectories differ?”\nStability / lagged prediction (CLPM/RI-CLPM): “Do individual changes predict later changes?”\nChange processes (LCS): “How is change from t→t+1 driven/coupled?”\n\n\n\n\nToday: Invariance over time + LGM (growth).\nRI-CLPM and LCS are linked as extras later."
  },
  {
    "objectID": "slides/09_longitudinal-sem_growth_invariance-over-time.html#minimal-key-concept-measurement-first-two-step",
    "href": "slides/09_longitudinal-sem_growth_invariance-over-time.html#minimal-key-concept-measurement-first-two-step",
    "title": "Longitudinal SEM: Growth + Invariance Over Time",
    "section": "Minimal key concept: measurement-first (two-step)",
    "text": "Minimal key concept: measurement-first (two-step)\nTwo-step mindset\n\nMeasurement model: is the construct measured comparably across waves?\n\nStructural/growth model: only then interpret change parameters.\n\nIf measurement shifts over time, “growth” can become a mixture of:\n\ntrue change in the latent construct\nchanges in item functioning / scaling / intercepts"
  },
  {
    "objectID": "slides/09_longitudinal-sem_growth_invariance-over-time.html#longitudinal-invariance-ladder",
    "href": "slides/09_longitudinal-sem_growth_invariance-over-time.html#longitudinal-invariance-ladder",
    "title": "Longitudinal SEM: Growth + Invariance Over Time",
    "section": "Longitudinal invariance ladder",
    "text": "Longitudinal invariance ladder\nMeasurement waves are our “groups” for the MG-CFA.\n\nConfigural: same factor structure each wave\nMetric: equal loadings (\\(Λ\\)) across waves\nScalar: equal intercepts (\\(τ\\)) across waves\n→ necessary for latent mean / growth mean interpretation\n\n\n\n\n\n\n\nWarning\n\n\nKey point: Without at least (partial) scalar invariance, mean differences over time can be artifacts of shifting intercepts (thresholds for ordinal items)."
  },
  {
    "objectID": "slides/09_longitudinal-sem_growth_invariance-over-time.html#identification-reminders-longitudinal-cfa",
    "href": "slides/09_longitudinal-sem_growth_invariance-over-time.html#identification-reminders-longitudinal-cfa",
    "title": "Longitudinal SEM: Growth + Invariance Over Time",
    "section": "Identification reminders (longitudinal CFA)",
    "text": "Identification reminders (longitudinal CFA)\nFor each wave:\n\nFix factor scale (e.g., one loading = 1, or factor variance = 1)\nWith multiple waves, keep scaling consistent across time\n\nIn longitudinal CFA with means, the usual identification logic extends:\n\nIntercepts and factor means can’t all be free without constraints\nIn lavaan, a standard way is fix factor mean at wave 1 to 0 and estimate others (or use growth factors later)"
  },
  {
    "objectID": "slides/09_longitudinal-sem_growth_invariance-over-time.html#diagram-longitudinal-cfa-same-items-multiple-waves",
    "href": "slides/09_longitudinal-sem_growth_invariance-over-time.html#diagram-longitudinal-cfa-same-items-multiple-waves",
    "title": "Longitudinal SEM: Growth + Invariance Over Time",
    "section": "Diagram: longitudinal CFA (same items, multiple waves)",
    "text": "Diagram: longitudinal CFA (same items, multiple waves)"
  },
  {
    "objectID": "slides/09_longitudinal-sem_growth_invariance-over-time.html#live-coding-setup",
    "href": "slides/09_longitudinal-sem_growth_invariance-over-time.html#live-coding-setup",
    "title": "Longitudinal SEM: Growth + Invariance Over Time",
    "section": "Live coding setup",
    "text": "Live coding setup\n\nlibrary(lavaan)\nlibrary(semTools)\nlibrary(dplyr)\n\nset.seed(12345)"
  },
  {
    "objectID": "slides/09_longitudinal-sem_growth_invariance-over-time.html#example-data-transparent-simulation",
    "href": "slides/09_longitudinal-sem_growth_invariance-over-time.html#example-data-transparent-simulation",
    "title": "Longitudinal SEM: Growth + Invariance Over Time",
    "section": "Example data (transparent simulation)",
    "text": "Example data (transparent simulation)\n\n\n\nWe simulate:\n\nOne latent trait at each wave\nStrong stability (correlated factors over time)\nSome correlated residuals for the same indicator across waves (realistic)\nLater we impose invariance constraints in fitting\n\n\n\n\n\n\n\nNote\n\n\nWe set meanstructure = TRUE in simulation to generate item intercepts + means consistently with the population model.\n\n\n\n\n\npop &lt;- '\n# Wave 1 factor\nF1 =~ 1*y1_1 + .8*y2_1 + .9*y3_1 + .7*y4_1\n# Wave 2 factor\nF2 =~ 1*y1_2 + .8*y2_2 + .9*y3_2 + .7*y4_2\n# Wave 3 factor\nF3 =~ 1*y1_3 + .8*y2_3 + .9*y3_3 + .7*y4_3\n# Wave 4 factor\nF4 =~ 1*y1_4 + .8*y2_4 + .9*y3_4 + .7*y4_4\n\n# Factor means (0 baseline; increasing means)\nF1 ~ 0*1\nF2 ~ .2*1\nF3 ~ .5*1\nF4 ~ .8*1\n\n# Factor variances\nF1 ~~ 1*F1\nF2 ~~ 1*F2\nF3 ~~ 1*F3\nF4 ~~ 1*F4\n\n# Stability (correlations)\nF1 ~~ .70*F2\nF2 ~~ .75*F3\nF3 ~~ .80*F4\nF1 ~~ .60*F3\nF2 ~~ .65*F4\nF1 ~~ .55*F4\n\n# Residual variances (items)\ny1_1 ~~ .5*y1_1; y2_1 ~~ .6*y2_1; y3_1 ~~ .5*y3_1; y4_1 ~~ .7*y4_1\ny1_2 ~~ .5*y1_2; y2_2 ~~ .6*y2_2; y3_2 ~~ .5*y3_2; y4_2 ~~ .7*y4_2\ny1_3 ~~ .5*y1_3; y2_3 ~~ .6*y2_3; y3_3 ~~ .5*y3_3; y4_3 ~~ .7*y4_3\ny1_4 ~~ .5*y1_4; y2_4 ~~ .6*y2_4; y3_4 ~~ .5*y3_4; y4_4 ~~ .7*y4_4\n\n# Correlated residuals across adjacent waves for same indicator (method/wording carryover)\ny1_1 ~~ .25*y1_2\ny1_2 ~~ .25*y1_3\ny1_3 ~~ .25*y1_4\ny2_1 ~~ .20*y2_2\ny2_2 ~~ .20*y2_3\ny2_3 ~~ .20*y2_4\n'\n\ndat &lt;- simulateData(pop, sample.nobs = 6000, meanstructure = TRUE)"
  },
  {
    "objectID": "slides/09_longitudinal-sem_growth_invariance-over-time.html#step-1-configural-longitudinal-cfa",
    "href": "slides/09_longitudinal-sem_growth_invariance-over-time.html#step-1-configural-longitudinal-cfa",
    "title": "Longitudinal SEM: Growth + Invariance Over Time",
    "section": "Step 1: Configural longitudinal CFA",
    "text": "Step 1: Configural longitudinal CFA\nWe specify one factor per wave, same indicators each wave.\nWe also allow conceptually justified correlated residuals (same items).\n\n\nmod_config &lt;- '\nF1 =~ y1_1 + y2_1 + y3_1 + y4_1\nF2 =~ y1_2 + y2_2 + y3_2 + y4_2\nF3 =~ y1_3 + y2_3 + y3_3 + y4_3\nF4 =~ y1_4 + y2_4 + y3_4 + y4_4\n\n# correlated residuals for the same item across adjacent waves \ny1_1 ~~ y1_2\ny1_2 ~~ y1_3\ny1_3 ~~ y1_4\ny2_1 ~~ y2_2\ny2_2 ~~ y2_3\ny2_3 ~~ y2_4\n'\n\nfit_config &lt;- cfa(mod_config, data = dat, meanstructure = TRUE)\nfitMeasures(fit_config, c(\"chisq\",\"df\",\"cfi\",\"tli\",\"rmsea\",\"srmr\"))\n\n chisq     df    cfi    tli  rmsea   srmr \n85.683 92.000  1.000  1.000  0.000  0.007"
  },
  {
    "objectID": "slides/09_longitudinal-sem_growth_invariance-over-time.html#step-2-metric-and-scalar-invariance-over-time",
    "href": "slides/09_longitudinal-sem_growth_invariance-over-time.html#step-2-metric-and-scalar-invariance-over-time",
    "title": "Longitudinal SEM: Growth + Invariance Over Time",
    "section": "Step 2: Metric and scalar invariance (over time)",
    "text": "Step 2: Metric and scalar invariance (over time)\nUse semTools::measurementInvariance() with waves as “groups” requires long format. For teaching, we’ll do the “manual wide approach” (explicit equality labels) to keep it transparent."
  },
  {
    "objectID": "slides/09_longitudinal-sem_growth_invariance-over-time.html#evaluate-invariance-fit-comparisons",
    "href": "slides/09_longitudinal-sem_growth_invariance-over-time.html#evaluate-invariance-fit-comparisons",
    "title": "Longitudinal SEM: Growth + Invariance Over Time",
    "section": "Evaluate invariance: fit comparisons",
    "text": "Evaluate invariance: fit comparisons\n\nlavTestLRT(fit_config, fit_metric, fit_scalar)\n\n\nChi-Squared Difference Test\n\n            Df    AIC    BIC Chisq Chisq diff   RMSEA Df diff Pr(&gt;Chisq)\nfit_config  92 246326 246728  85.7                                      \nfit_metric 101 246315 246657  92.7       7.06 0.00000       9       0.63\nfit_scalar 110 246309 246591 105.3      12.57 0.00813       9       0.18\n\n\n\ndata.frame(bind_rows(\n  config = fitMeasures(fit_config, c(\"cfi\",\"rmsea\",\"srmr\")),\n  metric = fitMeasures(fit_metric, c(\"cfi\",\"rmsea\",\"srmr\")),\n  scalar = fitMeasures(fit_scalar, c(\"cfi\",\"rmsea\",\"srmr\")),.id = \"model\"))\n\n   model cfi rmsea    srmr\n1 config   1     0 0.00684\n2 metric   1     0 0.00891\n3 scalar   1     0 0.00929\n\n\n\n\n\n\n\n\nTip\n\n\nAlways check where misfit arises (local diagnostics)."
  },
  {
    "objectID": "slides/09_longitudinal-sem_growth_invariance-over-time.html#diagnostics-global-vs-local-fit-in-invariance",
    "href": "slides/09_longitudinal-sem_growth_invariance-over-time.html#diagnostics-global-vs-local-fit-in-invariance",
    "title": "Longitudinal SEM: Growth + Invariance Over Time",
    "section": "Diagnostics: global vs local fit (in invariance)",
    "text": "Diagnostics: global vs local fit (in invariance)\nGlobal: χ², CFI/TLI, RMSEA (+CI), SRMR\nLocal:\n\nstandardized residuals\nmodification indices (MI)\ninspect which items/waves break invariance\n\n\n# Local diagnostics example\nmi &lt;- modificationIndices(fit_scalar)\nmi |&gt; arrange(desc(mi)) |&gt; head(10)\n\n    lhs op  rhs   mi    epc sepc.lv sepc.all sepc.nox\n1  y1_1 ~~ y4_1 7.95 -0.027  -0.027   -0.044   -0.044\n2    F2 =~ y1_1 5.27  0.027   0.027    0.022    0.022\n3    F3 =~ y1_1 5.03  0.024   0.023    0.019    0.019\n4    F2 =~ y4_1 3.95 -0.025  -0.025   -0.023   -0.023\n5    F1 =~ y4_4 3.75  0.025   0.025    0.023    0.023\n6  y4_3 ~~ y2_4 3.70  0.017   0.017    0.026    0.026\n7    F1 =~ y4_3 3.56 -0.024  -0.024   -0.023   -0.023\n8    F2 =~ y4_4 3.45  0.024   0.024    0.022    0.022\n9  y3_1 ~~ y4_3 3.31 -0.017  -0.017   -0.028   -0.028\n10 y4_1 ~~ y2_2 3.17 -0.015  -0.015   -0.023   -0.023"
  },
  {
    "objectID": "slides/09_longitudinal-sem_growth_invariance-over-time.html#pitfallcallout-partial-invariance-fishing",
    "href": "slides/09_longitudinal-sem_growth_invariance-over-time.html#pitfallcallout-partial-invariance-fishing",
    "title": "Longitudinal SEM: Growth + Invariance Over Time",
    "section": "Pitfall/callout: “Partial invariance = fishing?”",
    "text": "Pitfall/callout: “Partial invariance = fishing?”\n\n\n\n\n\n\nWarning\n\n\nPartial invariance is not “cheating” if done transparently:\n\nfree the smallest number of parameters\njustify based on item content / design changes\nreport which parameters were freed\nverify conclusions are robust (sensitivity)\n\n\n\n\nA good practice: free one intercept (or loading) at a time guided by theory + MI, then reassess."
  },
  {
    "objectID": "slides/09_longitudinal-sem_growth_invariance-over-time.html#transition-from-invariance-to-growth",
    "href": "slides/09_longitudinal-sem_growth_invariance-over-time.html#transition-from-invariance-to-growth",
    "title": "Longitudinal SEM: Growth + Invariance Over Time",
    "section": "Transition: from invariance to growth",
    "text": "Transition: from invariance to growth\nIf longitudinal (partial) scalar invariance holds, we can interpret latent means over time (like we did for group comparisons in MG-CFA).\nGrowth models re-express these latent means as a trajectory using growth factors:\n\nIntercept factor (i): baseline level (at a chosen time point)\nSlope factor (s): rate of change (linear, unless extended)\n\nOptional: quadratic slope, piecewise slopes…"
  },
  {
    "objectID": "slides/09_longitudinal-sem_growth_invariance-over-time.html#minimal-math-lgm-as-cfa-with-time-scores",
    "href": "slides/09_longitudinal-sem_growth_invariance-over-time.html#minimal-math-lgm-as-cfa-with-time-scores",
    "title": "Longitudinal SEM: Growth + Invariance Over Time",
    "section": "Minimal math: LGM as CFA with time scores",
    "text": "Minimal math: LGM as CFA with time scores\nFor person n at time t:\n\\[\n\\eta_{nt} = i_n + \\lambda_t s_n + \\varepsilon_{nt}\n\\]\n\n\\((i_n)\\) and \\((s_n)\\) are latent variables (random effects)\n\\((\\lambda_t)\\) are fixed time scores (e.g., 0,1,2,3)\n\\((\\varepsilon_{nt})\\) are time-specific residuals\n\nMeans and variances:\n\n\\((E(i_n) = \\mu_i)\\), \\((Var(i_n)=\\sigma_i^2)\\)\n\\((E(s_n) = \\mu_s)\\), \\((Var(s_n)=\\sigma_s^2)\\)\n\\((Cov(i_n,s_n)=\\sigma_{is})\\)"
  },
  {
    "objectID": "slides/09_longitudinal-sem_growth_invariance-over-time.html#diagram-growth-model-intercept-slope",
    "href": "slides/09_longitudinal-sem_growth_invariance-over-time.html#diagram-growth-model-intercept-slope",
    "title": "Longitudinal SEM: Growth + Invariance Over Time",
    "section": "Diagram: growth model (intercept + slope)",
    "text": "Diagram: growth model (intercept + slope)\n\n\n\n\n\n\n\nNote\n\n\nThis is a linear second-order latent growth curve model"
  },
  {
    "objectID": "slides/09_longitudinal-sem_growth_invariance-over-time.html#lgm-on-observed-composites-teaching-friendly",
    "href": "slides/09_longitudinal-sem_growth_invariance-over-time.html#lgm-on-observed-composites-teaching-friendly",
    "title": "Longitudinal SEM: Growth + Invariance Over Time",
    "section": "LGM on observed composites (teaching-friendly)",
    "text": "LGM on observed composites (teaching-friendly)\nWe’ll start with a simple observed repeated measure (think: scale score). In practice, you often combine: - longitudinal invariance CFA for measurement - then growth model on latent factors (“second-order” growth)\nCreate an observed score per wave (for illustration):\n\ndat &lt;- dat |&gt;\n  mutate(\n    y_t1 = rowMeans(across(c(y1_1,y2_1,y3_1,y4_1))),\n    y_t2 = rowMeans(across(c(y1_2,y2_2,y3_2,y4_2))),\n    y_t3 = rowMeans(across(c(y1_3,y2_3,y3_3,y4_3))),\n    y_t4 = rowMeans(across(c(y1_4,y2_4,y3_4,y4_4)))\n  )"
  },
  {
    "objectID": "slides/09_longitudinal-sem_growth_invariance-over-time.html#linear-growth-model-in-lavaan",
    "href": "slides/09_longitudinal-sem_growth_invariance-over-time.html#linear-growth-model-in-lavaan",
    "title": "Longitudinal SEM: Growth + Invariance Over Time",
    "section": "Linear growth model in lavaan",
    "text": "Linear growth model in lavaan\nIn lavaan, growth() is a convenience wrapper that fits an SEM with meanstructure=TRUE by default (needed to estimate growth means). If you use sem()/cfa(), you must set it explicitly.\n\nlgm_linear &lt;- '\n# growth factors\ni =~ 1*y_t1 + 1*y_t2 + 1*y_t3 + 1*y_t4\ns =~ 0*y_t1 + 1*y_t2 + 2*y_t3 + 3*y_t4\n\n# (optional) allow residual autocorrelation\ny_t1 ~~ y_t2\ny_t2 ~~ y_t3\ny_t3 ~~ y_t4\n'\n\nfit_lgm &lt;- growth(lgm_linear, data = dat)  # meanstructure handled\n\n\n\n\n\n\n\nWarning\n\n\nThis model is already assuming random intercepts and slopes"
  },
  {
    "objectID": "slides/09_longitudinal-sem_growth_invariance-over-time.html#interpreting-the-growth-output",
    "href": "slides/09_longitudinal-sem_growth_invariance-over-time.html#interpreting-the-growth-output",
    "title": "Longitudinal SEM: Growth + Invariance Over Time",
    "section": "Interpreting the growth output",
    "text": "Interpreting the growth output\nKey parameters:\n\nMean(i) = average baseline (at time score 0)\nMean(s) = average change per time unit\nVar(i) = between-person differences in baseline\nVar(s) = between-person differences in change (heterogeneity)\nCov(i,s) = association between intercept and slope (often negative due to artifacts: regression-to-mean, boundaries, heteroskedasticity - interpret carefully)\n\n\nparameterEstimates(fit_lgm) |&gt;\n  filter(op %in% c(\"~1\",\"~~\") & lhs %in% c(\"i\",\"s\"))\n\n  lhs op rhs    est    se     z pvalue ci.lower ci.upper\n1   i ~~   i  0.478 0.025 19.41  0.000    0.429    0.526\n2   s ~~   s  0.031 0.005  6.42  0.000    0.021    0.040\n3   i ~~   s -0.028 0.009 -3.21  0.001   -0.044   -0.011\n4   i ~1     -0.017 0.012 -1.47  0.141   -0.040    0.006\n5   s ~1      0.230 0.004 56.51  0.000    0.222    0.238"
  },
  {
    "objectID": "slides/09_longitudinal-sem_growth_invariance-over-time.html#pitfallcallout-time-coding-is-a-modeling-choice",
    "href": "slides/09_longitudinal-sem_growth_invariance-over-time.html#pitfallcallout-time-coding-is-a-modeling-choice",
    "title": "Longitudinal SEM: Growth + Invariance Over Time",
    "section": "Pitfall/callout: time coding is a modeling choice",
    "text": "Pitfall/callout: time coding is a modeling choice\n\n\n\n\n\n\nWarning\n\n\nChanging time scores changes interpretation.\nIf you code slope loadings as 0,1,2,3 then:\n\nintercept = expected value at wave 1\n\nIf you code as -1,0,1,2 then: - intercept = expected value at wave 2\nIf you center at the midpoint, intercept becomes “midpoint status.”\n\n\n\nRemember to choose a centering that matches the substantive interpretation you want.\n\n\n\n\n\n\nWarning\n\n\nTIME POINTS MUST BE CHOSEN A PRIORI, BASED ON THEORY.\ne.g. Is this time point large enough to see change?"
  },
  {
    "objectID": "slides/09_longitudinal-sem_growth_invariance-over-time.html#when-linear-growth-is-wrong",
    "href": "slides/09_longitudinal-sem_growth_invariance-over-time.html#when-linear-growth-is-wrong",
    "title": "Longitudinal SEM: Growth + Invariance Over Time",
    "section": "When linear growth is wrong",
    "text": "When linear growth is wrong\nSigns: - systematic residual patterns (local misfit) - poor global fit - slope mean doesn’t capture curvature\nOptions (in order of interpretability): 1) Add quadratic slope 2) Use piecewise slopes (e.g., pre/post intervention) 3) Use latent basis (free intermediate time scores)"
  },
  {
    "objectID": "slides/09_longitudinal-sem_growth_invariance-over-time.html#quadratic-growth-example",
    "href": "slides/09_longitudinal-sem_growth_invariance-over-time.html#quadratic-growth-example",
    "title": "Longitudinal SEM: Growth + Invariance Over Time",
    "section": "Quadratic growth example",
    "text": "Quadratic growth example\n\n\nset.seed(123)\n\n## ----------------------------\n## 1) Population model: quadratic growth on observed variables\n## ----------------------------\npop_quad &lt;- '\n# Growth factors (no first-order measurement factors; y_t* are the repeated measures)\ni =~ 1*y_t1 + 1*y_t2 + 1*y_t3 + 1*y_t4\ns =~ 0*y_t1 + 1*y_t2 + 2*y_t3 + 3*y_t4\nq =~ 0*y_t1 + 1*y_t2 + 4*y_t3 + 9*y_t4\n\n# Factor means (imply the mean trajectory)\ni ~ 0*1\ns ~ 0.40*1\nq ~ 0.15*1\n\n# Factor (co)variances (individual differences)\ni ~~ 1.00*i\ns ~~ 0.40*s\nq ~~ 0.10*q\ni ~~ 0.30*s\ni ~~ 0.10*q\ns ~~ 0.05*q\n\n# Fix observed intercepts so means come from i,s,q\ny_t1 ~ 0*1\ny_t2 ~ 0*1\ny_t3 ~ 0*1\ny_t4 ~ 0*1\n\n# Residual variances\ny_t1 ~~ 0.64*y_t1\ny_t2 ~~ 0.64*y_t2\ny_t3 ~~ 0.64*y_t3\ny_t4 ~~ 0.64*y_t4\n\n# Adjacent residual autocorrelation (covariances)\ny_t1 ~~ 0.192*y_t2\ny_t2 ~~ 0.192*y_t3\ny_t3 ~~ 0.192*y_t4\n'\n\ndat &lt;- simulateData(pop_quad, sample.nobs = 6000, meanstructure = TRUE)"
  },
  {
    "objectID": "slides/09_longitudinal-sem_growth_invariance-over-time.html#local-diagnostics-for-growth-models",
    "href": "slides/09_longitudinal-sem_growth_invariance-over-time.html#local-diagnostics-for-growth-models",
    "title": "Longitudinal SEM: Growth + Invariance Over Time",
    "section": "Local diagnostics for growth models",
    "text": "Local diagnostics for growth models\nGlobal fit is necessary but not sufficient.\n\nresidual autocorrelation (y_t2 ~~ y_t3, etc.)\nMIs suggesting additional residual correlations\nimplausible negative variances (Heywood)\nstandardized residuals / fitted vs observed means\n\n\nmi_g &lt;- modificationIndices(fit_quad)\nmi_g |&gt; arrange(desc(mi)) |&gt; head(10)\n\n    lhs op  rhs   mi    epc sepc.lv sepc.all sepc.nox\n1     i =~ y_t4 1.42  4.525   5.596    1.267    1.267\n2     i =~ y_t3 1.42 -1.508  -1.865   -0.682   -0.682\n3     i =~ y_t2 1.42  1.508   1.865    1.084    1.084\n4     s =~ y_t1 1.42  0.099   0.108    0.084    0.084\n5  y_t2 ~1      1.42 -0.014  -0.014   -0.008   -0.008\n6     s =~ y_t2 1.42 -0.033  -0.036   -0.021   -0.021\n7  y_t1 ~1      1.42  0.041   0.041    0.032    0.032\n8     q =~ y_t4 1.42 -0.281  -0.121   -0.027   -0.027\n9     q =~ y_t1 1.42  0.281   0.121    0.094    0.094\n10 y_t3 ~1      1.42  0.014   0.014    0.005    0.005"
  },
  {
    "objectID": "slides/09_longitudinal-sem_growth_invariance-over-time.html#conditional-growth-predictors-of-i-and-s",
    "href": "slides/09_longitudinal-sem_growth_invariance-over-time.html#conditional-growth-predictors-of-i-and-s",
    "title": "Longitudinal SEM: Growth + Invariance Over Time",
    "section": "Conditional growth: predictors of i and s",
    "text": "Conditional growth: predictors of i and s\nAdd a time-invariant covariate x predicting baseline and growth.\n\ndat$x &lt;- rnorm(nrow(dat))  # example covariate\n\nlgm_cond &lt;- '\ni =~ 1*y_t1 + 1*y_t2 + 1*y_t3 + 1*y_t4\ns =~ 0*y_t1 + 1*y_t2 + 2*y_t3 + 3*y_t4\n\n# regressions: predictors of growth factors\ni ~ x\ns ~ x\n\ny_t1 ~~ y_t2\ny_t2 ~~ y_t3\ny_t3 ~~ y_t4\n'\n\nfit_lgm_c &lt;- growth(lgm_cond, data = dat)"
  },
  {
    "objectID": "slides/09_longitudinal-sem_growth_invariance-over-time.html#what-we-did-not-do-on-purpose",
    "href": "slides/09_longitudinal-sem_growth_invariance-over-time.html#what-we-did-not-do-on-purpose",
    "title": "Longitudinal SEM: Growth + Invariance Over Time",
    "section": "What we did NOT do (on purpose)",
    "text": "What we did NOT do (on purpose)\n\nRI-CLPM and LCS families (they answer different questions)\n→ RI-CLPM warnings & alternatives: slides/opt05_riclpm_warning-and-alternatives.qmd (and/or extras/ex06_riclpm_vs_clpm.qmd) → Latent change score models: extras/ex07_latent-change-score_models.qmd"
  },
  {
    "objectID": "slides/09_longitudinal-sem_growth_invariance-over-time.html#exercises-lab09-explicit-links",
    "href": "slides/09_longitudinal-sem_growth_invariance-over-time.html#exercises-lab09-explicit-links",
    "title": "Longitudinal SEM: Growth + Invariance Over Time",
    "section": "Exercises → Lab09 (explicit links)",
    "text": "Exercises → Lab09 (explicit links)\nIn Lab09 (longitudinal growth) you will:\n\nLongitudinal invariance ladder\n\nFit configural → metric → scalar\nDecide if partial scalar is needed (and document what you free)\n\nFit linear LGM (time scores 0,1,2,3)\n\nInterpret mean/variance of intercept and slope\nRe-center time to change intercept meaning\n\nAdd curvature or residual autocorrelation\n\nCompare fit + interpretability (don’t respecify blindly)\n\nConditional growth\n\nAdd a predictor of intercept and slope; interpret effects"
  },
  {
    "objectID": "slides/09_longitudinal-sem_growth_invariance-over-time.html#take-home-summary-3-things",
    "href": "slides/09_longitudinal-sem_growth_invariance-over-time.html#take-home-summary-3-things",
    "title": "Longitudinal SEM: Growth + Invariance Over Time",
    "section": "Take-home summary: 3 things",
    "text": "Take-home summary: 3 things\n\nMeasurement invariance over time is the entry ticket to interpreting mean change.\nGrowth models are SEMs with time-coded loadings: interpretation depends on time coding/centering.\nDiagnostics matter: combine global fit with local checks; respecify with theory and transparency."
  },
  {
    "objectID": "slides/09_longitudinal-sem_growth_invariance-over-time.html#further-reading-extras",
    "href": "slides/09_longitudinal-sem_growth_invariance-over-time.html#further-reading-extras",
    "title": "Longitudinal SEM: Growth + Invariance Over Time",
    "section": "Further reading (extras)",
    "text": "Further reading (extras)\n\nRI-CLPM warnings & alternatives: slides/opt05_riclpm_warning-and-alternatives.qmd (and/or extras/ex06_riclpm_vs_clpm.qmd)\nLatent change score models: extras/ex07_latent-change-score_models.qmd\nOptional deepening: reporting and model comparison conventions (connect to Lesson 06 / reporting checklist)"
  },
  {
    "objectID": "slides/09_longitudinal-sem_growth_invariance-over-time.html#references",
    "href": "slides/09_longitudinal-sem_growth_invariance-over-time.html#references",
    "title": "Longitudinal SEM: Growth + Invariance Over Time",
    "section": "References",
    "text": "References\n(Generated from refs/references.bib using APA 7 CSL.)"
  },
  {
    "objectID": "slides/09_longitudinal-sem_growth_invariance-over-time.html#metric-invariance-equal-loadings",
    "href": "slides/09_longitudinal-sem_growth_invariance-over-time.html#metric-invariance-equal-loadings",
    "title": "Longitudinal SEM: Growth + Invariance Over Time",
    "section": "Metric invariance: equal loadings",
    "text": "Metric invariance: equal loadings\n\nmod_metric &lt;- '\nF1 =~ l1*y1_1 + l2*y2_1 + l3*y3_1 + l4*y4_1\nF2 =~ l1*y1_2 + l2*y2_2 + l3*y3_2 + l4*y4_2\nF3 =~ l1*y1_3 + l2*y2_3 + l3*y3_3 + l4*y4_3\nF4 =~ l1*y1_4 + l2*y2_4 + l3*y3_4 + l4*y4_4\n\ny1_1 ~~ y1_2\ny1_2 ~~ y1_3\ny1_3 ~~ y1_4\ny2_1 ~~ y2_2\ny2_2 ~~ y2_3\ny2_3 ~~ y2_4\n'\n\nfit_metric &lt;- cfa(mod_metric, data = dat, meanstructure = TRUE)"
  },
  {
    "objectID": "slides/09_longitudinal-sem_growth_invariance-over-time.html#scalar-invariance-equal-intercepts-too",
    "href": "slides/09_longitudinal-sem_growth_invariance-over-time.html#scalar-invariance-equal-intercepts-too",
    "title": "Longitudinal SEM: Growth + Invariance Over Time",
    "section": "Scalar invariance: equal intercepts too",
    "text": "Scalar invariance: equal intercepts too\n\nmod_scalar &lt;- '\nF1 =~ l1*y1_1 + l2*y2_1 + l3*y3_1 + l4*y4_1\nF2 =~ l1*y1_2 + l2*y2_2 + l3*y3_2 + l4*y4_2\nF3 =~ l1*y1_3 + l2*y2_3 + l3*y3_3 + l4*y4_3\nF4 =~ l1*y1_4 + l2*y2_4 + l3*y3_4 + l4*y4_4\n\n# equal intercepts across time\ny1_1 ~ i1*1; y1_2 ~ i1*1; y1_3 ~ i1*1; y1_4 ~ i1*1\ny2_1 ~ i2*1; y2_2 ~ i2*1; y2_3 ~ i2*1; y2_4 ~ i2*1\ny3_1 ~ i3*1; y3_2 ~ i3*1; y3_3 ~ i3*1; y3_4 ~ i3*1\ny4_1 ~ i4*1; y4_2 ~ i4*1; y4_3 ~ i4*1; y4_4 ~ i4*1\n\ny1_1 ~~ y1_2\ny1_2 ~~ y1_3\ny1_3 ~~ y1_4\ny2_1 ~~ y2_2\ny2_2 ~~ y2_3\ny2_3 ~~ y2_4\n'\n\nfit_scalar &lt;- cfa(mod_scalar, data = dat, meanstructure = TRUE)"
  },
  {
    "objectID": "slides/09_longitudinal-sem_growth_invariance-over-time.html#today-in-the-workflow",
    "href": "slides/09_longitudinal-sem_growth_invariance-over-time.html#today-in-the-workflow",
    "title": "Longitudinal SEM: Growth + Invariance Over Time",
    "section": "Today in the workflow",
    "text": "Today in the workflow\nSpecify → Identify → Estimate → Evaluate → Revise/Report\n\n\n\nToday: measurement in a longitudinal fashion.\nGrowth: measuring and testing change in latent variables."
  },
  {
    "objectID": "slides/09_longitudinal-sem_growth_invariance-over-time.html#diagram-longitudinal-cfa",
    "href": "slides/09_longitudinal-sem_growth_invariance-over-time.html#diagram-longitudinal-cfa",
    "title": "Longitudinal SEM: Growth + Invariance Over Time",
    "section": "Diagram: longitudinal CFA",
    "text": "Diagram: longitudinal CFA"
  },
  {
    "objectID": "slides/09_longitudinal-sem_growth_invariance-over-time.html#step-2-metric-invariance-equal-loadings",
    "href": "slides/09_longitudinal-sem_growth_invariance-over-time.html#step-2-metric-invariance-equal-loadings",
    "title": "Longitudinal SEM: Growth + Invariance Over Time",
    "section": "Step 2: Metric invariance: equal loadings",
    "text": "Step 2: Metric invariance: equal loadings\n\n\nmod_metric &lt;- '\n# equal loadings across timepoints\nF1 =~ l1*y1_1 + l2*y2_1 + l3*y3_1 + l4*y4_1\nF2 =~ l1*y1_2 + l2*y2_2 + l3*y3_2 + l4*y4_2\nF3 =~ l1*y1_3 + l2*y2_3 + l3*y3_3 + l4*y4_3\nF4 =~ l1*y1_4 + l2*y2_4 + l3*y3_4 + l4*y4_4\n\n# correlated residuals \ny1_1 ~~ y1_2\ny1_2 ~~ y1_3\ny1_3 ~~ y1_4\ny2_1 ~~ y2_2\ny2_2 ~~ y2_3\ny2_3 ~~ y2_4\n'\n\nfit_metric &lt;- cfa(mod_metric, data = dat, meanstructure = TRUE)"
  },
  {
    "objectID": "slides/09_longitudinal-sem_growth_invariance-over-time.html#step-3-scalar-invariance-equal-intercepts-too",
    "href": "slides/09_longitudinal-sem_growth_invariance-over-time.html#step-3-scalar-invariance-equal-intercepts-too",
    "title": "Longitudinal SEM: Growth + Invariance Over Time",
    "section": "Step 3: Scalar invariance: equal intercepts too",
    "text": "Step 3: Scalar invariance: equal intercepts too\n\n\nmod_scalar &lt;- '\n# equal loadings across timepoints\nF1 =~ l1*y1_1 + l2*y2_1 + l3*y3_1 + l4*y4_1\nF2 =~ l1*y1_2 + l2*y2_2 + l3*y3_2 + l4*y4_2\nF3 =~ l1*y1_3 + l2*y2_3 + l3*y3_3 + l4*y4_3\nF4 =~ l1*y1_4 + l2*y2_4 + l3*y3_4 + l4*y4_4\n\n# equal intercepts across time\ny1_1 ~ i1*1; y1_2 ~ i1*1; y1_3 ~ i1*1; y1_4 ~ i1*1\ny2_1 ~ i2*1; y2_2 ~ i2*1; y2_3 ~ i2*1; y2_4 ~ i2*1\ny3_1 ~ i3*1; y3_2 ~ i3*1; y3_3 ~ i3*1; y3_4 ~ i3*1\ny4_1 ~ i4*1; y4_2 ~ i4*1; y4_3 ~ i4*1; y4_4 ~ i4*1\n\n# correlated residuals \ny1_1 ~~ y1_2\ny1_2 ~~ y1_3\ny1_3 ~~ y1_4\ny2_1 ~~ y2_2\ny2_2 ~~ y2_3\ny2_3 ~~ y2_4\n\n# free means\nF1 ~ 0*1\nF2 ~ m2*1\nF3 ~ m3*1\nF4 ~ m4*1\n'\nfit_scalar &lt;- cfa(mod_scalar, data = dat, meanstructure = TRUE)\n\n\n\n\n\n\n\n\nTip\n\n\nFreeing means could be essential if there is actual mean change."
  },
  {
    "objectID": "slides/09_longitudinal-sem_growth_invariance-over-time.html#transition-from-invariance-to-growth-1",
    "href": "slides/09_longitudinal-sem_growth_invariance-over-time.html#transition-from-invariance-to-growth-1",
    "title": "Longitudinal SEM: Growth + Invariance Over Time",
    "section": "Transition: from invariance to growth",
    "text": "Transition: from invariance to growth\nWhat questions do you answer with latent growth models?\n\nWhat is the average trajectory for all respondents?\n\nWhat is their initial value (i.e., mean)?\nIs there any change?\n\nWhat’s the form of the change\n\n\nIs the average trajectory enough or participants vary in their trajectories?\n\nrandom effects of intercepts and slope\n\nAre random effects explainable? How? Do we need more variables?"
  },
  {
    "objectID": "slides/09_longitudinal-sem_growth_invariance-over-time.html#lgm-on-observed-composites",
    "href": "slides/09_longitudinal-sem_growth_invariance-over-time.html#lgm-on-observed-composites",
    "title": "Longitudinal SEM: Growth + Invariance Over Time",
    "section": "LGM on observed composites",
    "text": "LGM on observed composites\nWe’ll start with a simple observed repeated measure (think: scale score).\nIn practice, you often combine:\n\nlongitudinal invariance CFA for measurement\nthen growth model on latent factors (“second-order” growth)\n\nCreate an observed score per wave from the data we used before:\n\ndat &lt;- dat |&gt;\n  mutate(\n    y_t1 = rowMeans(across(c(y1_1,y2_1,y3_1,y4_1))),\n    y_t2 = rowMeans(across(c(y1_2,y2_2,y3_2,y4_2))),\n    y_t3 = rowMeans(across(c(y1_3,y2_3,y3_3,y4_3))),\n    y_t4 = rowMeans(across(c(y1_4,y2_4,y3_4,y4_4)))\n  )\n\n\n\n\n\n\n\nWarning\n\n\n(teaching-friendly less publication/SEM-friendly)"
  },
  {
    "objectID": "slides/09_longitudinal-sem_growth_invariance-over-time.html#the-growth-summary",
    "href": "slides/09_longitudinal-sem_growth_invariance-over-time.html#the-growth-summary",
    "title": "Longitudinal SEM: Growth + Invariance Over Time",
    "section": "The growth summary",
    "text": "The growth summary\n\nsummary(fit_lgm, fit.measures = TRUE, standardized = TRUE)\n\nlavaan 0.6-19 ended normally after 26 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        12\n\n  Number of observations                          6000\n\nModel Test User Model:\n                                                      \n  Test statistic                                39.720\n  Degrees of freedom                                 2\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                             10572.830\n  Degrees of freedom                                 6\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.996\n  Tucker-Lewis Index (TLI)                       0.989\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)             -26907.698\n  Loglikelihood unrestricted model (H1)     -26887.838\n                                                      \n  Akaike (AIC)                               53839.396\n  Bayesian (BIC)                             53919.790\n  Sample-size adjusted Bayesian (SABIC)      53881.658\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.056\n  90 Percent confidence interval - lower         0.042\n  90 Percent confidence interval - upper         0.072\n  P-value H_0: RMSEA &lt;= 0.050                    0.230\n  P-value H_0: RMSEA &gt;= 0.080                    0.006\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.014\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  i =~                                                                  \n    y_t1              1.000                               0.691    0.742\n    y_t2              1.000                               0.691    0.741\n    y_t3              1.000                               0.691    0.750\n    y_t4              1.000                               0.691    0.756\n  s =~                                                                  \n    y_t1              0.000                               0.000    0.000\n    y_t2              1.000                               0.175    0.187\n    y_t3              2.000                               0.350    0.379\n    y_t4              3.000                               0.524    0.574\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n .y_t1 ~~                                                               \n   .y_t2              0.084    0.014    5.812    0.000    0.084    0.208\n .y_t2 ~~                                                               \n   .y_t3              0.102    0.007   15.354    0.000    0.102    0.262\n .y_t3 ~~                                                               \n   .y_t4              0.065    0.015    4.253    0.000    0.065    0.218\n  i ~~                                                                  \n    s                -0.028    0.009   -3.213    0.001   -0.228   -0.228\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n    i                -0.017    0.012   -1.473    0.141   -0.025   -0.025\n    s                 0.230    0.004   56.514    0.000    1.317    1.317\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .y_t1              0.390    0.024   16.180    0.000    0.390    0.449\n   .y_t2              0.418    0.014   29.997    0.000    0.418    0.480\n   .y_t3              0.359    0.014   26.593    0.000    0.359    0.423\n   .y_t4              0.248    0.025    9.774    0.000    0.248    0.297\n    i                 0.478    0.025   19.414    0.000    1.000    1.000\n    s                 0.031    0.005    6.415    0.000    1.000    1.000"
  },
  {
    "objectID": "slides/09_longitudinal-sem_growth_invariance-over-time.html#a-stepwise-approach-to-lgm",
    "href": "slides/09_longitudinal-sem_growth_invariance-over-time.html#a-stepwise-approach-to-lgm",
    "title": "Longitudinal SEM: Growth + Invariance Over Time",
    "section": "A stepwise approach to LGM",
    "text": "A stepwise approach to LGM"
  },
  {
    "objectID": "slides/09_longitudinal-sem_growth_invariance-over-time.html#the-second-order-factor-model",
    "href": "slides/09_longitudinal-sem_growth_invariance-over-time.html#the-second-order-factor-model",
    "title": "Longitudinal SEM: Growth + Invariance Over Time",
    "section": "The second-order factor model",
    "text": "The second-order factor model\n\n\n\nThe measurement block\n\nlgm_linear_2ndorder &lt;- '\n## 1) MEASUREMENT (strong/scalar invariance)\n\n# equal loadings across time (metric invariance)\nF1 =~ 1*y1_1 + l2*y2_1 + l3*y3_1 + l4*y4_1\nF2 =~ 1*y1_2 + l2*y2_2 + l3*y3_2 + l4*y4_2\nF3 =~ 1*y1_3 + l2*y2_3 + l3*y3_3 + l4*y4_3\nF4 =~ 1*y1_4 + l2*y2_4 + l3*y3_4 + l4*y4_4\n\n# equal intercepts across time (scalar invariance)\ny1_1 ~ i1*1; y1_2 ~ i1*1; y1_3 ~ i1*1; y1_4 ~ i1*1\ny2_1 ~ i2*1; y2_2 ~ i2*1; y2_3 ~ i2*1; y2_4 ~ i2*1\ny3_1 ~ i3*1; y3_2 ~ i3*1; y3_3 ~ i3*1; y3_4 ~ i3*1\ny4_1 ~ i4*1; y4_2 ~ i4*1; y4_3 ~ i4*1; y4_4 ~ i4*1\n\n# (optional) correlated residuals across waves\ny1_1 ~~ r1*y1_2\ny1_2 ~~ r1*y1_3\ny1_3 ~~ r1*y1_4\n\ny2_1 ~~ r2*y2_2\ny2_2 ~~ r2*y2_3\ny2_3 ~~ r2*y2_4\n\ny3_1 ~~ r3*y3_2\ny3_2 ~~ r3*y3_3\ny3_3 ~~ r3*y3_4\n\ny4_1 ~~ r4*y4_2\ny4_2 ~~ r4*y4_3\ny4_3 ~~ r4*y4_4\n\n'\n\n\nThe latent change block\n\nlgm_linear_2ndorder &lt;- '\n## 2) SECOND-ORDER GROWTH ON LATENT FACTORS\n\n# growth factors (second-order)\ni =~ 1*F1 + 1*F2 + 1*F3 + 1*F4\ns =~ 0*F1 + 1*F2 + 2*F3 + 3*F4\n\n# estimate growth means (trajectory in the latent metric)\ni ~ 1\ns ~ 1\n\n# fix means of the first-order factors so i/s carry the mean structure\nF1 ~ 0*1\nF2 ~ 0*1\nF3 ~ 0*1\nF4 ~ 0*1\n\n# (optional) allow i-s covariance\ni ~~ s\n\n# (optional) residual autocorrelation among the time-specific factors\nF1 ~~ F2\nF2 ~~ F3\nF3 ~~ F4\n'\nfit_lgm_2nd &lt;- sem(lgm_linear_2ndorder, data = dat, meanstructure = TRUE)\n\n\n\n\n\n\n\n\n\nWarning\n\n\nWe are not using growth() here but sem + meanstructure=TRUE"
  },
  {
    "objectID": "slides/09_longitudinal-sem_growth_invariance-over-time.html#quadratic-results",
    "href": "slides/09_longitudinal-sem_growth_invariance-over-time.html#quadratic-results",
    "title": "Longitudinal SEM: Growth + Invariance Over Time",
    "section": "Quadratic results",
    "text": "Quadratic results\n\n\n\n\n## ----------------------------\n## 2) FIT LGM without quadratic\n## ----------------------------\nlgm_lin &lt;- '\ni =~ 1*y_t1 + 1*y_t2 + 1*y_t3 + 1*y_t4\ns =~ 0*y_t1 + 1*y_t2 + 2*y_t3 + 3*y_t4\n'\n\nfit_lin &lt;- growth(lgm_lin, data = dat)\n\nfitMeasures(fit_lin,  c(\"cfi\",\"tli\",\"rmsea\",\"srmr\",\"aic\",\"bic\"))\n\n      cfi       tli     rmsea      srmr       aic       bic \n    0.929     0.915     0.242     0.106 84653.539 84713.835 \n\n\n\n\n## ----------------------------\n## 3) FIT LGM with quadratic\n## ----------------------------\nlgm_quad &lt;- '\ni =~ 1*y_t1 + 1*y_t2 + 1*y_t3 + 1*y_t4\ns =~ 0*y_t1 + 1*y_t2 + 2*y_t3 + 3*y_t4\nq =~ 0*y_t1 + 1*y_t2 + 4*y_t3 + 9*y_t4\n'\n\nfit_quad &lt;- growth(lgm_quad, data = dat)\nfitMeasures(fit_quad, c(\"cfi\",\"tli\",\"rmsea\",\"srmr\",\"aic\",\"bic\"))\n\n      cfi       tli     rmsea      srmr       aic       bic \n    1.000     1.000     0.008     0.001 82904.604 82991.697 \n\n\n\n\nanova(fit_lin, fit_quad)  # chi-square diff test (nested models)\n\n\nChi-Squared Difference Test\n\n         Df   AIC   BIC   Chisq Chisq diff RMSEA Df diff          Pr(&gt;Chisq)\nfit_quad  1 82905 82992    1.42                                             \nfit_lin   5 84654 84714 1758.36       1757  0.27       4 &lt;0.0000000000000002\n            \nfit_quad    \nfit_lin  ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "slides/09_longitudinal-sem_growth_invariance-over-time.html#summary-of-the-conditional-model",
    "href": "slides/09_longitudinal-sem_growth_invariance-over-time.html#summary-of-the-conditional-model",
    "title": "Longitudinal SEM: Growth + Invariance Over Time",
    "section": "Summary of the conditional model",
    "text": "Summary of the conditional model\n\n\n\n\nsummary(fit_lgm_c, fit.measures = TRUE, standardized = TRUE)\n\nlavaan 0.6-19 ended normally after 41 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        14\n\n  Number of observations                          6000\n\nModel Test User Model:\n                                                      \n  Test statistic                               502.347\n  Degrees of freedom                                 4\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                             24670.853\n  Degrees of freedom                                10\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.980\n  Tucker-Lewis Index (TLI)                       0.949\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)             -41685.211\n  Loglikelihood unrestricted model (H1)     -41434.038\n                                                      \n  Akaike (AIC)                               83398.422\n  Bayesian (BIC)                             83492.216\n  Sample-size adjusted Bayesian (SABIC)      83447.727\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.144\n  90 Percent confidence interval - lower         0.134\n  90 Percent confidence interval - upper         0.155\n  P-value H_0: RMSEA &lt;= 0.050                    0.000\n  P-value H_0: RMSEA &gt;= 0.080                    1.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.052\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  i =~                                                                  \n    y_t1              1.000                               0.542    0.420\n    y_t2              1.000                               0.542    0.315\n    y_t3              1.000                               0.542    0.197\n    y_t4              1.000                               0.542    0.121\n  s =~                                                                  \n    y_t1              0.000                               0.000    0.000\n    y_t2              1.000                               0.832    0.483\n    y_t3              2.000                               1.664    0.605\n    y_t4              3.000                               2.496    0.557\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  i ~                                                                   \n    x                -0.012    0.016   -0.775    0.438   -0.022   -0.022\n  s ~                                                                   \n    x                 0.030    0.014    2.138    0.033    0.036    0.036\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n .y_t1 ~~                                                               \n   .y_t2              0.416    0.028   14.784    0.000    0.416    0.688\n .y_t2 ~~                                                               \n   .y_t3             -0.248    0.020  -12.374    0.000   -0.248   -0.465\n .y_t3 ~~                                                               \n   .y_t4              2.814    0.104   27.025    0.000    2.814    0.935\n .i ~~                                                                  \n   .s                 0.857    0.037   22.944    0.000    1.900    1.900\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .i                -0.141    0.016   -9.050    0.000   -0.259   -0.259\n   .s                 0.630    0.014   44.449    0.000    0.757    0.757\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .y_t1              1.373    0.058   23.604    0.000    1.373    0.823\n   .y_t2              0.266    0.027    9.840    0.000    0.266    0.090\n   .y_t3              1.073    0.065   16.476    0.000    1.073    0.142\n   .y_t4              8.445    0.223   37.805    0.000    8.445    0.420\n   .i                 0.294    0.053    5.575    0.000    1.000    1.000\n   .s                 0.692    0.028   24.380    0.000    0.999    0.999\n\n\n\n\n\n\n\n\n\nWarning\n\n\nAs for \\(i\\) ~~ \\(s\\) correlations, when an external variable is associated with the intercept, it will probably be associated with the slope, but this is often an artifact. A second-order model could help resolving this issue and avoid issues due to bounds in measures."
  },
  {
    "objectID": "slides/09_longitudinal-sem_growth_invariance-over-time.html#quadratic-growth-example-simulation",
    "href": "slides/09_longitudinal-sem_growth_invariance-over-time.html#quadratic-growth-example-simulation",
    "title": "Longitudinal SEM: Growth + Invariance Over Time",
    "section": "Quadratic growth example (simulation)",
    "text": "Quadratic growth example (simulation)\n\n\nset.seed(123)\n\n## ----------------------------\n## 1) Population model: quadratic growth on observed variables\n## ----------------------------\npop_quad &lt;- '\n# Growth factors (no first-order measurement factors; y_t* are the repeated measures)\ni =~ 1*y_t1 + 1*y_t2 + 1*y_t3 + 1*y_t4\ns =~ 0*y_t1 + 1*y_t2 + 2*y_t3 + 3*y_t4\nq =~ 0*y_t1 + 1*y_t2 + 4*y_t3 + 9*y_t4\n\n# Factor means (imply the mean trajectory)\ni ~ 0*1\ns ~ 0.40*1\nq ~ 0.15*1\n\n# Factor (co)variances (individual differences)\ni ~~ 1.00*i\ns ~~ 0.40*s\nq ~~ 0.10*q\ni ~~ 0.30*s\ni ~~ 0.10*q\ns ~~ 0.05*q\n\n# Fix observed intercepts so means come from i,s,q\ny_t1 ~ 0*1\ny_t2 ~ 0*1\ny_t3 ~ 0*1\ny_t4 ~ 0*1\n\n# Residual variances\ny_t1 ~~ 0.64*y_t1\ny_t2 ~~ 0.64*y_t2\ny_t3 ~~ 0.64*y_t3\ny_t4 ~~ 0.64*y_t4\n\n# Adjacent residual autocorrelation (covariances)\ny_t1 ~~ 0.192*y_t2\ny_t2 ~~ 0.192*y_t3\ny_t3 ~~ 0.192*y_t4\n'\n\ndat &lt;- simulateData(pop_quad, sample.nobs = 6000, meanstructure = TRUE)"
  },
  {
    "objectID": "labs/lab09_longitudinal_growth.html",
    "href": "labs/lab09_longitudinal_growth.html",
    "title": "Lab 09: Longitudinal SEM — Invariance Over Time & Latent Growth",
    "section": "",
    "text": "By the end of this lab you will be able to:\n\nFit a longitudinal CFA and evaluate configural → metric → scalar invariance across waves.\nUse global and local diagnostics to motivate disciplined partial invariance.\nFit latent growth curve models (LGM): linear, (optional) quadratic, and interpret growth parameters.\nExtend LGM with a predictor (conditional growth).\n\n\n\n\n\n\n\nNote\n\n\n\nTwo-step mindset: (1) Measurement invariance over time → (2) Growth model.\nIf the measurement shifts, “growth” can be an artifact."
  },
  {
    "objectID": "labs/lab09_longitudinal_growth.html#what-you-will-do",
    "href": "labs/lab09_longitudinal_growth.html#what-you-will-do",
    "title": "Lab 09: Longitudinal SEM — Invariance Over Time & Latent Growth",
    "section": "",
    "text": "By the end of this lab you will be able to:\n\nFit a longitudinal CFA and evaluate configural → metric → scalar invariance across waves.\nUse global and local diagnostics to motivate disciplined partial invariance.\nFit latent growth curve models (LGM): linear, (optional) quadratic, and interpret growth parameters.\nExtend LGM with a predictor (conditional growth).\n\n\n\n\n\n\n\nNote\n\n\n\nTwo-step mindset: (1) Measurement invariance over time → (2) Growth model.\nIf the measurement shifts, “growth” can be an artifact."
  },
  {
    "objectID": "labs/lab09_longitudinal_growth.html#setup",
    "href": "labs/lab09_longitudinal_growth.html#setup",
    "title": "Lab 09: Longitudinal SEM — Invariance Over Time & Latent Growth",
    "section": "0.2 Setup",
    "text": "0.2 Setup\n\n\nCode\nlibrary(lavaan)\nlibrary(semTools)\nlibrary(dplyr)\n\nset.seed(1234)"
  },
  {
    "objectID": "labs/lab09_longitudinal_growth.html#data-transparent-simulation",
    "href": "labs/lab09_longitudinal_growth.html#data-transparent-simulation",
    "title": "Lab 09: Longitudinal SEM — Invariance Over Time & Latent Growth",
    "section": "0.3 Data (transparent simulation)",
    "text": "0.3 Data (transparent simulation)\nWe simulate a construct measured by 4 indicators across 4 waves:\n\nOne latent factor per wave (F1–F4)\nStability across waves (correlated factors)\nCorrelated residuals across adjacent waves for the same indicator (common in repeated measures)\nIncreasing factor means over time (so growth exists in the population)\n\n\n\nCode\npop &lt;- '\n# Wave 1 factor\nF1 =~ 1*y1_1 + .8*y2_1 + .9*y3_1 + .7*y4_1\n# Wave 2 factor\nF2 =~ 1*y1_2 + .8*y2_2 + .9*y3_2 + .7*y4_2\n# Wave 3 factor\nF3 =~ 1*y1_3 + .8*y2_3 + .9*y3_3 + .7*y4_3\n# Wave 4 factor\nF4 =~ 1*y1_4 + .8*y2_4 + .9*y3_4 + .7*y4_4\n\n# Factor means (0 baseline; increasing means)\nF1 ~ 0*1\nF2 ~ .2*1\nF3 ~ .5*1\nF4 ~ .8*1\n\n# Factor variances\nF1 ~~ 1*F1\nF2 ~~ 1*F2\nF3 ~~ 1*F3\nF4 ~~ 1*F4\n\n# Stability (correlations)\nF1 ~~ .70*F2\nF2 ~~ .75*F3\nF3 ~~ .80*F4\nF1 ~~ .60*F3\nF2 ~~ .65*F4\nF1 ~~ .55*F4\n\n# Residual variances (items)\ny1_1 ~~ .5*y1_1; y2_1 ~~ .6*y2_1; y3_1 ~~ .5*y3_1; y4_1 ~~ .7*y4_1\ny1_2 ~~ .5*y1_2; y2_2 ~~ .6*y2_2; y3_2 ~~ .5*y3_2; y4_2 ~~ .7*y4_2\ny1_3 ~~ .5*y1_3; y2_3 ~~ .6*y2_3; y3_3 ~~ .5*y3_3; y4_3 ~~ .7*y4_3\ny1_4 ~~ .5*y1_4; y2_4 ~~ .6*y2_4; y3_4 ~~ .5*y3_4; y4_4 ~~ .7*y4_4\n\n# Correlated residuals across adjacent waves for same indicator\ny1_1 ~~ .25*y1_2\ny1_2 ~~ .25*y1_3\ny1_3 ~~ .25*y1_4\ny2_1 ~~ .20*y2_2\ny2_2 ~~ .20*y2_3\ny2_3 ~~ .20*y2_4\n'\n\ndat &lt;- simulateData(pop, sample.nobs = 600, meanstructure = TRUE)\n\n\n\n0.3.1 Optional: add missingness (realistic in longitudinal studies)\nIf you want a more realistic workflow, introduce missing data and use FIML.\n\n\nCode\n# OPTIONAL: comment out if you want complete data\nset.seed(2026)\nmiss_id &lt;- sample(seq_len(nrow(dat)), size = round(0.20*nrow(dat)))\ndat[miss_id, c(\"y1_4\",\"y2_4\",\"y3_4\",\"y4_4\")] &lt;- NA"
  },
  {
    "objectID": "labs/lab09_longitudinal_growth.html#a1.-configural-invariance",
    "href": "labs/lab09_longitudinal_growth.html#a1.-configural-invariance",
    "title": "Lab 09: Longitudinal SEM — Invariance Over Time & Latent Growth",
    "section": "1.1 A1. Configural invariance",
    "text": "1.1 A1. Configural invariance\nFit the configural model: same factor structure each wave, with correlated residuals for the same indicator across adjacent waves.\n\n\nCode\nmod_config &lt;- '\nF1 =~ y1_1 + y2_1 + y3_1 + y4_1\nF2 =~ y1_2 + y2_2 + y3_2 + y4_2\nF3 =~ y1_3 + y2_3 + y3_3 + y4_3\nF4 =~ y1_4 + y2_4 + y3_4 + y4_4\n\n# correlated residuals across time for same indicator (adjacent waves)\ny1_1 ~~ y1_2\ny1_2 ~~ y1_3\ny1_3 ~~ y1_4\ny2_1 ~~ y2_2\ny2_2 ~~ y2_3\ny2_3 ~~ y2_4\n'\nfit_config &lt;- cfa(mod_config, data = dat, meanstructure = TRUE, missing = \"fiml\")\nfitMeasures(fit_config, c(\"chisq\",\"df\",\"cfi\",\"tli\",\"rmsea\",\"srmr\"))\n\n\n chisq     df    cfi    tli  rmsea   srmr \n80.696 92.000  1.000  1.003  0.000  0.021 \n\n\n\n1.1.1 Questions\n\nIs the overall fit acceptable for a baseline model?\nDo the correlated residuals feel substantively justified here? Why might they be needed in repeated-measures measurement models?"
  },
  {
    "objectID": "labs/lab09_longitudinal_growth.html#a2.-metric-invariance-equal-loadings-across-waves",
    "href": "labs/lab09_longitudinal_growth.html#a2.-metric-invariance-equal-loadings-across-waves",
    "title": "Lab 09: Longitudinal SEM — Invariance Over Time & Latent Growth",
    "section": "1.2 A2. Metric invariance (equal loadings across waves)",
    "text": "1.2 A2. Metric invariance (equal loadings across waves)\nImpose equality constraints on loadings using labels (l1, l2, …). Keep the residual correlations.\n\n\nCode\nmod_metric &lt;- '\nF1 =~ l1*y1_1 + l2*y2_1 + l3*y3_1 + l4*y4_1\nF2 =~ l1*y1_2 + l2*y2_2 + l3*y3_2 + l4*y4_2\nF3 =~ l1*y1_3 + l2*y2_3 + l3*y3_3 + l4*y4_3\nF4 =~ l1*y1_4 + l2*y2_4 + l3*y3_4 + l4*y4_4\n\ny1_1 ~~ y1_2\ny1_2 ~~ y1_3\ny1_3 ~~ y1_4\ny2_1 ~~ y2_2\ny2_2 ~~ y2_3\ny2_3 ~~ y2_4\n'\nfit_metric &lt;- cfa(mod_metric, data = dat, meanstructure = TRUE, missing = \"fiml\")\nfitMeasures(fit_metric, c(\"chisq\",\"df\",\"cfi\",\"tli\",\"rmsea\",\"srmr\"))\n\n\n  chisq      df     cfi     tli   rmsea    srmr \n 83.889 101.000   1.000   1.004   0.000   0.026 \n\n\nCompare configural vs metric:\n\n\nCode\nlavTestLRT(fit_config, fit_metric)\n\n\n\nChi-Squared Difference Test\n\n            Df   AIC   BIC  Chisq Chisq diff RMSEA Df diff Pr(&gt;Chisq)\nfit_config  92 23287 23551 80.696                                    \nfit_metric 101 23272 23497 83.889     3.1932     0       9     0.9561\n\n\n\n\nCode\nrbind(\n  config = fitMeasures(fit_config, c(\"cfi\",\"rmsea\",\"srmr\")),\n  metric = fitMeasures(fit_metric, c(\"cfi\",\"rmsea\",\"srmr\"))\n)\n\n\n       cfi rmsea       srmr\nconfig   1     0 0.02105610\nmetric   1     0 0.02550694\n\n\n\n1.2.1 Questions\n\nDoes metric invariance appear plausible (based on fit changes)?\nIf you see a meaningful fit drop, where might non-invariance be coming from?"
  },
  {
    "objectID": "labs/lab09_longitudinal_growth.html#a3.-scalar-invariance-equal-intercepts-across-waves",
    "href": "labs/lab09_longitudinal_growth.html#a3.-scalar-invariance-equal-intercepts-across-waves",
    "title": "Lab 09: Longitudinal SEM — Invariance Over Time & Latent Growth",
    "section": "1.3 A3. Scalar invariance (equal intercepts across waves)",
    "text": "1.3 A3. Scalar invariance (equal intercepts across waves)\nAdd equality constraints on intercepts as well (i1, i2, …). This is the gateway to interpreting latent mean change.\n\n\nCode\nmod_scalar &lt;- '\nF1 =~ l1*y1_1 + l2*y2_1 + l3*y3_1 + l4*y4_1\nF2 =~ l1*y1_2 + l2*y2_2 + l3*y3_2 + l4*y4_2\nF3 =~ l1*y1_3 + l2*y2_3 + l3*y3_3 + l4*y4_3\nF4 =~ l1*y1_4 + l2*y2_4 + l3*y3_4 + l4*y4_4\n\n# equal intercepts across time\ny1_1 ~ i1*1; y1_2 ~ i1*1; y1_3 ~ i1*1; y1_4 ~ i1*1\ny2_1 ~ i2*1; y2_2 ~ i2*1; y2_3 ~ i2*1; y2_4 ~ i2*1\ny3_1 ~ i3*1; y3_2 ~ i3*1; y3_3 ~ i3*1; y3_4 ~ i3*1\ny4_1 ~ i4*1; y4_2 ~ i4*1; y4_3 ~ i4*1; y4_4 ~ i4*1\n\ny1_1 ~~ y1_2\ny1_2 ~~ y1_3\ny1_3 ~~ y1_4\ny2_1 ~~ y2_2\ny2_2 ~~ y2_3\ny2_3 ~~ y2_4\n'\nfit_scalar &lt;- cfa(mod_scalar, data = dat, meanstructure = TRUE, missing = \"fiml\")\nfitMeasures(fit_scalar, c(\"chisq\",\"df\",\"cfi\",\"tli\",\"rmsea\",\"srmr\"))\n\n\n  chisq      df     cfi     tli   rmsea    srmr \n323.401 113.000   0.958   0.956   0.056   0.085 \n\n\nCompare the three models:\n\n\nCode\nlavTestLRT(fit_config, fit_metric, fit_scalar)\n\n\n\nChi-Squared Difference Test\n\n            Df   AIC   BIC   Chisq Chisq diff   RMSEA Df diff Pr(&gt;Chisq)    \nfit_config  92 23287 23551  80.696                                          \nfit_metric 101 23272 23497  83.889      3.193 0.00000       9     0.9561    \nfit_scalar 113 23488 23659 323.401    239.512 0.17776      12     &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nCode\nbind_rows(\n  config = fitMeasures(fit_config, c(\"cfi\",\"rmsea\",\"srmr\")),\n  metric = fitMeasures(fit_metric, c(\"cfi\",\"rmsea\",\"srmr\")),\n  scalar = fitMeasures(fit_scalar, c(\"cfi\",\"rmsea\",\"srmr\")),\n  .id = \"model\"\n)\n\n\n# A tibble: 3 × 4\n  model  cfi        rmsea      srmr      \n  &lt;chr&gt;  &lt;lvn.vctr&gt; &lt;lvn.vctr&gt; &lt;lvn.vctr&gt;\n1 config 1.0000000  0.00000000 0.02105610\n2 metric 1.0000000  0.00000000 0.02550694\n3 scalar 0.9583592  0.05570686 0.08531473"
  },
  {
    "objectID": "labs/lab09_longitudinal_growth.html#a4.-local-diagnostics-partial-scalar-invariance-disciplined",
    "href": "labs/lab09_longitudinal_growth.html#a4.-local-diagnostics-partial-scalar-invariance-disciplined",
    "title": "Lab 09: Longitudinal SEM — Invariance Over Time & Latent Growth",
    "section": "1.4 A4. Local diagnostics + partial scalar invariance (disciplined)",
    "text": "1.4 A4. Local diagnostics + partial scalar invariance (disciplined)\nInspect modification indices (MIs) for the scalar model:\n\n\nCode\nmi &lt;- modificationIndices(fit_scalar) |&gt;\n  arrange(desc(mi))\nmi |&gt; head(15)\n\n\n    lhs op  rhs     mi    epc sepc.lv sepc.all sepc.nox\n1    F4 ~1      82.053  0.331   0.325    0.325    0.325\n2    F1 ~1      58.138 -0.272  -0.267   -0.267   -0.267\n3  y2_1 ~~ y2_3  6.683 -0.067  -0.067   -0.117   -0.117\n4    F2 ~1       5.631 -0.067  -0.064   -0.064   -0.064\n5  y1_4 ~~ y2_4  5.301  0.071   0.071    0.124    0.124\n6  y1_4 ~~ y3_4  4.479 -0.068  -0.068   -0.140   -0.140\n7  y3_1 ~~ y4_3  4.282  0.062   0.062    0.099    0.099\n8  y3_1 ~~ y4_1  4.173 -0.061  -0.061   -0.109   -0.109\n9  y1_3 ~~ y4_3  3.936  0.049   0.049    0.080    0.080\n10 y3_4 ~~ y4_4  3.561  0.063   0.063    0.115    0.115\n11 y4_2 ~~ y2_4  3.419 -0.055  -0.055   -0.088   -0.088\n12 y1_2 ~~ y2_4  3.316  0.042   0.042    0.077    0.077\n13   F2 =~ y4_1  3.226  0.068   0.071    0.067    0.067\n14 y4_2 ~~ y4_4  3.083  0.060   0.060    0.089    0.089\n15   F3 =~ y4_1  2.820  0.062   0.065    0.061    0.061\n\n\n\n1.4.1 Your task\n\nIdentify one intercept constraint that is strongly suggested to be freed (large MI) and is at least somewhat plausible substantively (e.g., an item that could drift over time).\nFit a partial scalar model freeing that single intercept equality.\nRe-evaluate fit vs full scalar.\n\n\n\n\n\n\n\nWarning\n\n\n\nPartial invariance is acceptable when: - you free the minimum needed, - you justify it, - you report it transparently, - you check your substantive conclusions don’t hinge on it.\n\n\nHint (how to free one intercept constraint):\nIf you labeled all intercepts equal (e.g., y3_1 ~ i3*1; y3_2 ~ i3*1; ...), you can break equality for one wave by giving it a different label:\n\n\nCode\n# Example (DO NOT run blindly): make y3_4 intercept free from the others\n# y3_1 ~ i3*1; y3_2 ~ i3*1; y3_3 ~ i3*1; y3_4 ~ i3_4*1\n\n\nCreate your modified model below.\n\n\nCode\n# TODO: write mod_partial_scalar\nmod_partial_scalar &lt;- mod_scalar\n\n# fit_partial_scalar &lt;- cfa(mod_partial_scalar, data = dat, meanstructure = TRUE, missing = \"fiml\")\n# fitMeasures(fit_partial_scalar, c(\"cfi\",\"rmsea\",\"srmr\"))"
  },
  {
    "objectID": "labs/lab09_longitudinal_growth.html#b1.-build-wave-level-observed-scores-teaching-friendly",
    "href": "labs/lab09_longitudinal_growth.html#b1.-build-wave-level-observed-scores-teaching-friendly",
    "title": "Lab 09: Longitudinal SEM — Invariance Over Time & Latent Growth",
    "section": "2.1 B1. Build wave-level observed scores (teaching-friendly)",
    "text": "2.1 B1. Build wave-level observed scores (teaching-friendly)\nTo keep growth interpretation simple, we create a wave score as the mean of the four indicators.\n\n\nCode\ndat &lt;- dat |&gt;\n  mutate(\n    y_t1 = rowMeans(across(c(y1_1,y2_1,y3_1,y4_1)), na.rm = TRUE),\n    y_t2 = rowMeans(across(c(y1_2,y2_2,y3_2,y4_2)), na.rm = TRUE),\n    y_t3 = rowMeans(across(c(y1_3,y2_3,y3_3,y4_3)), na.rm = TRUE),\n    y_t4 = rowMeans(across(c(y1_4,y2_4,y3_4,y4_4)), na.rm = TRUE)\n  )"
  },
  {
    "objectID": "labs/lab09_longitudinal_growth.html#b2.-linear-growth-model",
    "href": "labs/lab09_longitudinal_growth.html#b2.-linear-growth-model",
    "title": "Lab 09: Longitudinal SEM — Invariance Over Time & Latent Growth",
    "section": "2.2 B2. Linear growth model",
    "text": "2.2 B2. Linear growth model\nFit a linear LGM with time scores (0, 1, 2, 3).\n\n\nCode\nlgm_linear &lt;- '\ni =~ 1*y_t1 + 1*y_t2 + 1*y_t3 + 1*y_t4\ns =~ 0*y_t1 + 1*y_t2 + 2*y_t3 + 3*y_t4\n\n# optional residual autocorrelation (often helpful)\ny_t1 ~~ y_t2\ny_t2 ~~ y_t3\ny_t3 ~~ y_t4\n'\nfit_lgm &lt;- growth(lgm_linear, data = dat, missing = \"fiml\")\nsummary(fit_lgm, fit.measures = TRUE, standardized = TRUE)\n\n\nlavaan 0.6-19 ended normally after 29 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        12\n\n  Number of observations                           600\n  Number of missing patterns                         2\n\nModel Test User Model:\n                                                      \n  Test statistic                                 7.526\n  Degrees of freedom                                 2\n  P-value (Chi-square)                           0.023\n\nModel Test Baseline Model:\n\n  Test statistic                              1036.573\n  Degrees of freedom                                 6\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.995\n  Tucker-Lewis Index (TLI)                       0.984\n                                                      \n  Robust Comparative Fit Index (CFI)             0.995\n  Robust Tucker-Lewis Index (TLI)                0.985\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -2561.659\n  Loglikelihood unrestricted model (H1)      -2557.896\n                                                      \n  Akaike (AIC)                                5147.318\n  Bayesian (BIC)                              5200.081\n  Sample-size adjusted Bayesian (SABIC)       5161.984\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.068\n  90 Percent confidence interval - lower         0.021\n  90 Percent confidence interval - upper         0.122\n  P-value H_0: RMSEA &lt;= 0.050                    0.219\n  P-value H_0: RMSEA &gt;= 0.080                    0.415\n                                                      \n  Robust RMSEA                                   0.067\n  90 Percent confidence interval - lower         0.019\n  90 Percent confidence interval - upper         0.124\n  P-value H_0: Robust RMSEA &lt;= 0.050             0.229\n  P-value H_0: Robust RMSEA &gt;= 0.080             0.415\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.018\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Observed\n  Observed information based on                Hessian\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  i =~                                                                  \n    y_t1              1.000                               0.782    0.858\n    y_t2              1.000                               0.782    0.816\n    y_t3              1.000                               0.782    0.813\n    y_t4              1.000                               0.782    0.878\n  s =~                                                                  \n    y_t1              0.000                               0.000    0.000\n    y_t2              1.000                               0.221    0.230\n    y_t3              2.000                               0.442    0.459\n    y_t4              3.000                               0.663    0.744\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n .y_t1 ~~                                                               \n   .y_t2              0.019    0.048    0.393    0.695    0.019    0.064\n .y_t2 ~~                                                               \n   .y_t3              0.115    0.023    4.974    0.000    0.115    0.292\n .y_t3 ~~                                                               \n   .y_t4              0.024    0.050    0.489    0.625    0.024    0.099\n  i ~~                                                                  \n    s                -0.069    0.030   -2.322    0.020   -0.398   -0.398\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n    i                 0.030    0.037    0.814    0.416    0.038    0.038\n    s                 0.206    0.013   15.866    0.000    0.931    0.931\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .y_t1              0.220    0.079    2.793    0.005    0.220    0.264\n   .y_t2              0.397    0.046    8.641    0.000    0.397    0.431\n   .y_t3              0.394    0.047    8.403    0.000    0.394    0.425\n   .y_t4              0.156    0.082    1.908    0.056    0.156    0.196\n    i                 0.612    0.085    7.175    0.000    1.000    1.000\n    s                 0.049    0.016    3.123    0.002    1.000    1.000\n\n\nExtract and interpret the growth factor means/variances:\n\n\nCode\nparameterEstimates(fit_lgm) |&gt;\n  filter(op %in% c(\"~1\",\"~~\") & lhs %in% c(\"i\",\"s\"))\n\n\n  lhs op rhs    est    se      z pvalue ci.lower ci.upper\n1   i ~~   i  0.612 0.085  7.175  0.000    0.445    0.780\n2   s ~~   s  0.049 0.016  3.123  0.002    0.018    0.079\n3   i ~~   s -0.069 0.030 -2.322  0.020   -0.127   -0.011\n4   i ~1      0.030 0.037  0.814  0.416   -0.042    0.102\n5   s ~1      0.206 0.013 15.866  0.000    0.180    0.231\n\n\n\n2.2.1 Questions\n\nWhat is the interpretation of Mean(i) and Mean(s) with this time coding?\nAre there individual differences in baseline and change (variances of i and s)?\nWhat does Cov(i, s) suggest about baseline–change association?"
  },
  {
    "objectID": "labs/lab09_longitudinal_growth.html#b3.-re-centering-time-interpretation-exercise",
    "href": "labs/lab09_longitudinal_growth.html#b3.-re-centering-time-interpretation-exercise",
    "title": "Lab 09: Longitudinal SEM — Invariance Over Time & Latent Growth",
    "section": "2.3 B3. Re-centering time (interpretation exercise)",
    "text": "2.3 B3. Re-centering time (interpretation exercise)\nChange the slope loadings to make the intercept represent wave 2.\nExample time scores: (-1, 0, 1, 2).\n\n\nCode\nlgm_center_w2 &lt;- '\ni =~ 1*y_t1 + 1*y_t2 + 1*y_t3 + 1*y_t4\ns =~ -1*y_t1 + 0*y_t2 + 1*y_t3 + 2*y_t4\n\ny_t1 ~~ y_t2\ny_t2 ~~ y_t3\ny_t3 ~~ y_t4\n'\nfit_lgm_w2 &lt;- growth(lgm_center_w2, data = dat, missing = \"fiml\")\nparameterEstimates(fit_lgm_w2) |&gt;\n  filter(op %in% c(\"~1\",\"~~\") & lhs %in% c(\"i\",\"s\"))\n\n\n  lhs op rhs    est    se      z pvalue ci.lower ci.upper\n1   i ~~   i  0.523 0.046 11.304  0.000    0.433    0.614\n2   s ~~   s  0.049 0.016  3.123  0.002    0.018    0.079\n3   i ~~   s -0.020 0.020 -0.979  0.327   -0.060    0.020\n4   i ~1      0.236 0.032  7.295  0.000    0.172    0.299\n5   s ~1      0.206 0.013 15.866  0.000    0.180    0.231\n\n\n\n2.3.1 Question\n\nHow did the Mean(i) change relative to the previous model, and why?"
  },
  {
    "objectID": "labs/lab09_longitudinal_growth.html#b4.-if-linear-growth-is-not-enough-quadratic-growth-optional-but-recommended",
    "href": "labs/lab09_longitudinal_growth.html#b4.-if-linear-growth-is-not-enough-quadratic-growth-optional-but-recommended",
    "title": "Lab 09: Longitudinal SEM — Invariance Over Time & Latent Growth",
    "section": "2.4 B4. If linear growth is not enough: quadratic growth (optional but recommended)",
    "text": "2.4 B4. If linear growth is not enough: quadratic growth (optional but recommended)\n\n\nCode\nlgm_quad &lt;- '\ni =~ 1*y_t1 + 1*y_t2 + 1*y_t3 + 1*y_t4\ns =~ 0*y_t1 + 1*y_t2 + 2*y_t3 + 3*y_t4\nq =~ 0*y_t1 + 1*y_t2 + 4*y_t3 + 9*y_t4\n\ny_t1 ~~ y_t2\ny_t2 ~~ y_t3\ny_t3 ~~ y_t4\n'\nfit_lgm_q &lt;- growth(lgm_quad, data = dat, missing = \"fiml\")\n# anova(fit_lgm, fit_lgm_q)\nfitMeasures(fit_lgm_q, c(\"cfi\",\"rmsea\",\"srmr\"))\n\n\n  cfi rmsea  srmr \n   NA 0.000 0.013 \n\n\n\n2.4.1 Questions\n\nDoes quadratic growth improve fit meaningfully?\nIs the quadratic factor mean/variance interpretable and substantively plausible?"
  },
  {
    "objectID": "labs/lab09_longitudinal_growth.html#c1.-add-a-predictor",
    "href": "labs/lab09_longitudinal_growth.html#c1.-add-a-predictor",
    "title": "Lab 09: Longitudinal SEM — Invariance Over Time & Latent Growth",
    "section": "3.1 C1. Add a predictor",
    "text": "3.1 C1. Add a predictor\nCreate a predictor x (in real applications: trait, condition, demographic variable, baseline stress, etc.).\n\n\nCode\nset.seed(77)\ndat$x &lt;- rnorm(nrow(dat))\n\n\nFit conditional growth:\n\n\nCode\nlgm_cond &lt;- '\ni =~ 1*y_t1 + 1*y_t2 + 1*y_t3 + 1*y_t4\ns =~ 0*y_t1 + 1*y_t2 + 2*y_t3 + 3*y_t4\n\ni ~ x\ns ~ x\n\ny_t1 ~~ y_t2\ny_t2 ~~ y_t3\ny_t3 ~~ y_t4\n'\nfit_lgm_c &lt;- growth(lgm_cond, data = dat, missing = \"fiml\")\nsummary(fit_lgm_c, fit.measures = TRUE, standardized = TRUE)\n\n\nlavaan 0.6-19 ended normally after 29 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        14\n\n  Number of observations                           600\n  Number of missing patterns                         2\n\nModel Test User Model:\n                                                      \n  Test statistic                                 9.845\n  Degrees of freedom                                 4\n  P-value (Chi-square)                           0.043\n\nModel Test Baseline Model:\n\n  Test statistic                              1039.254\n  Degrees of freedom                                10\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.994\n  Tucker-Lewis Index (TLI)                       0.986\n                                                      \n  Robust Comparative Fit Index (CFI)             0.995\n  Robust Tucker-Lewis Index (TLI)                0.987\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -2561.478\n  Loglikelihood unrestricted model (H1)      -2556.555\n                                                      \n  Akaike (AIC)                                5150.955\n  Bayesian (BIC)                              5212.512\n  Sample-size adjusted Bayesian (SABIC)       5168.066\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.049\n  90 Percent confidence interval - lower         0.008\n  90 Percent confidence interval - upper         0.089\n  P-value H_0: RMSEA &lt;= 0.050                    0.445\n  P-value H_0: RMSEA &gt;= 0.080                    0.112\n                                                      \n  Robust RMSEA                                   0.048\n  90 Percent confidence interval - lower         0.000\n  90 Percent confidence interval - upper         0.090\n  P-value H_0: Robust RMSEA &lt;= 0.050             0.458\n  P-value H_0: Robust RMSEA &gt;= 0.080             0.115\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.017\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Observed\n  Observed information based on                Hessian\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  i =~                                                                  \n    y_t1              1.000                               0.782    0.857\n    y_t2              1.000                               0.782    0.815\n    y_t3              1.000                               0.782    0.812\n    y_t4              1.000                               0.782    0.877\n  s =~                                                                  \n    y_t1              0.000                               0.000    0.000\n    y_t2              1.000                               0.221    0.230\n    y_t3              2.000                               0.441    0.459\n    y_t4              3.000                               0.662    0.743\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  i ~                                                                   \n    x                 0.022    0.037    0.582    0.560    0.028    0.027\n  s ~                                                                   \n    x                -0.006    0.013   -0.422    0.673   -0.025   -0.025\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n .y_t1 ~~                                                               \n   .y_t2              0.020    0.048    0.420    0.675    0.020    0.068\n .y_t2 ~~                                                               \n   .y_t3              0.116    0.023    4.984    0.000    0.116    0.292\n .y_t3 ~~                                                               \n   .y_t4              0.024    0.050    0.483    0.629    0.024    0.098\n .i ~~                                                                  \n   .s                -0.068    0.030   -2.303    0.021   -0.396   -0.396\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .i                 0.029    0.037    0.778    0.437    0.037    0.037\n   .s                 0.206    0.013   15.865    0.000    0.934    0.934\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .y_t1              0.221    0.079    2.804    0.005    0.221    0.265\n   .y_t2              0.398    0.046    8.658    0.000    0.398    0.432\n   .y_t3              0.394    0.047    8.384    0.000    0.394    0.425\n   .y_t4              0.156    0.082    1.902    0.057    0.156    0.196\n   .i                 0.611    0.085    7.157    0.000    0.999    0.999\n   .s                 0.049    0.016    3.110    0.002    0.999    0.999\n\n\n\n3.1.1 Questions\n\nWhat does x → i mean? What does x → s mean?\nIf x → s is positive, how would you explain it in words?"
  },
  {
    "objectID": "labs/lab09_longitudinal_growth.html#what-to-hand-in-suggested",
    "href": "labs/lab09_longitudinal_growth.html#what-to-hand-in-suggested",
    "title": "Lab 09: Longitudinal SEM — Invariance Over Time & Latent Growth",
    "section": "4.1 What to hand in (suggested)",
    "text": "4.1 What to hand in (suggested)\n\nA small table with fit indices for configural, metric, scalar (and partial scalar if used).\nA brief justification (2–6 sentences) of your invariance decision.\nLinear LGM results: interpret mean(i), mean(s), var(s), cov(i,s).\nOne centering exercise: explain how time coding changes intercept meaning.\n(Optional) Quadratic growth comparison + interpretation.\nConditional growth: interpret the regression(s) of i and s on x.\n\n\n\n\n\n\n\nTip\n\n\n\nKeep it “report-ready”: always report χ²(df), CFI/TLI, RMSEA (+ CI if possible), SRMR + the key local decision you made (e.g., which intercept you freed)."
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html",
    "href": "slides/04_cfa_measurement_reliability.html",
    "title": "CFA: measurement models, identification, reliability",
    "section": "",
    "text": "Specify → Identify → Estimate → Evaluate → Revise/Report\n\n\n\n\n\n\nToday: the measurement part — CFA (and reliability from CFA).\nTwo-step mindset: measure first, then relate constructs (SEM deck 05)."
  }
]