[
  {
    "objectID": "templates/slides-template.html#today",
    "href": "templates/slides-template.html#today",
    "title": "Title of the lecture; Subtitle (optional)",
    "section": "",
    "text": "Point 1\nPoint 2\nPoint 3\n\n\n\n\n\n\n\nTip\n\n\n\nTeaching tip: keep one “workflow map” slide that reappears in every deck."
  },
  {
    "objectID": "templates/slides-template.html#learning-objectives",
    "href": "templates/slides-template.html#learning-objectives",
    "title": "Title of the lecture; Subtitle (optional)",
    "section": "Learning objectives",
    "text": "Learning objectives\nBy the end of this block, you can:\n\nWrite a minimal lavaan model string\nFit it with cfa() / sem()\nInterpret key parameters (loadings / paths)"
  },
  {
    "objectID": "templates/slides-template.html#minimal-example-code-output",
    "href": "templates/slides-template.html#minimal-example-code-output",
    "title": "Title of the lecture; Subtitle (optional)",
    "section": "Minimal example (code + output)",
    "text": "Minimal example (code + output)\n\nlibrary(lavaan)\n\n# Toy measurement model\nmodel &lt;- '\n  f =~ x1 + x2 + x3\n'\n\nfit &lt;- cfa(model, data = HolzingerSwineford1939)\nsummary(fit, fit.measures = TRUE, standardized = TRUE)\n\nlavaan 0.6-19 ended normally after 23 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         6\n\n  Number of observations                           301\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nModel Test Baseline Model:\n\n  Test statistic                               111.271\n  Degrees of freedom                                 3\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    1.000\n  Tucker-Lewis Index (TLI)                       1.000\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -1356.977\n  Loglikelihood unrestricted model (H1)      -1356.977\n                                                      \n  Akaike (AIC)                                2725.955\n  Bayesian (BIC)                              2748.197\n  Sample-size adjusted Bayesian (SABIC)       2729.169\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.000\n  90 Percent confidence interval - lower         0.000\n  90 Percent confidence interval - upper         0.000\n  P-value H_0: RMSEA &lt;= 0.050                       NA\n  P-value H_0: RMSEA &gt;= 0.080                       NA\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.000\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  f =~                                                                  \n    x1                1.000                               0.724    0.621\n    x2                0.778    0.141    5.532    0.000    0.563    0.479\n    x3                1.107    0.214    5.173    0.000    0.801    0.710\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .x1                0.835    0.118    7.064    0.000    0.835    0.614\n   .x2                1.065    0.105   10.177    0.000    1.065    0.771\n   .x3                0.633    0.129    4.899    0.000    0.633    0.496\n    f                 0.524    0.130    4.021    0.000    1.000    1.000"
  },
  {
    "objectID": "templates/slides-template.html#two-column-slide-uses-.two-col-from-slides.scss",
    "href": "templates/slides-template.html#two-column-slide-uses-.two-col-from-slides.scss",
    "title": "Title of the lecture; Subtitle (optional)",
    "section": "Two-column slide (uses .two-col from slides.scss)",
    "text": "Two-column slide (uses .two-col from slides.scss)\n\nConcept - What is identified? - Why constraints matter? - What is the scale of a latent factor?\nQuick check\n\ninspect(fit, \"converged\")\n\n[1] TRUE\n\nfitMeasures(fit, c(\"cfi\", \"rmsea\", \"srmr\"))\n\n  cfi rmsea  srmr \n    1     0     0"
  },
  {
    "objectID": "templates/slides-template.html#exercise",
    "href": "templates/slides-template.html#exercise",
    "title": "Title of the lecture; Subtitle (optional)",
    "section": "Exercise",
    "text": "Exercise\n\n\n\n\n\n\nImportant\n\n\n\nTry it (5–10 min)\n1. Add x4 to the factor (if available) or remove an indicator.\n2. Refit and compare fit measures.\n3. What changes in the standardized loadings?"
  },
  {
    "objectID": "templates/slides-template.html#common-mistakes",
    "href": "templates/slides-template.html#common-mistakes",
    "title": "Title of the lecture; Subtitle (optional)",
    "section": "Common mistakes",
    "text": "Common mistakes\n\nTreating arrows as “causal proof” (Rohrer et al., 2022)\nChasing modification indices without justification\nIgnoring estimator/data-type mismatch"
  },
  {
    "objectID": "templates/slides-template.html#references-manual",
    "href": "templates/slides-template.html#references-manual",
    "title": "Title of the lecture; Subtitle (optional)",
    "section": "References (manual)",
    "text": "References (manual)\n\nRosseel, Y. (2012). lavaan: An R package for structural equation modeling."
  },
  {
    "objectID": "templates/slides-template.html#references",
    "href": "templates/slides-template.html#references",
    "title": "Title of the lecture; Subtitle (optional)",
    "section": "References",
    "text": "References\n\n\nRohrer, J. M., Hünermund, P., Arslan, R. C., & Elson, M. (2022). That’s a Lot to Process! Pitfalls of Popular Path Models. Advances in Methods and Practices in Psychological Science, 5(2), 25152459221095827. https://doi.org/10.1177/25152459221095827"
  },
  {
    "objectID": "templates/lab-solution-template.html",
    "href": "templates/lab-solution-template.html",
    "title": "Lab X — Title",
    "section": "",
    "text": "By the end of this lab, you can:\n\nFit a model in lavaan\nInspect fit measures and key parameters\nMake (and justify) one defensible diagnostic decision"
  },
  {
    "objectID": "templates/lab-solution-template.html#references",
    "href": "templates/lab-solution-template.html#references",
    "title": "Lab X — Title",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "setup.html",
    "href": "setup.html",
    "title": "Setup",
    "section": "",
    "text": "This page helps you get R, packages, and the course repository running smoothly."
  },
  {
    "objectID": "setup.html#installupdate-software",
    "href": "setup.html#installupdate-software",
    "title": "Setup",
    "section": "1) Install/update software",
    "text": "1) Install/update software\n\nR (recommended: recent CRAN release)\nRStudio (recommended)\nQuarto (needed only if you want to render slides/labs locally)"
  },
  {
    "objectID": "setup.html#get-the-course-materials",
    "href": "setup.html#get-the-course-materials",
    "title": "Setup",
    "section": "2) Get the course materials",
    "text": "2) Get the course materials\n\nOption A — Git (recommended)\n\nClone the repository\nPull updates during the course if needed\n\n\n\nOption B — Download ZIP\n\nDownload the ZIP from GitHub\nUnzip and open the project folder in RStudio"
  },
  {
    "objectID": "setup.html#install-packages",
    "href": "setup.html#install-packages",
    "title": "Setup",
    "section": "3) Install packages",
    "text": "3) Install packages\nRun this once (edit if you already have everything):\n\npkgs &lt;- c(\n  \"lavaan\",\n  \"semTools\",\n  \"psych\",\n  \"MVN\",\n  \"mice\",\n  \"modsem\",\n  \"ggplot2\",\n  \"dplyr\",\n  \"tidyr\"\n)\n\nto_install &lt;- setdiff(pkgs, rownames(installed.packages()))\nif (length(to_install) &gt; 0) install.packages(to_install)\n\ninvisible(lapply(pkgs, library, character.only = TRUE))\n\nThis is lavaan 0.6-19\nlavaan is FREE software! Please report any bugs.\n\n\n \n\n\n###############################################################################\n\n\nThis is semTools 0.5-7\n\n\nAll users of R (or SEM) are invited to submit functions or ideas for functions.\n\n\n###############################################################################\n\n\n\nCaricamento pacchetto: 'psych'\n\n\nI seguenti oggetti sono mascherati da 'package:semTools':\n\n    reliability, skew\n\n\nIl seguente oggetto è mascherato da 'package:lavaan':\n\n    cor2cov\n\n\nWarning: il pacchetto 'MVN' è stato creato con R versione 4.5.2\n\n\n\nCaricamento pacchetto: 'MVN'\n\n\nIl seguente oggetto è mascherato da 'package:psych':\n\n    mardia\n\n\nWarning: il pacchetto 'mice' è stato creato con R versione 4.5.2\n\n\n\nCaricamento pacchetto: 'mice'\n\n\nIl seguente oggetto è mascherato da 'package:stats':\n\n    filter\n\n\nI seguenti oggetti sono mascherati da 'package:base':\n\n    cbind, rbind\n\n\nThis is modsem (1.0.11). Please report any bugs!\n\n\n\nCaricamento pacchetto: 'ggplot2'\n\n\nI seguenti oggetti sono mascherati da 'package:psych':\n\n    %+%, alpha\n\n\n\nCaricamento pacchetto: 'dplyr'\n\n\nI seguenti oggetti sono mascherati da 'package:stats':\n\n    filter, lag\n\n\nI seguenti oggetti sono mascherati da 'package:base':\n\n    intersect, setdiff, setequal, union"
  },
  {
    "objectID": "setup.html#reproducibility-option-recommended-renv",
    "href": "setup.html#reproducibility-option-recommended-renv",
    "title": "Setup",
    "section": "4) Reproducibility option (recommended): renv",
    "text": "4) Reproducibility option (recommended): renv\nIf the repo uses renv, you can restore the exact package versions:\n\n# install.packages(\"renv\")\n# renv::restore()"
  },
  {
    "objectID": "setup.html#quick-test-can-you-run-lavaan",
    "href": "setup.html#quick-test-can-you-run-lavaan",
    "title": "Setup",
    "section": "5) Quick test: can you run lavaan?",
    "text": "5) Quick test: can you run lavaan?\n\nlibrary(lavaan)\n\nm &lt;- 'f =~ x1 + x2 + x3'\nfit &lt;- cfa(m, data = HolzingerSwineford1939)\n\ninspect(fit, \"converged\")\n\n[1] TRUE\n\nfitMeasures(fit, c(\"cfi\",\"rmsea\",\"srmr\"))\n\n  cfi rmsea  srmr \n    1     0     0"
  },
  {
    "objectID": "setup.html#troubleshooting",
    "href": "setup.html#troubleshooting",
    "title": "Setup",
    "section": "Troubleshooting",
    "text": "Troubleshooting\n\n“Package X is not available”\n\nUpdate R\nTry a different CRAN mirror\nInstall from source if needed (rare)\n\n\n\n“Quarto not found”\n\nInstall Quarto and restart RStudio\n\n\n\n“Rendering fails”\n\nRe-run package installation\nTry rendering a single file first (e.g., one lab)\nCheck for path issues (especially on Windows)\n\n\n\n\n\n\n\nTip\n\n\n\nIf you run into errors during class, copy-paste the error message + the code you ran into your notes (or send it). It speeds up debugging a lot."
  },
  {
    "objectID": "labs/labs_index.html",
    "href": "labs/labs_index.html",
    "title": "Labs",
    "section": "",
    "text": "These labs are the hands-on part of the course. Each lab is designed to be runnable end-to-end and includes exercises."
  },
  {
    "objectID": "labs/labs_index.html#day-1",
    "href": "labs/labs_index.html#day-1",
    "title": "Labs",
    "section": "Day 1",
    "text": "Day 1\n\nLab 01 — lavaan basics\nOpen lab\nLab 02 — path analysis & mediation\nOpen lab"
  },
  {
    "objectID": "labs/labs_index.html#day-2",
    "href": "labs/labs_index.html#day-2",
    "title": "Labs",
    "section": "Day 2",
    "text": "Day 2\n\nLab 03 — fit diagnostics (residuals, MI/EPC)\nOpen lab\nLab 04 — CFA + reliability (omega)\nOpen lab"
  },
  {
    "objectID": "labs/labs_index.html#day-3",
    "href": "labs/labs_index.html#day-3",
    "title": "Labs",
    "section": "Day 3",
    "text": "Day 3\n\nLab 05 — SEM capstone (flagship dataset)\nOpen lab\nLab 06 — missing data (FIML/MI) + robustness\nOpen lab"
  },
  {
    "objectID": "labs/labs_index.html#day-4",
    "href": "labs/labs_index.html#day-4",
    "title": "Labs",
    "section": "Day 4",
    "text": "Day 4\n\nLab 07 — MG-CFA invariance\nOpen lab\nLab 08 — ordinal SEM + ordinal invariance\nOpen lab"
  },
  {
    "objectID": "labs/labs_index.html#day-5",
    "href": "labs/labs_index.html#day-5",
    "title": "Labs",
    "section": "Day 5",
    "text": "Day 5\n\nLab 09 — longitudinal SEM (growth model)\nOpen lab\nLab 10 — clustered data (robust SE) + two-level CFA\nOpen lab"
  },
  {
    "objectID": "labs/labs_index.html#optional-extra-practice",
    "href": "labs/labs_index.html#optional-extra-practice",
    "title": "Labs",
    "section": "Optional extra practice",
    "text": "Optional extra practice\nIf you want more practice beyond the core labs, check the Extras page."
  },
  {
    "objectID": "glossary.html",
    "href": "glossary.html",
    "title": "Glossary",
    "section": "",
    "text": "Short definitions + “what students usually confuse it with”."
  },
  {
    "objectID": "glossary.html#a",
    "href": "glossary.html#a",
    "title": "Glossary",
    "section": "A",
    "text": "A\nAbsolute fit\nFit measures that evaluate how well the model reproduces the observed covariance structure (e.g., χ², SRMR).\nAIC / BIC\nInformation criteria for comparing models (typically non-nested too). Lower is better (with caveats)."
  },
  {
    "objectID": "glossary.html#c",
    "href": "glossary.html#c",
    "title": "Glossary",
    "section": "C",
    "text": "C\nCFA (Confirmatory Factor Analysis)\nA measurement model where latent variables explain covariances among observed indicators via factor loadings.\nCFI / TLI\nIncremental fit indices comparing your model to a baseline (independence) model.\nCluster-robust standard errors\nA correction to SEs/p-values when observations are clustered (e.g., students in classrooms) without explicitly fitting a multilevel model.\nConfigural / Metric / Scalar invariance\nLevels of measurement invariance across groups/time: - configural: same pattern of loadings - metric: equal loadings - scalar: equal loadings + intercepts (or thresholds for ordinal)"
  },
  {
    "objectID": "glossary.html#d",
    "href": "glossary.html#d",
    "title": "Glossary",
    "section": "D",
    "text": "D\nDWLS / WLSMV\nCommon estimators for ordinal indicators. Naming can be confusing: the practical takeaway is that ordinal models often use a weighted least squares approach with robust corrections."
  },
  {
    "objectID": "glossary.html#e",
    "href": "glossary.html#e",
    "title": "Glossary",
    "section": "E",
    "text": "E\nEquivalent models\nDifferent path diagrams that imply the same covariance structure (same global fit). Fit alone cannot identify the “true” causal story.\nEPC (Expected Parameter Change)\nHow much a parameter estimate would change if a fixed constraint were freed; often reported with modification indices."
  },
  {
    "objectID": "glossary.html#f",
    "href": "glossary.html#f",
    "title": "Glossary",
    "section": "F",
    "text": "F\nFIML (Full Information Maximum Likelihood)\nA likelihood-based approach to handle missing data under MAR assumptions (with ML-family estimators).\nFit indices (global)\nSummaries of how well the overall model fits (CFI/TLI/RMSEA/SRMR/χ²).\nFit indices (local)\nDiagnostics for specific parts of a model (residuals, MI/EPC, standardized residual covariances)."
  },
  {
    "objectID": "glossary.html#i",
    "href": "glossary.html#i",
    "title": "Glossary",
    "section": "I",
    "text": "I\nIdentification\nWhether model parameters can be uniquely estimated from the data (rules of thumb help, but do not guarantee identification).\nIntercepts vs thresholds (ordinal)\n- Intercepts: continuous indicator mean structure - Thresholds: cut-points that map a continuous latent response to ordinal categories"
  },
  {
    "objectID": "glossary.html#l",
    "href": "glossary.html#l",
    "title": "Glossary",
    "section": "L",
    "text": "L\nLatent variable\nUnobserved construct inferred from observed indicators.\nLatent interaction\nAn interaction between latent variables (e.g., F1 × F2 predicting Y). Estimation/interpretation differs from standard linear SEM."
  },
  {
    "objectID": "glossary.html#m",
    "href": "glossary.html#m",
    "title": "Glossary",
    "section": "M",
    "text": "M\nMeasurement model\nThe part of SEM that links indicators to latent factors (loadings, intercepts/thresholds, residual variances).\nMI (Modification Index)\nA statistic indicating how much χ² would drop if a fixed parameter were freed. Useful but easy to abuse.\nMissingness (MCAR/MAR/MNAR)\nAssumptions about why data are missing: - MCAR: unrelated to observed/unobserved variables - MAR: related to observed variables - MNAR: related to unobserved values themselves"
  },
  {
    "objectID": "glossary.html#r",
    "href": "glossary.html#r",
    "title": "Glossary",
    "section": "R",
    "text": "R\nRMSEA\nA parsimony-adjusted fit index; usually reported with a confidence interval."
  },
  {
    "objectID": "glossary.html#s",
    "href": "glossary.html#s",
    "title": "Glossary",
    "section": "S",
    "text": "S\nSAM (Structural After Measurement)\nA two-stage estimation strategy: estimate measurement first, then structural relations using implied latent moments.\nSEM (Structural Equation Model)\nAn integrated model including both measurement (latent variables) and structural relations (regressions/covariances among latents/observeds).\nSRMR\nA fit index based on standardized residuals (difference between observed and model-implied covariances/correlations)."
  },
  {
    "objectID": "glossary.html#t",
    "href": "glossary.html#t",
    "title": "Glossary",
    "section": "T",
    "text": "T\nTwo-step mindset\nA practical workflow: evaluate measurement quality before interpreting structural relations.\n\n\n\n\n\n\n\nTip\n\n\n\nIf you want to add to this glossary during the course, just make a PR / issue or send the term + how you’d define it."
  },
  {
    "objectID": "book/index.html",
    "href": "book/index.html",
    "title": "Structural Equation Modelling in Psychological Sciences",
    "section": "",
    "text": "Welcome! This book is a practical introduction to Structural Equation Modelling (SEM) for psychological research, with examples in R (mainly using lavaan).\nThis book is built from the course materials in the companion repository and is designed to be:"
  },
  {
    "objectID": "book/index.html#how-to-read-this-book",
    "href": "book/index.html#how-to-read-this-book",
    "title": "Structural Equation Modelling in Psychological Sciences",
    "section": "How to read this book",
    "text": "How to read this book\n\nIf you are new to SEM: read chapters 1–5 in order.\nIf you already know basics: jump to the chapter you need (ordinal, invariance, longitudinal, multilevel).\nEach chapter ends with:\n\na summary of key points\ncommon pitfalls\nexercises (optional)"
  },
  {
    "objectID": "book/index.html#what-you-should-know-already",
    "href": "book/index.html#what-you-should-know-already",
    "title": "Structural Equation Modelling in Psychological Sciences",
    "section": "What you should know already",
    "text": "What you should know already\n\nComfortable with R (data wrangling, plotting, writing functions)\nLinear regression basics\nCorrelation/covariance intuition"
  },
  {
    "objectID": "book/index.html#companion-materials",
    "href": "book/index.html#companion-materials",
    "title": "Structural Equation Modelling in Psychological Sciences",
    "section": "Companion materials",
    "text": "Companion materials\n\nSlides and labs: see the course GitHub Pages site\nGlossary: key terms and common confusions\nReporting checklist: copy-paste guidance for papers and theses\nExtras: optional modules (power, latent interactions, SAM today’s methods, etc.)"
  },
  {
    "objectID": "book/index.html#book-roadmap",
    "href": "book/index.html#book-roadmap",
    "title": "Structural Equation Modelling in Psychological Sciences",
    "section": "Book roadmap",
    "text": "Book roadmap\n\nFoundations: SEM logic, identification intuition, estimation choices, lavaan grammar\nPath analysis: regression models in SEM form, mediation, equivalent models\nFit & diagnostics: global vs local fit, residuals, MI discipline\nCFA: measurement models, identification strategies, reliability\nSEM: measurement + structure, two-step mindset, applied workflow\nExtensions: missing data, invariance, ordinal SEM, longitudinal, multilevel\nAppendices: lavaan recipes + reporting templates"
  },
  {
    "objectID": "book/index.html#citation",
    "href": "book/index.html#citation",
    "title": "Structural Equation Modelling in Psychological Sciences",
    "section": "Citation",
    "text": "Citation\nIf you cite this book/course notes, you can use the following format (update the year/date when final):\n\nFeraco, T. (Year). Structural Equation Modelling in Psychological Sciences: Applied SEM with lavaan. Course notes, University of Padova."
  },
  {
    "objectID": "book/index.html#acknowledgements-optional",
    "href": "book/index.html#acknowledgements-optional",
    "title": "Structural Equation Modelling in Psychological Sciences",
    "section": "Acknowledgements (optional)",
    "text": "Acknowledgements (optional)\nThanks to colleagues and students who provided feedback on earlier versions of these materials."
  },
  {
    "objectID": "extras/extras_index.html",
    "href": "extras/extras_index.html",
    "title": "Extras",
    "section": "",
    "text": "These are optional, self-contained modules you can read when relevant. Each module should include: - a short concept note (why/when) - minimal reproducible example (R code) - exercises (+ solutions if provided)"
  },
  {
    "objectID": "extras/extras_index.html#methods-inference",
    "href": "extras/extras_index.html#methods-inference",
    "title": "Extras",
    "section": "Methods & inference",
    "text": "Methods & inference\n\nex01 Power: Monte Carlo for SEM\nex02 Bayesian SEM: quickstart"
  },
  {
    "objectID": "extras/extras_index.html#advanced-sem",
    "href": "extras/extras_index.html#advanced-sem",
    "title": "Extras",
    "section": "Advanced SEM",
    "text": "Advanced SEM\n\nex03 Latent interactions (modsem)\nex04 SAM in lavaan\nex05 MIIVs & consistent factor score regression"
  },
  {
    "objectID": "extras/extras_index.html#longitudinal-deep-dives",
    "href": "extras/extras_index.html#longitudinal-deep-dives",
    "title": "Extras",
    "section": "Longitudinal deep dives",
    "text": "Longitudinal deep dives\n\nex06 RI-CLPM vs CLPM\nex07 Latent change score models"
  },
  {
    "objectID": "extras/extras_index.html#measurement-extensions",
    "href": "extras/extras_index.html#measurement-extensions",
    "title": "Extras",
    "section": "Measurement extensions",
    "text": "Measurement extensions\n\nex09 Alignment / approximate invariance\nex10 Bifactor / ESEM / method factors"
  },
  {
    "objectID": "extras/extras_index.html#missing-data-sensitivity",
    "href": "extras/extras_index.html#missing-data-sensitivity",
    "title": "Extras",
    "section": "Missing data sensitivity",
    "text": "Missing data sensitivity\n\nex08 MNAR sensitivity: conceptual + simple strategies"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Structural Equation Modelling in Psychological Sciences",
    "section": "",
    "text": "Welcome! This repository contains slides (Quarto revealjs), hands-on labs, and extras for self-study."
  },
  {
    "objectID": "index.html#how-to-use-this-repo",
    "href": "index.html#how-to-use-this-repo",
    "title": "Structural Equation Modelling in Psychological Sciences",
    "section": "How to use this repo",
    "text": "How to use this repo\n\nDuring class: open the slides for today + run the matching lab.\nAfter class: use the Glossary and Reporting checklist while doing exercises/projects.\nExtras: optional modules (power, SAM, latent interactions, etc.) you can read when relevant.\n\n\n\n\n\n\n\nTip\n\n\n\nTip\nIf you get lost: come back here. This page is the “map” for everything."
  },
  {
    "objectID": "index.html#timetable-54h-split-into-two-2-hour-blocks",
    "href": "index.html#timetable-54h-split-into-two-2-hour-blocks",
    "title": "Structural Equation Modelling in Psychological Sciences",
    "section": "Timetable (5×4h, split into two 2-hour blocks)",
    "text": "Timetable (5×4h, split into two 2-hour blocks)\n\nLinks will work after rendering the project (or if you open the pre-rendered website).\n\n\n\n\nDay\nBlock A (2h)\nBlock B (2h)\nCore lab\n\n\n\n\n1\n00 Course map + 01 Foundations\n02 Path analysis\nLab 01 + Lab 02\n\n\n2\n03 Fit & diagnostics\n04 CFA\nLab 03 + Lab 04\n\n\n3\n05 SEM capstone\n06 Missing/robust/reporting\nLab 05 + Lab 06\n\n\n4\n07 Invariance (MG-CFA)\n08 Ordinal SEM\nLab 07 + Lab 08\n\n\n5\n09 Longitudinal on-ramp\n10 Multilevel/clustered\nLab 09 + Lab 10"
  },
  {
    "objectID": "index.html#what-you-should-keep-open-while-working",
    "href": "index.html#what-you-should-keep-open-while-working",
    "title": "Structural Equation Modelling in Psychological Sciences",
    "section": "What you should keep open while working",
    "text": "What you should keep open while working\n\nSetup (only once, then keep for troubleshooting)\nGlossary (quick definitions, naming conventions)\nReporting checklist (what to report in CFA/SEM/invariance/ordinal/etc.)\nExtras (optional modules; useful later)"
  },
  {
    "objectID": "index.html#conventions-used-in-this-course",
    "href": "index.html#conventions-used-in-this-course",
    "title": "Structural Equation Modelling in Psychological Sciences",
    "section": "Conventions used in this course",
    "text": "Conventions used in this course\n\nCore fit indices (default): χ², CFI/TLI, RMSEA (+ CI), SRMR\nLocal fit: residuals + MI/EPC (with “modification discipline”)\nDefault mindset: measurement first, then structure (“two-step mindset”)\n\n\n\n\n\n\n\nImportant\n\n\n\nImportant\nSlides are optimized for live teaching. “Extras” are designed to be self-contained reading modules with code + exercises."
  },
  {
    "objectID": "reporting-checklist.html",
    "href": "reporting-checklist.html",
    "title": "Reporting checklist",
    "section": "",
    "text": "Use this as a copy/paste checklist for assignments, papers, and thesis chapters."
  },
  {
    "objectID": "reporting-checklist.html#always-report-any-semcfa",
    "href": "reporting-checklist.html#always-report-any-semcfa",
    "title": "Reporting checklist",
    "section": "Always report (any SEM/CFA)",
    "text": "Always report (any SEM/CFA)\n\nSoftware + version (R, lavaan, semTools, etc.)\nSample size (N) and any exclusions\nVariables (which indicators for each factor; scales; whether ordinal)\nEstimator (ML / MLR / WLSMV etc.) + justification\nMissing data handling (FIML / MI / listwise) + justification\nModel syntax (append or supplement)\nModel identification choices (marker vs std.lv=TRUE, constraints, etc.)\nGlobal fit: χ²(df), CFI/TLI, RMSEA (+ CI), SRMR\nKey parameters: estimates + SE/CI + standardized solution (when meaningful)\nInterpretation tied to the research question\nDiagnostics: what you checked (residuals, MI/EPC) and what you changed (if anything)\nReproducibility: session info (and seed if simulation)"
  },
  {
    "objectID": "reporting-checklist.html#cfa-specific",
    "href": "reporting-checklist.html#cfa-specific",
    "title": "Reporting checklist",
    "section": "CFA-specific",
    "text": "CFA-specific\n\nFactor loadings (unstd + std), indicator residual variances\nFactor variances/covariances\nReliability: ω (omega) and/or other chosen indices (with method stated)\nHandling of cross-loadings / correlated residuals:\n\nwere any added?\nwhat was the substantive rationale?\nwas this preregistered / cross-validated / replicated?"
  },
  {
    "objectID": "reporting-checklist.html#sem-structural-specific",
    "href": "reporting-checklist.html#sem-structural-specific",
    "title": "Reporting checklist",
    "section": "SEM (structural) specific",
    "text": "SEM (structural) specific\n\nStructural paths (standardized + CI)\nR² for endogenous variables\nIndirect effects:\n\nmethod (bootstrap recommended when appropriate)\neffect + CI + interpretation (avoid “p-value only” reporting)\n\nClarify causal language:\n\nobservational vs experimental\nidentification assumptions (temporal ordering, confounding, etc.)"
  },
  {
    "objectID": "reporting-checklist.html#multi-group-invariance",
    "href": "reporting-checklist.html#multi-group-invariance",
    "title": "Reporting checklist",
    "section": "Multi-group / invariance",
    "text": "Multi-group / invariance\n\nGroups (definition, Ns per group)\nInvariance steps tested:\n\nconfigural, metric, scalar (and strict if used)\n\nWhat constraints were imposed at each step\nDecision rules used (e.g., ΔCFI / ΔRMSEA thresholds) and references for your rule\nIf partial invariance:\n\nwhich parameters freed\nrationale (substantive + statistical)\nwhat comparisons remain interpretable (e.g., latent means only after (partial) scalar)"
  },
  {
    "objectID": "reporting-checklist.html#ordinal-indicators",
    "href": "reporting-checklist.html#ordinal-indicators",
    "title": "Reporting checklist",
    "section": "Ordinal indicators",
    "text": "Ordinal indicators\n\nWhich variables treated as ordered\nEstimator and link (e.g., WLSMV / probit-type default framework)\nThresholds vs intercepts (make clear what was constrained in invariance)\nFit interpretation caveat: note if thresholds or residual structures drive misfit\nSensitivity check (optional but strong): treat as continuous vs ordered and compare conclusions"
  },
  {
    "objectID": "reporting-checklist.html#longitudinal-sem",
    "href": "reporting-checklist.html#longitudinal-sem",
    "title": "Reporting checklist",
    "section": "Longitudinal SEM",
    "text": "Longitudinal SEM\n\nTime points and spacing\nWhether you tested longitudinal measurement invariance\nHow you handled correlated uniqueness (same items across time)\nFor growth models:\n\ncoding of slope loadings (0,1,2… or actual time)\nrandom effects included (intercept/slope variance)\n\nFor cross-lagged models:\n\nclarify whether you used CLPM vs alternatives (if relevant)\ninterpret cross-lagged paths cautiously"
  },
  {
    "objectID": "reporting-checklist.html#clustered-multilevel",
    "href": "reporting-checklist.html#clustered-multilevel",
    "title": "Reporting checklist",
    "section": "Clustered / multilevel",
    "text": "Clustered / multilevel\n\nClustering variable (e.g., class, clinic, therapist) and cluster sizes\nStrategy used:\n\ncluster-robust SE (and why sufficient), or\nexplicit multilevel model (within/between)\n\nIf multilevel:\n\nwhich parameters vary within vs between\nICC motivation (optional but helpful)"
  },
  {
    "objectID": "reporting-checklist.html#a-short-results-paragraph-template",
    "href": "reporting-checklist.html#a-short-results-paragraph-template",
    "title": "Reporting checklist",
    "section": "A short “results paragraph” template",
    "text": "A short “results paragraph” template\n\n“We fit a [CFA/SEM] using lavaan (version …) with estimator … . Missing data were handled using … . Model fit was [acceptable/problematic] (χ²(df)=…, CFI=…, RMSEA=… [CI], SRMR=…). The key effect of interest was … (β=…, 95% CI […, …]). Diagnostics indicated … ; we [did/did not] respecify the model. Results suggest …, with limitations including … .”\n\n\n\n\n\n\n\n\nImportant\n\n\n\nRule of thumb\nIf you changed the model after looking at the data, state exactly what you changed and why. “Transparency beats perfection.”"
  },
  {
    "objectID": "slides/slides_index.html",
    "href": "slides/slides_index.html",
    "title": "Slides",
    "section": "",
    "text": "Here are the slide decks for the course (5×4h, split into two blocks each day)."
  },
  {
    "objectID": "slides/slides_index.html#day-1",
    "href": "slides/slides_index.html#day-1",
    "title": "Slides",
    "section": "Day 1",
    "text": "Day 1\n\nBlock A: 00 Course map, 01 Foundations\nBlock B: 02 Path analysis"
  },
  {
    "objectID": "slides/slides_index.html#day-2",
    "href": "slides/slides_index.html#day-2",
    "title": "Slides",
    "section": "Day 2",
    "text": "Day 2\n\nBlock A: 03 Fit & diagnostics\nBlock B: 04 CFA"
  },
  {
    "objectID": "slides/slides_index.html#day-3",
    "href": "slides/slides_index.html#day-3",
    "title": "Slides",
    "section": "Day 3",
    "text": "Day 3\n\nBlock A: 05 SEM capstone\nBlock B: 06 Missing/robust/reporting"
  },
  {
    "objectID": "slides/slides_index.html#day-4",
    "href": "slides/slides_index.html#day-4",
    "title": "Slides",
    "section": "Day 4",
    "text": "Day 4\n\nBlock A: 07 Invariance (MG-CFA)\nBlock B: 08 Ordinal SEM"
  },
  {
    "objectID": "slides/slides_index.html#day-5",
    "href": "slides/slides_index.html#day-5",
    "title": "Slides",
    "section": "Day 5",
    "text": "Day 5\n\nBlock A: 09 Longitudinal on-ramp\nBlock B: 10 Multilevel/clustered"
  },
  {
    "objectID": "templates/report-template.html",
    "href": "templates/report-template.html",
    "title": "SEM Report — Title",
    "section": "",
    "text": "Write 3–6 lines: - What is the substantive question? - What are the constructs? - What would be convincing evidence?"
  },
  {
    "objectID": "templates/report-template.html#sample",
    "href": "templates/report-template.html#sample",
    "title": "SEM Report — Title",
    "section": "2.1 Sample",
    "text": "2.1 Sample\n\nN =\nInclusion/exclusion =\nGrouping variable (if any) =\nClustering (if any) = (e.g., students in classrooms)"
  },
  {
    "objectID": "templates/report-template.html#variables",
    "href": "templates/report-template.html#variables",
    "title": "SEM Report — Title",
    "section": "2.2 Variables",
    "text": "2.2 Variables\nBrief table (optional): - Indicators for each latent factor - Outcomes/predictors - Scale type (continuous vs ordinal Likert)"
  },
  {
    "objectID": "templates/report-template.html#missingness",
    "href": "templates/report-template.html#missingness",
    "title": "SEM Report — Title",
    "section": "2.3 Missingness",
    "text": "2.3 Missingness\n\n% missing overall =\nKey variables with missingness =\nStrategy (FIML / MI / listwise) + short justification\n\n\n\nShow code\n# Optional quick checks (edit to match your data)\n# summary(dat)\n# colMeans(is.na(dat))"
  },
  {
    "objectID": "templates/report-template.html#conceptual-model-diagram",
    "href": "templates/report-template.html#conceptual-model-diagram",
    "title": "SEM Report — Title",
    "section": "3.1 Conceptual model (diagram)",
    "text": "3.1 Conceptual model (diagram)\nInsert a figure if you have one:"
  },
  {
    "objectID": "templates/report-template.html#lavaan-syntax",
    "href": "templates/report-template.html#lavaan-syntax",
    "title": "SEM Report — Title",
    "section": "3.2 lavaan syntax",
    "text": "3.2 lavaan syntax\n\n\nShow code\nlibrary(lavaan)\n\nmodel &lt;- '\n  # Measurement\n  f1 =~ x1 + x2 + x3\n  f2 =~ y1 + y2 + y3\n\n  # Structural\n  f2 ~ f1\n'"
  },
  {
    "objectID": "templates/report-template.html#global-fit",
    "href": "templates/report-template.html#global-fit",
    "title": "SEM Report — Title",
    "section": "5.1 Global fit",
    "text": "5.1 Global fit\nReport a small set consistently (and add CI where relevant): - χ²(df) = - CFI = - TLI = - RMSEA [90% CI] = - SRMR =\n\n\nShow code\n# Example\n# fitMeasures(fit, c(\"chisq\",\"df\",\"cfi\",\"tli\",\"rmsea\",\"rmsea.ci.lower\",\"rmsea.ci.upper\",\"srmr\"))"
  },
  {
    "objectID": "templates/report-template.html#key-parameters",
    "href": "templates/report-template.html#key-parameters",
    "title": "SEM Report — Title",
    "section": "5.2 Key parameters",
    "text": "5.2 Key parameters\nFocus on the parameters tied to your research question. - Main paths (standardized estimates + CI) - Loadings (and any problematic indicators) - R² for outcomes\n\n\nShow code\n# Example: parameter table\n# pe &lt;- parameterEstimates(fit, standardized = TRUE)\n# pe[pe$op %in% c(\"~\",\"=~\"), c(\"lhs\",\"op\",\"rhs\",\"est\",\"se\",\"pvalue\",\"std.all\")]"
  },
  {
    "objectID": "templates/report-template.html#interpretation-write-up",
    "href": "templates/report-template.html#interpretation-write-up",
    "title": "SEM Report — Title",
    "section": "5.3 Interpretation (write-up)",
    "text": "5.3 Interpretation (write-up)\nWrite 1–2 short paragraphs: - What do the results mean substantively? - Are effects small/medium/large in context? - What alternative explanations remain?\nInclude citations when relevant, e.g. (rosseel2012lavaan?)."
  },
  {
    "objectID": "templates/report-template.html#references",
    "href": "templates/report-template.html#references",
    "title": "SEM Report — Title",
    "section": "10.1 References",
    "text": "10.1 References"
  },
  {
    "objectID": "slides/00_introduction.html#outline",
    "href": "slides/00_introduction.html#outline",
    "title": "Introducing the introduction",
    "section": "Outline",
    "text": "Outline\n\nCourse contents\nApproaching the course"
  },
  {
    "objectID": "slides/00_introduction.html#topics-that-we-will-hopefully-cover-in-the-course",
    "href": "slides/00_introduction.html#topics-that-we-will-hopefully-cover-in-the-course",
    "title": "Introducing the introduction",
    "section": "Topics that we will (hopefully) cover in the course",
    "text": "Topics that we will (hopefully) cover in the course\n\nlavaan\nBasic knowledge about SEM\nModels with manifest variables - path analysis\nMeasurement models with SEM - CFA\nFull SEM: measurement + structural part\nModel invariance - MG-CFA\nModels for ordinal data\nPower analysis for SEM\nOther miscellaneous topics (briefly)"
  },
  {
    "objectID": "slides/00_introduction.html#why-am-i-here",
    "href": "slides/00_introduction.html#why-am-i-here",
    "title": "Introducing the introduction",
    "section": "Why am I here?",
    "text": "Why am I here?\nI am convinced that SEM is a fundamental tool for research in psychology and most, if not all, researchers in this area should know it. Indeed, it is key for many aspects of your research:\n\nMeasurement\nMultivariate analyses\nComplex regression models\nLongitudinal analyses\n…"
  },
  {
    "objectID": "slides/00_introduction.html#what-you-can-expect-from-this-course",
    "href": "slides/00_introduction.html#what-you-can-expect-from-this-course",
    "title": "Introducing the introduction",
    "section": "What you can expect from this course",
    "text": "What you can expect from this course\nI am not a statisticians. This will have negative consequences on your statistical knowledge at the end of the course, but hopefully more practical and psychology-based examples and experiences.\n\nPractical example\nData simulation\nFew equations\nOpen discussions\nHands-on your data"
  },
  {
    "objectID": "slides/00_introduction.html#what-i-need-from-you",
    "href": "slides/00_introduction.html#what-i-need-from-you",
    "title": "Introducing the introduction",
    "section": "What I need from you",
    "text": "What I need from you\n\nA PC (optional)\nBasic R knowledge\n‘for’ loops knowledge\nSome packages installed\n\n\ninstall.packages(c(\"lavaan\", \"semTools\", \n                   \"semPlot\", \"MASS\"))"
  },
  {
    "objectID": "slides/00_introduction.html#materials-and-organization",
    "href": "slides/00_introduction.html#materials-and-organization",
    "title": "Introducing the introduction",
    "section": "Materials and organization",
    "text": "Materials and organization\n\nThe material is divided in arguments\nFor each argument you will find\nSlides\nAdditional code\nData\nWe will probably do live coding when needed. I will work on this file: LiveCode\nI also prepared this file where we can collect questions, if it is too early to answer or if you want to save it: Q doc\nIn general, live materials are in this folder"
  },
  {
    "objectID": "slides/00_introduction.html#moodle",
    "href": "slides/00_introduction.html#moodle",
    "title": "Introducing the introduction",
    "section": "Moodle",
    "text": "Moodle\nSlides and materials are in the Moodle page of the course\n\nOR moodle psicologia unipd &gt; Formazione Post Lauream &gt; Corsi di Dottorato &gt; Psychological Sciences aa 2023/2024 &gt; Structural Equations"
  },
  {
    "objectID": "slides/00_introduction.html#registro-didattico",
    "href": "slides/00_introduction.html#registro-didattico",
    "title": "Introducing the introduction",
    "section": "Registro didattico",
    "text": "Registro didattico\nlogbook: Please fill the logbook everyday."
  },
  {
    "objectID": "slides/00_introduction.html#contacts",
    "href": "slides/00_introduction.html#contacts",
    "title": "Introducing the introduction",
    "section": "Contacts",
    "text": "Contacts\ntommaso.feraco@unipd.it"
  },
  {
    "objectID": "slides/00_introduction.html#introduction",
    "href": "slides/00_introduction.html#introduction",
    "title": "Introducing the introduction",
    "section": "Introduction",
    "text": "Introduction\nStructural Equation Modeling\nDoctoral School in Psychological Sciences\nUniversity of Padova — 2023\nCREDITS TO PROF. MASSIMILIANO PASTORE FOR THE SLIDES"
  },
  {
    "objectID": "slides/00_introduction.html#outline-1",
    "href": "slides/00_introduction.html#outline-1",
    "title": "Introducing the introduction",
    "section": "Outline",
    "text": "Outline\n\nBasics\nVariables and relationships\nSteps\nBasic concepts\nGraphics\nSEM world\nAppendix\nnew section"
  },
  {
    "objectID": "slides/00_introduction.html#how-do-you-fit-these",
    "href": "slides/00_introduction.html#how-do-you-fit-these",
    "title": "Introducing the introduction",
    "section": "How do you fit these?",
    "text": "How do you fit these?"
  },
  {
    "objectID": "slides/00_introduction.html#sem-structural-equation-modeling",
    "href": "slides/00_introduction.html#sem-structural-equation-modeling",
    "title": "Introducing the introduction",
    "section": "SEM = Structural Equation Modeling",
    "text": "SEM = Structural Equation Modeling\n\nSEM is a multivariate statistical modeling technique\n\nit includes path-analysis, causal models, factorial models, measurement models, Latent Growth Models, but even simple multiple regression or ANOVA could be considered particular cases of SEM.\nAll these techniques use the covariance matrix (\\(\\boldsymbol{S}\\)) for estimating target model parameters.\n\nSEM allows us to test a hypothesis/model about the data\n\nwe postulate a data-generating model\nwe evaluate whether this model fits the data or not\n\nWhat is so special about SEM?\n\nwe can model latent variables (e.g., ‘invisible constructs’)\nwe can test indirect and reciprocal effects and more\nlast but not least, we can make diagrams (or PAINTINGS if theory is weak!)"
  },
  {
    "objectID": "slides/00_introduction.html#variance-covariance-matrices",
    "href": "slides/00_introduction.html#variance-covariance-matrices",
    "title": "Introducing the introduction",
    "section": "Variance-covariance matrices",
    "text": "Variance-covariance matrices\n\n\n\noptions(digits = 2)\ncov(PoliticalDemocracy[1:7])\n\n    y1   y2   y3   y4  y5   y6   y7\ny1 6.9  6.3  5.8  6.1 5.1  5.7  5.8\ny2 6.3 15.6  5.8  9.5 5.6  9.4  7.5\ny3 5.8  5.8 10.8  6.7 4.9  4.7  7.0\ny4 6.1  9.5  6.7 11.2 5.7  7.4  7.5\ny5 5.1  5.6  4.9  5.7 6.8  5.0  5.8\ny6 5.7  9.4  4.7  7.4 5.0 11.4  6.7\ny7 5.8  7.5  7.0  7.5 5.8  6.7 10.8\n\n\n\nSEM works with matrices\n\n\\(\\boldsymbol{S}\\) observed var-cov\n\\(\\boldsymbol{\\Sigma}\\) true var-cov\n\\(\\boldsymbol{\\hat{\\Sigma}}\\) model-implied var-cov\n\\(\\boldsymbol{\\Sigma}(\\theta)\\)\n\n\nTHE MAIN AIM OF SEM IS TO RECONSTRUCT THE TRUE VARIANCE-COVARIANCE MATRIX"
  },
  {
    "objectID": "slides/00_introduction.html#classification-of-variables",
    "href": "slides/00_introduction.html#classification-of-variables",
    "title": "Introducing the introduction",
    "section": "Classification of variables",
    "text": "Classification of variables\nVariables are the way those attributes that vary across individuals are operationalized and represented for further data processing. These can be categorized according to many criteria (e.g, dependent/independent…), but in SEM we classify them firstly as:\n\nLatent variables\n\nhypothetical variables that correspond to more or less abstract concepts\nformative or reflective\nexamples are intelligence, anxiety, executive functions, personality traits…\n\nObserved variables\n\nvariables that can be directly observed and measured\nexamples can be weight, height, gender, income…"
  },
  {
    "objectID": "slides/00_introduction.html#classification-of-variables-1",
    "href": "slides/00_introduction.html#classification-of-variables-1",
    "title": "Introducing the introduction",
    "section": "Classification of variables",
    "text": "Classification of variables\nIn SEM we also have an additional type of classification:\n\nExogenous variables\n\nVariables whose causes lie outside the model; they will be used only as predictors in the model. They do not receive arrows.\nThey are indicated with \\(x\\), if observed, or with \\(\\xi\\), if latent.\n\nEndogenous variables\n\nVariables that are determined by variables within the model (they receive arrows); can be used as predictors or dependent variables in the model.\nThey are indicated with \\(y\\), if observed, or with \\(\\eta\\), if latent.\n\n\nThis brings us to deepen the relationships between variables."
  },
  {
    "objectID": "slides/00_introduction.html#relationships-between-variables",
    "href": "slides/00_introduction.html#relationships-between-variables",
    "title": "Introducing the introduction",
    "section": "Relationships between variables",
    "text": "Relationships between variables\n\nThe general aim of statistical analysis is to study relationship among variables\nOn the basis of the relationship among the variables, we distinguish two kind of models: symmetrical and asymmetrical."
  },
  {
    "objectID": "slides/00_introduction.html#asymmetrical-relationships",
    "href": "slides/00_introduction.html#asymmetrical-relationships",
    "title": "Introducing the introduction",
    "section": "Asymmetrical relationships",
    "text": "Asymmetrical relationships\nX -&gt; Y\n\nVariables are divided into two sets: dependent or response variables and predictors or explanatory variables\nX is the set of explanatory variables, \\(Y\\) is the set of response variables, arrows represents the direction of the hypothesized relationship.\nThese models imply cause-and-effect relationships.\n\nExample\nPeople who study more obtain higher grades."
  },
  {
    "objectID": "slides/00_introduction.html#symmetrical-relationships",
    "href": "slides/00_introduction.html#symmetrical-relationships",
    "title": "Introducing the introduction",
    "section": "Symmetrical relationships",
    "text": "Symmetrical relationships\n\\[\nX_i \\Leftrightarrow Y_j \\quad \\forall i,j\n\\]\n\nThis means that neither a variable causes the other, neither a variable can be considered prior in time to the other; all these relationships are bidirectional.\nThese models do not imply nor consider causality.\n\nExample\nPeople who have higher grades in math have higher grades in art."
  },
  {
    "objectID": "slides/00_introduction.html#regression-model",
    "href": "slides/00_introduction.html#regression-model",
    "title": "Introducing the introduction",
    "section": "Regression model",
    "text": "Regression model\nAsymmetrical relationships are usually tested with regressions!\nAs you remember, regression models can be written, using classical formulation, as the expression below and graphically depicted (getting closer to SEM) like this:"
  },
  {
    "objectID": "slides/00_introduction.html#more-regression",
    "href": "slides/00_introduction.html#more-regression",
    "title": "Introducing the introduction",
    "section": "More regression?",
    "text": "More regression?\nBut what if we have in mind a more complex pattern of relationships? What if we have more regression models in mind and need to estimate all of them contemporarily?\n\nWhat we need is a system of equations."
  },
  {
    "objectID": "slides/00_introduction.html#more-regression-1",
    "href": "slides/00_introduction.html#more-regression-1",
    "title": "Introducing the introduction",
    "section": "More regression?",
    "text": "More regression?\nThis system can also be drawn with SEM notation, but is actually the same…just better!"
  },
  {
    "objectID": "slides/00_introduction.html#covariance-matrix",
    "href": "slides/00_introduction.html#covariance-matrix",
    "title": "Introducing the introduction",
    "section": "Covariance matrix",
    "text": "Covariance matrix\nThe covariance matrix is the input for the estimation process. In general, given \\(q\\) exogenous (\\(x\\)) and \\(p\\) endogenous (\\(y\\)) variables, the covariance matrix will be:\n\nIn which the diagonal elements are variances and off diagonal elements are covariances."
  },
  {
    "objectID": "slides/00_introduction.html#variables-and-errors",
    "href": "slides/00_introduction.html#variables-and-errors",
    "title": "Introducing the introduction",
    "section": "Variables and errors",
    "text": "Variables and errors\n\nVariables\n\n\\(x\\) exogenous observed (\\(q\\))\n\\(\\xi\\) exogenous latent (\\(n\\))\n\\(y\\) endogenous observed (\\(p\\))\n\\(\\eta\\) endogenous latent (\\(m\\))\n\nStochastic errors\n\n\\(\\delta\\) measurement errors in \\(x\\)\n\\(\\epsilon\\) measurement errors in \\(y\\)\n\\(\\zeta\\) equation errors in the structural relationship between \\(\\eta\\) and \\(\\xi\\)"
  },
  {
    "objectID": "slides/00_introduction.html#sem-matrices---lavaan-model",
    "href": "slides/00_introduction.html#sem-matrices---lavaan-model",
    "title": "Introducing the introduction",
    "section": "SEM matrices - lavaan model",
    "text": "SEM matrices - lavaan model\n\nParameter matrices\n\n\\(\\boldsymbol{\\Lambda}\\) relationship between latent (\\(\\xi\\) and \\(\\eta\\)) and observed (\\(x\\) and \\(y\\)) [\\((p + q) X (m + n)\\)]\n\\(\\boldsymbol{B}\\) relationship between latent variables [\\((m + n) X (m + n)\\)]\n\nCovariance matrices\n\n\\(Cov\\)(\\(\\zeta\\), \\(\\xi\\)) = \\(\\boldsymbol{\\Psi}\\) matrix [\\((m + n) X (m + n)\\)]\n\\(Cov\\)(\\(\\epsilon\\), \\(\\delta\\)) = \\(\\boldsymbol{\\Theta}\\) matrix [\\((p + q) X (p + q)\\)]"
  },
  {
    "objectID": "slides/00_introduction.html#sem-equations",
    "href": "slides/00_introduction.html#sem-equations",
    "title": "Introducing the introduction",
    "section": "SEM equations",
    "text": "SEM equations\nThe SEM model in its most general form consists of two parts\n\nThe measurement model\n\n\\(x = \\boldsymbol{\\Lambda}_x\\boldsymbol{\\xi} + \\boldsymbol{\\delta}\\)\n\\(y = \\boldsymbol{\\Lambda}_y\\boldsymbol{\\eta} + \\boldsymbol{\\epsilon}\\)\n\nThe structural model\n\n\\(\\boldsymbol{\\eta} = \\boldsymbol{B\\eta} + \\boldsymbol{\\Gamma\\xi} + \\boldsymbol{\\zeta}\\)\n\\(\\boldsymbol{\\eta} = \\boldsymbol{B(\\eta\\xi} + \\boldsymbol{\\zeta})\\)"
  },
  {
    "objectID": "slides/00_introduction.html#sem-assumtions",
    "href": "slides/00_introduction.html#sem-assumtions",
    "title": "Introducing the introduction",
    "section": "SEM assumtions",
    "text": "SEM assumtions\n\nExpected values of latent variables and stochastic errors are 0:\n\\(E\\)(\\(\\eta\\)) = 0\n\\(E\\)(\\(\\xi\\)) = 0\n\\(E\\)(\\(\\zeta\\)) = 0\n\\(E\\)(\\(\\epsilon\\)) = 0\n\\(E\\)(\\(\\delta\\)) = 0\nErrors are uncorrelated with latent variables and are mutually uncorrelated:"
  },
  {
    "objectID": "slides/00_introduction.html#sem-steps",
    "href": "slides/00_introduction.html#sem-steps",
    "title": "Introducing the introduction",
    "section": "SEM steps",
    "text": "SEM steps\nThere are 5 principal steps in Structural Equation Modeling:\n\nmodel specification\nmodel identification\nparameters estimation\ntesting\nmodel modification\n\nAs usual, these steps are like a cycle: when you arrive at step 5 you can always come back to step 1."
  },
  {
    "objectID": "slides/00_introduction.html#model-specification",
    "href": "slides/00_introduction.html#model-specification",
    "title": "Introducing the introduction",
    "section": "1. Model specification",
    "text": "1. Model specification\nAim of the model\n\nWe fit models because we want to better understand the data and the process of data generation (to better understand this we will use simulation…simulate, simulate, simulate!)\n\nWhat is a model\n\nA model is a formal representation of a theory and is composed by a set of parameters that we will estimate.\n\nExamples"
  },
  {
    "objectID": "slides/00_introduction.html#model-identification",
    "href": "slides/00_introduction.html#model-identification",
    "title": "Introducing the introduction",
    "section": "2. Model identification",
    "text": "2. Model identification\nBasically, we want to know if there is enough information to identify a solution (aka estimate all the unknown parameters).\nA model can be:\n\nUnder-identified\nJust-identified\nOver-identified"
  },
  {
    "objectID": "slides/00_introduction.html#model-identification-1",
    "href": "slides/00_introduction.html#model-identification-1",
    "title": "Introducing the introduction",
    "section": "2. Model identification",
    "text": "2. Model identification\nBasically, we want to know if there is enough information to identify a solution (aka estimate all the unknown parameters).\nA model can be:\n\nUnder-identified: there are MORE parameters to be estimated than elements in the covariance matrix (e.g., \\(X + Y = 10\\))\nJust-identified: the number of parameters to be estimated equals the number of elements in the covariance matrix (\\(df = 0\\))\nOver-identified: there are LESS parameters to be estimated than elements in the covariance matrix (\\(df &gt; 0\\))"
  },
  {
    "objectID": "slides/00_introduction.html#model-identification-2",
    "href": "slides/00_introduction.html#model-identification-2",
    "title": "Introducing the introduction",
    "section": "3. Model identification",
    "text": "3. Model identification\nTo ensure that the number of unknown parameters (\\(t\\)) is not greater than the number of nonredundant elements in the covariance matrix of \\(q\\) observed variables. We can use the following formula:\n\\[\nt \\leq \\frac{q(q+1)}{2}\n\\]"
  },
  {
    "objectID": "slides/00_introduction.html#an-under-identified-model",
    "href": "slides/00_introduction.html#an-under-identified-model",
    "title": "Introducing the introduction",
    "section": "An under-identified model",
    "text": "An under-identified model\nTo ensure that the number of unknown parameters (\\(t\\)) is not greater than the number of nonredundant elements in the covariance matrix of \\(q\\) observed variables. We can use the following formula:\n\\[\nt \\leq \\frac{q(q+1)}{2}\n\\]"
  },
  {
    "objectID": "slides/00_introduction.html#an-over-identified-model",
    "href": "slides/00_introduction.html#an-over-identified-model",
    "title": "Introducing the introduction",
    "section": "An over-identified model",
    "text": "An over-identified model\nTo ensure that the number of unknown parameters (\\(t\\)) is not greater than the number of nonredundant elements in the covariance matrix of \\(q\\) observed variables. We can use the following formula:\n\\[\nt \\leq \\frac{q(q+1)}{2}\n\\]"
  },
  {
    "objectID": "slides/00_introduction.html#parameter-estimation",
    "href": "slides/00_introduction.html#parameter-estimation",
    "title": "Introducing the introduction",
    "section": "3. Parameter estimation",
    "text": "3. Parameter estimation\nTo estimate the model parameters we can use different estimation methods. These aim to estimate the model implied (theoretical) correlation matrix \\(\\boldsymbol{\\Sigma}\\), which is a function of the model parameters, and should hopefully be similar to the observed correlation matrix \\(\\boldsymbol{S}\\).\nSome of the many estimation methods are:\n\nMaximum Likelihood (ML), default in lavaan\nUnweighted Least Squares (ULS)\nGeneralized Least Squares (GLS)\nDiagonally Weighted Least Squares (DWLS), default for ordinal variables in lavaan"
  },
  {
    "objectID": "slides/00_introduction.html#model-evaluation",
    "href": "slides/00_introduction.html#model-evaluation",
    "title": "Introducing the introduction",
    "section": "4. Model evaluation",
    "text": "4. Model evaluation\nIs the model adequate? Are our parameter able to construct a theoretical matrix (\\(\\boldsymbol{\\Sigma}\\)) which is close to the original empirical covariance matrix \\(\\boldsymbol{S}\\)?\nThis is the goal of a good model: reproduce, from a set of theoretical associations/effects (aka covariance matrix), the original covariance matrix.\nFormally:\n\\[\nH_0 : \\boldsymbol{\\hat{\\Sigma}}(\\theta) = \\boldsymbol{\\Sigma}\n\\] where \\(\\boldsymbol{\\Sigma}\\) is the true covariance matrix among model variables, \\(\\theta\\) the parameters vector, and \\(\\boldsymbol{\\hat{\\Sigma}}\\) the reproduced covariance matrix."
  },
  {
    "objectID": "slides/00_introduction.html#model-modification",
    "href": "slides/00_introduction.html#model-modification",
    "title": "Introducing the introduction",
    "section": "5. Model modification",
    "text": "5. Model modification\nAt this point you are free to modify the model based on the results obtained…AND THE THEORY!"
  },
  {
    "objectID": "slides/00_introduction.html#a-full-representation",
    "href": "slides/00_introduction.html#a-full-representation",
    "title": "Introducing the introduction",
    "section": "A full representation",
    "text": "A full representation\n img credits to dr. Johnny Lin"
  },
  {
    "objectID": "slides/00_introduction.html#graphical-representation",
    "href": "slides/00_introduction.html#graphical-representation",
    "title": "Introducing the introduction",
    "section": "Graphical representation",
    "text": "Graphical representation\nIf that all seemed difficult and boring, now comes the funny part: colors, figures, and arrows!\nGraphical representation is a key attribute of structural equation modeling:\n\nIt helps understanding the model\nIt helps thinking and reasoning about the model (a priori)\nIt helps writing and formalizing the model\nIt is easy, but few rules must be followed to have a readable model"
  },
  {
    "objectID": "slides/00_introduction.html#graphical-representation-1",
    "href": "slides/00_introduction.html#graphical-representation-1",
    "title": "Introducing the introduction",
    "section": "Graphical representation",
    "text": "Graphical representation\n\nLatent variables are circles or ellipses\n\nManifest/observed variables are square or rectangular boxes\n\nErrors are represented by corresponding letters (or values) only\n\n\\[\n\\delta_1  /  \\epsilon_1  /  \\zeta_1\n\\]"
  },
  {
    "objectID": "slides/00_introduction.html#graphic-relationships",
    "href": "slides/00_introduction.html#graphic-relationships",
    "title": "Introducing the introduction",
    "section": "Graphic relationships",
    "text": "Graphic relationships\n\nAll model relationships are represented by arrows;\n NO relationship NO arrow... \n\n ...and usually NO arrow NO relationship\nEach arrow is a model parameter and has two indices (e.g., \\(\\beta_{21}\\))\nAsymmetrical relationship are represented by a single headed arrow: the first index indicates the variable the arrow is pointing to, the second index indicates the variable of origin.\nSymmetrical relationships are represented by double-headed arrows and two indices, one for each variable."
  },
  {
    "objectID": "slides/00_introduction.html#graphic-relationships-1",
    "href": "slides/00_introduction.html#graphic-relationships-1",
    "title": "Introducing the introduction",
    "section": "Graphic relationships",
    "text": "Graphic relationships\nA summary"
  },
  {
    "objectID": "slides/00_introduction.html#asymmetrical-relationships-1",
    "href": "slides/00_introduction.html#asymmetrical-relationships-1",
    "title": "Introducing the introduction",
    "section": "Asymmetrical relationships",
    "text": "Asymmetrical relationships"
  },
  {
    "objectID": "slides/00_introduction.html#symmetrical-relationships-1",
    "href": "slides/00_introduction.html#symmetrical-relationships-1",
    "title": "Introducing the introduction",
    "section": "Symmetrical relationships",
    "text": "Symmetrical relationships"
  },
  {
    "objectID": "slides/00_introduction.html#graphical-errors",
    "href": "slides/00_introduction.html#graphical-errors",
    "title": "Introducing the introduction",
    "section": "Graphical errors",
    "text": "Graphical errors\n\nAll errors have a single headed arrow pointing to a variable; all variables, except \\(\\xi\\), may have an error.\nDouble-headed arrows associated to errors indicate error variances."
  },
  {
    "objectID": "slides/00_introduction.html#a-full-representation-1",
    "href": "slides/00_introduction.html#a-full-representation-1",
    "title": "Introducing the introduction",
    "section": "A full representation",
    "text": "A full representation\n img credits to dr. Johnny Lin"
  },
  {
    "objectID": "slides/00_introduction.html#univariate-regressions",
    "href": "slides/00_introduction.html#univariate-regressions",
    "title": "Introducing the introduction",
    "section": "Univariate regressions",
    "text": "Univariate regressions"
  },
  {
    "objectID": "slides/00_introduction.html#multivariate-regressions",
    "href": "slides/00_introduction.html#multivariate-regressions",
    "title": "Introducing the introduction",
    "section": "Multivariate regressions",
    "text": "Multivariate regressions"
  },
  {
    "objectID": "slides/00_introduction.html#path-analysis",
    "href": "slides/00_introduction.html#path-analysis",
    "title": "Introducing the introduction",
    "section": "Path analysis",
    "text": "Path analysis"
  },
  {
    "objectID": "slides/00_introduction.html#confirmatory-factor-analysis-cfa",
    "href": "slides/00_introduction.html#confirmatory-factor-analysis-cfa",
    "title": "Introducing the introduction",
    "section": "Confirmatory factor analysis (CFA)",
    "text": "Confirmatory factor analysis (CFA)"
  },
  {
    "objectID": "slides/00_introduction.html#sem-path-analysis",
    "href": "slides/00_introduction.html#sem-path-analysis",
    "title": "Introducing the introduction",
    "section": "SEM path analysis",
    "text": "SEM path analysis"
  },
  {
    "objectID": "slides/00_introduction.html#t-test-with-latent-variables",
    "href": "slides/00_introduction.html#t-test-with-latent-variables",
    "title": "Introducing the introduction",
    "section": "t test with latent variables",
    "text": "t test with latent variables"
  },
  {
    "objectID": "slides/00_introduction.html#cross-lagged-panel-models",
    "href": "slides/00_introduction.html#cross-lagged-panel-models",
    "title": "Introducing the introduction",
    "section": "Cross-lagged panel models",
    "text": "Cross-lagged panel models"
  },
  {
    "objectID": "slides/00_introduction.html#growth-curve-models",
    "href": "slides/00_introduction.html#growth-curve-models",
    "title": "Introducing the introduction",
    "section": "Growth curve models",
    "text": "Growth curve models"
  },
  {
    "objectID": "slides/00_introduction.html#and-much-more",
    "href": "slides/00_introduction.html#and-much-more",
    "title": "Introducing the introduction",
    "section": "And much more",
    "text": "And much more\n…and much more\nTHERE IS EVEN A JOURNAL ON SEM\nStructural Equation Modeling: A Multidisciplinary Journal"
  },
  {
    "objectID": "slides/00_introduction.html#contacts-1",
    "href": "slides/00_introduction.html#contacts-1",
    "title": "Introducing the introduction",
    "section": "Contacts",
    "text": "Contacts\ntommaso.feraco@unipd.it"
  },
  {
    "objectID": "slides/00_introduction.html#sem-assumptions",
    "href": "slides/00_introduction.html#sem-assumptions",
    "title": "Introducing the introduction",
    "section": "SEM assumptions",
    "text": "SEM assumptions\n\nExpected values of latent variables and stochastic errors are 0:\n\n\\(E\\)(\\(\\eta\\)) = 0\n\\(E\\)(\\(\\xi\\)) = 0\n\\(E\\)(\\(\\zeta\\)) = 0\n\\(E\\)(\\(\\epsilon\\)) = 0\n\\(E\\)(\\(\\delta\\)) = 0\n\nErrors are uncorrelated with latent variables and are mutually uncorrelated:"
  },
  {
    "objectID": "slides/01_path_models.html#outline",
    "href": "slides/01_path_models.html#outline",
    "title": "Models with observed variables",
    "section": "Outline",
    "text": "Outline\n\nFrom lm to lavaan\nExercise 1\nPath models\nExercise 2\nModel fit\nMediation analysis"
  },
  {
    "objectID": "slides/01_path_models.html#regression-models",
    "href": "slides/01_path_models.html#regression-models",
    "title": "Models with observed variables",
    "section": "Regression models",
    "text": "Regression models\nWhat you did since the beginning of the year (with link functions or not) was something like this \\[\ny = X\\beta + \\epsilon\n\\] Where \\(y\\) is the response variable, \\(X\\) the set of predictors and \\(\\epsilon\\) the error term. \nThese models, - assume that all variables are directly observed/manifest - allow measurement errors only in endogenous variables - are just particular cases of SEM"
  },
  {
    "objectID": "slides/01_path_models.html#sem-formula",
    "href": "slides/01_path_models.html#sem-formula",
    "title": "Models with observed variables",
    "section": "SEM formula",
    "text": "SEM formula\nIn fact, the structural model of a SEM (i.e., excluding latent variables) can be expressed with the following equation: \\[\nY = X^\\ast B' + \\zeta\n\\] Where - \\(Y\\) is the (n x p) matrix of endogenous variables - \\(X^\\ast\\) is the n x (p + q) matrix of endogenous and exogenous variables - \\(B\\) is the (p + q) x (p + q) coefficient matrices - \\(\\zeta\\) is the (p x q) matrix of errors in the equations This looks pretty similar to the regression formula, but with some matrices!  Univariate regression models are just a special case of this formula where the parameter matrix is full of 0!"
  },
  {
    "objectID": "slides/01_path_models.html#lets-try-to-fit-and-compare-regression-models",
    "href": "slides/01_path_models.html#lets-try-to-fit-and-compare-regression-models",
    "title": "Models with observed variables",
    "section": "LET’S TRY TO FIT AND COMPARE REGRESSION MODELS",
    "text": "LET’S TRY TO FIT AND COMPARE REGRESSION MODELS\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   y x1 x2 x3\ny  0  1  2  3\nx1 0  0  0  0\nx2 0  0  0  0\nx3 0  0  0  0\n\n\n\n\n   y x3 x2 x1\ny  0  3  2  1\nx3 0  0  5  4\nx2 0  0  0  6\nx1 0  0  0  0\n\n\n\nLET'S TRY TO FIT AND COMPARE REGRESSION MODELS"
  },
  {
    "objectID": "slides/01_path_models.html#a-first-example-with-simulated-data",
    "href": "slides/01_path_models.html#a-first-example-with-simulated-data",
    "title": "Models with observed variables",
    "section": "A first example with simulated data",
    "text": "A first example with simulated data\nImagine you want to predict scores in the test we will do at the end of this corse (\\(y\\)), based on your prior statistical knowledge (\\(x_1\\)) and interest (\\(x_2\\)): - First define the model\n\n\nSecond simulate the data"
  },
  {
    "objectID": "slides/01_path_models.html#a-first-example-with-simulated-data-1",
    "href": "slides/01_path_models.html#a-first-example-with-simulated-data-1",
    "title": "Models with observed variables",
    "section": "A first example with simulated data",
    "text": "A first example with simulated data\n\n# Simulate knowledge and interest as predictors of Y\nset.seed(12)\nN = 100\nx1 = rnorm(N)\nx2 = rnorm(N)\ny = .35*x1 + .20*x2 + rnorm(N)\nd &lt;- data.frame(x1,x2,y)\n\n\ncor(d)\n\n       x1     x2     y\nx1 1.0000 0.0159 0.386\nx2 0.0159 1.0000 0.118\ny  0.3863 0.1185 1.000\n\n#\ncov(d)\n\n       x1     x2     y\nx1 0.7484 0.0138 0.364\nx2 0.0138 0.9982 0.129\ny  0.3644 0.1291 1.189"
  },
  {
    "objectID": "slides/01_path_models.html#lm-regression",
    "href": "slides/01_path_models.html#lm-regression",
    "title": "Models with observed variables",
    "section": "lm regression",
    "text": "lm regression\n\n# fit a regression model\nm &lt;- lm(y ~ x1 + x2, data = d)\nsummary(m)\n\n\nCall:\nlm(formula = y ~ x1 + x2, data = d)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.8022 -0.6244 -0.0259  0.7150  1.8090 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  -0.0251     0.1009   -0.25     0.80    \nx1            0.4846     0.1172    4.14  7.5e-05 ***\nx2            0.1226     0.1015    1.21     0.23    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.01 on 97 degrees of freedom\nMultiple R-squared:  0.162, Adjusted R-squared:  0.145 \nF-statistic: 9.36 on 2 and 97 DF,  p-value: 0.000191"
  },
  {
    "objectID": "slides/01_path_models.html#introducing-lavaan",
    "href": "slides/01_path_models.html#introducing-lavaan",
    "title": "Models with observed variables",
    "section": "Introducing lavaan",
    "text": "Introducing lavaan\nlavaan (latent variable analysis) is actually THE package for SEM. You can use it to estimate a wide family of latent variable models, including: factor analysis, structural equation, longitudinal, multilevel, latent class, item respons, and missing data models… \n..But also simple regressions"
  },
  {
    "objectID": "slides/01_path_models.html#model-fit-and-info",
    "href": "slides/01_path_models.html#model-fit-and-info",
    "title": "Models with observed variables",
    "section": "Model fit and info",
    "text": "Model fit and info\n\nlibrary(lavaan)\nml &lt;- \"y ~ 1 + x1 + x2\" #1 + gives the intercept\nfit &lt;- sem(ml, data = d)\n# summary(fit, rsquare=T)\n\n\n\nlavaan 0.6-19 ended normally after 1 iteration\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         4\n\n  Number of observations                           100\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\n[...]"
  },
  {
    "objectID": "slides/01_path_models.html#model-parameters",
    "href": "slides/01_path_models.html#model-parameters",
    "title": "Models with observed variables",
    "section": "Model parameters",
    "text": "Model parameters\n\n\n[...]\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  y ~                                                 \n    x1                0.485    0.115    4.199    0.000\n    x2                0.123    0.100    1.227    0.220\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .y                -0.025    0.099   -0.253    0.800\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .y                 0.987    0.140    7.071    0.000\n\nR-Square:\n                   Estimate\n    y                 0.162\n\n[...]\n\n\nQUESTIONS? COMMENTS? What about lm?"
  },
  {
    "objectID": "slides/01_path_models.html#model-plot",
    "href": "slides/01_path_models.html#model-plot",
    "title": "Models with observed variables",
    "section": "Model plot",
    "text": "Model plot\n\n\n\n# And we can plot it\nlibrary(semPlot)\nsemPaths(fit, whatLabels = \"parameters\",\n         edge.label.cex = 1.5, rotation = 2,\n         residuals = F,\n         sizeMan = 10,\n         curve = 1.9,\n         edge.color=\"black\", edge.label.color=\"black\")"
  },
  {
    "objectID": "slides/01_path_models.html#model-matrices",
    "href": "slides/01_path_models.html#model-matrices",
    "title": "Models with observed variables",
    "section": "Model matrices",
    "text": "Model matrices\n\n#We can also look at the matrices\n#The parameters matrix\ninspect(fit)$beta\n\n   y x1 x2\ny  0  2  3\nx1 0  0  0\nx2 0  0  0\n\ninspect(fit, \"estimates\")$beta\n\n   y    x1    x2\ny  0 0.485 0.123\nx1 0 0.000 0.000\nx2 0 0.000 0.000\n\n#The residual var-covar matrix\ninspect(fit)$psi\n\n   y x1 x2\ny  4      \nx1 0  0   \nx2 0  0  0\n\ninspect(fit, \"estimates\")$psi\n\n       y    x1    x2\ny  0.987            \nx1 0.000 0.741      \nx2 0.000 0.014 0.988"
  },
  {
    "objectID": "slides/01_path_models.html#basic-lavaan-syntax",
    "href": "slides/01_path_models.html#basic-lavaan-syntax",
    "title": "Models with observed variables",
    "section": "Basic lavaan syntax",
    "text": "Basic lavaan syntax\nAs you can see, the regression syntax of lavaan is actually the same as lm, but there is much more in lavaan. \nModel specification sintax:\n\n\n\n\n\n\n\n\nSyntax\nFunction\nExample\n\n\n\n\n~\nRegress onto\nRegress B onto A: B ~ A\n\n\n~~\nResidual (co)variance\nVariance of A: A ~~ A  Variance of A and B: A ~~ B\n\n\n=~\nDefine a reflective LV\nF1 is defined by items 1-4: F1 =~ i1 + i2 + i3 + i4\n\n\n&lt;~\nDefine a formative LV\nF1 is defined by items 1-4: F1 &lt;~ i1 + i2 + i3 + i4\n\n\n:=\nDefine non-model parameters\nu2 := x + y\n\n\n*\nLabel or fix parameter\nZ ~ b*X labels the regression as b"
  },
  {
    "objectID": "slides/01_path_models.html#exercise-1",
    "href": "slides/01_path_models.html#exercise-1",
    "title": "Models with observed variables",
    "section": "Exercise 1",
    "text": "Exercise 1\nJust a very easy exercise to start practicing with the lavaan sintax. The example is similar to the one above.  The dataset “Exercise1.csv” contains: - N = 1100 participants - 5 variables - - gender: coded 1;2 - age: between 13 and 19 - anxiety - nevroticism - math We want to know whether anxiety and nevroticism have an effect on math achievement. Additionally, is there any effect of demographics variables?"
  },
  {
    "objectID": "slides/01_path_models.html#plot-of-the-exercise",
    "href": "slides/01_path_models.html#plot-of-the-exercise",
    "title": "Models with observed variables",
    "section": "Plot of the exercise",
    "text": "Plot of the exercise\n\n# E1 &lt;- read.csv(\"data/Exercise1.csv\")\nsemPaths(fitE1, rotation = 2, sizeMan = 10,\n         edge.color=\"black\", edge.label.color=\"black\",\n         residuals = F, exoCov = F)"
  },
  {
    "objectID": "slides/01_path_models.html#results---estimation-info",
    "href": "slides/01_path_models.html#results---estimation-info",
    "title": "Models with observed variables",
    "section": "Results - estimation info",
    "text": "Results - estimation info\n\n\nlavaan 0.6-19 ended normally after 1 iteration\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         5\n\n  Number of observations                           723\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\n[...]"
  },
  {
    "objectID": "slides/01_path_models.html#regression-results",
    "href": "slides/01_path_models.html#regression-results",
    "title": "Models with observed variables",
    "section": "Regression results",
    "text": "Regression results\n\n\n[...]\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  math ~                                                                \n    age               0.052    0.009    5.452    0.000    0.052    0.170\n    anxiety           0.357    0.021   16.878    0.000    0.357    0.591\n    nevroticism      -0.156    0.021   -7.354    0.000   -0.156   -0.257\n    gender            0.020    0.039    0.518    0.604    0.020    0.016\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .math              0.263    0.014   19.013    0.000    0.263    0.698"
  },
  {
    "objectID": "slides/01_path_models.html#indirect-effects",
    "href": "slides/01_path_models.html#indirect-effects",
    "title": "Models with observed variables",
    "section": "Indirect effects?",
    "text": "Indirect effects?\nWE JUST ANALYZED NEUROTICISM AND ANXIETY. DO WE REALLY BELIEVE THEY ARE ON THE SAME LEVEL?"
  },
  {
    "objectID": "slides/01_path_models.html#path-models",
    "href": "slides/01_path_models.html#path-models",
    "title": "Models with observed variables",
    "section": "Path models",
    "text": "Path models\nPath models are just pictorial representations of theoretical relationships between variables.  Representations (and simulations) should be the starting point of almost every study.  Based on these representations, we can build a statistical model and estimate the theoretical paths.\n\nThis, of course, is possible in lavaan."
  },
  {
    "objectID": "slides/01_path_models.html#path-models---the-previous-example",
    "href": "slides/01_path_models.html#path-models---the-previous-example",
    "title": "Models with observed variables",
    "section": "Path models - the previous example",
    "text": "Path models - the previous example\nFor example, do we really believe that anxiety and nevroticism could stay on the same level? Isn’t there a theoretical effect of one on the other?"
  },
  {
    "objectID": "slides/01_path_models.html#path-models---the-previous-example-1",
    "href": "slides/01_path_models.html#path-models---the-previous-example-1",
    "title": "Models with observed variables",
    "section": "Path models - the previous example",
    "text": "Path models - the previous example\nFor example, do we really believe that anxiety and nevroticism could stay on the same level? Isn’t there a theoretical effect of one on the other?"
  },
  {
    "objectID": "slides/01_path_models.html#path-models---the-previous-example-2",
    "href": "slides/01_path_models.html#path-models---the-previous-example-2",
    "title": "Models with observed variables",
    "section": "Path models - the previous example",
    "text": "Path models - the previous example\nCode: We can write the additional regression just by adding one line to the model (plus some additional things for indirect and total effects): \n\nm &lt;- \"math ~ age + anxiety + nevroticism + gender\n      anxiety ~ nevroticism\"\nfitE1 &lt;- sem(m, data = E1)\n\n\nm &lt;- \"math ~ age + am*anxiety + nm*nevroticism + gender\n      anxiety ~ n*nevroticism\n      # Indirect effect\n      ind := n*am\n      # Total effect\n      tot := n*am + nm\"\nfitE1 &lt;- sem(m, data = E1)"
  },
  {
    "objectID": "slides/01_path_models.html#path-model-example",
    "href": "slides/01_path_models.html#path-model-example",
    "title": "Models with observed variables",
    "section": "Path model example",
    "text": "Path model example\nWe have collected data from 1100 Italian cities.  Research question: to what extent do economic factors, education, and environmental policies influence the quality of life of Italian people? Are these relationships mediated by social cohesion? - gdp - education - environment - wellbeing - cohesion The model can be expressed with the following equations: \\[\n\\begin{cases}\n\\text{cohesion} & = \\beta_{13} X_{\\text{gdp}} + \\beta_{14} X_{\\text{education}} + \\beta_{15} X_{\\text{environment}} + \\zeta_1 \\\\\n\\text{wellbeing} & = \\beta_{23} X_{\\text{gdp}} + \\beta_{24} X_{\\text{education}} + \\beta_{25} X_{\\text{environment}} + \\beta_{21} X_{\\text{cohesion}} + \\zeta_2\n\\end{cases}\n\\]"
  },
  {
    "objectID": "slides/01_path_models.html#script",
    "href": "slides/01_path_models.html#script",
    "title": "Models with observed variables",
    "section": "Script",
    "text": "Script\n\nm &lt;- \"\ncohesion ~ gdp + education + environment\nwellbeing ~ gdp + education + environment + cohesion\n\"\nfit &lt;- sem(m, data = Dprov)"
  },
  {
    "objectID": "slides/01_path_models.html#results",
    "href": "slides/01_path_models.html#results",
    "title": "Models with observed variables",
    "section": "Results",
    "text": "Results\nThere is an effect of cohesion, which is in the middle.\n\n\n[...]\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  cohesion ~                                          \n    gdp              -0.324    0.030  -10.722    0.000\n    education         0.178    0.030    5.883    0.000\n    environment       0.453    0.030   15.177    0.000\n  wellbeing ~                                         \n    gdp               0.371    0.030   12.372    0.000\n    education         0.154    0.029    5.304    0.000\n    environment      -0.132    0.031   -4.251    0.000\n    cohesion          0.678    0.028   23.821    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .cohesion          1.004    0.043   23.452    0.000\n   .wellbeing         0.896    0.038   23.452    0.000"
  },
  {
    "objectID": "slides/01_path_models.html#matrices-again",
    "href": "slides/01_path_models.html#matrices-again",
    "title": "Models with observed variables",
    "section": "Matrices, again",
    "text": "Matrices, again\n\ninspect(fit, \"estimates\")$psi\n\n            cohesn wllbng    gdp eductn envrnm\ncohesion     1.004                            \nwellbeing    0.000  0.896                     \ngdp          0.000  0.000  1.032              \neducation    0.000  0.000  0.173  1.035       \nenvironment  0.000  0.000  0.038 -0.065  1.029\n\n#\ninspect(fit, \"estimates\")$beta\n\n            cohesn wllbng    gdp eductn envrnm\ncohesion     0.000      0 -0.324  0.178  0.453\nwellbeing    0.678      0  0.371  0.154 -0.132\ngdp          0.000      0  0.000  0.000  0.000\neducation    0.000      0  0.000  0.000  0.000\nenvironment  0.000      0  0.000  0.000  0.000"
  },
  {
    "objectID": "slides/01_path_models.html#the-lavaan-psi-matrix",
    "href": "slides/01_path_models.html#the-lavaan-psi-matrix",
    "title": "Models with observed variables",
    "section": "The lavaan Psi matrix",
    "text": "The lavaan Psi matrix\nIt is composed by the actual residual covariance matrix \\(\\Psi\\)\n\ninspect(fit, \"estimates\")$psi[1:2,1:2]\n\n          cohesion wellbeing\ncohesion         1     0.000\nwellbeing        0     0.896\n\n\nAnd the fitted/reproduced covariance matrix \\(\\hat{\\Sigma}(\\theta)\\)\n\ninspect(fit, \"estimates\")$psi[3:5, 3:5]\n\n               gdp education environment\ngdp         1.0318     0.173      0.0378\neducation   0.1727     1.035     -0.0650\nenvironment 0.0378    -0.065      1.0294"
  },
  {
    "objectID": "slides/01_path_models.html#forgetting-a-mediator",
    "href": "slides/01_path_models.html#forgetting-a-mediator",
    "title": "Models with observed variables",
    "section": "Forgetting a mediator?",
    "text": "Forgetting a mediator?\n\nround(cor(Dprov),2)\n\n            cohesion wellbeing   gdp education environment\ncohesion        1.00      0.53 -0.25      0.08        0.38\nwellbeing       0.53      1.00  0.17      0.24        0.14\ngdp            -0.25      0.17  1.00      0.17        0.04\neducation       0.08      0.24  0.17      1.00       -0.06\nenvironment     0.38      0.14  0.04     -0.06        1.00\n\n## m &lt;- lm(wellbeing ~ gdp + education + environment, data = Dprov)\n## summary(m)"
  },
  {
    "objectID": "slides/01_path_models.html#exercise-2",
    "href": "slides/01_path_models.html#exercise-2",
    "title": "Models with observed variables",
    "section": "Exercise 2",
    "text": "Exercise 2\n\nN = 483\nm &lt;- \"\nlifeSatisfaction ~ .05*attachment + .25*selfEsteem + .40*parentalSupport + .30*salary\nselfEsteem ~ .40*parentalSupport + .20*attachment\nattachment ~~ .30*parentalSupport\n\"\nm1 &lt;- \"\nlifeSatisfaction ~ selfEsteem + salary #+ parentalSupport\nselfEsteem ~ parentalSupport + attachment\n#attachment ~~ parentalSupport\n\"\nE2 &lt;- simulateData(m, sample.nobs = N, seed = 12)\n\nThe dataset “Exercise2.csv” contains:\n\nN = 1100 participants\n5 variables\n\n\nsalary\n\n\nattachment\nparental support\nself-esteem\nlife satisfaction\n\nWe want to fit this model (also calculate indirect effects):"
  },
  {
    "objectID": "slides/01_path_models.html#fit-a-model-with-indirect-effects",
    "href": "slides/01_path_models.html#fit-a-model-with-indirect-effects",
    "title": "Models with observed variables",
    "section": "Fit a model with indirect effects",
    "text": "Fit a model with indirect effects\n\nmE2 &lt;- \"\n#we name (_*variable) the parameters of interest\nlifeSatisfaction ~ a*selfEsteem + salary\nselfEsteem ~ b*parentalSupport + c*attachment\nattachment ~ salary\nparentalSupport ~ salary\n\n#and then define the non-model parameters\nindAttSelf  := c*a\nindSuppSelf := b*a\n\"\nfitE2 &lt;- sem(mE2, data = E2) #, se = \"bootstrap\")"
  },
  {
    "objectID": "slides/01_path_models.html#results---estimation-info-1",
    "href": "slides/01_path_models.html#results---estimation-info-1",
    "title": "Models with observed variables",
    "section": "Results - estimation info",
    "text": "Results - estimation info\n\n\nlavaan 0.6-19 ended normally after 10 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        10\n\n  Number of observations                           483\n\nModel Test User Model:\n                                                      \n  Test statistic                               114.172\n  Degrees of freedom                                 4\n  P-value (Chi-square)                           0.000\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\n[...]"
  },
  {
    "objectID": "slides/01_path_models.html#regression-results-1",
    "href": "slides/01_path_models.html#regression-results-1",
    "title": "Models with observed variables",
    "section": "Regression results",
    "text": "Regression results\n\n\n[...]\nRegressions:\n                     Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  lifeSatisfaction ~                                                      \n    selfEsteem (a)      0.373    0.044    8.379    0.000    0.373    0.349\n    salary              0.234    0.049    4.805    0.000    0.234    0.200\n  selfEsteem ~                                                            \n    prntlSpprt (b)      0.360    0.049    7.349    0.000    0.360    0.314\n    attachment (c)      0.145    0.046    3.177    0.001    0.145    0.136\n  attachment ~                                                            \n    salary             -0.009    0.047   -0.198    0.843   -0.009   -0.009\n  parentalSupport ~                                                       \n    salary              0.001    0.043    0.025    0.980    0.001    0.001\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .lifeSatisfactn    1.112    0.072   15.540    0.000    1.112    0.838\n   .selfEsteem        1.028    0.066   15.540    0.000    1.028    0.883\n   .attachment        1.016    0.065   15.540    0.000    1.016    1.000\n   .parentalSupprt    0.885    0.057   15.540    0.000    0.885    1.000\n\n[...]"
  },
  {
    "objectID": "slides/01_path_models.html#indirect-effects-1",
    "href": "slides/01_path_models.html#indirect-effects-1",
    "title": "Models with observed variables",
    "section": "Indirect effects",
    "text": "Indirect effects\nThe indirect effects estimated with lavaan in this way are just a mere multiplication of the parameters. You can apply bootstrap procedures to obtain more robust results and errors! \n\n\n[...]\nDefined Parameters:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n    indAttSelf        0.054    0.018    2.971    0.003    0.054    0.047\n    indSuppSelf       0.134    0.024    5.525    0.000    0.134    0.110"
  },
  {
    "objectID": "slides/01_path_models.html#model-fit",
    "href": "slides/01_path_models.html#model-fit",
    "title": "Models with observed variables",
    "section": "Model fit",
    "text": "Model fit\nYou surely remember this slide from before:\n*’This is the goal of a good model: reproduce, from a set of theoretical associations/effects (aka covariance matrix), the original covariance matrix.\nFormally:\n\\[\nH_0 : \\hat{\\Sigma}(\\theta) = \\Sigma\n\\]\nwhere \\(\\Sigma\\) is the true covariance matrix among model variables, \\(\\theta\\) the parameters vector, and \\(\\hat{\\Sigma}\\) the reproduced covariance matrix.’*"
  },
  {
    "objectID": "slides/01_path_models.html#model-fit-1",
    "href": "slides/01_path_models.html#model-fit-1",
    "title": "Models with observed variables",
    "section": "Model fit",
    "text": "Model fit\n\\[\nH_0 : \\hat{\\Sigma}(\\theta) = \\Sigma\n\\]\n\nIt’s time to evaluate whether our model is capable of it. To do it, we mainly compare the two matrices and obtain different fit indices."
  },
  {
    "objectID": "slides/01_path_models.html#fit-measures",
    "href": "slides/01_path_models.html#fit-measures",
    "title": "Models with observed variables",
    "section": "Fit measures",
    "text": "Fit measures\nModel fit refers to the ability of a model to reproduce the original covariance matrix. Fit indexes are the tools we use to estimate how good is our model in reproducing such mutrix. Most fit indexes only work with overidentified models, but some (e.g., the residualbased ones) can work with just-identified models, as well.\n\n\\(\\chi^2\\) based\nAlternative indexes\n\nIncremental indexes (or relative or comparative fit indexes)\nParsimony indexes\nAbsolute (Standalone) indexes\nResiduals"
  },
  {
    "objectID": "slides/01_path_models.html#chi2-based",
    "href": "slides/01_path_models.html#chi2-based",
    "title": "Models with observed variables",
    "section": "\\(\\chi^2\\) based",
    "text": "\\(\\chi^2\\) based\nA T statistics following \\(\\chi^2\\) distribution can be obtained by multiplying the sample size with the value of the fit function. df will be equal to the amount of non-redundant information minus the number of estimated parameters (remember?).  This is rarely used because of its assumptions - independent observations - the non-standardized sample cov matrix is used - N is sufficiently large - manifest endogenous variables follow a multivariate normal …and because it tends to reject \\(H_0\\), especially with large sample sizes.\n\nfitmeasures(fit,fit.measures=c(\"npar\", \"chisq\", \"df\", \"pvalue\"))\n\n  npar  chisq     df pvalue \n     9      0      0     NA"
  },
  {
    "objectID": "slides/01_path_models.html#comparative-indices",
    "href": "slides/01_path_models.html#comparative-indices",
    "title": "Models with observed variables",
    "section": "Comparative indices",
    "text": "Comparative indices\nThese include: - Comparative Fit Index (CFI) - Normed Fit Index (NFI) - Tucker Lewis Index (TLI) These indices compare the user model with a baseline model (the worst model).\n\nfitmeasures(fit, fit.measures =\nc(\"cfi\", \"tli\", \"nfi\"))\n\ncfi tli nfi \n  1   1   1"
  },
  {
    "objectID": "slides/01_path_models.html#baseline-model",
    "href": "slides/01_path_models.html#baseline-model",
    "title": "Models with observed variables",
    "section": "Baseline model",
    "text": "Baseline model\n\nbm &lt;- \"lifeSatisfaction ~~ lifeSatisfaction\n       selfEsteem ~~ selfEsteem\n       salary ~~ salary\n       parentalSupport ~~ parentalSupport\n       attachment ~~  attachment\"\nfitbm &lt;- sem(bm, data = E2)"
  },
  {
    "objectID": "slides/01_path_models.html#baseline-vs-user-model",
    "href": "slides/01_path_models.html#baseline-vs-user-model",
    "title": "Models with observed variables",
    "section": "Baseline vs user model",
    "text": "Baseline vs user model\n\n\n\n# summary(fitE2, fit.measures=TRUE)\n\n\n\nlavaan 0.6-19 ended normally after 10 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        10\n\n  Number of observations                           483\n\nModel Test User Model:\n                                                      \n  Test statistic                               114.172\n  Degrees of freedom                                 4\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                               276.610\n  Degrees of freedom                                10\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.587\n  Tucker-Lewis Index (TLI)                      -0.033\n\n[...]\n\n\n\n[ = ] [ = ]\nWith \\(\\delta\\) being the difference between \\(\\chi^2\\) and \\(df\\) and \\(\\delta(\\text{Saturated}) = 0\\)"
  },
  {
    "objectID": "slides/01_path_models.html#parsimony-indexes",
    "href": "slides/01_path_models.html#parsimony-indexes",
    "title": "Models with observed variables",
    "section": "Parsimony indexes",
    "text": "Parsimony indexes\nThese include: - Information Criteria (AIC, BIC, SABIC) - Noncentrality Parameter-Based Indexes (RNI, Mc/MFI) - RMSEA: Root Mean Square Error of Approximation These models favor parsimony and penalize complex models.  Among these, the RMSEA is probably the most used index. It assess how well the model approximate the data (as opposed to assessing if it is an exact fit). It is bounded between 0.0 and 1.0, with values closer to 0 (ZERO) indicating better fit.\n\nfitmeasures(fit, fit.measures =\nc(\"rmsea\", \"rmsea.ci.lower\", \"rmsea.ci.upper\", \"aic\", \"bic\"))\n\n         rmsea rmsea.ci.lower rmsea.ci.upper            aic            bic \n             0              0              0           6145           6190"
  },
  {
    "objectID": "slides/01_path_models.html#absolute-fit-indexes",
    "href": "slides/01_path_models.html#absolute-fit-indexes",
    "title": "Models with observed variables",
    "section": "Absolute fit indexes",
    "text": "Absolute fit indexes\nThese include: - \\(\\chi^2 / *df*\\) ratio - GFI: Goodness of Fit Index - AGFI: Adjusted Goodness of Fit Index - SRMR/RMR: (Standardized) Root Mean Square Residual GFI and AGFI want to be 1, while the SRMR wants to be 0!\n\nfitmeasures(fit,fit.measures=c(\"gfi\", \"agfi\", \"srmr\", \"rmr\"))\n\n gfi agfi srmr  rmr \n   1    1    0    0"
  },
  {
    "objectID": "slides/01_path_models.html#models-that-fit",
    "href": "slides/01_path_models.html#models-that-fit",
    "title": "Models with observed variables",
    "section": "Models that fit",
    "text": "Models that fit\nRemember that just because your model fits the data, doesn’t allow to conclude that your model is correct nor that the data generation process follows your hypothesized paths. - With path analysis, the same fit might be achieved with opposite arrows! - Test alternative models - Errors are included in manifest variables…and in the estimates! As usual all models are false, but some are useful."
  },
  {
    "objectID": "slides/01_path_models.html#what-about-our-model",
    "href": "slides/01_path_models.html#what-about-our-model",
    "title": "Models with observed variables",
    "section": "What about our model?",
    "text": "What about our model?\nIn Exercise 2 we fit a perfect model, all our hypotheses were confirmed, effects were significant with three stars.  We were happy…"
  },
  {
    "objectID": "slides/01_path_models.html#what-about-our-model-1",
    "href": "slides/01_path_models.html#what-about-our-model-1",
    "title": "Models with observed variables",
    "section": "What about our model?",
    "text": "What about our model?\nIn Exercise 2 we fit a perfect model, all our hypotheses were confirmed, effects were significant with three stars.  We were happy…"
  },
  {
    "objectID": "slides/01_path_models.html#step-5-model-modification",
    "href": "slides/01_path_models.html#step-5-model-modification",
    "title": "Models with observed variables",
    "section": "Step 5 model modification",
    "text": "Step 5 model modification\nUnfortunately, it’s time to modify the model or to accept that something was wrong in our hypotheses."
  },
  {
    "objectID": "slides/01_path_models.html#modification-indices",
    "href": "slides/01_path_models.html#modification-indices",
    "title": "Models with observed variables",
    "section": "Modification indices",
    "text": "Modification indices\nIf you have no clue about the reason why the model doesn’t converge, statistics could help you.\n\nmodificationindices(fitE2, sort. = T)[,1:7]\n\n                lhs op              rhs     mi    epc sepc.lv sepc.all\n14 lifeSatisfaction ~~       selfEsteem 63.000 -1.128  -1.128   -1.055\n27  parentalSupport  ~ lifeSatisfaction 62.255  0.337   0.337    0.412\n21 lifeSatisfaction  ~  parentalSupport 56.583  0.404   0.404    0.330\n16 lifeSatisfaction ~~  parentalSupport 56.583  0.358   0.358    0.361\n25       attachment  ~       selfEsteem 48.860  0.945   0.945    1.012\n29  parentalSupport  ~       attachment 48.570  0.296   0.296    0.317\n26       attachment  ~  parentalSupport 48.570  0.340   0.340    0.317\n19       attachment ~~  parentalSupport 48.570  0.301   0.301    0.317\n28  parentalSupport  ~       selfEsteem 48.473  2.032   2.032    2.332\n22       selfEsteem  ~ lifeSatisfaction 38.716 -0.670  -0.670   -0.715\n24       attachment  ~ lifeSatisfaction  9.730  0.136   0.136    0.155\n15 lifeSatisfaction ~~       attachment  5.275  0.112   0.112    0.105\n20 lifeSatisfaction  ~       attachment  5.275  0.110   0.110    0.097\n17       selfEsteem ~~       attachment  0.752  4.478   4.478    4.380\n23       selfEsteem  ~           salary  0.752  0.041   0.041    0.037\n31           salary  ~       selfEsteem  0.752  0.038   0.038    0.042\n30           salary  ~ lifeSatisfaction  0.752  0.103   0.103    0.120\n\n\nUse it with caution!\n\nm &lt;- \"\nlifeSatisfaction ~ .05*attachment + .25*selfEsteem + .40*parentalSupport + .30*salary\nselfEsteem ~ .40*parentalSupport + .20*attachment\nattachment ~~ .30*parentalSupport\n\""
  },
  {
    "objectID": "slides/01_path_models.html#mediation-analysis",
    "href": "slides/01_path_models.html#mediation-analysis",
    "title": "Models with observed variables",
    "section": "Mediation analysis",
    "text": "Mediation analysis\nWhile the independent variable is assumed to cause the outcome variable, it’s total effect (\\(c\\)) is partially/totally mediated by another intervening variable, the mediator variable.\n\nNote that our independent causes the mediator (\\(a\\)), and the mediator causes the outcome (\\(b\\)). The independent can still cause the outcome, but the path might have changed to \\(c'\\)."
  },
  {
    "objectID": "slides/01_path_models.html#total-effects",
    "href": "slides/01_path_models.html#total-effects",
    "title": "Models with observed variables",
    "section": "Total effects",
    "text": "Total effects\nWhen we have a mediation, the effect of the independent variable (X) on the outcome is given by the sum of the direct and indirect effect.\ntotal effect = direct effect + indirect effect  OR  c = c’ + ab\n\nm &lt;- \"\n# Regressions\nY ~ c*X + b*M\nM ~ a*X\n# Indirect effect\nindirect := a*b\n# Total effect\ntotal := c + a*b\n\"\n# Here of course we have no c'...to avoid R errors\n\nCOMMENTS?"
  },
  {
    "objectID": "slides/01_path_models.html#assumptions",
    "href": "slides/01_path_models.html#assumptions",
    "title": "Models with observed variables",
    "section": "Assumptions",
    "text": "Assumptions\nThe problem with mediation analyses is that they rely on often-neglected assumptions:\n\nNo X-M Interaction: The effect of M on Y or b does not vary across levels of X.\nCausal Direction: The variable M causes Y, but Y does not cause M.\nPerfect Reliability in M: The reliability of M is perfect.\nNo Confounding: There is no variable that causes M and Y."
  },
  {
    "objectID": "slides/01_path_models.html#other-limitations",
    "href": "slides/01_path_models.html#other-limitations",
    "title": "Models with observed variables",
    "section": "Other limitations",
    "text": "Other limitations\n\nFull mediation models are saturated models and we cannot obtain fit indices\n\nYou can use BIC, AIC, or SABIC and test (and compare) different models:\nno direct effect model\n\nno effect from causal variable to the mediator\nno effect from the mediator to outcome\nModels with inverted arrows fit the model as well as opposite models\n\nThis is true for all equivalent models. Avoid drawing paintings and base your models on strong theoretical assumptions!"
  },
  {
    "objectID": "slides/01_path_models.html#thinking-first",
    "href": "slides/01_path_models.html#thinking-first",
    "title": "Models with observed variables",
    "section": "Thinking first",
    "text": "Thinking first"
  },
  {
    "objectID": "slides/01_path_models.html#comparison",
    "href": "slides/01_path_models.html#comparison",
    "title": "Models with observed variables",
    "section": "Comparison",
    "text": "Comparison\n\n\n\n\n\n\n\n\n\n\n\n  cfi   tli  srmr rmsea \n0.976 0.853 0.031 0.094 \n\n\n\n\n\n\n\n\n\n\n\n  cfi   tli  srmr rmsea \n0.976 0.853 0.031 0.094 \n\n\n\n\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  math ~                                              \n    anxiety           0.350    0.050    6.979    0.000\n    sex               0.143    0.106    1.347    0.178\n    height            0.034    0.048    0.699    0.484\n  sex ~                                               \n    anxiety           0.075    0.024    3.092    0.002\n  height ~                                            \n    sex               0.984    0.091   10.807    0.000\n\n[...]\n\n\n\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  math ~                                              \n    anxiety           0.350    0.050    6.979    0.000\n    sex               0.143    0.106    1.347    0.178\n    height            0.034    0.048    0.699    0.484\n  anxiety ~                                           \n    sex               0.271    0.088    3.092    0.002\n  height ~                                            \n    sex               0.984    0.091   10.807    0.000\n\n[...]"
  },
  {
    "objectID": "slides/01_path_models.html#readings",
    "href": "slides/01_path_models.html#readings",
    "title": "Models with observed variables",
    "section": "Readings",
    "text": "Readings\nAbout mediation analyses, you can read: - the webpages by Dave Kenny: - - The history of mediations - Mediations explained and advanced topics - Roher et al. publication…but there’s a lot of information"
  },
  {
    "objectID": "slides/01_path_models.html#contacts",
    "href": "slides/01_path_models.html#contacts",
    "title": "Models with observed variables",
    "section": "Contacts",
    "text": "Contacts\ntommaso.feraco@unipd.it"
  },
  {
    "objectID": "slides/01_path_models.html#basic-lavaan-functions",
    "href": "slides/01_path_models.html#basic-lavaan-functions",
    "title": "Models with observed variables",
    "section": "Basic lavaan functions",
    "text": "Basic lavaan functions\n\n\n\n\n\n\n\nFunction\nCommand\n\n\n\n\nsem() / cfa()\nFit the SEM model (cfa is nested in sem…which is nested in lavaan)\n\n\nfitMeasures()\nReturn fit indices of the SEM model\n\n\ninspect()\nInspect/extract information that is stored in a fitted model\n\n\nlavPredict()\nCompute estimated latent scores\n\n\nlavTestLRT()\nCompare (nested) lavaan models\n\n\nmodificationIndices()\nCompute the modification indices of a model\n\n\nparameterEstimates()\nParameter estimates of a latent variable model\n\n\nparameterTable()\nShow the table of the parameters of a fitted model\n\n\nsimulateData()\nSimulate data starting from a lavaan model syntax"
  },
  {
    "objectID": "slides/02_cfa.html#outline",
    "href": "slides/02_cfa.html#outline",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Outline",
    "text": "Outline\n\nIntro\nCFA\nIdentification and fit\nCFA and validity - R\nExercise 3.2\nA neglected implication\nReadings"
  },
  {
    "objectID": "slides/02_cfa.html#factor-analysis",
    "href": "slides/02_cfa.html#factor-analysis",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Factor analysis",
    "text": "Factor analysis\n\nFactor analysis is a statistical technique widely used in the social sciences\nIt is a statistical method used to describe variability among observed, correlated variables in terms of a potentially lower number of unobserved variables called factors.\nIn its original definition (Spearman, 1904) the relationship between observed and latent variables is not defined a priori (Exploratory Factor Analysis, EFA).\nIn SEM framework, the researcher first develops a hypothesis about what factors s/he believes are underlying the measures s/he has used and may impose constraints on the model based on these a priori hypotheses (Confirmatory Factor Analysis, CFA)."
  },
  {
    "objectID": "slides/02_cfa.html#exploratory-factor-analysis-efa",
    "href": "slides/02_cfa.html#exploratory-factor-analysis-efa",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Exploratory Factor Analysis (EFA)",
    "text": "Exploratory Factor Analysis (EFA)\nYou can run an exploratory factor analysis in R using the in-built function factanal. (you can also do it in lavaan: efa())\n\n\n\n\n\nThe number of latent factor is not predetermined\nAll latent variables are free to influence all the observed variables\nMeasurement errors are not allowed to correlate\n\n\nIs this a good way to find latent variables? YOUR OPINION?"
  },
  {
    "objectID": "slides/02_cfa.html#confirmatory-factor-analysis-cfa",
    "href": "slides/02_cfa.html#confirmatory-factor-analysis-cfa",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Confirmatory Factor Analysis (CFA)",
    "text": "Confirmatory Factor Analysis (CFA)\nYou can run an CFA in R using the lavaan functions cfa.\n\n\n\n\n\nWe personally determine the model and the latent variables a priori\nLatent variables only affect predefined observed variables\nMeasurement errors may correlate\n\n\nIs this a good way to find latent variables? YOUR OPINION?"
  },
  {
    "objectID": "slides/02_cfa.html#general-formula",
    "href": "slides/02_cfa.html#general-formula",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "General formula",
    "text": "General formula\n\nThe general model for confirmatory factor analysis can be written as:\n\n\\[\n\\begin{aligned}\n\\mathbf{x} &= \\mathbf{\\Lambda}_x\\,\\mathbf{\\xi} + \\mathbf{\\delta} \\\\\n\\mathbf{y} &= \\mathbf{\\Lambda}_y\\,\\mathbf{\\eta} + \\mathbf{\\epsilon}\n\\end{aligned}\n\\]\nwhere \\(\\mathbf{x}\\) and \\(\\mathbf{y}\\) are observed variables, \\(\\mathbf{\\xi}\\) and \\(\\mathbf{\\eta}\\) are latent factors, and \\(\\mathbf{\\delta}\\) and \\(\\mathbf{\\epsilon}\\) are errors of measurement.\n\nThe coefficients in \\(\\mathbf{\\Lambda}_x\\) and \\(\\mathbf{\\Lambda}_y\\) describe the effects of the latent variables on the observed variables."
  },
  {
    "objectID": "slides/02_cfa.html#the-general-formula-explained",
    "href": "slides/02_cfa.html#the-general-formula-explained",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "The general formula explained",
    "text": "The general formula explained\n\\[\n\\begin{aligned}\ny &= b_0 + b_1 x + \\epsilon \\\\\ny_1 &= \\tau_1 + \\lambda_1\\eta + \\epsilon_1\n\\end{aligned}\n\\]\n\\[\n\\begin{bmatrix}\n  y_1 \\\\\n  y_2 \\\\\n  y_3\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n  \\tau_1 \\\\\n  \\tau_2 \\\\\n  \\tau_3\n\\end{bmatrix}\n+\n\\begin{bmatrix}\n  \\lambda_1 \\\\\n  \\lambda_2 \\\\\n  \\lambda_3\n\\end{bmatrix}\n(\\eta_1)\n\\begin{bmatrix}\n  \\epsilon_1 \\\\\n  \\epsilon_2 \\\\\n  \\epsilon_3\n\\end{bmatrix}\n\\]\n\\[\n\\begin{aligned}\ny_1 &= \\tau_1 + \\lambda_1\\eta_1 + \\epsilon_1 \\\\\ny_2 &= \\tau_2 + \\lambda_2\\eta_1 + \\epsilon_2 \\\\\ny_3 &= \\tau_3 + \\lambda_3\\eta_1 + \\epsilon_3\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/02_cfa.html#reflective-variables-in-a-realist-definition",
    "href": "slides/02_cfa.html#reflective-variables-in-a-realist-definition",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Reflective variables in a realist definition",
    "text": "Reflective variables in a realist definition\nWhen we talk about an effect \\(\\mathbf{\\Lambda}\\) (\\(\\Rightarrow\\)) of a latent variable on an observed variable (\\(\\mathbf{x}\\)), we are basing our model on a realist framework of reflective latent variables. In other words, we assume that:\n\nARROWS are ARROWS: it is the latent construct that affects the observed responses\nA realist interpretation is needed: the latent variable is something that really exists!\nObservations are things that are really affected/produced by the latent variable + some error\n\nPragmatic interpretation of latent variables are of no help: “a factor model is just a good way of summarizing a large number of items”."
  },
  {
    "objectID": "slides/02_cfa.html#reflective-variables-in-a-realist-definition-1",
    "href": "slides/02_cfa.html#reflective-variables-in-a-realist-definition-1",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Reflective variables in a realist definition",
    "text": "Reflective variables in a realist definition\nREMEMBER: every statistical method applied to psychology has theoretical implications that not only concerns the results obtained. The selected method/model has implication on its own, and CFA is no exception!\nIf you do not want to assume any realist position or reflective assumptions on your latent variables, you should adopt other methods of data reduction:\n\nPCA\nEGA\n…"
  },
  {
    "objectID": "slides/02_cfa.html#one-factor-model",
    "href": "slides/02_cfa.html#one-factor-model",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "One-factor model",
    "text": "One-factor model"
  },
  {
    "objectID": "slides/02_cfa.html#two-factor-model-with-correlated-variables",
    "href": "slides/02_cfa.html#two-factor-model-with-correlated-variables",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Two-factor model with correlated variables",
    "text": "Two-factor model with correlated variables"
  },
  {
    "objectID": "slides/02_cfa.html#two-factor-model-with-hortogonal-variables",
    "href": "slides/02_cfa.html#two-factor-model-with-hortogonal-variables",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Two-factor model with hortogonal variables",
    "text": "Two-factor model with hortogonal variables"
  },
  {
    "objectID": "slides/02_cfa.html#hierarchical-model",
    "href": "slides/02_cfa.html#hierarchical-model",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Hierarchical model",
    "text": "Hierarchical model"
  },
  {
    "objectID": "slides/02_cfa.html#in-r",
    "href": "slides/02_cfa.html#in-r",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "In R",
    "text": "In R\n\n\n\nm &lt;- \"\nlatent1 =~ x1 + x2 + x3 \nlatent2 =~ x4 + x5 + x6\n\"\nsemPlot::semPaths(fit)\n\n\n\n\n\n\n\n\n\n\nThe first latent variable explains item 1,2,3\nThe second latent variable explains item 4,5,6\nThe diagram represents the hypothesized model"
  },
  {
    "objectID": "slides/02_cfa.html#matrices",
    "href": "slides/02_cfa.html#matrices",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Matrices",
    "text": "Matrices\n\n\nLambda: matrix of loadings\n\n\nPhi: latent variance-covariance matrix\n\n\nTheta: observed variance-covariance matrix"
  },
  {
    "objectID": "slides/02_cfa.html#constraints",
    "href": "slides/02_cfa.html#constraints",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Constraints",
    "text": "Constraints\nIn order to estimate the parameters in structural equation models with latent variables, you must set some identification constraints in these models. Otherwise, you won’t be able to estimate the variables (the model is not identifiable).\nWe can choose one of the two following strategies:\n\nTo standardize latent variables such that factor means are fixed to 0 and factor variances are fixed to 1.\nTo set to one a loading (\\(\\lambda\\)) for each latent variable.\n\nIn R, the function sem() or cfa() uses the second strategy as default. To change it, use the std.lv option to TRUE.\n\nfit &lt;- sem(m, std.lv = TRUE, ...)"
  },
  {
    "objectID": "slides/02_cfa.html#constraints-explained",
    "href": "slides/02_cfa.html#constraints-explained",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Constraints explained",
    "text": "Constraints explained\n\n\n\\[\n\\Sigma(\\eta) = \\Lambda\\Psi\\Lambda' + \\Theta_{\\epsilon}\n\\]\nMarker method\n\\[\n\\Sigma(\\eta)\n=\n\\psi_{11}\n\\begin{bmatrix}\n  1 \\\\\n  \\lambda_2 \\\\\n  \\lambda_3\n\\end{bmatrix}\n(1\\,\\lambda_2\\,\\lambda_3)\n\\begin{bmatrix}\n  \\theta_{11} & 0 & 0 \\\\\n  0 & \\theta_{22} & 0 \\\\\n  0 & 0 & \\theta_{33}\n\\end{bmatrix}\n\\]\nStandardization\n\\[\n\\Sigma(\\eta)\n=\n(1)\n\\begin{bmatrix}\n  \\lambda_1 \\\\\n  \\lambda_2 \\\\\n  \\lambda_3\n\\end{bmatrix}\n(\\lambda_1\\,\\lambda_2\\,\\lambda_3)\n\\begin{bmatrix}\n  \\theta_{11} & 0 & 0 \\\\\n  0 & \\theta_{22} & 0 \\\\\n  0 & 0 & \\theta_{33}\n\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "slides/02_cfa.html#identification-rules",
    "href": "slides/02_cfa.html#identification-rules",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Identification rules",
    "text": "Identification rules\nIf you remember, we talked about identification in the Introduction. For CFA models, the following identification rules can be followed:\n\nthe t-rule\nthe Three-Indicator Rules\nthe Two-Indicator Rules"
  },
  {
    "objectID": "slides/02_cfa.html#the-t-rule",
    "href": "slides/02_cfa.html#the-t-rule",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "the t-rule",
    "text": "the t-rule\nWe have already seen it. This is a necessary but not sufficient condition:\n\\[\nt \\leq \\frac{q(q+1)}{2}\n\\]\nwhere \\(t\\) is the number of free parameters and \\(q\\) the number of observed variables.\nIn this case:\n\nThe number of free parameters (\\(t\\)) must be less or equal to the number of nonredundant elements in the covariance matrix of the observed variables\n\nIn other words: the number of nonredundant elements in \\(\\mathbf{S}\\) is the maximum number of possible equations; if the number of unknowns exceeds the number of equations, the identification of \\(\\mathbf{\\theta}\\) is not possible."
  },
  {
    "objectID": "slides/02_cfa.html#the-three-indicator-rules",
    "href": "slides/02_cfa.html#the-three-indicator-rules",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "the Three-Indicator Rules",
    "text": "the Three-Indicator Rules\nThe three-indicatore rules is a sufficient but not necessary condition. It poses no restrictions on \\(\\mathbf{\\Phi}\\) (the var-covar of exogenous latent variables)\n\nA sufficient condition to identify a one-factor model is to have at least three indicators with nonzero loadings (\\(\\lambda\\)) and \\(\\mathbf{\\Theta}\\) diagonal.\nA multifactor model is identified when:\n\nIt has three or more indicators per latent variable.\nEach row of \\(\\mathbf{\\Lambda}\\) has one and only one nonzero element.\n\\(\\mathbf{\\Theta}\\) is diagonal."
  },
  {
    "objectID": "slides/02_cfa.html#the-two-indicator-rules",
    "href": "slides/02_cfa.html#the-two-indicator-rules",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "the Two-Indicator Rules",
    "text": "the Two-Indicator Rules\nThe two-indicatore rules is a sufficient but not necessary condition for models with more than one \\(\\mathbf{\\xi}\\).\n\n\\(\\mathbf{\\Theta}\\) is diagonal\nEach latent variable is scaled (one \\(\\lambda_{ij}\\) set to 1 for each \\(\\mathbf{\\xi}\\)).\nIt requires the following conditions:\n\nThere are at least two indicators per latent variable\nEach row of \\(\\mathbf{\\Lambda}\\) has one and only one nonzero element\n\\(\\mathbf{\\Theta}\\) is diagonal\nEach row of \\(\\mathbf{\\Phi}\\) has at least one nonzero off-diagonal element"
  },
  {
    "objectID": "slides/02_cfa.html#model-fit",
    "href": "slides/02_cfa.html#model-fit",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Model fit",
    "text": "Model fit\nAs before, we can evaluate model fit of a CFA using:\n\n\\(\\chi^2\\) test\n\n\nAbsolute fit indices\n\n\ninspect(fit, \"fit\")[c(\"gfi\", \"agfi\")]\n\n\nAbsolute fit indices based on residuals\n\n\ninspect(fit, \"fit\")[c(\"srmr\", \"rmsea\")]\n\n\nIncremental fit indices\n\n\ninspect(fit, \"fit\")[c(\"cfi\", \"nnfi\")]\n\n\nInformation criterion based indices\n\n\ninspect(fit, \"fit\")[c(\"aic\", \"bic\")]\n\n\n\\(R^2\\) and the total coefficient of determination\n\n\ninspect(fit, \"rsquare\")"
  },
  {
    "objectID": "slides/02_cfa.html#the-total-coefficient-of-determination",
    "href": "slides/02_cfa.html#the-total-coefficient-of-determination",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "The total coefficient of determination",
    "text": "The total coefficient of determination\nWhile \\(R^2\\) gives the portion of explained variance in single dependent variables\n\ninspect(fit, \"rsquare\")\n\n  x1   x2   x3   x4   x5   x6 \n0.27 0.46 0.32 0.31 0.40 0.29 \n\n\n… the total coefficient of determination represents the proportion of variance in the dependent variables that is explained by all the variables in the model, both directly and indirectly.\n\nTH &lt;- inspect(fit, \"estimates\")$theta\nS &lt;- fitted(fit)$cov\n1 - det(TH) / det(S)\n\n[1] 0.85"
  },
  {
    "objectID": "slides/02_cfa.html#introduction-to-cfa-and-validity",
    "href": "slides/02_cfa.html#introduction-to-cfa-and-validity",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Introduction to CFA and validity",
    "text": "Introduction to CFA and validity\nWhenever we estimate a latent variable, we are MEASURING a latent trait that explains observed (or other latent) factors.\nIn other words, CFA is a tool that is used to measure constructs that are not directly observable (remember the realist framework)."
  },
  {
    "objectID": "slides/02_cfa.html#step-1-the-construct",
    "href": "slides/02_cfa.html#step-1-the-construct",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Step 1: the construct",
    "text": "Step 1: the construct\n… this is not the topic of this course but, after theoretical reflections, answer at least these questions that will guide your modeling and draw it:\n\n\n\nis it unidimensional?\nis it multidimensional?\nare the factors correlated?\nis it hierarchic?\nhas it a bifactor structure?\n\nAll these answers have statistical and theoretical consequences / assumptions."
  },
  {
    "objectID": "slides/02_cfa.html#step-2-items-and-scale-construction",
    "href": "slides/02_cfa.html#step-2-items-and-scale-construction",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Step 2: items and scale construction",
    "text": "Step 2: items and scale construction\nAssuming that the construct exists, you need\n\nan explicit, precise definition of the measured attribute or construct\na set of items sensible to variations of the measured attribute or construct\n\nIn fact, we assume that the observations (item responses) should change according to modifications of the latent trait.\nItems should (possibly) cover all the aspects of the construct.\nTo help your work, there are tools that can be used:\n\nSpoto et al., 2023 https://doi.org/10.1037/met0000545\n\nthis of course happens if the questionnaire/test is new (or if you want to develop a new version)"
  },
  {
    "objectID": "slides/02_cfa.html#step-3-collect-the-data",
    "href": "slides/02_cfa.html#step-3-collect-the-data",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Step 3: collect the data!",
    "text": "Step 3: collect the data!\nData collection is not obvious and follows your previous decisions. We might plan:\n\n2 data collections (cfa measurement + nomological network)\n3 data collections (efa + cfa + nomological network)\nfocus groups + pilot on item comprension + […]\n[…]\n[…]"
  },
  {
    "objectID": "slides/02_cfa.html#step-4-data-analysis-cfa-only",
    "href": "slides/02_cfa.html#step-4-data-analysis-cfa-only",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Step 4: data analysis (CFA only)",
    "text": "Step 4: data analysis (CFA only)\nOf all the possible options, we will only focus on the CFA.\nImagine we have collected data for 862 participants using the WISC-IV, one of the most famous tests of intelligence. It comprises 15 subtests measuring:\n\n\n\nVCI: verbal comprehension ind\nSI: Similarities\nVC: Vocabulary\nCO: Comprehension\nWMI: working memory index\nDS: Digit span\nLN: Letter-Number seq.\n\n\n\nPRI: perceptual reasoning index\nBD: Block design\nPCn: Picture concepts\nMR: Matrix reasoning\nPSI: processing speed index\nCD: Coding\nSS: Symbol search\n\n\nThe subtests are assumed to belong to specific abilities (bold), that are influenced by a general factor: we have a hierarchical structure."
  },
  {
    "objectID": "slides/02_cfa.html#open-the-data",
    "href": "slides/02_cfa.html#open-the-data",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Open the data",
    "text": "Open the data\nOps, the data are not in standard form!\n\n# Exercise 3.1\nload(\"../data/Exercise3_1.Rdata\")\n# view(d)\n\n\n\n\n\n\nBD\nSI\nDS\nPCn\nCD\nVC\nLN\nMR\nCO\nSS\n\n\n\n\n1.00\n0.38\n0.26\n0.34\n0.25\n0.33\n0.29\n0.42\n0.27\n0.30\n\n\n0.38\n1.00\n0.35\n0.43\n0.14\n0.62\n0.35\n0.41\n0.51\n0.27\n\n\n0.26\n0.35\n1.00\n0.28\n0.15\n0.33\n0.42\n0.29\n0.24\n0.20\n\n\n0.34\n0.43\n0.28\n1.00\n0.11\n0.41\n0.35\n0.43\n0.35\n0.24\n\n\n0.25\n0.14\n0.15\n0.11\n1.00\n0.13\n0.19\n0.20\n0.15\n0.46\n\n\n0.33\n0.62\n0.33\n0.41\n0.13\n1.00\n0.38\n0.40\n0.59\n0.24\n\n\n0.29\n0.35\n0.42\n0.35\n0.19\n0.38\n1.00\n0.35\n0.30\n0.24\n\n\n0.42\n0.41\n0.29\n0.43\n0.20\n0.40\n0.35\n1.00\n0.30\n0.26\n\n\n0.27\n0.51\n0.24\n0.35\n0.15\n0.59\n0.30\n0.30\n1.00\n0.22\n\n\n0.30\n0.27\n0.20\n0.24\n0.46\n0.24\n0.24\n0.26\n0.22\n1.00"
  },
  {
    "objectID": "slides/02_cfa.html#the-theoretical-model",
    "href": "slides/02_cfa.html#the-theoretical-model",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "The theoretical model",
    "text": "The theoretical model\nIntelligence theory suppose that test scores are affected by specific abilities (e.g., processing speed), that are directly influenced by an overarching latent factor (g)\n\nTry to write the model"
  },
  {
    "objectID": "slides/02_cfa.html#specify-and-fit-the-mode",
    "href": "slides/02_cfa.html#specify-and-fit-the-mode",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Specify and fit the mode",
    "text": "Specify and fit the mode\nWe are skipping some steps (validity of single tests and of first-order abilities) … you cannot do it!\n\nm &lt;- \"\nVCI=~SI+VC+CO\nPRI=~BD+PCn+MR\nWMI=~DS+LN\nPSI=~CD+SS\ng=~VCI+PRI+WMI+PSI\n\"\nfit &lt;- sem(m, std.lv = TRUE, sample.cov = d, sample.nobs = N)"
  },
  {
    "objectID": "slides/02_cfa.html#model-parameters",
    "href": "slides/02_cfa.html#model-parameters",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Model parameters",
    "text": "Model parameters\n\nparameterestimates(fit, standardized = TRUE)[1:14, 1:11]\n\n   lhs op rhs  est    se    z pvalue ci.lower ci.upper std.lv std.all\n1  VCI =~  SI 0.46 0.032 14.4  0.000    0.394     0.52   0.77    0.77\n2  VCI =~  VC 0.48 0.033 14.5  0.000    0.419     0.55   0.82    0.82\n3  VCI =~  CO 0.41 0.030 13.6  0.000    0.348     0.46   0.68    0.69\n4  PRI =~  BD 0.19 0.052  3.6  0.000    0.087     0.29   0.58    0.59\n5  PRI =~ PCn 0.21 0.057  3.6  0.000    0.095     0.32   0.64    0.64\n6  PRI =~  MR 0.22 0.060  3.6  0.000    0.100     0.33   0.67    0.67\n7  WMI =~  DS 0.36 0.038  9.5  0.000    0.284     0.43   0.60    0.60\n8  WMI =~  LN 0.42 0.045  9.2  0.000    0.327     0.50   0.70    0.70\n9  PSI =~  CD 0.48 0.037 12.9  0.000    0.405     0.55   0.55    0.55\n10 PSI =~  SS 0.71 0.059 12.1  0.000    0.599     0.83   0.83    0.83\n11   g =~ VCI 1.36 0.129 10.5  0.000    1.107     1.61   0.80    0.80\n12   g =~ PRI 2.92 0.865  3.4  0.001    1.220     4.61   0.95    0.95\n13   g =~ WMI 1.35 0.171  7.9  0.000    1.013     1.68   0.80    0.80\n14   g =~ PSI 0.59 0.067  8.8  0.000    0.457     0.72   0.51    0.51\n\n# [...]"
  },
  {
    "objectID": "slides/02_cfa.html#model-parameters-1",
    "href": "slides/02_cfa.html#model-parameters-1",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Model parameters",
    "text": "Model parameters\n\n# [...]\nparameterestimates(fit, standardized = TRUE)[15:20, 1:11]\n\n   lhs op rhs  est    se  z pvalue ci.lower ci.upper std.lv std.all\n15  SI ~~  SI 0.40 0.028 14      0     0.35     0.46   0.40    0.41\n16  VC ~~  VC 0.33 0.027 12      0     0.28     0.38   0.33    0.33\n17  CO ~~  CO 0.53 0.031 17      0     0.47     0.59   0.53    0.53\n18  BD ~~  BD 0.66 0.037 18      0     0.58     0.73   0.66    0.66\n19 PCn ~~ PCn 0.59 0.036 16      0     0.52     0.66   0.59    0.59\n20  MR ~~  MR 0.55 0.035 16      0     0.48     0.62   0.55    0.55"
  },
  {
    "objectID": "slides/02_cfa.html#model-fit-1",
    "href": "slides/02_cfa.html#model-fit-1",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Model fit",
    "text": "Model fit\n\nfi &lt;- c(\"cfi\", \"tli\", \"nnfi\", \"agfi\", \"srmr\", \"rmsea\")\nround(inspect(fit, \"fit\")[fi], 3)\n\n  cfi   tli  nnfi  agfi  srmr rmsea \n0.985 0.978 0.978 0.973 0.028 0.037"
  },
  {
    "objectID": "slides/02_cfa.html#reliability",
    "href": "slides/02_cfa.html#reliability",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Reliability",
    "text": "Reliability\n\nsemTools::reliability(fit)\n\n        VCI  PRI  WMI  PSI\nalpha  0.80 0.66 0.59 0.63\nomega  0.80 0.67 0.59 0.66\nomega2 0.80 0.67 0.59 0.66\nomega3 0.80 0.67 0.59 0.66\navevar 0.58 0.40 0.42 0.50\n\n\n\nsemTools::reliabilityL2(fit, secondFactor = \"g\")\n\n       omegaL1        omegaL2 partialOmegaL1 \n          0.75           0.91           0.85"
  },
  {
    "objectID": "slides/02_cfa.html#graphical-representation",
    "href": "slides/02_cfa.html#graphical-representation",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Graphical representation",
    "text": "Graphical representation\n\nsemPlot::semPaths(\n  fit,\n  edge.label.cex = .8,\n  what = \"std\",\n  sizeMan = 7,\n  sizeLat = 7,\n  edge.color = \"black\",\n  edge.label.color = \"black\"\n)"
  },
  {
    "objectID": "slides/02_cfa.html#a-second-theoretical-model",
    "href": "slides/02_cfa.html#a-second-theoretical-model",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "A second theoretical model",
    "text": "A second theoretical model\nParallel theories of intelligence suppose that test scores are affected by a general factor (g) AND by specific abilities that explain the remaining variance. Both type of factors directly influence observed scores.\nAll factors are set to be orthogonal!"
  },
  {
    "objectID": "slides/02_cfa.html#bifactor-model-in-r",
    "href": "slides/02_cfa.html#bifactor-model-in-r",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Bifactor model in R",
    "text": "Bifactor model in R\n\n# Modello bifattoriale\nmb &lt;- \"\nVCI=~a*SI+a*VC+a*CO\nPRI=~b*BD+b*PCn+b*MR\nWMI=~c*DS+c*LN\nPSI=~d*CD+d*SS\ng=~SI+VC+CO+BD+PCn+MR+DS+LN+CD+SS\n\"\n\nfitb &lt;- sem(\n  mb,\n  orthogonal = TRUE,\n  std.lv = TRUE,\n  sample.cov = d,\n  sample.nobs = N\n)\n\nThis model fits the data like the previous one.\nCOMMENTS? QUESTIONS?"
  },
  {
    "objectID": "slides/02_cfa.html#exercise-3.2",
    "href": "slides/02_cfa.html#exercise-3.2",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Exercise 3.2",
    "text": "Exercise 3.2\n\n# 2. Exercise 3.2 - working with real data and Likert scales\n# The dataset contains data collected from 1083 students on one questionnaire\n# The questionnaire aims to measure adaptability with 9 items on a 7-point scale\n# The first column is just the student's id\nD.ad &lt;- read.csv(\"../data/Exercise3_2.csv\")\n\n# We want to test the factorial validity of the Italian questionnaire\n# Martin et al., 2012 hypothesize three subscales:\n# (behavior [1:3], cognition [4:6], and emotion[7:9])\n# But found 1 or 2 factors in an EFA:\n# (cognitive-bahavioral [1:6] AND affective [7:9])\n# Later, they tested these models with a CFA\n# Test the two models, compare them and make your decisions"
  },
  {
    "objectID": "slides/02_cfa.html#predictions-with-latent-variables",
    "href": "slides/02_cfa.html#predictions-with-latent-variables",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Predictions with latent variables",
    "text": "Predictions with latent variables\nThis will directly bring us to the next set of slides, but some questions before:\n\nCan we use a latent variable to ‘predict’ another variable?"
  },
  {
    "objectID": "slides/02_cfa.html#predictions-with-latent-variables-1",
    "href": "slides/02_cfa.html#predictions-with-latent-variables-1",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Predictions with latent variables",
    "text": "Predictions with latent variables\nThis will directly bring us to the next set of slides, but some questions before:\n\nCan we use a latent variable to ‘predict’ another variable?\nHow (in R)?"
  },
  {
    "objectID": "slides/02_cfa.html#predictions-with-latent-variables-2",
    "href": "slides/02_cfa.html#predictions-with-latent-variables-2",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Predictions with latent variables",
    "text": "Predictions with latent variables\nThis will directly bring us to the next set of slides, but some questions before:\n\nCan we use a latent variable to ‘predict’ another variable?\nHow (in R)?\nAfter we confirm that a latent variable ‘exists’, can we use manifest variables as predictors?\n\nLET'S SIMULATE"
  },
  {
    "objectID": "slides/02_cfa.html#predictions-with-latent-variables-3",
    "href": "slides/02_cfa.html#predictions-with-latent-variables-3",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Predictions with latent variables",
    "text": "Predictions with latent variables\nThis will directly bring us to the next set of slides, but some questions before:\n\nCan we use a latent variable to ‘predict’ another variable?\nHow (in R)?\nAfter we confirm that a latent variable ‘exists’, can we use manifest variables as predictors?\nCan we use residuals as predictors?"
  },
  {
    "objectID": "slides/02_cfa.html#suggested-readings",
    "href": "slides/02_cfa.html#suggested-readings",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "Suggested readings",
    "text": "Suggested readings\n\nBest practices for scale development: https://doi.org/10.3389/fpubh.2018.00149\nContent validity: https://doi.org/10.1037/met0000545\n(as always) Latent Variable Modeling Using R: A Step-by-Step Guide (Beaujean, 2014)"
  },
  {
    "objectID": "slides/02_cfa.html#references",
    "href": "slides/02_cfa.html#references",
    "title": "Measurement models and Confirmatory Factor Analysis",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "slides/03_sem.html#outline",
    "href": "slides/03_sem.html#outline",
    "title": "Structural Equation Models",
    "section": "Outline",
    "text": "Outline\n\nIntroduction\nIdentification\nExample\nExercise\nResults"
  },
  {
    "objectID": "slides/03_sem.html#structural-equation-models",
    "href": "slides/03_sem.html#structural-equation-models",
    "title": "Structural Equation Models",
    "section": "Structural equation models",
    "text": "Structural equation models\nUp to now, we have seen how to model the relationship between different variables/constructs at the same time (path analysis) and how to build a measurement model with one or more latent variables.\nA complete SEM takes both of these things and put them together"
  },
  {
    "objectID": "slides/03_sem.html#the-two-parts-of-a-sem",
    "href": "slides/03_sem.html#the-two-parts-of-a-sem",
    "title": "Structural Equation Models",
    "section": "The two parts of a SEM",
    "text": "The two parts of a SEM\n\nThe measurement model \\[\n\\begin{aligned}\nx = \\Lambda_x\\xi + \\delta\ny =\\Lambda_y\\eta + \\epsilon\n\\end{aligned}\n\\]\nThe structural model \\[\n\\begin{aligned}\n\\eta = B\\eta + \\Gamma\\xi + \\zeta\n\\end{aligned}\n\\]\n\nalready seen in the first slides"
  },
  {
    "objectID": "slides/03_sem.html#matrices",
    "href": "slides/03_sem.html#matrices",
    "title": "Structural Equation Models",
    "section": "Matrices",
    "text": "Matrices\nThese models (can) have all the possible matrices: - Loadings and coefficients matrices \\[\n\\begin{aligned}\n\\Lambda^x &  - relation among  \\xi  and  x\n    \\Lambda^y &  - relation among  \\eta  and  y\n    B &  - relation among  \\eta  and  \\eta\n    \\Gamma &  - relation among  \\xi  and  \\eta\n\\end{aligned}\n\\] - Covariance matrices \\[\n\\begin{aligned}\n\\Theta^\\delta &  -  x  errors\n    \\Theta^\\epsilon &  -  y  errors\n    \\Psi &  -  \\eta  errors\n    \\Phi &  - relations among  \\eta\n\\end{aligned}\n\\] Different models are allowew based on the way we define relationships among variables"
  },
  {
    "objectID": "slides/03_sem.html#lavaan-matrices",
    "href": "slides/03_sem.html#lavaan-matrices",
    "title": "Structural Equation Models",
    "section": "… lavaan matrices",
    "text": "… lavaan matrices\nlavaan does not distinguish between endogenous and exogenous variables. This leads to an easier parametrization and to four matrices only: 1. \\(\\Lambda\\) factor loadings matrix \\([p x m]\\) 1. \\(\\Theta\\) measurement residual errors covariance matrix \\([p x p]\\) 1. \\(B\\) regression coefficients matrix \\([m x m]\\) 1. \\(\\Psi\\) residual structural errors covariance matrix \\([m x m]\\) With p being the number of manifest variables and m being the number of latent variables."
  },
  {
    "objectID": "slides/03_sem.html#the-lavaan-matrices",
    "href": "slides/03_sem.html#the-lavaan-matrices",
    "title": "Structural Equation Models",
    "section": "The lavaan matrices",
    "text": "The lavaan matrices\n{Lambda: matrix of loadings}\n\n{Beta: regression coefficients}\n\n{Psi: residual structural errors matrix}\n\n{Theta: observed variance-covariance matrix}"
  },
  {
    "objectID": "slides/03_sem.html#a-sem-example---simulation",
    "href": "slides/03_sem.html#a-sem-example---simulation",
    "title": "Structural Equation Models",
    "section": "A SEM example - simulation",
    "text": "A SEM example - simulation\n\nlibrary(lavaan)\ndSEM &lt;- simulateData(\"xi =~ .74*x1 + .65*x2\n                      eta =~ .56*y1 + .75*y2\n                      eta ~ .30*xi\n                     \", sample.nobs = 1000)"
  },
  {
    "objectID": "slides/03_sem.html#a-sem-example---specification-and-constraints",
    "href": "slides/03_sem.html#a-sem-example---specification-and-constraints",
    "title": "Structural Equation Models",
    "section": "A SEM example - specification and constraints",
    "text": "A SEM example - specification and constraints\n\nfit &lt;- sem(model = \"xi =~ x1 + x2\n                     eta =~ y1 + y2\n                     eta ~ xi\", data = dSEM)\n\nConstraints\nTo estimate the model we need to set constraints: - the sem or cfa functions default is setting to 1 one loading for each latent variable - an alternative is to standardized latent variables using the std.lv = TRUE option"
  },
  {
    "objectID": "slides/03_sem.html#constraints-default",
    "href": "slides/03_sem.html#constraints-default",
    "title": "Structural Equation Models",
    "section": "Constraints: default",
    "text": "Constraints: default\n\n\n[...]\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  xi =~                                                                 \n    x1                1.000                               0.769    0.644\n    x2                0.728    0.296    2.464    0.014    0.560    0.476\n  eta =~                                                                \n    y1                1.000                               0.630    0.548\n    y2                1.227    0.459    2.672    0.008    0.773    0.595\n\n[...]\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .x1                0.835    0.243    3.440    0.001    0.835    0.586\n   .x2                1.070    0.136    7.865    0.000    1.070    0.773\n   .y1                0.923    0.154    5.986    0.000    0.923    0.699\n   .y2                1.092    0.229    4.766    0.000    1.092    0.646\n    xi                0.591    0.245    2.409    0.016    1.000    1.000\n   .eta               0.373    0.145    2.574    0.010    0.941    0.941\n\n[...]"
  },
  {
    "objectID": "slides/03_sem.html#constraints-std.lvt",
    "href": "slides/03_sem.html#constraints-std.lvt",
    "title": "Structural Equation Models",
    "section": "Constraints: std.lv=T",
    "text": "Constraints: std.lv=T\n\n\n[...]\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  xi =~                                                                 \n    x1                0.769    0.160    4.818    0.000    0.769    0.644\n    x2                0.560    0.119    4.710    0.000    0.560    0.476\n  eta =~                                                                \n    y1                0.611    0.119    5.148    0.000    0.630    0.548\n    y2                0.750    0.147    5.113    0.000    0.773    0.595\n\n[...]\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .x1                0.835    0.243    3.440    0.001    0.835    0.586\n   .x2                1.070    0.136    7.865    0.000    1.070    0.773\n   .y1                0.923    0.154    5.986    0.000    0.923    0.699\n   .y2                1.092    0.229    4.766    0.000    1.092    0.646\n    xi                1.000                               1.000    1.000\n   .eta               1.000                               0.941    0.941\n\n[...]"
  },
  {
    "objectID": "slides/03_sem.html#lavaan-matrices-1",
    "href": "slides/03_sem.html#lavaan-matrices-1",
    "title": "Structural Equation Models",
    "section": "lavaan matrices",
    "text": "lavaan matrices\n\ninspect(fit, \"std\") # OR \"est\"\n\n\n\n$lambda\n     xi  eta\nx1 0.64 0.00\nx2 0.48 0.00\ny1 0.00 0.55\ny2 0.00 0.59\n\n$theta\n     x1   x2   y1   y2\nx1 0.59               \nx2 0.00 0.77          \ny1 0.00 0.00 0.70     \ny2 0.00 0.00 0.00 0.65\n\n\n\n\n$psi\n      xi  eta\nxi  1.00     \neta 0.00 0.94\n\n$beta\n      xi eta\nxi  0.00   0\neta 0.24   0"
  },
  {
    "objectID": "slides/03_sem.html#sem-identification",
    "href": "slides/03_sem.html#sem-identification",
    "title": "Structural Equation Models",
    "section": "SEM identification",
    "text": "SEM identification\nOnce again, remember that identification is a topic relevant to all structural equation models.\nIf an unknown parameter in \\(\\theta\\) can be written as a function of one or more elements of \\(\\Sigma\\), that parameter is identified.\nIf all unknown parameters in \\(\\theta\\) are identified, the model is identified. - the t-rule (again) - the Two-Steps rule"
  },
  {
    "objectID": "slides/03_sem.html#two-steps-rule",
    "href": "slides/03_sem.html#two-steps-rule",
    "title": "Structural Equation Models",
    "section": "Two-Steps rule",
    "text": "Two-Steps rule\n\nStep 1. Treat the model as a confirmatory factor analysis: view the original \\(x\\) and \\(y\\) as \\(x\\) variables and the original \\(\\xi\\) and \\(\\eta\\) as \\(\\xi\\) variables. The only relationship between latent variables of interest are their variance and covariance \\(Phi\\). That is, ignore the \\(B\\), \\(\\Gamma\\), and \\(\\Psi\\) elements.\n\\(\\rightarrow\\) apply CFA identification rules\nStep 2. Examine the latent variable equation of the original model (\\(\\eta = B\\eta + \\Gamma\\xi + \\zeta\\)), assuming that each latent variable is an observed variable that is perfectly measured."
  },
  {
    "objectID": "slides/03_sem.html#two-steps-rule-1",
    "href": "slides/03_sem.html#two-steps-rule-1",
    "title": "Structural Equation Models",
    "section": "Two-Steps rule",
    "text": "Two-Steps rule\nSummary\nIf the first step shows that the measurement parameters are identified and the second step shows that the latent variable model parameters also are identified, then this is suficient to identify the whole model."
  },
  {
    "objectID": "slides/03_sem.html#political-democracy-dataset",
    "href": "slides/03_sem.html#political-democracy-dataset",
    "title": "Structural Equation Models",
    "section": "Political democracy dataset",
    "text": "Political democracy dataset\nBollen (1989) studied the relation between industrialization in 1960 and political democracy of developing countries in 1960 and 1965.\nWe have 11 variables\n\n\n   y1  y2   y3  y4  y5  y6   y7   y8  x1  x2  x3\n1 2.5 0.0  3.3 0.0 1.2 0.0  3.7 3.33 4.4 3.6 2.6\n2 1.2 0.0  3.3 0.0 6.2 1.1  6.7 0.74 5.4 5.1 3.6\n3 7.5 8.8 10.0 9.2 8.8 8.1 10.0 8.21 6.0 6.3 5.2\n\n\nA first latent variable, Industrialization (\\(I = x_1 + x_2 + x_3\\))\nA second latent variable, political democracy in 1960 (\\(D60 = y_1 + y_2 + y_3 + y_4\\))\nA third latent variable, political democracy in 1965 (\\(D65 = y_5 + y_6 + y_7 + y_8\\)).\nLET'S APLLY THE TWO-STEPS RULE"
  },
  {
    "objectID": "slides/03_sem.html#step-1---model-plot",
    "href": "slides/03_sem.html#step-1---model-plot",
    "title": "Structural Equation Models",
    "section": "Step 1 - model plot",
    "text": "Step 1 - model plot\nThe CFA model"
  },
  {
    "objectID": "slides/03_sem.html#step-1---model-specification-and-results",
    "href": "slides/03_sem.html#step-1---model-specification-and-results",
    "title": "Structural Equation Models",
    "section": "Step 1 - model specification and results",
    "text": "Step 1 - model specification and results\nThe CFA model\n\nm &lt;- \"I =~ x1 + x2 + x3\nD60 =~ y1 + y2 + y3 + y4\nD65 =~ y5 + y6 + y7 + y8\n\"\n\n\nfit1 &lt;- sem(m, data = PoliticalDemocracy)\nfit1@Fit@converged\n\n[1] TRUE\n\n\nPARAMETERS ARE ALL IDENTIFIED. LET'S GO TO STEP 2"
  },
  {
    "objectID": "slides/03_sem.html#step-2---model-plot",
    "href": "slides/03_sem.html#step-2---model-plot",
    "title": "Structural Equation Models",
    "section": "Step 2 - model plot",
    "text": "Step 2 - model plot\nThe structural model"
  },
  {
    "objectID": "slides/03_sem.html#step-2---model-specification-and-results",
    "href": "slides/03_sem.html#step-2---model-specification-and-results",
    "title": "Structural Equation Models",
    "section": "Step 2 - model specification and results",
    "text": "Step 2 - model specification and results\nThe structural model\n\nm2 &lt;- \"I =~ x1 + x2 + x3\nD60 =~ y1 + y2 + y3 + y4\nD65 =~ y5 + y6 + y7 + y8\nD65 ~ I + D60\nD60 ~ I\n\"\n\n\nfit2 &lt;- sem(m2, data = PoliticalDemocracy)\nfit2@Fit@converged\n\n[1] TRUE\n\n\nSTRUCTURAL PARAMETERS ARE ALSO IDENTIFIED.\nLET'S DEFINE THE MODEL CONSIDERING LONGITUDINAL MEASURES"
  },
  {
    "objectID": "slides/03_sem.html#final-model",
    "href": "slides/03_sem.html#final-model",
    "title": "Structural Equation Models",
    "section": "Final model",
    "text": "Final model\nThe modified model"
  },
  {
    "objectID": "slides/03_sem.html#final-model-specification",
    "href": "slides/03_sem.html#final-model-specification",
    "title": "Structural Equation Models",
    "section": "Final model specification",
    "text": "Final model specification\nThe modified model\n\nm3 &lt;- \"I =~ x1 + x2 + x3\nD60 =~ y1 + y2 + y3 + y4\nD65 =~ y5 + y6 + y7 + y8\nD65 ~ I + D60\nD60 ~ I\ny1 ~~ y5\ny2 ~~ y6\ny3 ~~ y7\ny4 ~~ y8\n\"\n\nSAME ITEMS AT DIFFERENT TIME POINTS HAVE CORRELATED RESIDUALS"
  },
  {
    "objectID": "slides/03_sem.html#final-model-results",
    "href": "slides/03_sem.html#final-model-results",
    "title": "Structural Equation Models",
    "section": "Final model results",
    "text": "Final model results\nThe modified model\n\n(fit3 &lt;- sem(m3, data = PoliticalDemocracy))\n\nlavaan 0.6-19 ended normally after 58 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        29\n\n  Number of observations                            75\n\nModel Test User Model:\n                                                      \n  Test statistic                                50.835\n  Degrees of freedom                                37\n  P-value (Chi-square)                           0.064\n\ninspect(fit3, what = \"fitmeasures\")[\n  c(\"cfi\", \"srmr\", \"rmsea\")]\n\n  cfi  srmr rmsea \n0.980 0.050 0.071 \n\n\nMODEL FIT IS GOOD!"
  },
  {
    "objectID": "slides/03_sem.html#model-comparisons",
    "href": "slides/03_sem.html#model-comparisons",
    "title": "Structural Equation Models",
    "section": "Model comparisons",
    "text": "Model comparisons\n\nanova(fit1,fit2,fit3)\n\nWarning: lavaan-&gt;lavTestLRT():  \n   some models have the same degrees of freedom\n\n\n\nChi-Squared Difference Test\n\n     Df  AIC  BIC Chisq Chisq diff RMSEA Df diff Pr(&gt;Chisq)    \nfit3 37 3166 3233  50.8                                        \nfit1 41 3180 3238  72.5       21.6 0.242       4    0.00024 ***\nfit2 41 3180 3238  72.5        0.0 0.000       0               \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "slides/03_sem.html#model-comparisons-1",
    "href": "slides/03_sem.html#model-comparisons-1",
    "title": "Structural Equation Models",
    "section": "Model comparisons",
    "text": "Model comparisons\nWe can also compare the models using fit indices:\n\n\n\n\n\n\nchisq\ndf\ncfi\ntli\nsrmr\nrmsea\naic\nbic\n\n\n\n\nmodel1\n72\n41\n0.95\n0.94\n0.055\n0.101\n3180\n3238\n\n\nmodel2\n72\n41\n0.95\n0.94\n0.055\n0.101\n3180\n3238\n\n\nmodel3\n51\n37\n0.98\n0.97\n0.050\n0.071\n3166\n3233\n\n\n\n\n\nWHAT IS THE BEST MODEL? QUESTIONS? COMMENTS?"
  },
  {
    "objectID": "slides/03_sem.html#the-eat-dataset",
    "href": "slides/03_sem.html#the-eat-dataset",
    "title": "Structural Equation Models",
    "section": "The EAT dataset",
    "text": "The EAT dataset\nThe dataset includes 13 items that measure ‘peer pressure’, ‘social media use’, ‘social comparison’, and ‘eating disorders’.\n\nload(\"../data/Exercise4_1.Rdata\")\nround(head(dE4_1),2)\n\n    PP1   PP2   PP3   PP4   SM1   SM2   SM3   SM4  SC1   SC2   SC3   ED1   ED2\n1  0.23  1.91  0.59 -0.70  2.31  1.06  1.43 -0.77  1.2  2.20  0.18 -0.38  1.61\n2 -0.65 -3.18 -0.84 -0.43  0.69  0.10  1.24  0.51 -1.9 -1.17 -1.23 -1.74 -1.73\n3  0.26 -1.46 -0.43 -0.05 -0.21 -0.46 -0.02  1.26  1.4  1.03  0.90  1.07  2.04\n4 -0.68 -0.29 -0.08 -2.24 -0.64  0.47 -0.76  0.58  1.2  0.97  2.73  0.71  0.32\n5 -0.06  0.89  0.04 -0.41  0.17  1.02  0.18  0.61  3.7  1.38  1.85  1.25  0.66\n6 -0.29 -2.74 -0.52  2.58  0.15 -1.08  1.08  0.99  1.3 -0.24  0.93 -0.97 -0.68"
  },
  {
    "objectID": "slides/03_sem.html#the-theoretical-model",
    "href": "slides/03_sem.html#the-theoretical-model",
    "title": "Structural Equation Models",
    "section": "The theoretical model",
    "text": "The theoretical model"
  },
  {
    "objectID": "slides/03_sem.html#the-exercise",
    "href": "slides/03_sem.html#the-exercise",
    "title": "Structural Equation Models",
    "section": "The exercise",
    "text": "The exercise\n\nApply the two-step rule:\n\nTest the CFA model\nTest the structural model\n\nInspect model results and fit indices\n\nAre the hypotheses confirmed?\nDoes the model fit the data well?\n\nIf the model is not satisfactory, understand why and change it\nDraw the model (in R, ppt, or with a pencil)\nTry to fit a simple path model using sum scores instead of latent scores"
  },
  {
    "objectID": "slides/03_sem.html#model-specification",
    "href": "slides/03_sem.html#model-specification",
    "title": "Structural Equation Models",
    "section": "Model specification",
    "text": "Model specification\nSTEP 1 and 2\n\nm1 &lt;- \"\n # CFA model\n peerPressure =~ PP1 + PP2 + PP3 + PP4\n socialMedia =~ SM1 + SM2 + SM3 + SM4\n socialComparison =~ SC1 + SC2 + SC3\n eatingDisorder =~ ED1 + ED2\n\"\nfit1 &lt;- sem(m1, data = dE4_1, std.lv=T)\nfit1@Fit@converged\nm2 &lt;- \"\n [...]\n # Structural model\n eatingDisorder ~ socialComparison\n socialComparison ~ peerPressure + socialMedia\"\nfit2 &lt;- sem(m2, data = dE4_1, std.lv=T)\nfit2@Fit@converged\n\nOK?"
  },
  {
    "objectID": "slides/03_sem.html#results-and-fit",
    "href": "slides/03_sem.html#results-and-fit",
    "title": "Structural Equation Models",
    "section": "Results and fit",
    "text": "Results and fit\n\nsummary(fitE4_1, std=T)\n\n\n\n[...]\nRegressions:\n                     Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  eatingDisorder ~                                                        \n    socialComparsn      0.344    0.047    7.322    0.000    0.356    0.356\n  socialComparison ~                                                      \n    peerPressure        0.139    0.038    3.636    0.000    0.125    0.125\n    socialMedia         0.455    0.049    9.221    0.000    0.411    0.411\n\n[...]\n\n\n\nfitmeasures(fitE4_1, \n            fit.measures = \n            c(\"cfi\", \"tli\", \"srmr\", \"rmsea\"))\n\n  cfi   tli  srmr rmsea \n0.880 0.846 0.044 0.065"
  },
  {
    "objectID": "slides/03_sem.html#model-modification",
    "href": "slides/03_sem.html#model-modification",
    "title": "Structural Equation Models",
    "section": "Model modification",
    "text": "Model modification\n\nmodificationIndices(fitE4_1, sort. = T)[1:10,]\n\n                 lhs op rhs  mi   epc sepc.lv sepc.all sepc.nox\n120              SM1 ~~ SC2 329  0.56    0.56     0.63     0.63\n49       socialMedia =~ SC2  57  0.38    0.38     0.29     0.29\n57  socialComparison =~ SM1  55  0.29    0.32     0.28     0.28\n121              SM1 ~~ SC3  52 -0.23   -0.23    -0.23    -0.23\n50       socialMedia =~ SC3  31 -0.28   -0.28    -0.21    -0.21\n119              SM1 ~~ SC1  22 -0.15   -0.15    -0.15    -0.15\n143              SC1 ~~ SC3  19  0.29    0.29     0.28     0.28\n74               PP1 ~~ PP2  18  0.66    0.66     1.20     1.20\n97               PP3 ~~ PP4  15  0.13    0.13     0.11     0.11\n58  socialComparison =~ SM2  13 -0.15   -0.16    -0.14    -0.14\n\n\n\nm2.1 &lt;- \"\n[...]\n# Residual correlations\nSM1 ~~ SC2\n\"\nfitmeasures(fit2.1, ...)\n\n\n\n  cfi   tli  srmr rmsea \n0.995 0.994 0.023 0.013"
  },
  {
    "objectID": "slides/03_sem.html#sum-scores",
    "href": "slides/03_sem.html#sum-scores",
    "title": "Structural Equation Models",
    "section": "Sum scores",
    "text": "Sum scores\n\nd2 &lt;- data.frame(\n  peerPressure = dE4_1$PP1 + dE4_1$PP2 + dE4_1$PP3 + dE4_1$PP4, \n  socialMedia = dE4_1$SM1 + dE4_1$SM2 + dE4_1$SM3 + dE4_1$SM4,\n  socialComparison = dE4_1$SC1 + dE4_1$SC2 + dE4_1$SC3,\n  eatingDisorder = dE4_1$ED1 + dE4_1$ED2)\npath &lt;- \"\neatingDisorder ~ socialComparison\nsocialComparison ~ peerPressure + socialMedia\"\nfitP &lt;- sem(path, d2)\nfitmeasures(fitP, fit.measures = \n              c(\"cfi\", \"tli\", \"srmr\", \"rmsea\"))\n\n  cfi   tli  srmr rmsea \n0.978 0.946 0.019 0.037"
  },
  {
    "objectID": "slides/03_sem.html#sum-scores-vs-latent-scores",
    "href": "slides/03_sem.html#sum-scores-vs-latent-scores",
    "title": "Structural Equation Models",
    "section": "Sum scores VS latent scores",
    "text": "Sum scores VS latent scores\nHowever, the debate is still open:\n\nThinking twice about sum scores\n\nThinking thrice about sum scores, and then some more about measurement and analysis\n\nPsychometric properties of sum scores and factor scores differ even when their correlation is 0.98: A response to Widaman and Revelle\n\nOr some more Schimmack:\n\nSchimmack vs Gelman 1\nSchimmack vs Gelman 2"
  },
  {
    "objectID": "slides/03_sem.html#the-ground-truth",
    "href": "slides/03_sem.html#the-ground-truth",
    "title": "Structural Equation Models",
    "section": "The ground truth",
    "text": "The ground truth\n\n# peer pressure AND social media -&gt; social comparison -&gt; eating disorder\nmE4_1 &lt;- \"\n # CFA model\n peerPressure =~ .75*PP1 + .72*PP2 + .59*PP3 + .65*PP4\n socialMedia =~ .45*SM1 + .55*SM2 + .59*SM3 + .65*SM4\n socialComparison =~ .81*SC1 + .75*SC2 + .86*SC3\n eatingDisorder =~ .70*ED1 + .65*ED2\n \n # Structural model\n eatingDisorder ~ .37*socialComparison\n socialComparison ~ .23*peerPressure + .41*socialMedia\n \n # Misspecifications\n # within construct\n PP1 ~~ .43*PP2\n # between construct\n SM1 ~~ .53*SC2\n\""
  },
  {
    "objectID": "slides/03_sem.html#sum-scores-vs-latent-scores-1",
    "href": "slides/03_sem.html#sum-scores-vs-latent-scores-1",
    "title": "Structural Equation Models",
    "section": "Sum scores VS latent scores",
    "text": "Sum scores VS latent scores\nHowever, the debate is still open:\n\nThinking twice about sum scores\n\nThinking thrice about sum scores, and then some more about measurement and analysis\n\nPsychometric properties of sum scores and factor scores differ even when their correlation is 0.98: A response to Widaman and Revelle\n\nOr some more Schimmack:\n\nSchimmack vs Gelman 1\nSchimmack vs Gelman 2"
  },
  {
    "objectID": "slides/03_sem.html#the-indifference-of-the-indicator",
    "href": "slides/03_sem.html#the-indifference-of-the-indicator",
    "title": "Structural Equation Models",
    "section": "The indifference of the indicator",
    "text": "The indifference of the indicator\n\nHow many indicators do we need?\nHow should I select them?\n… LET'S SEE THE ADDITIONAL CODE"
  },
  {
    "objectID": "slides/04_invariance.html#outline",
    "href": "slides/04_invariance.html#outline",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Outline",
    "text": "Outline\n\nTheoretical Background\nR code\nA real case study\nRegressions\nReferences"
  },
  {
    "objectID": "slides/04_invariance.html#a-hot-topic",
    "href": "slides/04_invariance.html#a-hot-topic",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "A hot topic",
    "text": "A hot topic"
  },
  {
    "objectID": "slides/04_invariance.html#introduction",
    "href": "slides/04_invariance.html#introduction",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\nCOMMENTS?"
  },
  {
    "objectID": "slides/04_invariance.html#the-importance-of-measurement-invariance",
    "href": "slides/04_invariance.html#the-importance-of-measurement-invariance",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "The importance of Measurement Invariance",
    "text": "The importance of Measurement Invariance\n\nResearchers often compare groups of subjects on psychological variables … assuming that the adopted instruments similarly measure the same latent constructs across groups\n\nDespite its appeal, this assumption is often not justified and needs to be tested to make comparisons across groups valid and interpretable\nThe assessment of Measurement Invariance is a prerequisite for meaningful comparisons across groups (or across time for the same groups)\n\n\n…but not everyone (fully) agrees: doi:10.1080/10705511.2023.2191292"
  },
  {
    "objectID": "slides/04_invariance.html#invariance-of-a-structural-equation-model",
    "href": "slides/04_invariance.html#invariance-of-a-structural-equation-model",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Invariance of a Structural Equation Model",
    "text": "Invariance of a Structural Equation Model\nMore generally, testing for Invariance allows us to evaluate to what extent a hypothesized Structural Equation Model (SEM) can be considered invariant (i.e., having the same parameters) across groups"
  },
  {
    "objectID": "slides/04_invariance.html#some-applications",
    "href": "slides/04_invariance.html#some-applications",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "(Some) Applications",
    "text": "(Some) Applications\n\nEvaluation of the psychometric properties of a psychological test or of a theoretical model on different sub-groups\n\nFor example, assessment of invariance across:\n  -  gender\n  -  age group\n  -  pathological state\n  -  culture, ethnicity, nationality\n\\end {itemize} - Longitudinal factorial invariance: the invariance of corresponding parameters across time within a group"
  },
  {
    "objectID": "slides/04_invariance.html#assessing-invariance-the-multi-group-analysis",
    "href": "slides/04_invariance.html#assessing-invariance-the-multi-group-analysis",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Assessing Invariance:\\ The Multi-Group Analysis",
    "text": "Assessing Invariance:\\ The Multi-Group Analysis\n\nThe Multi-group analysis is the most widely used method to assess invariance of a SEM model\n\nIn this lesson we will focus on a particular class of SEM models:\n\n\nThe Confirmatory Factor Analysis (CFA) models - In particular, we will adopt The Multi-Group Confirmatory Factor Analysis (MG-CFA) approach"
  },
  {
    "objectID": "slides/04_invariance.html#assessing-invariance-the-starting-point",
    "href": "slides/04_invariance.html#assessing-invariance-the-starting-point",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Assessing Invariance: The starting point",
    "text": "Assessing Invariance: The starting point"
  },
  {
    "objectID": "slides/04_invariance.html#assessing-invariance-the-idea",
    "href": "slides/04_invariance.html#assessing-invariance-the-idea",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Assessing Invariance: The idea",
    "text": "Assessing Invariance: The idea\n\nIn MG analysis we start from a baseline situation in which the hypothesized CFA model is simultaneously estimated on all groups. At the beginning, all structural parameters are free to vary across groups\n\nNext, more restrictive models are built in which some parameters (e.g., factor loadings) are constrained to be invariant across groups\nThe comparison of increasingly restrictive models allows to evaluate the increasing level of invariance between groups"
  },
  {
    "objectID": "slides/04_invariance.html#invariance-steps",
    "href": "slides/04_invariance.html#invariance-steps",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Invariance steps:",
    "text": "Invariance steps:\n\nConfigural Invariance: the structure of the latent variable(s) is the same across groups (\\(g \\ne g'\\)) and/or over time (\\(\\xi_g = \\xi_{g'}\\))\n\nMetric Invariance (or Weak Invariance): factor loadings are equivalent across groups and/or over time (\\(\\Lambda_g = \\Lambda_{g'}\\))\nScalar Invariance (or Strong Invariance): intercepts of observed variables are equivalent across groups and/or over time (\\(\\tau_g = \\tau_{g'}\\))\nStrict Invariance (or Residual or Invariant Uniqueness Invariance): residual variances of observed exogenous variables are equivalent across groups and/or over time (\\(\\Theta_{\\delta,g} = \\Theta_{\\delta,g'}\\))\n…\nScalar/Strong invariance is required for meaningful mean comparisons"
  },
  {
    "objectID": "slides/04_invariance.html#assessing-factorial-invariance-a-step-by-step-guide",
    "href": "slides/04_invariance.html#assessing-factorial-invariance-a-step-by-step-guide",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Assessing Factorial Invariance: A step-by-step guide",
    "text": "Assessing Factorial Invariance: A step-by-step guide\n\n\n\n\n\n\n\n\n\n#\nInvariance\nConstrained parameters\nComparison model\n\n\n\n\n0\nSeparete models\n-\n-\n\n\n1\nConfigural\nNone\n-\n\n\n2\nMetric\n\\(\\lambda_{ij}\\)\nConfigural\n\n\n3\nScalar\n\\(\\lambda_{ij}\\; , \\tau_{i}\\)\nMetric\n\n\n4\nObserved residual var.\n\\(\\lambda_{ij}\\; , \\tau_{i}\\; , \\theta_{ii}^{\\delta}\\)\nScalar\n\n\n5\nLatent variances\n${ij}; , {i}; , {ii}^{}; , {ii} $\nObserved residual var.\n\n\n6\nLatent covariances\n${ij}; , {i}; , {ii}^{}; , {ii}; , _{ij} $\nLatent variances\n\n\n7\nLatent means\n\\(\\lambda_{ij}\\; , \\tau_{i}\\; , \\theta_{ii}^{\\delta}\\; , \\phi_{ii}\\;  , \\phi_{ij}\\; , \\kappa_{i}\\)\nLatent covariances\n\n\n\n-  **Steps from 1 to 4:** *Measurement Invariance*\n\n-  **Steps from 5 to 7:** *Structural Invariance*"
  },
  {
    "objectID": "slides/04_invariance.html#mg-cfa-scheme-steps-1-4",
    "href": "slides/04_invariance.html#mg-cfa-scheme-steps-1-4",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "MG-CFA scheme (steps 1-4)",
    "text": "MG-CFA scheme (steps 1-4)"
  },
  {
    "objectID": "slides/04_invariance.html#step-0-separate-models-for-each-group",
    "href": "slides/04_invariance.html#step-0-separate-models-for-each-group",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Step 0: Separate models for each group",
    "text": "Step 0: Separate models for each group"
  },
  {
    "objectID": "slides/04_invariance.html#step-1-configural-invariance",
    "href": "slides/04_invariance.html#step-1-configural-invariance",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Step 1: Configural invariance",
    "text": "Step 1: Configural invariance"
  },
  {
    "objectID": "slides/04_invariance.html#step-1-configural-non-invariance",
    "href": "slides/04_invariance.html#step-1-configural-non-invariance",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Step 1: Configural (non-)invariance",
    "text": "Step 1: Configural (non-)invariance\nConfigural invariance means that the “form” of the models is the same in the groups of interest. Form entails both the number of latent variables and whether the loadings are non-zero to begin with."
  },
  {
    "objectID": "slides/04_invariance.html#step-2-metric-invariance",
    "href": "slides/04_invariance.html#step-2-metric-invariance",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Step 2: Metric invariance",
    "text": "Step 2: Metric invariance"
  },
  {
    "objectID": "slides/04_invariance.html#step-2-metric-non-invariance",
    "href": "slides/04_invariance.html#step-2-metric-non-invariance",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Step 2: Metric (non-)invariance",
    "text": "Step 2: Metric (non-)invariance\nMetric invariance means that for each item, the loading of the factor on the item is the same in the two groups (or, again more precisely, that we cannot reject the hypothesis that the loadings are the same)."
  },
  {
    "objectID": "slides/04_invariance.html#step-2-metric-non-invariance-1",
    "href": "slides/04_invariance.html#step-2-metric-non-invariance-1",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Step 2: Metric (non-)invariance",
    "text": "Step 2: Metric (non-)invariance\nThe source of group differences does not come from the latent variable!"
  },
  {
    "objectID": "slides/04_invariance.html#step-3-scalar-invariance",
    "href": "slides/04_invariance.html#step-3-scalar-invariance",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Step 3: Scalar invariance",
    "text": "Step 3: Scalar invariance"
  },
  {
    "objectID": "slides/04_invariance.html#step-3-scalar-invariance-1",
    "href": "slides/04_invariance.html#step-3-scalar-invariance-1",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Step 3: Scalar invariance",
    "text": "Step 3: Scalar invariance\nScalar invariance means that for each item, the intercept is the same. This means that group differences in the item responses are fully accounted for by group differences in the latent construct."
  },
  {
    "objectID": "slides/04_invariance.html#step-4-invariance-of-observed-residual-variances",
    "href": "slides/04_invariance.html#step-4-invariance-of-observed-residual-variances",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Step 4: Invariance of observed residual variances",
    "text": "Step 4: Invariance of observed residual variances\nResidual invariance means that for each item, the residual variance—the variance of the ominous E pointing into the items—is the same. We can again phrase this statistically: if we regressed the item scores on the factor, then the variance of the remaining residual would be the same in the groups (i.e., there would be homoscedasticity)."
  },
  {
    "objectID": "slides/04_invariance.html#step-4-invariance-of-observed-residual-variances-1",
    "href": "slides/04_invariance.html#step-4-invariance-of-observed-residual-variances-1",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Step 4: Invariance of observed residual variances",
    "text": "Step 4: Invariance of observed residual variances\n\nThe thing about the residual is that it captures everything that’s not explained in the model, and explaining changes in the amount of unexplained things seems a bit futile. Residual invariance is often not tested because it’s not necessary for latent mean comparisons. It’s a bit of an anticlimactic level to end on."
  },
  {
    "objectID": "slides/04_invariance.html#step-5-invariance-of-latent-variances",
    "href": "slides/04_invariance.html#step-5-invariance-of-latent-variances",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Step 5: Invariance of latent variances",
    "text": "Step 5: Invariance of latent variances"
  },
  {
    "objectID": "slides/04_invariance.html#step-6-invariance-of-latent-covariances",
    "href": "slides/04_invariance.html#step-6-invariance-of-latent-covariances",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Step 6: Invariance of latent covariances",
    "text": "Step 6: Invariance of latent covariances"
  },
  {
    "objectID": "slides/04_invariance.html#step-7-invariance-of-latent-means",
    "href": "slides/04_invariance.html#step-7-invariance-of-latent-means",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Step 7: Invariance of latent means",
    "text": "Step 7: Invariance of latent means"
  },
  {
    "objectID": "slides/04_invariance.html#evaluation-of-level-of-invariance",
    "href": "slides/04_invariance.html#evaluation-of-level-of-invariance",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Evaluation of level of invariance",
    "text": "Evaluation of level of invariance\n\nAnalysis of fit indices of the considered invariance model (\\(\\chi^{2}\\), \\(RMSEA\\), \\(CFI\\), \\(NNFI\\)):\n\nA good fit supports the validity of invariance - Comparison between fit indices of the considered invariance model and a less restrictive model:\n    -   $\\Delta_{\\chi^{2}}$  (strongly dependent on $n$)\n    -  $\\Delta_{CFI}$\n    -  $\\Delta_{BIC}$\n    -  ...\nA marked worsening of fit indices indicates that the considered invariance model is too restrictive and thus must be rejected\nNote: It is strongly recommended to make a comprehensive evaluation based on different fit indices, rather than on a single fit criterion"
  },
  {
    "objectID": "slides/04_invariance.html#some-general-indications-on-model-comparison",
    "href": "slides/04_invariance.html#some-general-indications-on-model-comparison",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Some general indications on model comparison",
    "text": "Some general indications on model comparison\nLet:\n-  $MOD_{A}$ be a model of invariance taken as reference model\n-  $MOD_{B}$ be a more restrictive model of invariance than $MOD_{A}$\nWe will have:\n-  $\\Delta_{\\chi^{2}_{BA}} = \\chi^{2}_{MOD_{B}} - \\chi^{2}_{MOD_{A}} \\sim \\chi^{2}_{BA}$ with $df$ equal to $df_{Mod_{B}} - df_{Mod_{A}}$  \nIf the \\(p-value\\) associated with \\(\\chi^{2}_{BA}\\) is less than a critical \\(\\alpha\\) value then \\({MOD_{B}}\\) must be rejected Always assume \\(\\alpha_{CRITICAL}=.05\\) is not reasonable - \\(\\Delta_{CFI_{BA}} = CFI_{MOD_B}-CFI_{MOD_A}\\) If \\(\\Delta_{CFI_{BA}} &gt; -.01\\) then \\({MOD_{B}}\\) can be accepted - \\(\\Delta_{BIC_{BA}} = BIC_{MOD_B}-BIC_{MOD_A}\\) If ${BIC{BA}} &lt; 0 $ then \\({MOD_{B}}\\) is more plausible than \\({MOD_{A}}\\)"
  },
  {
    "objectID": "slides/04_invariance.html#partial-invariance",
    "href": "slides/04_invariance.html#partial-invariance",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Partial invariance",
    "text": "Partial invariance\nWhen model invariance is untenable at a certain level (scalar, metric, or residual) we can determine what specific indicator(s) contribute to the misfit. Partial invariance is when most but not all parameters are constrained to be invariant. If partial invariance exists at a given level for a model, there are a variety of ways to proceed:\n1.  Leave the non-invariant indicator variables in the model, but not constrain them to be invariant across groups, arguing that the invariant indicators are sufficient to establish comparability of the constructs.\n2.  Argue that the differences between indicator variables are small enough that they would not make a substantive difference and proceed with invariance constraints in place.\n3.  Remove the indicator variables that are not fully invariant, and then re-run the invariance assessment.\n4.  Conclude that because there is not full invariance, the indicator variables must be measuring different constructs across the groups and, therefore, not use the indicators."
  },
  {
    "objectID": "slides/04_invariance.html#how-can-we-recognize-the-parameters-to-free",
    "href": "slides/04_invariance.html#how-can-we-recognize-the-parameters-to-free",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "How can we recognize the parameters to ``free’’?",
    "text": "How can we recognize the parameters to ``free’’?\n\nInspection of parameters estimated separately for each group\n\nThe more the same parameter differs among groups, the more it will be plausible to free it - Inspection of Modification indices\n    -  The *Modification Index* of a constrained parameter indicates the extent to which the model could improve if the parameter would be left free to vary across groups\n    -  In general, we start from a more restrictive model and free one by one the parameters with higher Modification indices... until we obtain invariance\nNote: Parameters left to vary freely across groups must be interpreted based on relevant theory"
  },
  {
    "objectID": "slides/04_invariance.html#cfa-hypothesized-model",
    "href": "slides/04_invariance.html#cfa-hypothesized-model",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "CFA hypothesized model",
    "text": "CFA hypothesized model"
  },
  {
    "objectID": "slides/04_invariance.html#the-data",
    "href": "slides/04_invariance.html#the-data",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "The Data",
    "text": "The Data\n\nData are in the data frame ``d’’\n\n\nstr(d)\n\n'data.frame':   589 obs. of  8 variables:\n $ x1   : num  1.21 -1.34 1.05 1.02 2.51 ...\n $ x2   : num  0.725 -0.927 -1.037 1.953 1.823 ...\n $ x3   : num  1.153 -1.635 3.148 -0.183 2.449 ...\n $ x4   : num  2.185 -1.788 -0.101 0.978 0.77 ...\n $ x5   : num  0.668 -0.414 1.843 -1.994 -1.774 ...\n $ x6   : num  -1.0233 -0.4756 -0.0675 -0.1684 1.2472 ...\n $ x7   : num  1.046 -0.213 1.572 -1.513 0.194 ...\n $ Group: int  1 0 0 1 1 1 1 0 1 1 ...\n\n\n\nThe groups are composed by:\n\n\ntable(d$Group)\n\n\n  0   1 \n234 355"
  },
  {
    "objectID": "slides/04_invariance.html#model-building-in-r",
    "href": "slides/04_invariance.html#model-building-in-r",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Model building in R",
    "text": "Model building in R\nThis is the reference theoretical model that we want to evaluate\n\nm &lt;- \"\nf1 =~ x1 + x2 + x3 + x4\nf2 =~ x5 + x6 + x7\n\""
  },
  {
    "objectID": "slides/04_invariance.html#step-0-separate-models-for-each-group-1",
    "href": "slides/04_invariance.html#step-0-separate-models-for-each-group-1",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Step 0: Separate models for each group",
    "text": "Step 0: Separate models for each group\nFirst of all, try to fit the model separately in the two groups.\nThis is not configural invariance! We are just testing if the model works in the two groups, not if the model has the same ‘form’ in the two groups.\n\n# Fit the model in the two groups\nm0&lt;-cfa(m, data=d[d$Group==0,])\nm1&lt;-cfa(m, data=d[d$Group==1,])\n\n# Evaluating parameters and goodness-of-fit indices\nsummary(m0,fit.measures=TRUE)\nsummary(m1,fit.measures=TRUE)"
  },
  {
    "objectID": "slides/04_invariance.html#step-1-configural-invariance-1",
    "href": "slides/04_invariance.html#step-1-configural-invariance-1",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Step 1: Configural invariance",
    "text": "Step 1: Configural invariance\nFitting a configural model is very easy: just add group=“groupVariableName” to the cfa sintax.\n\n# Fit the configural model\nm.conf&lt;-cfa(m, data=d, group = \"Group\")\n\n# Evaluating parameters and goodness-of-fit indices\nsummary(m.conf)\nfitmeasures(m.conf, fit.measures = fi)\n\n# Do they decrease compared to the full model?"
  },
  {
    "objectID": "slides/04_invariance.html#step-2-metric-invariance-1",
    "href": "slides/04_invariance.html#step-2-metric-invariance-1",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Step 2: Metric invariance",
    "text": "Step 2: Metric invariance\nAdding metric invariance to the model means fixing the loadings to force them to be equal in the two groups.\n\n# Fit the model for metric invariance\nm.metr&lt;-cfa(m, data=d, group = \"Group\",\n            group.equal = \"loadings\")\n\n# Evaluating parameters and goodness-of-fit indices\nsummary(m.metr)\nfitmeasures(m.metr, fit.measures = fi)\n# Comparison between metric and configural invariance (delta chi)\nanova(m.metr,m.conf)\n# Comparison between metric and configural invariance (delta CFI)\nfitMeasures(m.metr,\"cfi\") - fitMeasures(m.conf,\"cfi\")\n# Comparison between metric and configural invariance (delta BIC)\nfitMeasures(m.metr,\"bic\")-fitMeasures(m.conf,\"bic\")\n# Inspection of the modification indices\nlavTestScore(m.metr)\nparameterTable(m.metr)"
  },
  {
    "objectID": "slides/04_invariance.html#steps-3-7-evaluation-of-different-invariance-models",
    "href": "slides/04_invariance.html#steps-3-7-evaluation-of-different-invariance-models",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Steps 3-7: Evaluation of different invariance models",
    "text": "Steps 3-7: Evaluation of different invariance models\nThrough the option group.equal , it is possible to constrain groups of parameters to be equal across groups in order to assess increasingly restrictive invariance hypotheses:\n\n\n\nConstrained parameters\nIn R\n\n\n\n\nFactor loadings\nloadings\n\n\nIntercepts of manifest variables\nintercepts\n\n\nResidual variances of manifest variables\nresiduals\n\n\nResidual covariances of manifest variables\nresidual.covariances\n\n\nResidual variances of latent variables\nlv.variances\n\n\nResidual covariances of latent variable\nlv.covariances\n\n\nIntercepts/means of latent variables\nmeans\n\n\nAll regression coefficients\nregressions\n\n\n\n\n# Example: Model for assessing scalar invariance\nm.scal&lt;-cfa(m,d,group=\"Group\",\n            group.equal=c(\"loadings\",\"intercepts\"))"
  },
  {
    "objectID": "slides/04_invariance.html#a-magic",
    "href": "slides/04_invariance.html#a-magic",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "A magic ",
    "text": "A magic \n\nlibrary(semTools)\nmeasurementInvariance(model = model,\n                      d,group=\"Group\",\n                      fit.measures = fi)\n\nThis is DEPRECATED from the authors of the package and will be deleted from future versions of semTools.\nYou can use it exploratorily, but you cannot:\n\nfollow and interpret the estimates step by step\nmodel partial invariance!\n\nLet’s see what partial invariance is."
  },
  {
    "objectID": "slides/04_invariance.html#models-of-partial-invariance",
    "href": "slides/04_invariance.html#models-of-partial-invariance",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Models of partial invariance",
    "text": "Models of partial invariance\nThrough the option group.partial , you can test for partial invariance by allowing a few parameters to remain free:\n\n# After the inspection of MI, we decided to estimate a model\n# of partial metric invariance in which the loadgin of the\n# item x5 is free to vary between groups:\nm.metr&lt;-cfa(m,data=d,group=\"Group\",\n            group.equal=\"loadings\",\n            group.partial=\"f2 =~ x5\")\n\nWhat should we do now?\nShould we compare this model with what?\nHow can we interpret the results?\n\n… Now it’s time for a real case study!"
  },
  {
    "objectID": "slides/04_invariance.html#the-case-study",
    "href": "slides/04_invariance.html#the-case-study",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "The case study",
    "text": "The case study\n\n*SEM work with variance-covariance matrices. For this reason, it is sufficient to find it in the original articles to use their “data”!. The data we will use have been generated based on the parameters provided in the article, modifying the sample size. How? Open dataGen.R* in the \\texttt{'data' folder}"
  },
  {
    "objectID": "slides/04_invariance.html#theoretical-model-and-reference-groups",
    "href": "slides/04_invariance.html#theoretical-model-and-reference-groups",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Theoretical model and reference groups",
    "text": "Theoretical model and reference groups\n\n-  Group A: Youths With Manics  Symptoms ($n=150$)\n-  Group B: Control Group ($n=150$)"
  },
  {
    "objectID": "slides/04_invariance.html#the-data-on-moodle-dmg.rdata",
    "href": "slides/04_invariance.html#the-data-on-moodle-dmg.rdata",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "The Data (On MOODLE: dmg.RData)",
    "text": "The Data (On MOODLE: dmg.RData)\n\nrm(list=ls())\n# Loading useful packages:\nlibrary(lavaan) ; library(semTools) ; library (semPlot)\nload(\"../data/dmg.RData\")\nstr(dmg)\n\n'data.frame':   300 obs. of  10 variables:\n $ id       : int  1 2 3 4 5 6 7 8 9 10 ...\n $ diagnosis: Factor w/ 2 levels \"manic\",\"norming\": 1 1 1 1 1 1 1 1 1 1 ...\n $ Info     : num  8.95 11.94 5.8 14.69 6 ...\n $ Sim      : num  9.34 9.93 6.64 17.72 6.56 ...\n $ Vocab    : num  12.39 4.57 6.03 13.21 7.83 ...\n $ Comp     : num  11.61 8.86 5.03 13.38 5.77 ...\n $ PicComp  : num  11.15 4.95 8.02 11.54 8.84 ...\n $ PicArr   : num  15.7 5.46 7.65 12.06 5.39 ...\n $ BlkDsgn  : num  11.45 3.43 9.28 10.46 7.39 ...\n $ ObjAsmb  : num  15.54 3.8 8.63 14.38 9.92 ..."
  },
  {
    "objectID": "slides/04_invariance.html#evaluation-of-multivariate-normality",
    "href": "slides/04_invariance.html#evaluation-of-multivariate-normality",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Evaluation of multivariate normality",
    "text": "Evaluation of multivariate normality\n\nlibrary(QuantPsyc)\nmult.norm(dmg[,3:10])$mult.test # (Mardia, 1970)\n\n          Beta-hat       kappa     p-val\nSkewness  2.110397 105.5198437 0.8242484\nKurtosis 79.118959  -0.6032073 0.5463708\n\n# We can assume multivariate normality\n#   and therefore use, in SEM,\n#   the Maximum Likelihood Method"
  },
  {
    "objectID": "slides/04_invariance.html#theoretical-model-in-r",
    "href": "slides/04_invariance.html#theoretical-model-in-r",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Theoretical model in R",
    "text": "Theoretical model in R\n\nmodel&lt;-\"gc =~ Info + Sim + Vocab + Comp\n        gv =~ PicComp + PicArr + BlkDsgn + ObjAsmb\""
  },
  {
    "objectID": "slides/04_invariance.html#separate-models-for-each-group",
    "href": "slides/04_invariance.html#separate-models-for-each-group",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Separate models for each group",
    "text": "Separate models for each group\n\n# Separate models\nm.man&lt;-cfa(model,data=dmg[dmg$diagnosis==\"manic\",])\nm.nor&lt;-cfa(model,data=dmg[dmg$diagnosis==\"norming\",])\n# Inspection of fit indices\nfitMeasures(m.man,c(\"chisq\",\"df\",\"rmsea\",\"cfi\",\"nnfi\"))\n\n chisq     df  rmsea    cfi   nnfi \n54.052 19.000  0.111  0.949  0.924 \n\nfitMeasures(m.nor,c(\"chisq\",\"df\",\"rmsea\",\"cfi\",\"nnfi\"))\n\n chisq     df  rmsea    cfi   nnfi \n18.151 19.000  0.000  1.000  1.003 \n\n# ANY COMMENTS?"
  },
  {
    "objectID": "slides/04_invariance.html#configural-invariance",
    "href": "slides/04_invariance.html#configural-invariance",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Configural Invariance",
    "text": "Configural Invariance\n\nm.conf&lt;-cfa(model,data=dmg,group=\"diagnosis\")\n# Inspection of fit indices\nfitMeasures(m.conf,c(\"chisq\",\"df\",\"rmsea\",\"cfi\",\"nnfi\"))\n\n chisq     df  rmsea    cfi   nnfi \n72.203 38.000  0.077  0.971  0.957 \n\n# ANY COMMENTS?"
  },
  {
    "objectID": "slides/04_invariance.html#metric-invariance-1",
    "href": "slides/04_invariance.html#metric-invariance-1",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Metric invariance (1)",
    "text": "Metric invariance (1)\n\n# Model of metric invariance\nm.metr&lt;-cfa(model,dmg,group=\"diagnosis\",group.equal=\"loadings\")\n# Inspection of fit indices\nfitMeasures(m.metr,c(\"chisq\",\"df\",\"rmsea\",\"cfi\",\"nnfi\"))\n\n chisq     df  rmsea    cfi   nnfi \n88.153 44.000  0.082  0.963  0.952"
  },
  {
    "objectID": "slides/04_invariance.html#metric-invariance-2",
    "href": "slides/04_invariance.html#metric-invariance-2",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Metric invariance (2)",
    "text": "Metric invariance (2)\n\n#### Metric vs. Configural invariance:\nanova(m.metr,m.conf) # (delta chi-square)\n\n\nChi-Squared Difference Test\n\n       Df   AIC   BIC  Chisq Chisq diff   RMSEA Df diff Pr(&gt;Chisq)  \nm.conf 38 11239 11424 72.203                                        \nm.metr 44 11243 11406 88.153      15.95 0.10515       6    0.01402 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nfitMeasures(m.metr,\"cfi\")-fitMeasures(m.conf,\"cfi\") # (delta cfi)\n\n   cfi \n-0.008 \n\nfitMeasures(m.metr,\"bic\")-fitMeasures(m.conf,\"bic\") # (delta BIC)\n\n    bic \n-18.272 \n\n# ANY COMMENTS?"
  },
  {
    "objectID": "slides/04_invariance.html#scalar-invariance-1",
    "href": "slides/04_invariance.html#scalar-invariance-1",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Scalar invariance (1)",
    "text": "Scalar invariance (1)\n\n# Model of Scalar invariance\nm.scal&lt;-cfa(model,dmg,group=\"diagnosis\",\n            group.equal=c(\"loadings\",\"intercepts\"))\n# Inspection of fit indices\nfitMeasures(m.scal,c(\"chisq\",\"df\",\"rmsea\",\"cfi\",\"nnfi\"))\n\n  chisq      df   rmsea     cfi    nnfi \n144.667  50.000   0.112   0.920   0.910 \n\n# ANY COMMENTS?"
  },
  {
    "objectID": "slides/04_invariance.html#scalar-invariance-2",
    "href": "slides/04_invariance.html#scalar-invariance-2",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Scalar invariance (2)",
    "text": "Scalar invariance (2)\n\n# Evaluation of Scalar invariance\nfitMeasures(m.scal,c(\"chisq\",\"df\",\"rmsea\",\"cfi\",\"nnfi\"))\n\n  chisq      df   rmsea     cfi    nnfi \n144.667  50.000   0.112   0.920   0.910 \n\nanova(m.scal,m.metr)\n\n\nChi-Squared Difference Test\n\n       Df   AIC   BIC   Chisq Chisq diff   RMSEA Df diff Pr(&gt;Chisq)    \nm.metr 44 11243 11406  88.153                                          \nm.scal 50 11287 11428 144.667     56.513 0.23691       6  2.292e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nfitMeasures(m.scal,\"cfi\")-fitMeasures(m.metr,\"cfi\")\n\n   cfi \n-0.043 \n\nfitMeasures(m.scal,\"bic\")-fitMeasures(m.metr,\"bic\")\n\n   bic \n22.291 \n\n# ANY COMMENTS?  ... Global Scalar invariance is not satisfactory\n# ... let's try with Partial Scalar invariance"
  },
  {
    "objectID": "slides/04_invariance.html#inspection-of-equality-constraints",
    "href": "slides/04_invariance.html#inspection-of-equality-constraints",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Inspection of equality constraints",
    "text": "Inspection of equality constraints\n\nlavTestScore(m.scal)$uni\n\n\n\n\nunivariate score tests:\n\n     lhs op   rhs     X2 df p.value\n1   .p2. == .p31.  0.419  1   0.517\n2   .p3. == .p32.  0.335  1   0.563\n3   .p4. == .p33.  2.389  1   0.122\n4   .p6. == .p35.  7.026  1   0.008\n5   .p7. == .p36.  0.072  1   0.789\n6   .p8. == .p37.  0.000  1   0.988\n7  .p20. == .p49.  8.342  1   0.004\n8  .p21. == .p50. 42.173  1   0.000\n9  .p22. == .p51.  2.691  1   0.101\n10 .p23. == .p52. 11.089  1   0.001\n11 .p24. == .p53.  2.042  1   0.153\n12 .p25. == .p54.  3.555  1   0.059\n13 .p26. == .p55.  1.018  1   0.313\n14 .p27. == .p56.  3.018  1   0.082\n\n\n\n# From a first analysis, we can see that the intercept of the variable \"Sim\"\n# (constraint p21 == p50) has a high Modification Index\n# ... freeing this parameter results in an improved fit\n# (see parTable(m.scal), column id, to \"find the meaning\" of p21 and p50)\n# Let's build a model of Partial Metric invariance by freeing the intercept of \"Sim\" ..."
  },
  {
    "objectID": "slides/04_invariance.html#partial-scalar-invariance-1",
    "href": "slides/04_invariance.html#partial-scalar-invariance-1",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Partial Scalar invariance (1)",
    "text": "Partial Scalar invariance (1)\n\nm.scal.P=cfa(model,dmg,group=\"diagnosis\",\n             group.equal=c(\"loadings\",\"intercepts\"),\n             group.partial=\"Sim~1\")\n# Inspection of fit indices\nfitMeasures(m.scal.P,c(\"chisq\",\"df\",\"rmsea\",\"cfi\",\"nnfi\"))\n\n  chisq      df   rmsea     cfi    nnfi \n100.174  49.000   0.083   0.957   0.950 \n\n# ANY COMMENTS?\n# What model can we now compare with the\n# Partial Invariance model?"
  },
  {
    "objectID": "slides/04_invariance.html#partial-scalar-invariance-2",
    "href": "slides/04_invariance.html#partial-scalar-invariance-2",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Partial Scalar invariance (2)",
    "text": "Partial Scalar invariance (2)\n\n# Evaluation. Partial Scalar invariance\nanova(m.scal.P,m.metr) # Note: Comparison model Metric invariance\n\n\nChi-Squared Difference Test\n\n         Df   AIC   BIC   Chisq Chisq diff    RMSEA Df diff Pr(&gt;Chisq)  \nm.metr   44 11243 11406  88.153                                         \nm.scal.P 49 11245 11389 100.174     12.021 0.096752       5     0.0345 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nfitMeasures(m.scal.P,\"cfi\")-fitMeasures(m.metr,\"cfi\")\n\n   cfi \n-0.006 \n\nfitMeasures(m.scal.P,\"bic\")-fitMeasures(m.metr,\"bic\")\n\n    bic \n-16.498 \n\n# Partial Scalar invariance is satisfactory\n# and now becomes our reference model\n# Question: How can we interpret this result?"
  },
  {
    "objectID": "slides/04_invariance.html#invariance-of-residuals-of-observed-variables1",
    "href": "slides/04_invariance.html#invariance-of-residuals-of-observed-variables1",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Invariance of Residuals of observed variables(1)",
    "text": "Invariance of Residuals of observed variables(1)\n\n# Note: parameter \"Sim~1\" remains free\nm.rvo=cfa(model,dmg,group=\"diagnosis\",\n          group.equal=c(\"loadings\",\"intercepts\",\"residuals\"),\n          group.partial=\"Sim~1\") #Note that this is still here\n# Inspection of fit indices\nfitMeasures(m.rvo,c(\"chisq\",\"df\",\"rmsea\",\"cfi\",\"nnfi\"))\n\n  chisq      df   rmsea     cfi    nnfi \n127.344  57.000   0.091   0.940   0.941"
  },
  {
    "objectID": "slides/04_invariance.html#invariance-of-residuals-of-observed-variables-2",
    "href": "slides/04_invariance.html#invariance-of-residuals-of-observed-variables-2",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Invariance of Residuals of observed variables (2)",
    "text": "Invariance of Residuals of observed variables (2)\n\n# Evaluation of Invariance of Residuals of observed variables\nanova(m.rvo,m.scal.P) # Note: Comparison model Partial Scalar invariance\n\n\nChi-Squared Difference Test\n\n         Df   AIC   BIC  Chisq Chisq diff   RMSEA Df diff Pr(&gt;Chisq)    \nm.scal.P 49 11245 11389 100.17                                          \nm.rvo    57 11256 11371 127.34     27.169 0.12639       8  0.0006609 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nfitMeasures(m.rvo,\"cfi\")-fitMeasures(m.scal.P,\"cfi\")\n\n   cfi \n-0.016 \n\nfitMeasures(m.rvo,\"bic\")-fitMeasures(m.scal.P,\"bic\")\n\n    bic \n-18.461 \n\n# The Invariance of Residuals of observed variables\n#   is not satisfactory. Let's take a look at equality constraints"
  },
  {
    "objectID": "slides/04_invariance.html#inspection-of-equality-constraints-1",
    "href": "slides/04_invariance.html#inspection-of-equality-constraints-1",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Inspection of equality constraints",
    "text": "Inspection of equality constraints\n\nlavTestScore(m.rvo)$uni\n\n\n# (... see complete output )\n# From a first analysis, we can see that\n#  the residuals of variables  “Comp” and “PicComp”\n#  have Modification indices that are\n#  particularly high, so let's free them"
  },
  {
    "objectID": "slides/04_invariance.html#invariance-of-residuals-of-observed-variables-1",
    "href": "slides/04_invariance.html#invariance-of-residuals-of-observed-variables-1",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Invariance of Residuals of observed variables (1)",
    "text": "Invariance of Residuals of observed variables (1)\n\n# Partial Invariance of Residuals of observed variables\nm.rvo.P=cfa(model,dmg,group=\"diagnosis\",\n            group.equal=c(\"loadings\",\"intercepts\",\"residuals\"),\n            group.partial=c(\"Sim~1\",\"PicComp~~PicComp\",\"Comp~~Comp\"))\n# Fit indices\nfitMeasures(m.rvo.P,c(\"chisq\",\"df\",\"rmsea\",\"cfi\",\"nnfi\"))\n\n  chisq      df   rmsea     cfi    nnfi \n102.420  55.000   0.076   0.960   0.959"
  },
  {
    "objectID": "slides/04_invariance.html#partial-invariance-of-residuals-of-observed-variables-2",
    "href": "slides/04_invariance.html#partial-invariance-of-residuals-of-observed-variables-2",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Partial Invariance of Residuals of observed variables (2)",
    "text": "Partial Invariance of Residuals of observed variables (2)\n\n# Evaluation of Partial Invariance of Residuals of observed variables\nanova(m.rvo.P,m.scal.P) # Note: Comparison model Partial Scalar invariance\n\n\nChi-Squared Difference Test\n\n         Df   AIC   BIC  Chisq Chisq diff RMSEA Df diff Pr(&gt;Chisq)\nm.scal.P 49 11245 11389 100.17                                    \nm.rvo.P  55 11235 11357 102.42     2.2458     0       6     0.8958\n\nfitMeasures(m.rvo.P,\"cfi\")-fitMeasures(m.scal.P,\"cfi\")\n\n  cfi \n0.003 \n\nfitMeasures(m.rvo.P,\"bic\")-fitMeasures(m.scal.P,\"bic\")\n\n    bic \n-31.977 \n\n# Paartial Invariance of Residuals of observed variables\n# is satisfactory.\n# Question: What can we say about overall\n# Measurement Invariance of the baseline theoretical model?"
  },
  {
    "objectID": "slides/04_invariance.html#invariance-of-variance-of-latent-variables-1",
    "href": "slides/04_invariance.html#invariance-of-variance-of-latent-variables-1",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Invariance of Variance of latent variables (1)",
    "text": "Invariance of Variance of latent variables (1)\n\nm.vvl=cfa(model,dmg,group=\"diagnosis\",\n          group.equal=c(\"loadings\",\"intercepts\",\"residuals\",\n                        \"lv.variances\"),\n          group.partial=c(\"Sim~1\",\"PicComp~~PicComp\",\"Comp~~Comp\"))\n# Fit indices\nfitMeasures(m.vvl,c(\"chisq\",\"df\",\"rmsea\",\"cfi\",\"nnfi\"))\n\n  chisq      df   rmsea     cfi    nnfi \n105.825  57.000   0.076   0.959   0.959"
  },
  {
    "objectID": "slides/04_invariance.html#invariance-of-variance-of-latent-variables-2",
    "href": "slides/04_invariance.html#invariance-of-variance-of-latent-variables-2",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Invariance of Variance of latent variables (2)",
    "text": "Invariance of Variance of latent variables (2)\n\n# Evaluation of Invariance of latent variables\nanova(m.vvl,m.rvo.P)\n\n\nChi-Squared Difference Test\n\n        Df   AIC   BIC  Chisq Chisq diff    RMSEA Df diff Pr(&gt;Chisq)\nm.rvo.P 55 11235 11357 102.42                                       \nm.vvl   57 11234 11349 105.83     3.4056 0.068449       2     0.1822\n\nfitMeasures(m.vvl,\"cfi\")-fitMeasures(m.rvo.P,\"cfi\")\n\n   cfi \n-0.001 \n\nfitMeasures(m.vvl,\"bic\")-fitMeasures(m.rvo.P,\"bic\")\n\n   bic \n-8.002 \n\n# OK, this looks good!"
  },
  {
    "objectID": "slides/04_invariance.html#invariance-of-covariance-of-latent-variables-1",
    "href": "slides/04_invariance.html#invariance-of-covariance-of-latent-variables-1",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Invariance of Covariance of latent variables (1)",
    "text": "Invariance of Covariance of latent variables (1)\n\nm.cvl=cfa(model,dmg,group=\"diagnosis\",\n          group.equal=c(\"loadings\",\"intercepts\"\n                        ,\"residuals\",\"lv.variances\",\"lv.covariances\"),\n          group.partial=c(\"Sim~1\",\"PicComp~~PicComp\",\"Comp~~Comp\"))\n# Fit indices\nfitMeasures(m.cvl,c(\"chisq\",\"df\",\"rmsea\",\"cfi\",\"nnfi\"))\n\n  chisq      df   rmsea     cfi    nnfi \n106.412  58.000   0.075   0.959   0.960"
  },
  {
    "objectID": "slides/04_invariance.html#invariance-of-covariance-of-latent-variables2",
    "href": "slides/04_invariance.html#invariance-of-covariance-of-latent-variables2",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Invariance of Covariance of latent variables(2)",
    "text": "Invariance of Covariance of latent variables(2)\n\n# Evaluation of Invariance of Covariance of latent variables\nanova(m.cvl,m.vvl)\n\n\nChi-Squared Difference Test\n\n      Df   AIC   BIC  Chisq Chisq diff RMSEA Df diff Pr(&gt;Chisq)\nm.vvl 57 11234 11349 105.83                                    \nm.cvl 58 11233 11344 106.41    0.58642     0       1     0.4438\n\nfitMeasures(m.cvl,\"cfi\")-fitMeasures(m.vvl,\"cfi\")\n\ncfi \n  0 \n\nfitMeasures(m.cvl,\"bic\")-fitMeasures(m.vvl,\"bic\")\n\n   bic \n-5.117 \n\n# OK, we're almost there!"
  },
  {
    "objectID": "slides/04_invariance.html#invariance-of-means-of-latent-variables-1",
    "href": "slides/04_invariance.html#invariance-of-means-of-latent-variables-1",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Invariance of Means of latent variables (1)",
    "text": "Invariance of Means of latent variables (1)\n\n# last step\nm.med=cfa(model,dmg,group=\"diagnosis\",\n          group.equal=c(\"loadings\",\"intercepts\"\n                        ,\"residuals\",\"lv.variances\",\"lv.covariances\",\n                        \"means\"),\n          group.partial=c(\"Sim~1\",\"PicComp~~PicComp\",\"Comp~~Comp\"))\n# Fit indices\nfitMeasures(m.med,c(\"chisq\",\"df\",\"rmsea\",\"cfi\",\"nnfi\"))\n\n  chisq      df   rmsea     cfi    nnfi \n110.933  60.000   0.075   0.957   0.960"
  },
  {
    "objectID": "slides/04_invariance.html#invariance-of-means-of-latent-variables-2",
    "href": "slides/04_invariance.html#invariance-of-means-of-latent-variables-2",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Invariance of Means of latent variables (2)",
    "text": "Invariance of Means of latent variables (2)\n\n# Evaluation of Invariance of Means of latent variables\nanova(m.med,m.cvl)\n\n\nChi-Squared Difference Test\n\n      Df   AIC   BIC  Chisq Chisq diff    RMSEA Df diff Pr(&gt;Chisq)\nm.cvl 58 11233 11344 106.41                                       \nm.med 60 11234 11337 110.93     4.5212 0.091673       2     0.1043\n\nfitMeasures(m.med,\"cfi\")-fitMeasures(m.cvl,\"cfi\")\n\n   cfi \n-0.002 \n\nfitMeasures(m.med,\"bic\")-fitMeasures(m.cvl,\"bic\")\n\n   bic \n-6.886 \n\n# This last model is also satisfactory\n# ANY COMMENTS?"
  },
  {
    "objectID": "slides/04_invariance.html#summing-up",
    "href": "slides/04_invariance.html#summing-up",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Summing up",
    "text": "Summing up\n\n\n\n\n\nModels\nnpar\ndf\nchisq\ncfi\ntli\nnnfi\nagfi\nsrmr\nrmsea\nbic\naic\n\n\n\n\nManics\n17\n19\n54.05\n0.95\n0.92\n0.92\n0.84\n0.05\n0.11\n5590.65\n5539.47\n\n\nNorming\n17\n19\n18.15\n1\n1\n1\n0.94\n0.03\n0\n5718.64\n5667.46\n\n\nConfigural\n50\n38\n72.2\n0.97\n0.96\n0.96\n0.98\n0.04\n0.08\n11424.11\n11238.93\n\n\nMetric\n44\n44\n88.15\n0.96\n0.95\n0.95\n0.98\n0.06\n0.08\n11405.84\n11242.88\n\n\nScalar\n38\n50\n144.67\n0.92\n0.91\n0.91\n0.97\n0.08\n0.11\n11428.13\n11287.39\n\n\nScalar Partial\n39\n49\n100.17\n0.96\n0.95\n0.95\n0.98\n0.07\n0.08\n11389.34\n11244.9\n\n\nResidual Variances\n31\n57\n127.34\n0.94\n0.94\n0.94\n0.98\n0.08\n0.09\n11370.88\n11256.07\n\n\nResidual Variances Partial\n33\n55\n102.42\n0.96\n0.96\n0.96\n0.98\n0.07\n0.08\n11357.37\n11235.14\n\n\nLatent Variances\n31\n57\n105.83\n0.96\n0.96\n0.96\n0.98\n0.09\n0.08\n11349.36\n11234.55\n\n\nLatent Covariances\n30\n58\n106.41\n0.96\n0.96\n0.96\n0.98\n0.09\n0.07\n11344.25\n11233.13\n\n\nLatent Means\n28\n60\n110.93\n0.96\n0.96\n0.96\n0.98\n0.09\n0.08\n11337.36\n11233.66\n\n\n\n\n\nInterpretations, comments, or questions?"
  },
  {
    "objectID": "slides/04_invariance.html#to-combine-usefulness-and-fun",
    "href": "slides/04_invariance.html#to-combine-usefulness-and-fun",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "To combine usefulness and fun …",
    "text": "To combine usefulness and fun …\nGraphical representation of the Configural Invariance model with standardized parameters (attached R code)\n\nExcercise: Graphically represent the former invariance models using the function semPaths of the package semPlot"
  },
  {
    "objectID": "slides/04_invariance.html#invariance-of-regression-coefficients",
    "href": "slides/04_invariance.html#invariance-of-regression-coefficients",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Invariance of regression coefficients",
    "text": "Invariance of regression coefficients\nTest of multigroup invariance can also be used to compare differences in the regression coefficients of two or more groups."
  },
  {
    "objectID": "slides/04_invariance.html#invariance-of-regression-coefficients-1",
    "href": "slides/04_invariance.html#invariance-of-regression-coefficients-1",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Invariance of regression coefficients",
    "text": "Invariance of regression coefficients\nFollowing the same steps of the previous example, we can add the \"regressions\" to the group.equal argument.\n\nfitPreg &lt;- sem(path, d, group = \"group\",\n               group.equal = \"regressions\")\n\nYou can apply this to a path model with manifest variables only or to a full SEM after measurement invariance is tested.\nQUESTIONS? LET'S SEE THE \"code\""
  },
  {
    "objectID": "slides/04_invariance.html#useful-references",
    "href": "slides/04_invariance.html#useful-references",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Useful references",
    "text": "Useful references\n\nBeaujean, Freeman, Youngstrom & Carlson (2012). The structure of cognitive abilities in youths with manic symptoms: a factorial invariance study. Assessment, 19, 462 - 471\n\nNon-invariance materials were directly taken from the wonderful blogpost of Julia Rohrer. READ IT!\nHow much is invariance disregarded?\nProtzko’s humorous preprint on what we can actually claim with measurement invariance…without good measures!\nlavaan.ugent.be/tutorial/groups.html\nwww.structuralequations.com/\n\nbut also some controversies\n… more controversies"
  },
  {
    "objectID": "slides/04_invariance.html#contact",
    "href": "slides/04_invariance.html#contact",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "Contact",
    "text": "Contact\ntommaso.feraco@unipd.it"
  },
  {
    "objectID": "slides/04_invariance.html#references",
    "href": "slides/04_invariance.html#references",
    "title": "Evaluating Measurement and Structural Invariance via Multi-Group Analysis",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "slides/05_ordinal.html#credits",
    "href": "slides/05_ordinal.html#credits",
    "title": "SEM with ordinal variables",
    "section": "Credits",
    "text": "Credits\nCredits to Prof. Massimiliano Pastore for the original slides."
  },
  {
    "objectID": "slides/05_ordinal.html#outline",
    "href": "slides/05_ordinal.html#outline",
    "title": "SEM with ordinal variables",
    "section": "Outline",
    "text": "Outline\n\nIntroduction\nIn lavaan\nModel fit\nMG-CFA with ordinal data"
  },
  {
    "objectID": "slides/05_ordinal.html#introduction",
    "href": "slides/05_ordinal.html#introduction",
    "title": "SEM with ordinal variables",
    "section": "Introduction",
    "text": "Introduction\nIn psychology we rarely have data that are normally distributed or that follow a continuous distribution. Our data are probably ordinal or the consequence of ordinal/dichotomous processes:\n\nset.seed(42); n=10000; items = 30;\nscore &lt;- rbinom(n,items, rnorm(n,.80,.10))\n\n\nCOMMENTS?"
  },
  {
    "objectID": "slides/05_ordinal.html#introduction-1",
    "href": "slides/05_ordinal.html#introduction-1",
    "title": "SEM with ordinal variables",
    "section": "Introduction",
    "text": "Introduction\nHowever, we postulate that they are generated from continuous normal latent distributions\n\nCOMMENTS?"
  },
  {
    "objectID": "slides/05_ordinal.html#likert-scales",
    "href": "slides/05_ordinal.html#likert-scales",
    "title": "SEM with ordinal variables",
    "section": "Likert scales",
    "text": "Likert scales\nThis also applies to Liker scales, where the difference between reporting a score of 1 or 2, and the difference between reporting a score of 2 or 3 is not the same!"
  },
  {
    "objectID": "slides/05_ordinal.html#the-adaptability-data",
    "href": "slides/05_ordinal.html#the-adaptability-data",
    "title": "SEM with ordinal variables",
    "section": "The adaptability data",
    "text": "The adaptability data\nAnd in real data they are often not normally distributed"
  },
  {
    "objectID": "slides/05_ordinal.html#wrong-correlations",
    "href": "slides/05_ordinal.html#wrong-correlations",
    "title": "SEM with ordinal variables",
    "section": "Wrong correlations",
    "text": "Wrong correlations\nUnfortunately, when we use data that follow discrete distributions and treat them as they were continuous, we can fail to recreate true correlation matrices accurately. That’s why you usually use polychoric correlations when you calculate correlations with dichotomous or ordinal variables.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData were generated from a multivariate normal distribution using MASS::mvrnorm and then manually truncated on a 3-point scale\nThis, of course, has consequences on SEM parameters, which are based on covariance"
  },
  {
    "objectID": "slides/05_ordinal.html#in-lavaan-and-sem",
    "href": "slides/05_ordinal.html#in-lavaan-and-sem",
    "title": "SEM with ordinal variables",
    "section": "In lavaan and SEM",
    "text": "In lavaan and SEM\nTo estimate a model treating items/observations as ordinal data, we need to change the estimationd method - ML is not always accurate with ordinal data (especially with few categories) - lavaan, when ordered is TRUE, automatically use DWLS (diagonally weighted least squares) - A great alternative is ULS, which usually performs better, but has more convergence problems - We can also use robust ML alternatives, like MLR - Other available estimators: lavaan tutorial on estimators (see course site)"
  },
  {
    "objectID": "slides/05_ordinal.html#how-to-fit-a-cfa-with-ordinal-data",
    "href": "slides/05_ordinal.html#how-to-fit-a-cfa-with-ordinal-data",
    "title": "SEM with ordinal variables",
    "section": "How to fit a CFA with ordinal data",
    "text": "How to fit a CFA with ordinal data\n\nlibrary(lavaan)\n\n\n# THE MODEL IS SPECIFIED AS USUAL\nmOrd &lt;- \"\ncb =~ Adaptability_1 + Adaptability_2 + Adaptability_3 + \n      Adaptability_4 + Adaptability_5 + Adaptability_6\nem =~ Adaptability_7 + Adaptability_8 + Adaptability_9\nem ~~ cb\n\"\n# WE JUST NEED TO ADD\nfitOrd &lt;- sem(mOrd, D.ad, std.lv=T,\n              estimator = \"ULS\", # optional\n              ordered = colnames(D.ad)) # the list of ord vars\n#             ordered = T) # or just \"TRUE\" if all ordered"
  },
  {
    "objectID": "slides/05_ordinal.html#results-1",
    "href": "slides/05_ordinal.html#results-1",
    "title": "SEM with ordinal variables",
    "section": "Results (1)",
    "text": "Results (1)\n\ntemp = capture.output(summary(fitOrd, std=T))\ncat(c(temp[1:21], \"[...]\"), sep = \"\\n\")\n\nlavaan 0.6-19 ended normally after 16 iterations\n\n  Estimator                                        ULS\n  Optimization method                           NLMINB\n  Number of model parameters                        64\n\n                                                  Used       Total\n  Number of observations                          1044        1083\n\nModel Test User Model:\n                                                      \n  Test statistic                                73.746\n  Degrees of freedom                                26\n  P-value (Unknown)                                 NA\n\nParameter Estimates:\n\n  Parameterization                               Delta\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model        Unstructured\n[...]"
  },
  {
    "objectID": "slides/05_ordinal.html#results-2",
    "href": "slides/05_ordinal.html#results-2",
    "title": "SEM with ordinal variables",
    "section": "Results (2)",
    "text": "Results (2)\n\n\n[...]\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  cb =~                                                                 \n    Adaptability_1    0.659    0.021   30.831    0.000    0.659    0.659\n    Adaptability_2    0.659    0.021   30.841    0.000    0.659    0.659\n    Adaptability_3    0.664    0.021   30.983    0.000    0.664    0.664\n    Adaptability_4    0.551    0.020   26.957    0.000    0.551    0.551\n    Adaptability_5    0.619    0.021   29.486    0.000    0.619    0.619\n    Adaptability_6    0.553    0.020   27.012    0.000    0.553    0.553\n  em =~                                                                 \n    Adaptability_7    0.642    0.026   24.949    0.000    0.642    0.642\n    Adaptability_8    0.671    0.026   25.513    0.000    0.671    0.671\n    Adaptability_9    0.699    0.027   25.983    0.000    0.699    0.699\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  cb ~~                                                                 \n    em                0.587    0.022   26.729    0.000    0.587    0.587\n[...]"
  },
  {
    "objectID": "slides/05_ordinal.html#results-3",
    "href": "slides/05_ordinal.html#results-3",
    "title": "SEM with ordinal variables",
    "section": "Results (3)",
    "text": "Results (3)\n\n\n[...]\n\nThresholds:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n    Adaptblty_1|t1   -2.114    0.031  -68.285    0.000   -2.114   -2.114\n    Adaptblty_1|t2   -1.647    0.031  -53.181    0.000   -1.647   -1.647\n    Adaptblty_1|t3   -1.056    0.031  -34.089    0.000   -1.056   -1.056\n    Adaptblty_1|t4   -0.320    0.031  -10.331    0.000   -0.320   -0.320\n    Adaptblty_1|t5    0.495    0.031   15.982    0.000    0.495    0.495\n    Adaptblty_1|t6    1.181    0.031   38.145    0.000    1.181    1.181\n    Adaptblty_2|t1   -2.071    0.031  -66.899    0.000   -2.071   -2.071\n    Adaptblty_2|t2   -1.421    0.031  -45.908    0.000   -1.421   -1.421\n    Adaptblty_2|t3   -0.794    0.031  -25.642    0.000   -0.794   -0.794\n    Adaptblty_2|t4   -0.188    0.031   -6.084    0.000   -0.188   -0.188\n    Adaptblty_2|t5    0.492    0.031   15.895    0.000    0.492    0.492\n    Adaptblty_2|t6    1.257    0.031   40.590    0.000    1.257    1.257\n    Adaptblty_3|t1   -1.930    0.031  -62.322    0.000   -1.930   -1.930\n    Adaptblty_3|t2   -1.415    0.031  -45.696    0.000   -1.415   -1.415\n    Adaptblty_3|t3   -0.858    0.031  -27.715    0.000   -0.858   -0.858\n    Adaptblty_3|t4   -0.250    0.031   -8.070    0.000   -0.250   -0.250\n    Adaptblty_3|t5    0.350    0.031   11.316    0.000    0.350    0.350\n    Adaptblty_3|t6    1.162    0.031   37.529    0.000    1.162    1.162\n[...]"
  },
  {
    "objectID": "slides/05_ordinal.html#results-4",
    "href": "slides/05_ordinal.html#results-4",
    "title": "SEM with ordinal variables",
    "section": "Results (4)",
    "text": "Results (4)\n\n\n[...]\n    Adaptblty_4|t1   -1.962    0.031  -63.351    0.000   -1.962   -1.962\n    Adaptblty_4|t2   -1.476    0.031  -47.680    0.000   -1.476   -1.476\n    Adaptblty_4|t3   -0.817    0.031  -26.393    0.000   -0.817   -0.817\n    Adaptblty_4|t4   -0.257    0.031   -8.310    0.000   -0.257   -0.257\n    Adaptblty_4|t5    0.295    0.031    9.518    0.000    0.295    0.295\n    Adaptblty_4|t6    1.094    0.031   35.332    0.000    1.094    1.094\n    Adaptblty_5|t1   -1.978    0.031  -63.891    0.000   -1.978   -1.978\n    Adaptblty_5|t2   -1.408    0.031  -45.486    0.000   -1.408   -1.408\n    Adaptblty_5|t3   -0.781    0.031  -25.219    0.000   -0.781   -0.781\n    Adaptblty_5|t4   -0.196    0.031   -6.321    0.000   -0.196   -0.196\n    Adaptblty_5|t5    0.397    0.031   12.812    0.000    0.397    0.397\n    Adaptblty_5|t6    1.081    0.031   34.912    0.000    1.081    1.081\n    Adaptblty_6|t1   -1.705    0.031  -55.076    0.000   -1.705   -1.705\n    Adaptblty_6|t2   -1.186    0.031  -38.302    0.000   -1.186   -1.186\n    Adaptblty_6|t3   -0.654    0.031  -21.106    0.000   -0.654   -0.654\n    Adaptblty_6|t4   -0.055    0.031   -1.784    0.074   -0.055   -0.055\n    Adaptblty_6|t5    0.519    0.031   16.776    0.000    0.519    0.519\n    Adaptblty_6|t6    1.211    0.031   39.097    0.000    1.211    1.211\n[...]\n[...]"
  },
  {
    "objectID": "slides/05_ordinal.html#thresholds-1",
    "href": "slides/05_ordinal.html#thresholds-1",
    "title": "SEM with ordinal variables",
    "section": "Thresholds (1)",
    "text": "Thresholds (1)\n\nWe can assume that a discrete variable \\(x\\) (expressed with \\(k\\) ordered categories) represents an approximation of a continuous latent variable \\(\\xi\\), normally distributed with mean 0.\nTherefore, when we observe \\(x = i\\), it means that the true corresponding value \\(\\xi\\) is ranging between two values, i.e.\n\n\\[\n\\alpha_{i-1} &lt; \\xi \\leq \\alpha_i\n\\] where \\(\\alpha_0 = - \\infty, \\alpha_1 &lt; \\alpha_2 &lt; \\dots &lt; \\alpha_{k-1}\\) e \\(\\alpha_k = +\\infty\\) are the thresholds - Consequenlty we will have that, given a discrete ordered variable with \\(k\\) possible values, there are \\(k - 1\\) unknown thresholds."
  },
  {
    "objectID": "slides/05_ordinal.html#thresholds-2",
    "href": "slides/05_ordinal.html#thresholds-2",
    "title": "SEM with ordinal variables",
    "section": "Thresholds (2)",
    "text": "Thresholds (2)\nThresholds represent the link between the (continuous) latent variable \\(\\xi\\) and the observed values (on a discrete scale).\nFor example, the item Adaptability_1\n\n\n[1] -2.11 -1.65 -1.06 -0.32  0.49  1.18\n\n\nThat we can manually compute as:\n\nround(qnorm(cumsum(table(D.ad$Adaptability_1)) /\n             sum(table(D.ad$Adaptability_1))),2)\n\n    1     2     3     4     5     6     7 \n-2.12 -1.65 -1.06 -0.32  0.49  1.18   Inf"
  },
  {
    "objectID": "slides/05_ordinal.html#results-5",
    "href": "slides/05_ordinal.html#results-5",
    "title": "SEM with ordinal variables",
    "section": "Results (5)",
    "text": "Results (5)\n\n\n[...]\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .Adaptability_1    0.566                               0.566    0.566\n   .Adaptability_2    0.565                               0.565    0.565\n   .Adaptability_3    0.559                               0.559    0.559\n   .Adaptability_4    0.696                               0.696    0.696\n   .Adaptability_5    0.616                               0.616    0.616\n   .Adaptability_6    0.695                               0.695    0.695\n   .Adaptability_7    0.588                               0.588    0.588\n   .Adaptability_8    0.550                               0.550    0.550\n   .Adaptability_9    0.511                               0.511    0.511\n    cb                1.000                               1.000    1.000\n    em                1.000                               1.000    1.000\n\n[...]"
  },
  {
    "objectID": "slides/05_ordinal.html#model-fit",
    "href": "slides/05_ordinal.html#model-fit",
    "title": "SEM with ordinal variables",
    "section": "Model fit",
    "text": "Model fit\nThis works as usual\n\nfi &lt;- c(\"npar\", \"df\", \"chisq\", \n        \"cfi\", \"tli\", \"nnfi\", \"agfi\", \n        \"srmr\", \"rmsea\", \"bic\", \"aic\")\nfitmeasures(fitOrd, fit.measures = fi)\n# OR inspect(fitOrd, \"fit\")[fi]\n\n\n\n    npar       df    chisq \n64.00000 26.00000 73.74574 \n\n\n      cfi       tli      nnfi      agfi \n0.9883022 0.9838030 0.9838030 0.9964375 \n\n\n      srmr      rmsea        bic        aic \n0.03963876 0.04196029         NA         NA \n\n\nBUT YOU CANNOT INTERPRET THEM AS WE USED TO DO!"
  },
  {
    "objectID": "slides/05_ordinal.html#model-fit-references",
    "href": "slides/05_ordinal.html#model-fit-references",
    "title": "SEM with ordinal variables",
    "section": "Model fit, references",
    "text": "Model fit, references\nSome references for model fit with ordinal data: - RMSEA (doi:10.1080/10705511.2019.1611434) tends to reject models with large datasets and 5-point scales - CFI and TLI tend to overestimate model fit - SRMR seems to be less biased\nBut there are many contradictory suggestions and it is not easy to navigate them. Look for what you need as simulation studies depend on many variables.\nThis (doi:10.1027/2698-1866/a000034) might be a helpful summary/reflection."
  },
  {
    "objectID": "slides/05_ordinal.html#reviewer-2",
    "href": "slides/05_ordinal.html#reviewer-2",
    "title": "SEM with ordinal variables",
    "section": "Reviewer 2",
    "text": "Reviewer 2"
  },
  {
    "objectID": "slides/05_ordinal.html#prerequisites",
    "href": "slides/05_ordinal.html#prerequisites",
    "title": "SEM with ordinal variables",
    "section": "Prerequisites",
    "text": "Prerequisites\nWhen we test multigroup invariance with ordinal data we assume that the THRESHOLDS are also equal between the two groups, but before running the analysis, remember: - the number of parameters is higher than with continuous data…and you split the data in two or more parts! Be sure you have enough data in each group - all the observed indicators hold the same categories in each group, otherwise you cannot fit the model"
  },
  {
    "objectID": "slides/05_ordinal.html#steps",
    "href": "slides/05_ordinal.html#steps",
    "title": "SEM with ordinal variables",
    "section": "Steps",
    "text": "Steps\nThe steps that you should follow fo MG-CFA with ordinal data are slightly different: - Baseline model, as the configural model - Equal thresholds model, you should start by forcing the thresholds to be equal across groups - Equal loadings and thresholds model, only now you can fix the loadings to be equal across groups"
  },
  {
    "objectID": "slides/05_ordinal.html#in-r",
    "href": "slides/05_ordinal.html#in-r",
    "title": "SEM with ordinal variables",
    "section": "In R",
    "text": "In R\nI use again the adaptability items. I manually added a group variable.\n\nD.ad$group &lt;- c(rep(\"G1\", 428), rep(\"G2\", 1083-428))\n# 1. FIT THE BASELINE/CONFIGURAL MODEL\nfConf &lt;- sem(mOrd, D.ad, std.lv=T, estimator = \"ULS\",\n             ordered = T, group = \"group\")\n# 2. FIT THE FIXED THRESHOLDS MODEL\nfTresh&lt;- sem(mOrd, D.ad, std.lv=T, estimator = \"ULS\",\n             ordered = T, group = \"group\",\n             group.equal = c(\"thresholds\"))\n# 3. FIT THE FIXED LOADINGS MODEL\nfLoad &lt;- sem(mOrd, D.ad, std.lv=T, estimator = \"ULS\",\n             ordered = T, group = \"group\",\n             group.equal = c(\"thresholds\", \"loadings\"))"
  },
  {
    "objectID": "slides/05_ordinal.html#model-fit-comparison",
    "href": "slides/05_ordinal.html#model-fit-comparison",
    "title": "SEM with ordinal variables",
    "section": "Model fit comparison",
    "text": "Model fit comparison\n\nfitTable &lt;- rbind(fitmeasures(fConf, fi),\n                  fitmeasures(fTresh, fi),\n                  fitmeasures(fLoad, fi))\n\n\n\n\n\nnpar\ndf\nchisq\ncfi\ntli\nnnfi\nagfi\nsrmr\nrmsea\nbic\naic\n\n\n\n\nbaseline\n128\n52\n91.652\n0.990\n0.987\n0.987\n0.996\n0.044\n0.038\nNA\nNA\n\n\nthresholds\n85\n95\n166.552\n0.983\n0.987\n0.987\n0.996\n0.044\n0.038\nNA\nNA\n\n\nloadings\n78\n102\n173.785\n0.983\n0.988\n0.988\n0.996\n0.046\n0.037\nNA\nNA"
  },
  {
    "objectID": "slides/05_ordinal.html#model-results",
    "href": "slides/05_ordinal.html#model-results",
    "title": "SEM with ordinal variables",
    "section": "Model results",
    "text": "Model results\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGroup 1\n\n\n\nGroup 2\n\n\n\nlhs\nop\nrhs\nest\n||\nlhs\nop\nrhs\nest\n\n\n\n\nLoadings\n\n\ncb\n=~\nAdaptability_1\n0.69\n||\ncb\n=~\nAdaptability_1\n0.64\n\n\ncb\n=~\nAdaptability_2\n0.69\n||\ncb\n=~\nAdaptability_2\n0.64\n\n\ncb\n=~\nAdaptability_3\n0.70\n||\ncb\n=~\nAdaptability_3\n0.64\n\n\ncb\n=~\nAdaptability_4\n0.54\n||\ncb\n=~\nAdaptability_4\n0.56\n\n\ncb\n=~\nAdaptability_5\n0.66\n||\ncb\n=~\nAdaptability_5\n0.59\n\n\ncb\n=~\nAdaptability_6\n0.65\n||\ncb\n=~\nAdaptability_6\n0.49\n\n\nem\n=~\nAdaptability_7\n0.66\n||\nem\n=~\nAdaptability_7\n0.63\n\n\nem\n=~\nAdaptability_8\n0.67\n||\nem\n=~\nAdaptability_8\n0.67\n\n\nem\n=~\nAdaptability_9\n0.73\n||\nem\n=~\nAdaptability_9\n0.67\n\n\nLatent covariance\n\n\ncb\n~~\nem\n0.62\n||\ncb\n~~\nem\n0.56\n\n\nThresholds\n\n\nAdaptability_1\n|\nt1\n-2.13\n||\nAdaptability_1\n|\nt1\n-2.11\n\n\nAdaptability_1\n|\nt2\n-1.69\n||\nAdaptability_1\n|\nt2\n-1.62\n\n\nAdaptability_1\n|\nt3\n-1.06\n||\nAdaptability_1\n|\nt3\n-1.05\n\n\nAdaptability_1\n|\nt4\n-0.36\n||\nAdaptability_1\n|\nt4\n-0.30\n\n\nAdaptability_1\n|\nt5\n0.52\n||\nAdaptability_1\n|\nt5\n0.48\n\n\nAdaptability_1\n|\nt6\n1.14\n||\nAdaptability_1\n|\nt6\n1.21"
  },
  {
    "objectID": "slides/05_ordinal.html#additional-materials",
    "href": "slides/05_ordinal.html#additional-materials",
    "title": "SEM with ordinal variables",
    "section": "Additional materials",
    "text": "Additional materials\n\nSvetina et al. (doi:10.1080/10705511.2019.1602776) tutorial, suggestions, and model fit recommendations for MG-CFA with ordinal data\nEnrico Perinelli held a psicostat meeting on the topic following Svetina et al.’s code"
  },
  {
    "objectID": "slides/05_ordinal.html#contacts",
    "href": "slides/05_ordinal.html#contacts",
    "title": "SEM with ordinal variables",
    "section": "Contacts",
    "text": "Contacts\ntommaso.feraco@unipd.it"
  },
  {
    "objectID": "extras/ex90_power_misc.html#outline",
    "href": "extras/ex90_power_misc.html#outline",
    "title": "Power analysis for path and SEM models",
    "section": "Outline",
    "text": "Outline\n\nPower\nfor loops\nPath analysis — an example\nPower for model selection"
  },
  {
    "objectID": "extras/ex90_power_misc.html#power",
    "href": "extras/ex90_power_misc.html#power",
    "title": "Power analysis for path and SEM models",
    "section": "Power",
    "text": "Power\nWe can define power as the probability to reject the null hypothesis (\\(H_0\\)) when the hypothesized alternative hypothesis (\\(H_{1}\\)) is true.\nIt usually depends on:\n\nPrecision of the measurements\nPrecision of the effects\nSize of the (hypothesized) effect\nSample size\nNumber of effects of interest\n\\(\\alpha\\) level (e.g., .05, or the probability of making a type I error)\n\\(\\beta\\) level (e.g., .80, or the probability of making a type II error)\n\nIf we do not have the power, our results are inconclusive and estimates, in case we reject \\(H_0\\), inflated."
  },
  {
    "objectID": "extras/ex90_power_misc.html#calculating-the-power",
    "href": "extras/ex90_power_misc.html#calculating-the-power",
    "title": "Power analysis for path and SEM models",
    "section": "Calculating the power",
    "text": "Calculating the power\nFor power calculations we can:\n\nApply specific formulas\nUse monograms\nUse apps\n[…]\n\nSimulate data!"
  },
  {
    "objectID": "extras/ex90_power_misc.html#calculating-power-for-sem",
    "href": "extras/ex90_power_misc.html#calculating-power-for-sem",
    "title": "Power analysis for path and SEM models",
    "section": "Calculating power for SEM",
    "text": "Calculating power for SEM\nIn a SEM framework there are many ways to calculate power via simulation. We will only implement it manually in R. Here a list of alternatives:\n\nIf you want to detect specific effects\n\nUse the pwrSEM shiny app (Wang et al., 2021): https://doi.org/10.1177/2515245920918253\n\nUse simsem package (lavaan objects): https://simsem.org/ (see also Beaujean, 2014, chapter 8)\n\n[…]\n\nIf you want to detect model misspecification / fit\n\nUse semPower package\n\nUse the power4SEM shiny app (Jak et al., 2021): https://doi.org/10.3758/s13428-020-01479-0\n\nSatorra & Saris (1985)\n\nUse MBESS functions for power (e.g., ss.aipe.rmsea(); ss.aipe.sem.path(); ss.power.sem())\n\n[…]\n\n\nOr you can apply rules of thumb that recommend either absolute minimum sample sizes (e.g., \\(N = 100\\) or \\(200\\); Boomsma, 1982, 1985) or sample sizes based on model complexity (e.g., \\(n = 5\\)–\\(10\\) per estimated parameter; Bentler & Chou, 1987; \\(n = 3\\)–\\(6\\) per variable; Cattell, 1978) BUT, NO, PLEASE!"
  },
  {
    "objectID": "extras/ex90_power_misc.html#what-is-this",
    "href": "extras/ex90_power_misc.html#what-is-this",
    "title": "Power analysis for path and SEM models",
    "section": "What is this?",
    "text": "What is this?\n\n\nThis is a loop!"
  },
  {
    "objectID": "extras/ex90_power_misc.html#for-loops",
    "href": "extras/ex90_power_misc.html#for-loops",
    "title": "Power analysis for path and SEM models",
    "section": "for loops",
    "text": "for loops\nA fundamental skill that you should possess is doing for (or while) cycles in R. This is crucial for estimating power via simulation, but also for many other ordinary analyses."
  },
  {
    "objectID": "extras/ex90_power_misc.html#what-you-can-do",
    "href": "extras/ex90_power_misc.html#what-you-can-do",
    "title": "Power analysis for path and SEM models",
    "section": "What you can do",
    "text": "What you can do\nWith a for loop you can iterate one or more action along a sequence of values. This values usually go from 1 to N, but can also be character or unordered sequences, or sequences of increasing but random numbers.\n\n\n\nfor(i in 1:3){\n  #Sys.sleep(0.5)\n  print(i)\n  print(\"Well done!\")\n}\n\n[1] 1\n[1] \"Well done!\"\n[1] 2\n[1] \"Well done!\"\n[1] 3\n[1] \"Well done!\"\n\n\n\n\ncomplimento &lt;- c(\"bravo\",\n                 \"very well\",\n                 \"wow\")\nfor(i in complimento){\n  #Sys.sleep(1)\n  print(paste0(i,\n               \"Tommaso\"))\n}\n\n[1] \"bravoTommaso\"\n[1] \"very wellTommaso\"\n[1] \"wowTommaso\"\n\n\n\n\niter &lt;- c(2,4,11)\nfor (i in iter) {\n  #Sys.sleep(0.5)\n  print(4 + i)\n}\n\n[1] 6\n[1] 8\n[1] 15"
  },
  {
    "objectID": "extras/ex90_power_misc.html#more-difficult",
    "href": "extras/ex90_power_misc.html#more-difficult",
    "title": "Power analysis for path and SEM models",
    "section": "…more difficult",
    "text": "…more difficult\n\nrm(list = ls())\niter &lt;- 100\nd &lt;- data.frame(exam = rep(NA, iter),\n                M = rep(NA, iter),\n                X = 1:iter)\nfor (i in 1:iter) {\n  # simulate an exam\n  d$exam[i] &lt;- sample(18:30, 1)\n  # calculate mean at each step\n  d$M[i] &lt;- mean(d$exam, na.rm = TRUE)\n}"
  },
  {
    "objectID": "extras/ex90_power_misc.html#for-loops-for-power-analysis",
    "href": "extras/ex90_power_misc.html#for-loops-for-power-analysis",
    "title": "Power analysis for path and SEM models",
    "section": "for loops for power analysis",
    "text": "for loops for power analysis\nIf we want to run a power analysis via simulation using a for loop, in general we need the following structure and elements:\n\n# A set of basic info\niter = 100 # number of desired iterations (i)\nN = 400 # the sample size we test\npopulation = 1e6\n\n# A population with hypothesized effects\nx = rnorm(population); z = rnorm(population) # predictors\ny = .30*x + .20*z + rnorm(population) # hypothetical model with ES\nd = data.frame(x, y, z)\n\n# A set of objects to store the results\np &lt;- c()\n\n# A model\nm &lt;- \"y ~ x + z\"\n\n# The loop with minimum three parts\nfor (i in 1:iter) {\n  # Data simulation/sampling\n  dfor &lt;- d[sample(1:nrow(d), N), ]\n  # Test\n  fit &lt;- sem(m, dfor)\n  # Storage\n  p[i] &lt;- parameterEstimates(fit)[1, \"pvalue\"]\n}\n\nmean(p &lt; .05) # calculate power\n\nYou can do the same thing with any model (lm, glm, m-clust, meta-analysis…)."
  },
  {
    "objectID": "extras/ex90_power_misc.html#the-question",
    "href": "extras/ex90_power_misc.html#the-question",
    "title": "Power analysis for path and SEM models",
    "section": "The question",
    "text": "The question\nDoes adaptability predict academic achievement?"
  },
  {
    "objectID": "extras/ex90_power_misc.html#a-simple-association",
    "href": "extras/ex90_power_misc.html#a-simple-association",
    "title": "Power analysis for path and SEM models",
    "section": "A simple association",
    "text": "A simple association\nH: adaptability directly influence achievement with an effect = .20.\n\nlibrary(lavaan)\nlibrary(MASS)\n\n# Generate and rename two correlated variables (r = .20)\nCovMat &lt;- lav_matrix_lower2full(c(\n  1,\n  .20, 1\n))\ncolnames(CovMat) &lt;- rownames(CovMat) &lt;- c(\"Ad\", \"Gp\")\n\n# The for cycle\nN = 200 # Is this N sufficient to have power?\niter = 500 # How many iterations we want?\np = c() # store p-values\nb = c() # store betas\n\nfor (i in 1:iter) {\n  # Simulate the data\n  db &lt;- as.data.frame(\n    mvrnorm(CovMat, n = N, mu = c(0, 0),\n            empirical = FALSE) # EMPIRICAL IS FALSE HERE!\n  )\n  # Fit the model\n  m &lt;- lm(Gp ~ Ad, data = db)\n  # Storage\n  p[i] &lt;- summary(m)$coefficients[\"Ad\", \"Pr(&gt;|t|)\"]\n  b[i] &lt;- summary(m)$coefficients[\"Ad\", \"Estimate\"]\n}\n\nmean(p &lt; .05)  # calculate power\nmean(b &gt; .15)  # ..."
  },
  {
    "objectID": "extras/ex90_power_misc.html#things-are-not-so-easy-in-the-real-world",
    "href": "extras/ex90_power_misc.html#things-are-not-so-easy-in-the-real-world",
    "title": "Power analysis for path and SEM models",
    "section": "Things are not so easy in the real world",
    "text": "Things are not so easy in the real world\nThere are too many things that are important for achievement to ignore them!\n\n# A more complete matrix Ad Em Se Sr Gp\nCovMat &lt;- lav_matrix_lower2full(c(\n  1,\n  .30, 1,\n  .40, .30, 1,\n  .40, .30, .35, 1,\n  .20, .15, .45, .30, 1\n))\ncolnames(CovMat) &lt;- rownames(CovMat) &lt;- c(\"Ad\", \"Em\", \"Se\", \"Sr\", \"Gp\")\n\n# For cycle\niter = 1000\nN = 5000\n\np = as.data.frame(matrix(nrow = iter, ncol = 5))\ncolnames(p) &lt;- c(\"intercept\", \"ad\", \"em\", \"se\", \"sr\")\n\nfor (i in 1:iter) {\n  db &lt;- data.frame(mvrnorm(n = N, mu = c(0, 0, 0, 0, 0),\n                           CovMat, empirical = FALSE))\n  m &lt;- lm(Gp ~ Ad + Em + Se + Sr, data = db)\n  p[i, ] &lt;- summary(m)$coefficients[, \"Pr(&gt;|t|)\"]\n}\n\ncolMeans(p &lt; .05)                       # power for each effect\nmean(rowSums(p[, 2:5] &lt; .05) == 4)      # power for all effects together"
  },
  {
    "objectID": "extras/ex90_power_misc.html#and-finally-a-path",
    "href": "extras/ex90_power_misc.html#and-finally-a-path",
    "title": "Power analysis for path and SEM models",
    "section": "and finally a path",
    "text": "and finally a path\nHowever, we know that all these variables interact and we also have a hypothetical pattern of associations that suggests that adaptability has no direct link to achievement. Adaptability is associated with achievement only through the mediation of emotions, self-efficacy, and self-regulation.\n\nlibrary(lavaan)\n\npath &lt;- \"\n\n# REGRESSIONS\nGp ~ em*Em + se*Se + sr*Sr\nEm ~ ae*Ad\nSe ~ as*Ad\nSr ~ ar*Ad\n\n# INDIRECT EFFECTS\nad_em := ae*em\nad_se := as*se\nad_sr := ar*sr\n\n\""
  },
  {
    "objectID": "extras/ex90_power_misc.html#and-its-power",
    "href": "extras/ex90_power_misc.html#and-its-power",
    "title": "Power analysis for path and SEM models",
    "section": "…and its power",
    "text": "…and its power\nWe want to test whether the indirect effects are significant. Nothing else!\n\niter = 1000\nN = 500\n\n# Store only the three indirect effects\nps = as.data.frame(matrix(nrow = iter, ncol = 3))\ncolnames(ps) &lt;- c(\"em\", \"se\", \"sr\")\n\nfor (i in 1:iter) {\n  db &lt;- data.frame(mvrnorm(n = N, mu = c(0, 0, 0, 0, 0),\n                           CovMat, empirical = FALSE))\n  fit &lt;- sem(path, data = db)\n  ps[i, ] &lt;- parameterEstimates(fit)[12:14, \"pvalue\"]\n}\n\ncolMeans(ps &lt; .05) # specific powers\ncolMeans(ps &lt; .01)\n\nmean(rowSums(ps &lt; .05) == 3) # total power: all 3 indirect effects\nmean(rowSums(ps[, c(\"se\", \"sr\")] &lt; .05) == 2)\nmean(rowSums(ps[, c(\"se\", \"sr\")] &lt; .01) == 2)\n\n\nQUESTIONS? COMMENTS?"
  },
  {
    "objectID": "extras/ex90_power_misc.html#simulate-from-the-process-and-not-the-correlation-matrix",
    "href": "extras/ex90_power_misc.html#simulate-from-the-process-and-not-the-correlation-matrix",
    "title": "Power analysis for path and SEM models",
    "section": "Simulate from the process and not the correlation matrix",
    "text": "Simulate from the process and not the correlation matrix\nWe simulated the covariance matrix directly from a correlation matrix.\n\nThis might be useless (you could make a meta-sem)\nYou understand less what’s going on behind the data"
  },
  {
    "objectID": "extras/ex90_power_misc.html#simulatedata-function",
    "href": "extras/ex90_power_misc.html#simulatedata-function",
    "title": "Power analysis for path and SEM models",
    "section": "simulateData() function",
    "text": "simulateData() function\nAn easy way to do all these steps is to use the simulateData() function in lavaan. This make it easier to simulate the data:\n\nlibrary(lavaan)\n\n# YOU JUST SPECIFY A MODEL WITH PARAMETERS\nsimM &lt;- \"\n Y ~ .20*x1 + .40*x2 + .15*x3\n x1 ~ .40*x2 + .30*x3\n\"\n\nd &lt;- simulateData(simM, sample.nobs = N)\nhead(d)"
  },
  {
    "objectID": "extras/ex90_power_misc.html#and-put-it-in-the-loop",
    "href": "extras/ex90_power_misc.html#and-put-it-in-the-loop",
    "title": "Power analysis for path and SEM models",
    "section": "and put it in the loop",
    "text": "and put it in the loop\n\nN = 100\niter = 1000\n\nm &lt;- \"\n Y ~ x1 + x2 + x3\n x1 ~ x2 + x3\n\"\n\nps = as.data.frame(matrix(nrow = iter, ncol = 3))\nfor (i in 1:iter) {\n  d &lt;- simulateData(simM, sample.nobs = N)\n  fit &lt;- sem(m, data = d)\n  ps[i, ] &lt;- parameterEstimates(fit)[1:3, \"pvalue\"]\n}\n\n\nQUESTIONS? COMMENTS?"
  },
  {
    "objectID": "extras/ex90_power_misc.html#iterate-with-a-while-loop",
    "href": "extras/ex90_power_misc.html#iterate-with-a-while-loop",
    "title": "Power analysis for path and SEM models",
    "section": "Iterate with a while loop",
    "text": "Iterate with a while loop\nIf you don’t want to manually change N each time, you can nest multiple for loops one into the other, or use a while loop.\n\niter = 1000        # How many interactions\np = c()            # Save only what we are interested in\npower_at_n = c(0)  # Here we calculate the power every time a cycle ends\nN = 5000           # The sample size of the first cycle\nk = 2              # This is only needed to make the while loop work\nsample = c()       # Just to keep track of the 'N' used\n\nwhile (power_at_n[k-1] &lt; 0.80) { # Until power_at_n reaches 0.80, we continue\n  for (i in 1:iter) {\n    db &lt;- data.frame(mvrnorm(n = N, mu = c(0, 0, 0, 0, 0),\n                             CovMat, empirical = FALSE))\n    m &lt;- lm(Gp ~ Ad + Em + Se + Sr, data = db)\n    p[i] &lt;- summary(m)$coefficients[2, 4]\n  }\n  power_at_n[k] &lt;- mean(p &lt; .05) # Calculate the power\n  sample[k-1] &lt;- N               # Save the used N\n  N = N + 500                    # Increase the sample size\n  k = k + 1                      # Move on to the next cycle\n}"
  },
  {
    "objectID": "extras/ex90_power_misc.html#results",
    "href": "extras/ex90_power_misc.html#results",
    "title": "Power analysis for path and SEM models",
    "section": "Results",
    "text": "Results\n\nplot(sample, power_at_n[-1], ylab = \"power\")\nabline(h = 0.80, col = \"red\")"
  },
  {
    "objectID": "extras/ex90_power_misc.html#model-comparison-power",
    "href": "extras/ex90_power_misc.html#model-comparison-power",
    "title": "Power analysis for path and SEM models",
    "section": "Model comparison power?",
    "text": "Model comparison power?\nThe same concepts of power for statistical significance can be applied to every analysis and statistics. It might be interesting for you to compare alternative models (e.g., hierarchical vs oblique model).\nHow to do it is pretty straightforward."
  },
  {
    "objectID": "extras/ex90_power_misc.html#the-theoretical-model",
    "href": "extras/ex90_power_misc.html#the-theoretical-model",
    "title": "Power analysis for path and SEM models",
    "section": "The theoretical model",
    "text": "The theoretical model\nLet’s say we have a four-factor structure with three items per factor. We will keep loadings always equal for simplicity.\n\n\n\n# PREPARE THE MODEL FOR SIMULATION\nset.seed(12)\nN &lt;- 450; l &lt;- .65\n\n# Step 1. Simulate the latent variables (hierarchical model)\nhfactor &lt;- rnorm(N)\n\n# Step 2. Simulate the four specific factors\ns1 &lt;- l*hfactor + rnorm(N); s2 &lt;- l*hfactor + rnorm(N)\ns3 &lt;- l*hfactor + rnorm(N); s4 &lt;- l*hfactor + rnorm(N)\n\n# Step 3. Simulate the items of each specific factor\nd &lt;- matrix(nrow = N, ncol = 12)\ncolnames(d) &lt;- paste0(\n  rep(c(\"s1\", \"s2\", \"s3\", \"s4\"), each = 3),\n  rep(c(\".1\", \".2\", \".3\"), 4)\n)\n\nfor (i in 1:3) {\n  d[, i]    &lt;- l*s1 + rnorm(N)\n  d[, i+3]  &lt;- l*s2 + rnorm(N)\n  d[, i+6]  &lt;- l*s3 + rnorm(N)\n  d[, i+9]  &lt;- l*s4 + rnorm(N)\n}\n\nct &lt;- cor(d) # correlation matrix\n\n\n\n# quick visual check\ncorrplot::corrplot(ct, tl.cex = .7)"
  },
  {
    "objectID": "extras/ex90_power_misc.html#simulate",
    "href": "extras/ex90_power_misc.html#simulate",
    "title": "Power analysis for path and SEM models",
    "section": "Simulate",
    "text": "Simulate\nWe can simulate all the process each time, or use the correlation matrix as input for the simulation. You can do it either way. For space reason, let’s use the correlation matrix ct.\n\n\n\n# Hierarchical model\nmH &lt;- \"\ns1 =~ s1.1 + s1.2 + s1.3\ns2 =~ s2.1 + s2.2 + s2.3\ns3 =~ s3.1 + s3.2 + s3.3\ns4 =~ s4.1 + s4.2 + s4.3\nlv =~ s1 + s2 + s3 + s4\n\"\n\n# Oblique model\nmO &lt;- \"\ns1 =~ s1.1 + s1.2 + s1.3\ns2 =~ s2.1 + s2.2 + s2.3\ns3 =~ s3.1 + s3.2 + s3.3\ns4 =~ s4.1 + s4.2 + s4.3\ns1 ~~ s2 + s3 + s4\ns2 ~~ s3 + s4\ns3 ~~ s4\n\"\n\niter &lt;- 1000\nN &lt;- 200\nfi &lt;- c(\"cfi\", \"rmsea\", \"bic\", \"aic\")\n\n\n\nlibrary(MASS)\nlibrary(lavaan)\n\nfit &lt;- matrix(ncol = 4, nrow = iter)\ncompare &lt;- matrix(ncol = 4, nrow = iter)\n\nfor (i in 1:iter) {\n  tryCatch({\n    db &lt;- data.frame(mvrnorm(n = N, mu = rep(0, 12),\n                             ct, empirical = FALSE))\n    fH &lt;- sem(mH, data = db)\n    fO &lt;- sem(mO, data = db)\n\n    fitH &lt;- fitmeasures(fH, fi)\n    fitO &lt;- fitmeasures(fO, fi)\n\n    fit[i, ] &lt;- c(\n      ifelse(fitH[\"cfi\"] &gt; .95, 1, 0),\n      ifelse(fitH[\"rmsea\"] &lt; .08, 1, 0),\n      ifelse(fitO[\"cfi\"] &gt; .95, 1, 0),\n      ifelse(fitO[\"rmsea\"] &lt; .08, 1, 0)\n    )\n\n    compare[i, ] &lt;- c(\n      ifelse(fitH[\"cfi\"] &gt; fitO[\"cfi\"], 1, 0),\n      ifelse(fitH[\"rmsea\"] &lt; fitO[\"rmsea\"], 1, 0),\n      ifelse(fitH[\"bic\"] &lt; fitO[\"bic\"], 1, 0),\n      ifelse(fitH[\"aic\"] &lt; fitO[\"aic\"], 1, 0)\n    )\n  }, error = function(e) {\n    fit[i, ] &lt;- NA\n    compare[i, ] &lt;- NA\n  })\n}"
  },
  {
    "objectID": "extras/ex90_power_misc.html#results-1",
    "href": "extras/ex90_power_misc.html#results-1",
    "title": "Power analysis for path and SEM models",
    "section": "Results",
    "text": "Results\n\ncolnames(compare) &lt;- fi\ncolMeans(compare, na.rm = TRUE)\n\ncolnames(fit) &lt;- c(\"cfi\", \"rmsea\", \"cfi\", \"rmsea\")\ncolMeans(fit, na.rm = TRUE)\n\nsum(is.na(fit[, 1]))\n\n\nQUESTIONS? COMMENTS?"
  },
  {
    "objectID": "extras/ex90_power_misc.html#part-ii-miscellaneous-topics",
    "href": "extras/ex90_power_misc.html#part-ii-miscellaneous-topics",
    "title": "Power analysis for path and SEM models",
    "section": "Part II — Miscellaneous topics",
    "text": "Part II — Miscellaneous topics"
  },
  {
    "objectID": "extras/ex90_power_misc.html#outline-1",
    "href": "extras/ex90_power_misc.html#outline-1",
    "title": "Power analysis for path and SEM models",
    "section": "Outline",
    "text": "Outline\n\nMissing values\nBayesian SEM\nFit indices\nMore"
  },
  {
    "objectID": "extras/ex90_power_misc.html#missing-values-in-lavaan",
    "href": "extras/ex90_power_misc.html#missing-values-in-lavaan",
    "title": "Power analysis for path and SEM models",
    "section": "Missing values in lavaan",
    "text": "Missing values in lavaan\n\nThe default option in lavaan is a listwise deletion\nYou can set different options for missing values:\n\n\"pairwise\"\n\"ml\" or \"fiml\"\n\n\n\nfit &lt;- sem(m, data = d, missing = \"fiml\")\n\n\nIf you switch the estimator to estimator=\"MLR\", you will also estimate robust standard errors\n\nYou can also set standard errors with the se argument:\n\n\"robust\" or \"robust.mlm\" or \"robust.mlr\"\n\"bootstrap\"\n\"none\"\n\n\nfit &lt;- sem(m, data = d, se = \"robust\")"
  },
  {
    "objectID": "extras/ex90_power_misc.html#na-example",
    "href": "extras/ex90_power_misc.html#na-example",
    "title": "Power analysis for path and SEM models",
    "section": "NA example",
    "text": "NA example\n\noptions(digits = 2)\n\n# THESE ARE THE SAME DATA OF THE SEM SLIDES\nd &lt;- readxl::read_excel(\"../data/Dmissing.xlsx\")\n\ncolSums(apply(d, 2, is.na))\nsum(complete.cases(d))\nsum(complete.cases(d)) / nrow(d)\n\nm &lt;- \"\n# CFA model\npeerPressure =~ PP1 + PP2 + PP3 + PP4\nsocialMedia =~ SM1 + SM2 + SM3 + SM4\nsocialComparison =~ SC1 + SC2 + SC3\neatingDisorder =~ ED1 + ED2\n\n# Structural model\neatingDisorder ~ socialComparison\nsocialComparison ~ peerPressure + socialMedia\n\""
  },
  {
    "objectID": "extras/ex90_power_misc.html#results-with-missing-data",
    "href": "extras/ex90_power_misc.html#results-with-missing-data",
    "title": "Power analysis for path and SEM models",
    "section": "Results with missing data",
    "text": "Results with missing data\n\nfit &lt;- sem(m, d)\nsummary(fit, std = TRUE)"
  },
  {
    "objectID": "extras/ex90_power_misc.html#results-with-fiml-imputation",
    "href": "extras/ex90_power_misc.html#results-with-fiml-imputation",
    "title": "Power analysis for path and SEM models",
    "section": "Results with fiml imputation",
    "text": "Results with fiml imputation\n\nfitna &lt;- sem(m, d, missing = \"fiml\")\nsummary(fitna, std = TRUE)"
  },
  {
    "objectID": "extras/ex90_power_misc.html#estimates-comparison",
    "href": "extras/ex90_power_misc.html#estimates-comparison",
    "title": "Power analysis for path and SEM models",
    "section": "Estimates comparison",
    "text": "Estimates comparison\n\np00 &lt;- parameterEstimates(fit, standardized = TRUE)[1:16, 1:3]\npt1 &lt;- parameterEstimates(fit, standardized = TRUE)[1:16, 11]\np0 &lt;- rep(\"||\", 16)\npt2 &lt;- parameterEstimates(fitna, standardized = TRUE)[1:16, 11]\n\npt &lt;- cbind(p00, p0, pt1, p0, pt2)\npt[, c(5, 7)] &lt;- round(pt[, c(5, 7)], 3)\nnames(pt)[c(4, 6)] &lt;- \"||\"\n\nknitr::kable(pt)"
  },
  {
    "objectID": "extras/ex90_power_misc.html#bayesian-sem",
    "href": "extras/ex90_power_misc.html#bayesian-sem",
    "title": "Power analysis for path and SEM models",
    "section": "Bayesian SEM",
    "text": "Bayesian SEM\nIf you are interested in using Bayesian analyses, this can also be applied to the SEM framework.\nThis is not the place where we will learn Bayesian analysis, but let’s see how to code it using blavaan."
  },
  {
    "objectID": "extras/ex90_power_misc.html#blavaan",
    "href": "extras/ex90_power_misc.html#blavaan",
    "title": "Power analysis for path and SEM models",
    "section": "blavaan",
    "text": "blavaan\n\n# install.packages(\"blavaan\")\nlibrary(blavaan)\n\nmodel &lt;- '\n  # latent variable definitions\n  ind60 =~ x1 + x2 + x3\n  dem60 =~ y1 + y2 + y3 + y4\n  dem65 =~ y5 + y6 + y7 + y8\n\n  # regressions\n  dem60 ~ ind60\n  dem65 ~ ind60 + dem60\n\n  # residual covariances\n  y1 ~~ y5\n  y2 ~~ y4 + y6\n  y3 ~~ y7\n  y4 ~~ y8\n  y6 ~~ y8\n'\n\nbfit &lt;- bsem(model, data = PoliticalDemocracy)"
  },
  {
    "objectID": "extras/ex90_power_misc.html#results-2",
    "href": "extras/ex90_power_misc.html#results-2",
    "title": "Power analysis for path and SEM models",
    "section": "Results",
    "text": "Results\n\nsummary(bfit)"
  },
  {
    "objectID": "extras/ex90_power_misc.html#priors",
    "href": "extras/ex90_power_misc.html#priors",
    "title": "Power analysis for path and SEM models",
    "section": "Priors",
    "text": "Priors\nBut of course you need priors.\n\ndpriors(bfit)\n\nnu     = \"normal(0,32)\"     # MV intercept\nalpha  = \"normal(0,10)\"     # LV intercept\nlambda = \"normal(0,10)\"     # loading\nbeta   = \"normal(0,10)\"     # regression\ntheta  = \"gamma(1,.5)[sd]\"  # MV precision\npsi    = \"gamma(1,.5)[sd]\"  # LV precision\nrho    = \"beta(1,1)\"        # correlation\nibpsi  = \"wishart(3,iden)\"  # covariance matrix\ntau    = \"normal(0,1.5)\"    # threshold\n\n# AND YOU CAN CHANGE THEM\nmydp &lt;- dpriors(lambda = \"normal(1,2)\")"
  },
  {
    "objectID": "extras/ex90_power_misc.html#priors-for-individual-parameters",
    "href": "extras/ex90_power_misc.html#priors-for-individual-parameters",
    "title": "Power analysis for path and SEM models",
    "section": "Priors for individual parameters",
    "text": "Priors for individual parameters\nThe priors we just saw are used to set the same prior to all the parameters of a kind (e.g., all loadings).\nWe can also (we should probably), set priors for individual parameters. This is done within the model specification.\n\nHS.model &lt;- '\n  visual  =~ x1 + prior(\"normal(1,2)\")*x2 + x3\n  textual =~ x4 + x5 + prior(\"normal(3,1.5)\")*x6\n  speed   =~ x7 + x8 + x9\n  x1 ~~ prior(\"gamma(3,3)[sd]\")*x1\n  visual ~~ prior(\"beta(1,1)\")*textual\n'\n\nHSbfit &lt;- bsem(HS.model, data = HolzingerSwineford1939)"
  },
  {
    "objectID": "extras/ex90_power_misc.html#full-results",
    "href": "extras/ex90_power_misc.html#full-results",
    "title": "Power analysis for path and SEM models",
    "section": "Full results",
    "text": "Full results\n\n\n\nsp &lt;- standardizedposterior(bfit)\nhead(sp)[, 1:5]\n\nfitMeasures(bfit)\nblavFitIndices(bfit)\n\n\n\nplot(density(sp[, \"dem60~ind60\"]))\nabline(v = median(sp[, \"dem60~ind60\"]))"
  },
  {
    "objectID": "extras/ex90_power_misc.html#more-about-fit-indices",
    "href": "extras/ex90_power_misc.html#more-about-fit-indices",
    "title": "Power analysis for path and SEM models",
    "section": "More about fit indices",
    "text": "More about fit indices\nThe story about fit indices does not finish where we said. There is much more and much more is still going on."
  },
  {
    "objectID": "extras/ex90_power_misc.html#should-we-abandon-predefined-cut-offs",
    "href": "extras/ex90_power_misc.html#should-we-abandon-predefined-cut-offs",
    "title": "Power analysis for path and SEM models",
    "section": "Should we abandon predefined cut-offs?",
    "text": "Should we abandon predefined cut-offs?\n\n\n\nGroskurth et al. (2023): https://doi.org/10.3758/s13428-023-02193-3\nFit indices do not only depend on model fit/misfit, but also on intrinsic characteristics of the models/analysis."
  },
  {
    "objectID": "extras/ex90_power_misc.html#dynamic-fit-indices",
    "href": "extras/ex90_power_misc.html#dynamic-fit-indices",
    "title": "Power analysis for path and SEM models",
    "section": "Dynamic fit indices",
    "text": "Dynamic fit indices\n\n\n\nDynamic shiny app: https://www.dynamicfit.app/connect/"
  },
  {
    "objectID": "extras/ex90_power_misc.html#dynamic-fit-indices-1",
    "href": "extras/ex90_power_misc.html#dynamic-fit-indices-1",
    "title": "Power analysis for path and SEM models",
    "section": "Dynamic fit indices",
    "text": "Dynamic fit indices\n\n\n\nMcNeish & Wolf (2023): https://doi.org/10.1037/met0000425"
  },
  {
    "objectID": "extras/ex90_power_misc.html#random-materials",
    "href": "extras/ex90_power_misc.html#random-materials",
    "title": "Power analysis for path and SEM models",
    "section": "Random materials",
    "text": "Random materials\n\nSlides by Rosseel on lavaan basics: https://users.ugent.be/~yrosseel/lavaan/lavaan2.pdf\nblavaan introduction: https://ecmerkle.github.io/blavaan/index.html"
  },
  {
    "objectID": "extras/ex90_power_misc.html#contact",
    "href": "extras/ex90_power_misc.html#contact",
    "title": "Power analysis for path and SEM models",
    "section": "Contact",
    "text": "Contact\n\ntommaso.feraco@unipd.it"
  },
  {
    "objectID": "extras/ex90_power_misc.html#more-difficult-1",
    "href": "extras/ex90_power_misc.html#more-difficult-1",
    "title": "Power analysis for path and SEM models",
    "section": "…more difficult",
    "text": "…more difficult\n\nlibrary(ggplot2)\nlibrary(gganimate)\np &lt;- ggplot(d, aes(x = X, y = M)) +\n  geom_point(size = 5, color = \"red\") +\n  geom_line() +\n  theme_bw()\n\npanim &lt;- p +\n  gganimate::transition_reveal(X) +\n  gganimate::shadow_wake(wake_length = 0.1, alpha = FALSE)"
  },
  {
    "objectID": "slides/00_welcome_course-map.html#today-in-the-workflow",
    "href": "slides/00_welcome_course-map.html#today-in-the-workflow",
    "title": "Welcome & course map",
    "section": "Today in the workflow",
    "text": "Today in the workflow\n\n\n\nWelcome deck (today): logistics + course map + how we’ll work\nNext deck (01): workflow + lavaan foundations (from Specify → Identify → Estimate → Evaluate → Revise/Report)"
  },
  {
    "objectID": "slides/00_welcome_course-map.html#who-is-this-course-for",
    "href": "slides/00_welcome_course-map.html#who-is-this-course-for",
    "title": "Welcome & course map",
    "section": "Who is this course for?",
    "text": "Who is this course for?\n\nPsychology PhD students with solid R skills\nYou’ve run regressions/GLMs; you want to model constructs + relations with SEM\nYou’re willing to think in models (not just tests)"
  },
  {
    "objectID": "slides/00_welcome_course-map.html#what-youll-be-able-to-do-by-the-end",
    "href": "slides/00_welcome_course-map.html#what-youll-be-able-to-do-by-the-end",
    "title": "Welcome & course map",
    "section": "What you’ll be able to do (by the end)",
    "text": "What you’ll be able to do (by the end)\n\nTranslate a verbal theory into a diagram and a lavaan model\nEvaluate global fit and local misfit (and respecify responsibly)\nFit and report:\n\npath models / mediation\nCFA and SEM (measurement + structure)\ninvariance (MG-CFA), ordinal SEM, longitudinal and clustered strategies\n\nProduce reproducible reports (Quarto + a reporting checklist)"
  },
  {
    "objectID": "slides/00_welcome_course-map.html#course-contents-big-picture",
    "href": "slides/00_welcome_course-map.html#course-contents-big-picture",
    "title": "Welcome & course map",
    "section": "Course contents (big picture)",
    "text": "Course contents (big picture)\nWe will (hopefully) cover:\n\nlavaan workflow + foundations\n\nPath analysis & mediation (equivalence and interpretation)\n\nModel fit & diagnostics (global vs local; disciplined respecification)\n\nCFA (measurement first; reliability/validity)\n\nFull SEM (measurement + structural part; capstone)\n\nMeasurement invariance (MG-CFA; partial invariance)\n\nOrdinal SEM (thresholds; WLSMV/ULS; ordinal invariance)\n\nMissing/robustness/reporting (FIML/MI; robust SE; write-up)\n\nLongitudinal SEM (growth + invariance over time)\n\nClustered/multilevel strategies (robust SE; two-level CFA)"
  },
  {
    "objectID": "slides/00_welcome_course-map.html#what-we-will-not-focus-on-in-live-sessions",
    "href": "slides/00_welcome_course-map.html#what-we-will-not-focus-on-in-live-sessions",
    "title": "Welcome & course map",
    "section": "What we will not focus on (in live sessions)",
    "text": "What we will not focus on (in live sessions)\n\nEFA (we’ll mention it, but we are not doing an EFA course)\nBayesian SEM (optional extra)\nAdvanced/rare models (optional extras: latent interactions, SAM/MIIVs, etc.)\n\n\n\n\nIf you need something specific for your project, let me know: I’ll try to fit it into the right module."
  },
  {
    "objectID": "slides/00_welcome_course-map.html#format-5-mornings-4-hours",
    "href": "slides/00_welcome_course-map.html#format-5-mornings-4-hours",
    "title": "Welcome & course map",
    "section": "Format: 5 mornings × 4 hours",
    "text": "Format: 5 mornings × 4 hours\nEach morning is split into two 2-hour blocks including:\n\ntheoretical and practical concepts\nlive coding\nlab and excercises\noptional extra topics\ndiscussion"
  },
  {
    "objectID": "slides/00_welcome_course-map.html#the-repository-is-the-course",
    "href": "slides/00_welcome_course-map.html#the-repository-is-the-course",
    "title": "Welcome & course map",
    "section": "The repository is the course",
    "text": "The repository is the course\nSEM-phd-course is a Quarto website + source files:\n\n/slides/ revealjs decks (what you see in class)\n/labs/ hands-on labs (what you do)\n/extras/ self-study (or extra) modules\n/R/ helper functions (fit, plots, reporting)\n\n\n\n\nGoal: everything is “book-ready”: coherent headings, reproducible code, and consistent reporting. At some point, a discursive content might be available."
  },
  {
    "objectID": "slides/00_welcome_course-map.html#how-to-use-materials-during-class",
    "href": "slides/00_welcome_course-map.html#how-to-use-materials-during-class",
    "title": "Welcome & course map",
    "section": "How to use materials during class",
    "text": "How to use materials during class\n\nKeep the slides open (concepts + code snippets)\nWork in the lab file in parallel (copy/adapt code)\nWhen stuck:\n\nidentify where you are in the workflow (Specify / Identify / Estimate / Evaluate / Revise-Report)\nbring the smallest reproducible example\ntalk"
  },
  {
    "objectID": "slides/00_welcome_course-map.html#software-checklist-do-this-before-we-start",
    "href": "slides/00_welcome_course-map.html#software-checklist-do-this-before-we-start",
    "title": "Welcome & course map",
    "section": "Software checklist (do this before we start)",
    "text": "Software checklist (do this before we start)\n\nR (recent), RStudio\nQuarto\nPackages (minimum):\n\nlavaan, semTools, semPlot, tidyverse, quarto\n\nOptional but useful:\n\npsych, MVN, performance, broom, parameters\n\n\n\npkgs &lt;- c(\"lavaan\",\"semTools\",\"semPlot\",\"tidyverse\")\nto_install &lt;- pkgs[!pkgs %in% rownames(installed.packages())]\nif(length(to_install)) install.packages(to_install)"
  },
  {
    "objectID": "slides/00_welcome_course-map.html#ground-rules-so-this-is-actually-useful",
    "href": "slides/00_welcome_course-map.html#ground-rules-so-this-is-actually-useful",
    "title": "Welcome & course map",
    "section": "Ground rules (so this is actually useful)",
    "text": "Ground rules (so this is actually useful)\n\nMeasurement-first (“two-step mindset”): measure → then relate constructs\n\nFit ≠ truth: use theory + diagnostics; respecify with discipline\n\nPrefer transparent reporting over “hunting for good fit”"
  },
  {
    "objectID": "slides/00_welcome_course-map.html#what-i-need-from-you",
    "href": "slides/00_welcome_course-map.html#what-i-need-from-you",
    "title": "Welcome & course map",
    "section": "What I need from you",
    "text": "What I need from you\n\nBring a dataset and one research question (even if rough)\nBe ready to:\n\ndraw your model\nstate what would falsify it\naccept that “good fit” can still be a bad model"
  },
  {
    "objectID": "slides/00_welcome_course-map.html#parking-lot-questions",
    "href": "slides/00_welcome_course-map.html#parking-lot-questions",
    "title": "Welcome & course map",
    "section": "Parking lot questions",
    "text": "Parking lot questions\nIf your question is:\n\nabout your own project’s model → keep it; we’ll connect it to a module\n\nabout R/lavaan syntax → ask immediately\n\nabout advanced variants (Bayesian, latent interactions, MIIVs, etc.) → likely an extra. We can cover it if we have time."
  },
  {
    "objectID": "slides/00_welcome_course-map.html#take-home-3-things",
    "href": "slides/00_welcome_course-map.html#take-home-3-things",
    "title": "Welcome & course map",
    "section": "Take-home: 3 things",
    "text": "Take-home: 3 things\n\nSEM is not just a model, but also a mindset\nSEM is both theory and stat\n\nSEM is both measurement and structure, tests\n\n\nThe repo is your long-term reference (slides, labs, extras, helpers)"
  },
  {
    "objectID": "slides/00_welcome_course-map.html#next",
    "href": "slides/00_welcome_course-map.html#next",
    "title": "Welcome & course map",
    "section": "Next",
    "text": "Next\nNext deck (01): SEM foundations + workflow + lavaan basics\n→ we start coding immediately.\n\n\n\nOpen the repo, run the package check, and make sure Quarto renders."
  },
  {
    "objectID": "slides/00_welcome_course-map.html#references",
    "href": "slides/00_welcome_course-map.html#references",
    "title": "Welcome & course map",
    "section": "References",
    "text": "References\n(References for this welcome deck are mostly course materials; substantive citations start in the next modules.)"
  },
  {
    "objectID": "slides/00_welcome_course-map.html#why-am-i-here",
    "href": "slides/00_welcome_course-map.html#why-am-i-here",
    "title": "Welcome & course map",
    "section": "Why am I here?",
    "text": "Why am I here?\nI am convinced that SEM is a fundamental tool for research in psychology and most, if not all, researchers in this area should know it. Indeed, it is key for many aspects of your research:\n\nMeasurement\nMultivariate analyses\nComplex regression models\nLongitudinal analyses\n…"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#today-in-the-workflow",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#today-in-the-workflow",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Today in the workflow",
    "text": "Today in the workflow\nSpecify → Identify → Estimate → Evaluate → Revise/Report\n\n\n\nToday: SEM language + diagram grammar + the workflow, then first translation to lavaan.\nNext (02): path analysis & mediation (indirect effects, equivalence, interpretation)."
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#learning-objectives",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#learning-objectives",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Learning objectives",
    "text": "Learning objectives\nBy the end of this session you should be able to:\n\nTranslate a verbal hypothesis into a diagram\nUse the basic SEM “grammar” (variables, errors, arrows, covariances)\nExplain the SEM workflow: Specify → Identify → Estimate → Evaluate → Revise/Report\nWrite and run a minimal model in lavaan (and read the key parts of the output)"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#a-quick-motivation-how-do-you-fit-these",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#a-quick-motivation-how-do-you-fit-these",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "A quick motivation: “how do you fit these?”",
    "text": "A quick motivation: “how do you fit these?”"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#sem-structural-equation-modeling",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#sem-structural-equation-modeling",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "SEM = Structural Equation Modeling",
    "text": "SEM = Structural Equation Modeling\nA family of models that lets you:\n\nrepresent hypotheses as a system of relations\n\npostulate a data-generating model\nevaluate whether this model fits the data or not\n\nwork with measurement error (explicitly)\nmodel means and covariances implied by your theory\n\n\n\n\nit includes path-analysis, causal models, factorial models, measurement models, Latent Growth Models, but even regressions, ANOVAs, t-tests could be considered particular cases of SEM.\n\n\n\n\nmodel latent variables (e.g., ‘invisible constructs’)\ntest indirect, moderated, and reciprocal effects\nmake diagrams (or PAINTINGS if theory is weak!)\n\n\n\n\nnetwork models are better if you want good paintings with no theory."
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#variancecovariance-matrices-the-currency",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#variancecovariance-matrices-the-currency",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Variance–covariance matrices (the “currency”)",
    "text": "Variance–covariance matrices (the “currency”)\n\n\n\noptions(digits = 2)\ncov(PoliticalDemocracy[1:7])\n\n    y1   y2   y3   y4  y5   y6   y7\ny1 6.9  6.3  5.8  6.1 5.1  5.7  5.8\ny2 6.3 15.6  5.8  9.5 5.6  9.4  7.5\ny3 5.8  5.8 10.8  6.7 4.9  4.7  7.0\ny4 6.1  9.5  6.7 11.2 5.7  7.4  7.5\ny5 5.1  5.6  4.9  5.7 6.8  5.0  5.8\ny6 5.7  9.4  4.7  7.4 5.0 11.4  6.7\ny7 5.8  7.5  7.0  7.5 5.8  6.7 10.8\n\n\n\nSEM works with matrices\n\n\\(\\boldsymbol{S}\\) observed var-cov\n\\(\\boldsymbol{\\Sigma}\\) true var-cov\n\\(\\boldsymbol{\\hat{\\Sigma}}\\) model-implied var-cov\n\\(\\boldsymbol{\\Sigma}(\\theta)\\)\n\n\nTHE MAIN AIM OF SEM IS TO RECONSTRUCT THE TRUE VARIANCE-COVARIANCE MATRIX"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#classification-of-variables",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#classification-of-variables",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Classification of variables",
    "text": "Classification of variables\nVariables are the way those attributes that vary across individuals are operationalized and represented for further data processing. These can be categorized according to many criteria (e.g, dependent/independent…), but in SEM we classify them firstly as:\n\nLatent variables\n\nhypothetical variables that correspond to more or less abstract concepts (e.g., intelligence, anxiety, executive functions, personality traits…)\ncould be formative or reflective\n\nObserved variables\n\nvariables that can be directly observed and measured\nexamples can be weight, height, gender, income, items, HRV…"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#relationships-between-variables",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#relationships-between-variables",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Relationships between variables",
    "text": "Relationships between variables\n\nThe general aim of statistical analysis is to study relationships among variables\nOn the basis of the relationship among the variables, we distinguish two kind of models:\n\nsymmetrical\nasymmetrical"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#regression-model-as-an-sem-special-case",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#regression-model-as-an-sem-special-case",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Regression model (as an SEM special case)",
    "text": "Regression model (as an SEM special case)\nA familiar form:\n[ y = X+ ]\n\nall variables are manifest\nmeasurement error is only “hidden” in () for endogenous variables"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#from-one-equation-to-a-system",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#from-one-equation-to-a-system",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "From one equation to a system",
    "text": "From one equation to a system\nSEM often treats your hypothesis as multiple linked equations."
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#variables-and-errors-be-explicit",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#variables-and-errors-be-explicit",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Variables and errors (be explicit)",
    "text": "Variables and errors (be explicit)\nSEM forces you to draw/declare:\n\nresidual variances (errors/disturbances)\ncovariances (exogenous covariances; correlated residuals if justified)"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#sem-in-one-picture",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#sem-in-one-picture",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "SEM “in one picture”",
    "text": "SEM “in one picture”\nA full representation (we’ll decode it gradually):"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#sem-assumptions-conceptual-version",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#sem-assumptions-conceptual-version",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "SEM assumptions (conceptual version)",
    "text": "SEM assumptions (conceptual version)\n\nThe model is confirmatory: you propose it before looking for “fixes”\nThe model must be identified (estimable)\nEstimation relies on distributional assumptions"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#sem-steps-the-workflow",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#sem-steps-the-workflow",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "SEM steps (the workflow)",
    "text": "SEM steps (the workflow)\n\nModel specification (theory → diagram → equations)\nModel identification (can we estimate the parameters?)\nParameter estimation (choose estimator, get estimated matrices)\nModel evaluation (global + local diagnostics)\nModel modification / reporting (disciplined, transparent)"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#model-specification",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#model-specification",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "1) Model specification",
    "text": "1) Model specification\nWhat is a model\n\nA model is a formal representation of a theory and is composed by a set of parameters that we will estimate.\n\nWhat you must state explicitly:\n\nwhich variables are connected (and in what direction)\nwhich errors/covariances are allowed\nwhich parameters are fixed, free, or constrained"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#model-identification-intuition",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#model-identification-intuition",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "2) Model identification (intuition)",
    "text": "2) Model identification (intuition)\n\n\nTo ensure that the number of unknown parameters (\\(t\\)) is not greater than the number of nonredundant elements in the covariance matrix of \\(q\\) observed variables.\n\\[\nt \\leq \\frac{q(q+1)}{2}\n\\]\n\n\n\nIf the model is not identified, nothing else matters (no fit, no estimates).\n\n\n\n\nJust-identified\n\nUnder-identified\n\nOver-identified"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#identification-examples-visual",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#identification-examples-visual",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Identification examples (visual)",
    "text": "Identification examples (visual)\n\n\nJust-identified\n\n\nUnder-identified\n\n\nOver-identified\n\n\n\n\n\nIf the model is not identified, nothing else matters (no fit, no estimates)."
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#parameter-estimation-what-software-does",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#parameter-estimation-what-software-does",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "3) Parameter estimation (what software does)",
    "text": "3) Parameter estimation (what software does)\nTo estimate the model parameters we can use different estimation methods. These aim to estimate the model implied (theoretical) correlation matrix \\(\\boldsymbol{\\Sigma}\\), which is a function of the model parameters, and should hopefully be similar to the observed correlation matrix \\(\\boldsymbol{S}\\).\nSome of the many estimation methods are:\n\nMaximum Likelihood (ML), default in lavaan\nUnweighted Least Squares (ULS)\nGeneralized Least Squares (GLS)\nWeighted Least Squares, Mean- and Variance-adjusted (WLSMV), default for ordinal variables in lavaan\nDiagonally Weighted Least Squares (DWLS)"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#model-evaluation-preview",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#model-evaluation-preview",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "4) Model evaluation (preview)",
    "text": "4) Model evaluation (preview)\nIs the model adequate? Are our parameter able to construct a theoretical matrix (\\(\\boldsymbol{\\Sigma}\\)) which is close to the original empirical covariance matrix \\(\\boldsymbol{S}\\)?\nThis is the goal of a good model: reproduce, from a set of theoretical associations/effects (aka covariance matrix), the original covariance matrix.\n\nGlobal fit: is the overall model plausible?\nLocal fit: where does the model misfit?\n\n\n\n\nWe’ll do this properly in deck 03. Today: just remember that fit ≠ truth.\n\n\n\nFormally:\n\\[\nH_0 : \\boldsymbol{\\hat{\\Sigma}}(\\theta) = \\boldsymbol{\\Sigma}\n\\]\nwhere \\(\\boldsymbol{\\Sigma}\\) is the true covariance matrix among model variables, \\(\\theta\\) the parameters vector, and \\(\\boldsymbol{\\hat{\\Sigma}}\\) the reproduced covariance matrix."
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#model-modification-disciplined-respecification",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#model-modification-disciplined-respecification",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "5) Model modification (disciplined respecification)",
    "text": "5) Model modification (disciplined respecification)\nAt this point you are ‘free’ to modify the model based on the results obtained…AND THE THEORY!\n\nmodifications are hypotheses\nmodifications must be explicitly reported: both what you changed and why\navoid overfitting (change only what is strictly needed/justified)"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#diagram-grammar-legend",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#diagram-grammar-legend",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Diagram grammar (legend)",
    "text": "Diagram grammar (legend)\nCommon SEM symbols:"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#where-these-models-show-up-across-the-course",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#where-these-models-show-up-across-the-course",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Where these models show up across the course",
    "text": "Where these models show up across the course\n(These pictures are “landmarks” you’ll keep seeing.)"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#longitudinal-landmarks-later",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#longitudinal-landmarks-later",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Longitudinal landmarks (later)",
    "text": "Longitudinal landmarks (later)\nPanel / repeated measures:\n\nGrowth / change:"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#bridge-from-diagrams-to-lavaan",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#bridge-from-diagrams-to-lavaan",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Bridge: from diagrams to lavaan",
    "text": "Bridge: from diagrams to lavaan\nlavaan is mostly a model syntax language:\n\nyou write relations like “y ~ x”\nlavaan estimates the parameters\nyou read estimates + standard errors + fit indices + diagnostics\n\n\n\n\nThink: “diagram ↔︎ equations ↔︎ lavaan syntax” (three representations of the same model)."
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#from-lm-to-lavaansem",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#from-lm-to-lavaansem",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "From lm() to lavaan::sem()",
    "text": "From lm() to lavaan::sem()\nA regression in base R:\n\nfit_lm &lt;- lm(y ~ x1 + x2, data = dat)\nsummary(fit_lm)\n\nThe same idea in lavaan :\n\nlibrary(lavaan)\n\nmod &lt;- '\n  y ~ x1 + x2\n'\n\nfit &lt;- sem(mod, data = dat)\nsummary(fit, standardized = TRUE)"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#key-lavaan-syntax-operators",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#key-lavaan-syntax-operators",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Key lavaan syntax operators",
    "text": "Key lavaan syntax operators\n\n~ regression (single-headed arrow)\n~~ (co)variance (double-headed arrow)\n=~ measurement model (factor loading)\n\n\nmod &lt;- '\n  # regression\n  y ~ x1 + x2\n\n  # (co)variances\n  x1 ~~ x2\n  y  ~~ y\n\n  # measurement (example)\n  F =~ y1 + y2 + y3\n'"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#a-minimal-runnable-example-built-in-data",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#a-minimal-runnable-example-built-in-data",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "A minimal, runnable example (built-in data)",
    "text": "A minimal, runnable example (built-in data)\n\nlibrary(lavaan)\ndat &lt;- HolzingerSwineford1939\n\nmod_cfa &lt;- '\n  visual  =~ x1 + x2 + x3\n  textual =~ x4 + x5 + x6\n  speed   =~ x7 + x8 + x9\n'\n\nfit_cfa &lt;- cfa(mod_cfa, data = dat)\nsummary(fit_cfa, standardized = TRUE, fit.measures = TRUE)\n\n\n\n\nDon’t worry about fit indices yet—this is just to see the pipeline end-to-end."
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#visual-check-plot-the-model",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#visual-check-plot-the-model",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Visual check: plot the model",
    "text": "Visual check: plot the model\n\nlibrary(semPlot)\nsemPaths(fit_cfa, what = \"std\", layout = \"tree\", residuals = FALSE)\n\n(Plotting is optional—but very helpful for teaching your brain the diagram grammar.)"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#common-early-mistakes-and-how-to-debug",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#common-early-mistakes-and-how-to-debug",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Common early mistakes (and how to debug)",
    "text": "Common early mistakes (and how to debug)\n\n“lavaan ERROR: model is not identified” → go back to Identify\n“nothing converges” → simplify; check scaling; check data (missing, outliers)\n“why are SE huge?” → identification / multicollinearity / small N\n\n\n\n\nIn this course, debugging starts by asking: Which workflow step am I in?"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#exercises-lab-01",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#exercises-lab-01",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Exercises (Lab 01)",
    "text": "Exercises (Lab 01)\nGo to:\n\nlabs/lab01_lavaan-basics.qmd\n\nYou’ll practice:\n\nwriting tiny models (~, ~~, =~)\nfitting with sem() / cfa()\nextracting key output (estimates, standardized, basic fit)"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#take-home-3-things",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#take-home-3-things",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Take-home: 3 things",
    "text": "Take-home: 3 things\n\nSEM is a language: diagrams, equations, syntax\n\nSEM is a workflow: Specify → Identify → Estimate → Evaluate → Revise/Report\n\nlavaan is your translator from theory → estimable model"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#further-reading-self-study",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#further-reading-self-study",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Further reading / self-study",
    "text": "Further reading / self-study\n\nRevisit the glossary in the repo as new terms appear\n\n(Add materials list.)"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#references",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#references",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "References",
    "text": "References\n(Add citations as we stabilize the final reading list for the course website.)"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#variancecovariance-matrices-the-currency-1",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#variancecovariance-matrices-the-currency-1",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Variance–covariance matrices (the “currency”)",
    "text": "Variance–covariance matrices (the “currency”)\nSEM compares what you observe (S) with what your model implies (Σ(θ))."
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#classification-of-variables-1",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#classification-of-variables-1",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Classification of variables",
    "text": "Classification of variables\nIn SEM we also have an additional classification:\n\nExogenous variables\n\nVariables whose causes lie outside the model; they will be used only as predictors in the model. They do not receive arrows.\nThey are indicated with \\(x\\), if observed, or with \\(\\xi\\), if latent.\n\nEndogenous variables\n\nVariables that are determined by variables within the model (they receive arrows); can be used as predictors or dependent variables in the model.\nThey are indicated with \\(y\\), if observed, or with \\(\\eta\\), if latent."
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#classification-of-variables-2",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#classification-of-variables-2",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Classification of variables",
    "text": "Classification of variables\nVariables are the way those attributes that vary across individuals are operationalized and represented for further data processing. These can be categorized according to many criteria (e.g, dependent/independent…), but in SEM we classify them firstly as:\n\nLatent variables\n\nhypothetical variables that correspond to more or less abstract concepts\nformative or reflective\nexamples are intelligence, anxiety, executive functions, personality traits…\n\nObserved variables\n\nvariables that can be directly observed and measured\nexamples can be weight, height, gender, income…"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#classification-of-variables-3",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#classification-of-variables-3",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Classification of variables",
    "text": "Classification of variables\nIn SEM we also have an additional type of classification:\n\nExogenous variables\n\nVariables whose causes lie outside the model; they will be used only as predictors in the model. They do not receive arrows.\nThey are indicated with \\(x\\), if observed, or with \\(\\xi\\), if latent.\n\nEndogenous variables\n\nVariables that are determined by variables within the model (they receive arrows); can be used as predictors or dependent variables in the model.\nThey are indicated with \\(y\\), if observed, or with \\(\\eta\\), if latent.\n\n\nThis brings us to deepen the relationships between variables."
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#asymmetrical-relationships",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#asymmetrical-relationships",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Asymmetrical relationships",
    "text": "Asymmetrical relationships\n\\[\nX \\rightarrow Y\n\\]\n\nVariables are divided into two sets: dependent or response variables and predictors or explanatory variables\n\\(X\\) is the set of explanatory variables, \\(Y\\) is the set of response variables, arrows represents the direction of the hypothesized relationship.\nThese models imply cause-and-effect relationships.\n\nExample\nPeople who study more obtain higher grades."
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#symmetrical-relationships",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#symmetrical-relationships",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Symmetrical relationships",
    "text": "Symmetrical relationships\n\\[\nX_i \\Leftrightarrow Y_j \\quad \\forall i,j\n\\]\n\nThis means that neither a variable causes the other, neither a variable can be considered prior in time to the other; all these relationships are bidirectional.\nThese models do not imply nor consider causality.\n\nExample\nPeople who have higher grades in math have higher grades in art."
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#regression-model",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#regression-model",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Regression model",
    "text": "Regression model\nAsymmetrical relationships are usually tested with regressions!\nAs you remember, regression models can be written, using classical formulation, as the expression below and graphically depicted (getting closer to SEM) like this:"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#more-regression",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#more-regression",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "More regression?",
    "text": "More regression?\nBut what if we have in mind a more complex pattern of relationships? What if we have more regression models in mind and need to estimate all of them contemporarily?\n\nWhat we need is a system of equations."
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#more-regression-1",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#more-regression-1",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "More regression?",
    "text": "More regression?\nThis system can also be drawn with SEM notation, but is actually the same…just better!"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#variables-and-errors",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#variables-and-errors",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Variables and errors",
    "text": "Variables and errors\n\nVariables\n\n\\(x\\) exogenous observed (\\(q\\))\n\\(\\xi\\) exogenous latent (\\(n\\))\n\\(y\\) endogenous observed (\\(p\\))\n\\(\\eta\\) endogenous latent (\\(m\\))\n\nStochastic errors\n\n\\(\\delta\\) measurement errors in \\(x\\)\n\\(\\epsilon\\) measurement errors in \\(y\\)\n\\(\\zeta\\) equation errors in the structural relationship between \\(\\eta\\) and \\(\\xi\\)"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#sem-matrices---lavaan-model",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#sem-matrices---lavaan-model",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "SEM matrices - lavaan model",
    "text": "SEM matrices - lavaan model\n\nParameter matrices\n\n\\(\\boldsymbol{\\Lambda}\\) relationship between latent (\\(\\xi\\) and \\(\\eta\\)) and observed (\\(x\\) and \\(y\\)) [\\((p + q) X (m + n)\\)]\n\\(\\boldsymbol{B}\\) relationship between latent variables [\\((m + n) X (m + n)\\)]\n\nCovariance matrices\n\n\\(Cov\\)(\\(\\zeta\\), \\(\\xi\\)) = \\(\\boldsymbol{\\Psi}\\) matrix [\\((m + n) X (m + n)\\)]\n\\(Cov\\)(\\(\\epsilon\\), \\(\\delta\\)) = \\(\\boldsymbol{\\Theta}\\) matrix [\\((p + q) X (p + q)\\)]"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#sem-equations",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#sem-equations",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "SEM equations",
    "text": "SEM equations\nThe SEM model in its most general form consists of two parts\n\nThe measurement model\n\n\\(x = \\boldsymbol{\\Lambda}_x\\boldsymbol{\\xi} + \\boldsymbol{\\delta}\\)\n\\(y = \\boldsymbol{\\Lambda}_y\\boldsymbol{\\eta} + \\boldsymbol{\\epsilon}\\)\n\nThe structural model\n\n\\(\\boldsymbol{\\eta} = \\boldsymbol{B\\eta} + \\boldsymbol{\\Gamma\\xi} + \\boldsymbol{\\zeta}\\)\n\\(\\boldsymbol{\\eta} = \\boldsymbol{B(\\eta\\xi} + \\boldsymbol{\\zeta})\\)"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#sem-assumptions",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#sem-assumptions",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "SEM assumptions",
    "text": "SEM assumptions\n\nExpected values of latent variables and stochastic errors are 0:\n\n\\(E\\)(\\(\\eta\\)) = 0\n\\(E\\)(\\(\\xi\\)) = 0\n\\(E\\)(\\(\\zeta\\)) = 0\n\\(E\\)(\\(\\epsilon\\)) = 0\n\\(E\\)(\\(\\delta\\)) = 0\n\nErrors are uncorrelated with latent variables and are mutually uncorrelated:"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#classification-of-variables-4",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#classification-of-variables-4",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Classification of variables",
    "text": "Classification of variables\n latent variables (constructs)\n observed/manifest variables (items, scores)\n\n\n\nMeasurement-first mindset: define/validate constructs first, then relate them."
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#relationships-between-variables-1",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#relationships-between-variables-1",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Relationships between variables",
    "text": "Relationships between variables\nTwo basic arrow types:\n\n\n\nSingle-headed: regression / directional effect (A → B)\nDouble-headed: covariance/correlation (A ↔︎ B)"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#a-full-representation",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#a-full-representation",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "A full representation",
    "text": "A full representation\n img credits to dr. Johnny Lin"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#graphical-representation",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#graphical-representation",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Graphical representation",
    "text": "Graphical representation\nIf that all seemed difficult and boring, now comes the funny part: colors, figures, and arrows!\nGraphical representation is a key attribute of structural equation modeling:\n\nIt helps understanding the model\nIt helps thinking and reasoning about the model (a priori)\nIt helps writing and formalizing the model\nIt is easy, but few rules must be followed to have a readable model"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#graphical-representation-1",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#graphical-representation-1",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Graphical representation",
    "text": "Graphical representation\n\nLatent variables are circles or ellipses\n\nManifest/observed variables are square or rectangular boxes\n\nErrors are represented by corresponding letters (or values) only\n\n\\[\n\\delta_1  /  \\epsilon_1  /  \\zeta_1\n\\]"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#graphic-relationships",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#graphic-relationships",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Graphic relationships",
    "text": "Graphic relationships\n\nAll model relationships are represented by arrows;\n\n\n\n\n\n\n\nImportant\n\n\nNO relationship NO arrow…\n…and usually NO arrow NO relationship\n\n\n\n\nEach arrow is a model parameter and has two indices (e.g., \\(\\beta_{21}\\))\nAsymmetrical relationship are represented by a single headed arrow: the first index indicates the variable the arrow is pointing to, the second index indicates the variable of origin.\nSymmetrical relationships are represented by double-headed arrows and two indices, one for each variable."
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#graphic-relationships-1",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#graphic-relationships-1",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Graphic relationships",
    "text": "Graphic relationships\nA summary"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#asymmetrical-relationships-1",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#asymmetrical-relationships-1",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Asymmetrical relationships",
    "text": "Asymmetrical relationships"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#symmetrical-relationships-1",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#symmetrical-relationships-1",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Symmetrical relationships",
    "text": "Symmetrical relationships"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#graphical-errors",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#graphical-errors",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Graphical errors",
    "text": "Graphical errors\n\nAll errors have a single headed arrow pointing to a variable; all variables, except \\(\\xi\\), may have an error.\nDouble-headed arrows associated to errors indicate error variances."
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#a-full-representation-1",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#a-full-representation-1",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "A full representation",
    "text": "A full representation\n img credits to dr. Johnny Lin"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#model-identification",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#model-identification",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "2) Model identification",
    "text": "2) Model identification\nBasically, we want to know if there is enough information to identify a solution (aka estimate all the unknown parameters).\nA model can be:\n\nUnder-identified: there are MORE parameters to be estimated than elements in the covariance matrix (e.g., \\(X + Y = 10\\))\nJust-identified: the number of parameters to be estimated equals the number of elements in the covariance matrix (\\(df = 0\\))\nOver-identified: there are LESS parameters to be estimated than elements in the covariance matrix (\\(df &gt; 0\\))"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#univariate-regressions",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#univariate-regressions",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Univariate regressions",
    "text": "Univariate regressions"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#multivariate-regressions",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#multivariate-regressions",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Multivariate regressions",
    "text": "Multivariate regressions"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#path-analysis",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#path-analysis",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Path analysis",
    "text": "Path analysis"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#confirmatory-factor-analysis-cfa",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#confirmatory-factor-analysis-cfa",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Confirmatory factor analysis (CFA)",
    "text": "Confirmatory factor analysis (CFA)"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#sem-path-analysis",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#sem-path-analysis",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "SEM path analysis",
    "text": "SEM path analysis"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#t-test-with-latent-variables",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#t-test-with-latent-variables",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "t test with latent variables",
    "text": "t test with latent variables"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#cross-lagged-panel-models",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#cross-lagged-panel-models",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Cross-lagged panel models",
    "text": "Cross-lagged panel models"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#growth-curve-models",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#growth-curve-models",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Growth curve models",
    "text": "Growth curve models"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#and-much-more",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#and-much-more",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "And much more",
    "text": "And much more\n…and much more\nTHERE IS EVEN A JOURNAL ON SEM\nStructural Equation Modeling: A Multidisciplinary Journal"
  },
  {
    "objectID": "labs/lab01_lavaan-basics.html",
    "href": "labs/lab01_lavaan-basics.html",
    "title": "Lab 01 — lavaan basics with observed variables",
    "section": "",
    "text": "By the end of this lab, you can:\n\nFit observed-variable models in lavaan (no latent variables yet)\nExpress (multi)regression models using lavaan syntax (~, ~~)\nExtract and interpret key output (estimates, SE, standardized estimates)\nTest a simple equality constraint using nested model comparison"
  },
  {
    "objectID": "labs/lab01_lavaan-basics.html#packages",
    "href": "labs/lab01_lavaan-basics.html#packages",
    "title": "Lab 01 — lavaan basics with observed variables",
    "section": "Packages",
    "text": "Packages\n\nlibrary(lavaan)"
  },
  {
    "objectID": "labs/lab01_lavaan-basics.html#data",
    "href": "labs/lab01_lavaan-basics.html#data",
    "title": "Lab 01 — lavaan basics with observed variables",
    "section": "Data",
    "text": "Data\nWe will use the built-in dataset mtcars (motor trends cars; a classic toy dataset).\n\n\nShow code\ndat &lt;- mtcars\n\n# Keep only variables we use (and make names explicit)\ndat &lt;- dat[, c(\"mpg\", \"qsec\", \"wt\", \"hp\")]\n\n# Quick look\nsummary(dat)\n\n\n      mpg             qsec             wt              hp       \n Min.   :10.40   Min.   :14.50   Min.   :1.513   Min.   : 52.0  \n 1st Qu.:15.43   1st Qu.:16.89   1st Qu.:2.581   1st Qu.: 96.5  \n Median :19.20   Median :17.71   Median :3.325   Median :123.0  \n Mean   :20.09   Mean   :17.85   Mean   :3.217   Mean   :146.7  \n 3rd Qu.:22.80   3rd Qu.:18.90   3rd Qu.:3.610   3rd Qu.:180.0  \n Max.   :33.90   Max.   :22.90   Max.   :5.424   Max.   :335.0  \n\n\n\n\n\n\n\n\nWhy this dataset? It’s small, clean, and lets us practice the SEM workflow with manifest variables only."
  },
  {
    "objectID": "labs/lab01_lavaan-basics.html#extracting-parameters-programmatically",
    "href": "labs/lab01_lavaan-basics.html#extracting-parameters-programmatically",
    "title": "Lab 01 — lavaan basics with observed variables",
    "section": "Extracting parameters programmatically",
    "text": "Extracting parameters programmatically\nUse the function parameterEstimates() to obtain the estimates. How do you extract standardized estimate?\n\n\nShow code\npe &lt;- parameterEstimates(fit_sem, standardized = TRUE)\nhead(pe, 10)\n\n\n  lhs op rhs      est    se      z pvalue ci.lower ci.upper   std.lv std.all\n1 mpg  ~  wt   -3.878 0.602 -6.438      0   -5.058   -2.697   -3.878  -0.630\n2 mpg  ~  hp   -0.032 0.009 -3.696      0   -0.049   -0.015   -0.032  -0.361\n3 mpg ~~ mpg    6.095 1.524  4.000      0    3.109    9.082    6.095   0.173\n4  wt ~~  wt    0.927 0.000     NA     NA    0.927    0.927    0.927   1.000\n5  wt ~~  hp   42.812 0.000     NA     NA   42.812   42.812   42.812   0.659\n6  hp ~~  hp 4553.965 0.000     NA     NA 4553.965 4553.965 4553.965   1.000\n7 mpg ~1       37.227 1.522 24.459      0   34.244   40.210   37.227   6.276\n8  wt ~1        3.217 0.000     NA     NA    3.217    3.217    3.217   3.341\n9  hp ~1      146.688 0.000     NA     NA  146.688  146.688  146.688   2.174\n   std.nox\n1   -0.654\n2   -0.005\n3    0.173\n4    0.927\n5   42.812\n6 4553.965\n7    6.276\n8    3.217\n9  146.688\n\n\n\nop tells you the operator (~ regression, ~~ variance/covariance, ~1 intercept)\nest is the estimate\nse is the standard error\nz and pvalue are the usual Wald test outputs\nstd.all is the fully standardized estimate\n\n\n\n\n\n\n\nAt this stage, focus on estimates only. We’ll talk about modeling strategy and diagnostics later.\n\n\n\n\n\n\n\n\n\nCheck-in: You just used lavaan as a “regression engine”. SEM becomes interesting when we connect multiple equations and allow covariances explicitly."
  },
  {
    "objectID": "labs/lab01_lavaan-basics.html#compare-to-two-separate-regressions",
    "href": "labs/lab01_lavaan-basics.html#compare-to-two-separate-regressions",
    "title": "Lab 01 — lavaan basics with observed variables",
    "section": "Compare to two separate regressions",
    "text": "Compare to two separate regressions\n\n\nShow code\nfit_lm_mpg  &lt;- lm(mpg  ~ wt + hp, data = dat)\nfit_lm_qsec &lt;- lm(qsec ~ wt + hp, data = dat)\n\nsummary(fit_lm_mpg)$coef\n\n\n               Estimate Std. Error   t value     Pr(&gt;|t|)\n(Intercept) 37.22727012 1.59878754 23.284689 2.565459e-20\nwt          -3.87783074 0.63273349 -6.128695 1.119647e-06\nhp          -0.03177295 0.00902971 -3.518712 1.451229e-03\n\n\nShow code\nsummary(fit_lm_qsec)$coef\n\n\n               Estimate  Std. Error   t value     Pr(&gt;|t|)\n(Intercept) 18.82558525 0.671867025 28.019808 1.493575e-22\nwt           0.94153237 0.265896975  3.540967 1.368578e-03\nhp          -0.02730962 0.003794603 -7.196964 6.362107e-08\n\n\n\n\n\n\n\n\nSeparate lm() fits ignore the joint structure (e.g., residual covariance). lavaan makes it explicit."
  },
  {
    "objectID": "labs/lab01_lavaan-basics.html#a-unconstrained-model",
    "href": "labs/lab01_lavaan-basics.html#a-unconstrained-model",
    "title": "Lab 01 — lavaan basics with observed variables",
    "section": "4a) Unconstrained model",
    "text": "4a) Unconstrained model\n(You already fit it as fit_mv.)"
  },
  {
    "objectID": "labs/lab01_lavaan-basics.html#b-constrained-model",
    "href": "labs/lab01_lavaan-basics.html#b-constrained-model",
    "title": "Lab 01 — lavaan basics with observed variables",
    "section": "4b) Constrained model",
    "text": "4b) Constrained model\nLabel the two wt slopes with the same name (e.g., b_wt):\n\n\nShow code\nmod_mv_equal &lt;- '\n  mpg  ~ b_wt*wt + hp\n  qsec ~ b_wt*wt + hp\n\n  wt ~~ hp\n  mpg ~~ qsec\n'\n\nfit_mv_equal &lt;- sem(mod_mv_equal, data = dat, meanstructure = TRUE)\nsummary(fit_mv_equal, standardized = TRUE)\n\n\nlavaan 0.6-19 ended normally after 64 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        14\n  Number of equality constraints                     1\n\n  Number of observations                            32\n\nModel Test User Model:\n                                                      \n  Test statistic                                35.243\n  Degrees of freedom                                 1\n  P-value (Chi-square)                           0.000\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nRegressions:\n                   Estimate  Std.Err  z-value   P(&gt;|z|)   Std.lv  Std.all\n  mpg ~                                                                  \n    wt      (b_wt)    0.524    0.248     2.114    0.035    0.524    0.082\n    hp               -0.073    0.011    -6.762    0.000   -0.073   -0.805\n  qsec ~                                                                 \n    wt      (b_wt)    0.524    0.248     2.114    0.035    0.524    0.298\n    hp               -0.023    0.004    -6.378    0.000   -0.023   -0.932\n\nCovariances:\n                   Estimate  Std.Err  z-value   P(&gt;|z|)   Std.lv  Std.all\n  wt ~~                                                                  \n    hp               42.812    8.643     4.953    0.000   42.812    0.659\n .mpg ~~                                                                 \n   .qsec             -0.416    0.774    -0.537    0.591   -0.416   -0.095\n\nIntercepts:\n                   Estimate  Std.Err  z-value   P(&gt;|z|)   Std.lv  Std.all\n   .mpg              29.136    1.766    16.502    0.000   29.136    4.751\n   .qsec             19.594    0.645    30.368    0.000   19.594   11.579\n    wt                3.217    0.170    18.898    0.000    3.217    3.341\n    hp              146.687   11.929    12.296    0.000  146.687    2.174\n\nVariances:\n                   Estimate  Std.Err  z-value   P(&gt;|z|)   Std.lv  Std.all\n   .mpg              16.266    4.066     4.000    0.000   16.266    0.432\n   .qsec              1.168    0.292     4.000    0.000    1.168    0.408\n    wt                0.927    0.209     4.440    0.000    0.927    1.000\n    hp             4553.971    0.081 56034.919    0.000 4553.971    1.000"
  },
  {
    "objectID": "labs/lab01_lavaan-basics.html#c-compare-nested-models",
    "href": "labs/lab01_lavaan-basics.html#c-compare-nested-models",
    "title": "Lab 01 — lavaan basics with observed variables",
    "section": "4c) Compare nested models",
    "text": "4c) Compare nested models\n\n\nShow code\nanova(fit_mv, fit_mv_equal)\n\n\n\nChi-Squared Difference Test\n\n             Df    AIC    BIC  Chisq Chisq diff  RMSEA Df diff Pr(&gt;Chisq)    \nfit_mv        0 698.87 719.40  0.000                                         \nfit_mv_equal  1 732.12 751.17 35.243     35.243 1.0345       1  2.911e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nInterpretation questions\n\nIf the constrained model fits significantly worse, what does that imply?\nIf there is little/no difference, what does that imply?\nWhich model would you prefer and why (think theory + parsimony)?\n\n\n\n\n\n\n\nWe’ll later discuss when χ² difference tests are appropriate, and what changes under robust estimators."
  },
  {
    "objectID": "labs/lab01_lavaan-basics.html#what-you-should-take-away",
    "href": "labs/lab01_lavaan-basics.html#what-you-should-take-away",
    "title": "Lab 01 — lavaan basics with observed variables",
    "section": "What you should take away",
    "text": "What you should take away\n\nlavaan models are written with a small “grammar”: ~, ~~, ~1 (and later =~)\nEven with manifest variables only, SEM lets you model systems of equations and covariances\nEquality constraints are easy: reuse parameter labels"
  },
  {
    "objectID": "labs/lab01_lavaan-basics.html#whats-next",
    "href": "labs/lab01_lavaan-basics.html#whats-next",
    "title": "Lab 01 — lavaan basics with observed variables",
    "section": "What’s next",
    "text": "What’s next\n\nIn the next lecture we move from “multivariate regression” to path models and mediation\nYou will reuse the same syntax you practiced today (plus parameter labels for effects)"
  },
  {
    "objectID": "templates/slides-template.html",
    "href": "templates/slides-template.html",
    "title": "Title of the lecture; Subtitle (optional)",
    "section": "",
    "text": "Point 1\nPoint 2\nPoint 3\n\n\n\n\n\n\n\nTip\n\n\n\nTeaching tip: keep one “workflow map” slide that reappears in every deck."
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#regression-models",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#regression-models",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Regression models",
    "text": "Regression models\nWhat you did since the beginning of the year (with link functions or not) was something like this \\[\ny = X\\beta + \\epsilon\n\\] Where \\(y\\) is the response variable, \\(X\\) the set of predictors and \\(\\epsilon\\) the error term. \nThese models,\n\nassume that all variables are directly observed/manifest\nallow measurement errors only in endogenous variables\nare just particular cases of SEM"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#sem-formula",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#sem-formula",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "SEM formula",
    "text": "SEM formula\nIn fact, the structural model of a SEM (i.e., excluding latent variables) is:\n\\[\nY = X^\\ast B' + \\zeta\n\\]\nWhere\n\n\\(Y\\) is the (n x p) matrix of endogenous variables\n\\(X^\\ast\\) is the n x (p + q) matrix of endogenous and exogenous variables\n\\(B\\) is the (p + q) x (p + q) coefficient matrices\n\\(\\zeta\\) is the (p x q) matrix of errors in the equations\n\nThis looks pretty similar to the regression formula, but with some matrices! Univariate regression models are just a special case of this formula where the parameter matrix is full of 0"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#regressions-in-matrices",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#regressions-in-matrices",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Regressions in matrices",
    "text": "Regressions in matrices\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   y x1 x2 x3\ny  0  1  2  3\nx1 0  0  0  0\nx2 0  0  0  0\nx3 0  0  0  0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   y x3 x2 x1\ny  0  3  2  1\nx3 0  0  5  4\nx2 0  0  0  6\nx1 0  0  0  0"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#a-first-example-with-simulated-data",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#a-first-example-with-simulated-data",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "A first example with simulated data",
    "text": "A first example with simulated data\n\n\nImagine you want to predict scores in the test we will do at the end of this corse (\\(y\\)), based on your prior statistical knowledge (\\(x_1\\)) and interest (\\(x_2\\)):\nFirst define the model\n\n\n\n\n\n\n\n\n\n\nSecond simulate the data\n\n# Simulate knowledge and interest as predictors of Y\nset.seed(12)\nN = 100\nx1 = rnorm(N)\nx2 = rnorm(N)\ny = .35*x1 + .20*x2 + rnorm(N)\nd &lt;- data.frame(x1,x2,y)\n\n\ncor(d)\n\n      x1    x2    y\nx1 1.000 0.016 0.39\nx2 0.016 1.000 0.12\ny  0.386 0.118 1.00\n\ncov(d)\n\n      x1    x2    y\nx1 0.748 0.014 0.36\nx2 0.014 0.998 0.13\ny  0.364 0.129 1.19"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#a-first-example-with-simulated-data-1",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#a-first-example-with-simulated-data-1",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "A first example with simulated data",
    "text": "A first example with simulated data\n\n# Simulate knowledge and interest as predictors of Y\nset.seed(12)\nN = 100\nx1 = rnorm(N)\nx2 = rnorm(N)\ny = .35*x1 + .20*x2 + rnorm(N)\nd &lt;- data.frame(x1,x2,y)\n\n\ncor(d)\n\n      x1    x2    y\nx1 1.000 0.016 0.39\nx2 0.016 1.000 0.12\ny  0.386 0.118 1.00\n\n#\ncov(d)\n\n      x1    x2    y\nx1 0.748 0.014 0.36\nx2 0.014 0.998 0.13\ny  0.364 0.129 1.19"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#lm-regression",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#lm-regression",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "lm regression",
    "text": "lm regression\n\n# fit a regression model\nm &lt;- lm(y ~ x1 + x2, data = d)\nsummary(m)\n\n\nCall:\nlm(formula = y ~ x1 + x2, data = d)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.8022 -0.6244 -0.0259  0.7150  1.8090 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  -0.0251     0.1009   -0.25     0.80    \nx1            0.4846     0.1172    4.14  7.5e-05 ***\nx2            0.1226     0.1015    1.21     0.23    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1 on 97 degrees of freedom\nMultiple R-squared:  0.162, Adjusted R-squared:  0.145 \nF-statistic: 9.36 on 2 and 97 DF,  p-value: 0.000191"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#introducing-lavaan",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#introducing-lavaan",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Introducing lavaan",
    "text": "Introducing lavaan\nlavaan (latent variable analysis) is actually THE package for SEM. You can use it to estimate a wide family of latent variable models, including: factor analysis, structural equation, longitudinal, multilevel, latent class, item respons, and missing data models… \n..But also simple regressions"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#model-fit-and-info",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#model-fit-and-info",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Model fit and info",
    "text": "Model fit and info\n\nlibrary(lavaan)\nml &lt;- \"y ~ 1 + x1 + x2\" #1 + gives the intercept\nfit &lt;- sem(ml, data = d)\n# summary(fit, rsquare=T)\n\n\n\nlavaan 0.6-19 ended normally after 1 iteration\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         4\n\n  Number of observations                           100\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\n[...]"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#model-parameters",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#model-parameters",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Model parameters",
    "text": "Model parameters\n\n\n[...]\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  y ~                                                 \n    x1                0.485    0.115    4.199    0.000\n    x2                0.123    0.100    1.227    0.220\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .y                -0.025    0.099   -0.253    0.800\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .y                 0.987    0.140    7.071    0.000\n\nR-Square:\n                   Estimate\n    y                 0.162\n\n[...]\n\n\nQUESTIONS? COMMENTS? What about lm?"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#model-plot",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#model-plot",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Model plot",
    "text": "Model plot\n\n# And we can plot it\nlibrary(semPlot)\nsemPaths(fit, whatLabels = \"parameters\",\n         edge.label.cex = 1.5, rotation = 2,\n         residuals = F, sizeMan = 10, curve = 1.9,\n         edge.color=\"black\", edge.label.color=\"black\")"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#model-matrices",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#model-matrices",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Model matrices",
    "text": "Model matrices\nWe can also look at the matrices to enter in the SEM mindset\n\n\n\n#The parameters matrix\ninspect(fit)$beta\n\n   y x1 x2\ny  0  2  3\nx1 0  0  0\nx2 0  0  0\n\ninspect(fit, \"estimates\")$beta\n\n   y   x1   x2\ny  0 0.48 0.12\nx1 0 0.00 0.00\nx2 0 0.00 0.00\n\n\n\n\n#The residual var-covar matrix\ninspect(fit)$psi\n\n   y x1 x2\ny  4      \nx1 0  0   \nx2 0  0  0\n\ninspect(fit, \"estimates\")$psi\n\n       y    x1    x2\ny  0.987            \nx1 0.000 0.741      \nx2 0.000 0.014 0.988"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#basic-lavaan-syntax",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#basic-lavaan-syntax",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Basic lavaan syntax",
    "text": "Basic lavaan syntax\nAs you can see, the regression syntax of lavaan is actually the same as lm, but there is much more in lavaan. \nModel specification sintax:\n\n\n\n\n\n\n\n\nSyntax\nFunction\nExample\n\n\n\n\n~\nRegress onto\nRegress B onto A: B ~ A\n\n\n~~\nResidual (co)variance\nVariance of A: A ~~ A  Variance of A and B: A ~~ B\n\n\n=~\nDefine a reflective LV\nF1 is defined by items 1-4: F1 =~ i1 + i2 + i3 + i4\n\n\n&lt;~\nDefine a formative LV\nF1 is defined by items 1-4: F1 &lt;~ i1 + i2 + i3 + i4\n\n\n:=\nDefine non-model parameters\nu2 := x + y\n\n\n*\nLabel or fix parameter\nZ ~ b*X labels the regression as b"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#basic-lavaan-functions",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#basic-lavaan-functions",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Basic lavaan functions",
    "text": "Basic lavaan functions\n\n\n\n\n\n\n\nFunction\nCommand\n\n\n\n\nsem() / cfa()\nFit the SEM model (cfa is nested in sem…which is nested in lavaan)\n\n\nfitMeasures()\nReturn fit indices of the SEM model\n\n\ninspect()\nInspect/extract information that is stored in a fitted model\n\n\nlavPredict()\nCompute estimated latent scores\n\n\nlavTestLRT()\nCompare (nested) lavaan models\n\n\nmodificationIndices()\nCompute the modification indices of a model\n\n\nparameterEstimates()\nParameter estimates of a latent variable model\n\n\nparameterTable()\nShow the table of the parameters of a fitted model\n\n\nsimulateData()\nSimulate data starting from a lavaan model syntax"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#model-matrices-1",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#model-matrices-1",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "Model matrices",
    "text": "Model matrices\n\n#The residual var-covar matrix\ninspect(fit)$psi\n\n   y x1 x2\ny  4      \nx1 0  0   \nx2 0  0  0\n\ninspect(fit, \"estimates\")$psi\n\n       y    x1    x2\ny  0.987            \nx1 0.000 0.741      \nx2 0.000 0.014 0.988"
  },
  {
    "objectID": "slides/02_path-analysis_mediation_equivalence.html#today-in-the-workflow",
    "href": "slides/02_path-analysis_mediation_equivalence.html#today-in-the-workflow",
    "title": "Path analysis & mediation",
    "section": "Today in the workflow",
    "text": "Today in the workflow\nSpecify → Identify → Estimate → Evaluate → Revise/Report\n\n\n\nToday: observed-variable path models and mediation (direct, indirect, total effects) + equivalence/pitfalls.\nNext (03): model fit & diagnostics (global vs local, residuals, MI, disciplined respecification)."
  },
  {
    "objectID": "slides/02_path-analysis_mediation_equivalence.html#learning-objectives",
    "href": "slides/02_path-analysis_mediation_equivalence.html#learning-objectives",
    "title": "Path analysis & mediation",
    "section": "Learning objectives",
    "text": "Learning objectives\nBy the end of this session you should be able to:\n\nWrite a path model as a system of regressions\nDefine direct, indirect, and total effects (and compute them in lavaan)\nExplain why indirect effects have non-normal sampling distributions\nRecognize just-identified path models (why “fit” can be uninformative)\nExplain (and fear, a little) model equivalence and causal interpretation limits"
  },
  {
    "objectID": "slides/02_path-analysis_mediation_equivalence.html#path-analysis-one-sentence",
    "href": "slides/02_path-analysis_mediation_equivalence.html#path-analysis-one-sentence",
    "title": "Path analysis & mediation",
    "section": "Path analysis (one sentence)",
    "text": "Path analysis (one sentence)\nA path model is a set of linear regressions estimated jointly, with an explicit covariance structure and with at least one variable working as mediator.\n\nAs usual, depicting the models is always the best way to understand our models."
  },
  {
    "objectID": "slides/02_path-analysis_mediation_equivalence.html#from-effects-to-equations",
    "href": "slides/02_path-analysis_mediation_equivalence.html#from-effects-to-equations",
    "title": "Path analysis & mediation",
    "section": "From “effects” to equations",
    "text": "From “effects” to equations\nA path diagram is shorthand for a system like:\n\\[\n\\begin{aligned}\nM &= i_M + aX + \\varepsilon_M\\\\\nY &= i_Y + c'X + bM + \\varepsilon_Y\n\\end{aligned}\n\\]\n\n(X) exogenous (predictor)\n(M) mediator (endogenous)\n(Y) outcome (endogenous)"
  },
  {
    "objectID": "slides/02_path-analysis_mediation_equivalence.html#mediation-three-effects",
    "href": "slides/02_path-analysis_mediation_equivalence.html#mediation-three-effects",
    "title": "Path analysis & mediation",
    "section": "Mediation: three effects",
    "text": "Mediation: three effects\n\\[\n\\text{Indirect} = ab \\qquad\n\\text{Direct} = c' \\qquad\n\\text{Total} = c = c' + ab\n\\]\nInterpretation (linear, continuous case):\n\n(a): expected change in (M) per unit change in (X)\n(b): expected change in (Y) per unit change in (M) (holding (X) fixed)\n(c’): remaining effect of (X) on (Y) after (M)"
  },
  {
    "objectID": "slides/02_path-analysis_mediation_equivalence.html#diagram-mediation-template",
    "href": "slides/02_path-analysis_mediation_equivalence.html#diagram-mediation-template",
    "title": "Path analysis & mediation",
    "section": "Diagram: mediation template",
    "text": "Diagram: mediation template\n\n\n\n“Indirect effect” is not automatically “causal mediation”. Causal language requires assumptions!"
  },
  {
    "objectID": "slides/02_path-analysis_mediation_equivalence.html#why-sem-for-mediation",
    "href": "slides/02_path-analysis_mediation_equivalence.html#why-sem-for-mediation",
    "title": "Path analysis & mediation",
    "section": "Why SEM for mediation?",
    "text": "Why SEM for mediation?\nSEM makes it easy to:\n\nestimate the system jointly (including residual covariance if justified)\ncompute functions of parameters (e.g., \\((ab)\\), totals, contrasts)\nadd covariates, multiple mediators, constraints, and (later) measurement models"
  },
  {
    "objectID": "slides/02_path-analysis_mediation_equivalence.html#indirect-effects-are-products",
    "href": "slides/02_path-analysis_mediation_equivalence.html#indirect-effects-are-products",
    "title": "Path analysis & mediation",
    "section": "Indirect effects are products",
    "text": "Indirect effects are products\nThe indirect effect is a product (ab). Even if (a) and (b) are approximately normal, the product is not.\nA common large-sample approximation (delta method):\n\\[\n\\mathrm{Var}(\\widehat{ab}) \\approx\nb^2\\mathrm{Var}(\\hat a) + a^2\\mathrm{Var}(\\hat b) + 2ab\\,\\mathrm{Cov}(\\hat a,\\hat b)\n\\]\nSobel test (same idea, historically popular):\n\\[\nz = \\frac{\\widehat{ab}}{\\sqrt{\\widehat{\\mathrm{Var}}(\\widehat{ab})}}\n\\]\n\n\n\nIn practice, bootstrap is often preferred for indirect effects (especially with small–moderate (N))."
  },
  {
    "objectID": "slides/02_path-analysis_mediation_equivalence.html#lavaan-mediation-as-a-model-defined-parameters",
    "href": "slides/02_path-analysis_mediation_equivalence.html#lavaan-mediation-as-a-model-defined-parameters",
    "title": "Path analysis & mediation",
    "section": "lavaan: mediation as a model + defined parameters",
    "text": "lavaan: mediation as a model + defined parameters\nYou already know ~ and ~~. The new piece is:\n\nlabels (a*X) and defined parameters (ind := a*b)\n\n\nlibrary(lavaan)\n\nmod_med &lt;- '\n  # structural regressions\n  M ~ a*X\n  Y ~ cprime*X + b*M\n\n  # (optional) exogenous variance\n  X ~~ X\n\n  # defined effects\n  ind := a*b\n  tot := cprime + (a*b)\n'\n\nfit &lt;- sem(mod_med, data = dat, meanstructure = TRUE)\nsummary(fit, standardized = TRUE)"
  },
  {
    "objectID": "slides/02_path-analysis_mediation_equivalence.html#bootstrap-the-indirect-effect",
    "href": "slides/02_path-analysis_mediation_equivalence.html#bootstrap-the-indirect-effect",
    "title": "Path analysis & mediation",
    "section": "Bootstrap the indirect effect",
    "text": "Bootstrap the indirect effect\n\nfit_b &lt;- sem(\n  mod_med, data = dat,\n  se = \"bootstrap\", bootstrap = 2000,\n  meanstructure = TRUE\n)\n\nparameterEstimates(fit_b, ci = TRUE, level = .95,\n                   standardized = TRUE) |&gt;\n  subset(op %in% c(\"~\", \":=\"))\n\nInterpretation:\n\nfocus on \\((ab)\\) estimate and its CI\nbootstrap CI is not magic; it’s still conditional on model assumptions"
  },
  {
    "objectID": "slides/02_path-analysis_mediation_equivalence.html#a-richer-example-multiple-indirect-paths",
    "href": "slides/02_path-analysis_mediation_equivalence.html#a-richer-example-multiple-indirect-paths",
    "title": "Path analysis & mediation",
    "section": "A richer example: multiple indirect paths",
    "text": "A richer example: multiple indirect paths\nSometimes the theory implies more than one mediated route.\n(Example structure; your variables will differ.)\n\nNotation. If there are two indirect paths:\n\\[\n\\text{ind}_1 = a_1 b_1,\n\\qquad\n\\text{ind}_2 = a_2 b_2,\n\\qquad\n\\text{total indirect} = \\text{ind}_1 + \\text{ind}_2\n\\]\nYou can define each and test/CI them separately."
  },
  {
    "objectID": "slides/02_path-analysis_mediation_equivalence.html#multiple-indirect-effects-notation",
    "href": "slides/02_path-analysis_mediation_equivalence.html#multiple-indirect-effects-notation",
    "title": "Path analysis & mediation",
    "section": "Multiple indirect effects: notation",
    "text": "Multiple indirect effects: notation\nIf there are two indirect paths:\n\\[\n\\text{ind}_1 = a_1 b_1,\n\\qquad\n\\text{ind}_2 = a_2 b_2,\n\\qquad\n\\text{total indirect} = \\text{ind}_1 + \\text{ind}_2\n\\]\nYou can define each and test/CI them separately."
  },
  {
    "objectID": "slides/02_path-analysis_mediation_equivalence.html#lavaan-multiple-indirect-effects-template",
    "href": "slides/02_path-analysis_mediation_equivalence.html#lavaan-multiple-indirect-effects-template",
    "title": "Path analysis & mediation",
    "section": "lavaan: multiple indirect effects (template)",
    "text": "lavaan: multiple indirect effects (template)\n\nmod_multi &lt;- '\n  # example: two mediators in parallel\n  M1 ~ a1*X\n  M2 ~ a2*X\n  Y  ~ cprime*X + b1*M1 + b2*M2\n\n  # optional: allow mediators to covary\n  M1 ~~ M2\n\n  ind1 := a1*b1\n  ind2 := a2*b2\n  indT := ind1 + ind2\n  tot  := cprime + indT\n'\n\nfit &lt;- sem(mod_multi, data = dat, se = \"bootstrap\", bootstrap = 2000)\nsummary(fit, standardized = TRUE)\n\n\n\n\nParallel mediators are easy to write; the hard part is interpretation (confounding, causal ordering, measurement)."
  },
  {
    "objectID": "slides/02_path-analysis_mediation_equivalence.html#standardized-vs-unstandardized-effects",
    "href": "slides/02_path-analysis_mediation_equivalence.html#standardized-vs-unstandardized-effects",
    "title": "Path analysis & mediation",
    "section": "Standardized vs unstandardized effects",
    "text": "Standardized vs unstandardized effects\n\nUnstandardized (\\(\\hat a\\), \\(\\hat b\\), \\(\\widehat{ab}\\)) are in original units → best for substantive interpretation if units matter.\nStandardized effects help compare across variables/scales.\n\nFor a simple mediation (continuous variables), a fully standardized indirect effect is:\n\\[\n(ab)_{\\text{std}} = ab \\cdot \\frac{\\sigma_X}{\\sigma_Y}\n\\]\n(because the (\\(\\sigma_M\\)) cancels)."
  },
  {
    "objectID": "slides/02_path-analysis_mediation_equivalence.html#identification-fit-can-be-perfect",
    "href": "slides/02_path-analysis_mediation_equivalence.html#identification-fit-can-be-perfect",
    "title": "Path analysis & mediation",
    "section": "Identification + “fit can be perfect”",
    "text": "Identification + “fit can be perfect”\nMany basic path/mediation models are just-identified:\n\nno degrees of freedom \\((df = 0)\\)\nthe model reproduces the sample covariance matrix exactly\nfit indices will look “perfect” even if the causal story is wrong\n\nA useful counting rule:\n\\[\ndf = \\frac{p(p+1)}{2} - t\n\\]\nwhere \\((p)\\) = observed variables, \\((t)\\) = free parameters."
  },
  {
    "objectID": "slides/02_path-analysis_mediation_equivalence.html#model-fit-what-is-being-tested-preview",
    "href": "slides/02_path-analysis_mediation_equivalence.html#model-fit-what-is-being-tested-preview",
    "title": "Path analysis & mediation",
    "section": "Model fit: what is being tested (preview)",
    "text": "Model fit: what is being tested (preview)\nThe global test compares the model-implied covariance to the sample covariance:\n\\[\nH_0:\\ \\Sigma(\\theta) = \\Sigma\n\\]\nIn ML estimation:\n\\[\n\\chi^2 = (N-1)\\,F_{ML}\n\\]\nwhere \\((F_{ML})\\) is the ML discrepancy function.\n\n\n\n\nDeck 03 is where we learn to use this information (global + local diagnostics) without worshipping cutoffs."
  },
  {
    "objectID": "slides/02_path-analysis_mediation_equivalence.html#a-meme-but-also-a-warning",
    "href": "slides/02_path-analysis_mediation_equivalence.html#a-meme-but-also-a-warning",
    "title": "Path analysis & mediation",
    "section": "A meme, but also a warning",
    "text": "A meme, but also a warning\n\n\n\n\nGood fit ≠ true model. In path analysis, equivalence is a real problem."
  },
  {
    "objectID": "slides/02_path-analysis_mediation_equivalence.html#model-equivalence-the-uncomfortable-truth",
    "href": "slides/02_path-analysis_mediation_equivalence.html#model-equivalence-the-uncomfortable-truth",
    "title": "Path analysis & mediation",
    "section": "Model equivalence: the uncomfortable truth",
    "text": "Model equivalence: the uncomfortable truth\nDifferent path diagrams can imply the same covariance matrix.\nSo:\n\nyou often cannot “prove” directionality from cross-sectional covariances alone\nmediation in SEM can be statistically identified and still be causally ambiguous\n\nPractical implication:\n\nTreat a path model as a quantitative claim under a set of assumptions, not as a discovery engine."
  },
  {
    "objectID": "slides/02_path-analysis_mediation_equivalence.html#when-can-mediation-be-interpreted-causally",
    "href": "slides/02_path-analysis_mediation_equivalence.html#when-can-mediation-be-interpreted-causally",
    "title": "Path analysis & mediation",
    "section": "When can mediation be interpreted causally?",
    "text": "When can mediation be interpreted causally?\nAt minimum, you need assumptions such as:\n\ntemporal ordering (X precedes M precedes Y)\nno unmeasured confounding for:\n\n\\((X \\rightarrow M)\\)\n\\((M \\rightarrow Y)\\)\n\\((X \\rightarrow Y)\\)\n\ncorrect model form (linearity, additivity, no omitted interactions unless modeled)\n\nWe will revisit causal interpretation when we discuss: - longitudinal designs (deck 09) - measurement error (decks 04–05)"
  },
  {
    "objectID": "slides/02_path-analysis_mediation_equivalence.html#diagnostics-what-to-check-now",
    "href": "slides/02_path-analysis_mediation_equivalence.html#diagnostics-what-to-check-now",
    "title": "Path analysis & mediation",
    "section": "Diagnostics (what to check now)",
    "text": "Diagnostics (what to check now)\nEven before learning “fit”, you should check:\n\nsign and magnitude of parameters (are they plausible?)\nstandard errors / CIs (especially for \\(ab\\))\nresidual variances (negative? huge? suspiciously tiny?)\ncollinearity among predictors/mediators (unstable estimates)\n\n\n\n\nFor mediation, your first diagnostic is often conceptual: is this ordering defensible? then statistical: is \\((ab)\\) estimated precisely?\n\n\n\n\n\n\nCan ‘sex’ be a mediator?!"
  },
  {
    "objectID": "slides/02_path-analysis_mediation_equivalence.html#exercises-lab-02",
    "href": "slides/02_path-analysis_mediation_equivalence.html#exercises-lab-02",
    "title": "Path analysis & mediation",
    "section": "Exercises (Lab 02)",
    "text": "Exercises (Lab 02)\nGo to:\n\nlabs/lab02_path-mediation.qmd\n\nYou will practice:\n\nFit a simple mediation with bootstrap CI for \\((ab)\\)\nAdd covariates (and observe what happens to \\((a)\\), \\((b)\\), and \\((c')\\))\nCompare partial vs “full” mediation (constraint \\((c'=0)\\))\nFit a parallel-mediator model and interpret \\((ind_1)\\), \\((ind_2)\\), \\((ind_T)\\)"
  },
  {
    "objectID": "slides/02_path-analysis_mediation_equivalence.html#pitfall-callout-full-mediation-is-rarely-a-good-goal",
    "href": "slides/02_path-analysis_mediation_equivalence.html#pitfall-callout-full-mediation-is-rarely-a-good-goal",
    "title": "Path analysis & mediation",
    "section": "Pitfall callout: “full mediation” is rarely a good goal",
    "text": "Pitfall callout: “full mediation” is rarely a good goal\nEven if \\((c')\\) is small/non-significant:\n\nit does not prove the direct path is zero\npower and measurement error can make \\((c')\\) hard to detect\nthe direct effect can be suppressed or masked by omitted paths\n\nBetter framing:\n\nfocus on effect sizes + uncertainty\ntest theoretically motivated constraints (and report them transparently)"
  },
  {
    "objectID": "slides/02_path-analysis_mediation_equivalence.html#take-home-3-things",
    "href": "slides/02_path-analysis_mediation_equivalence.html#take-home-3-things",
    "title": "Path analysis & mediation",
    "section": "Take-home: 3 things",
    "text": "Take-home: 3 things\n\nMediation effects are functions of parameters (\\((ab)\\), \\((c'+ab)\\)) → compute them explicitly\n\nThe indirect effect’s sampling distribution is non-normal → bootstrap is often sensible\n\nPath models are vulnerable to equivalence → fit alone cannot justify causal stories"
  },
  {
    "objectID": "slides/02_path-analysis_mediation_equivalence.html#further-reading-self-study",
    "href": "slides/02_path-analysis_mediation_equivalence.html#further-reading-self-study",
    "title": "Path analysis & mediation",
    "section": "Further reading / self-study",
    "text": "Further reading / self-study\n\nex01_power_montecarlo_sem.qmd — power and precision for indirect effects via simulation\n\n(Optional) causal inference perspective: add a short reading list in the course site resources"
  },
  {
    "objectID": "slides/02_path-analysis_mediation_equivalence.html#references",
    "href": "slides/02_path-analysis_mediation_equivalence.html#references",
    "title": "Path analysis & mediation",
    "section": "References",
    "text": "References\n(Add citations/keys once the course bibliography is finalized for the website.)"
  },
  {
    "objectID": "labs/lab02_path-mediation.html",
    "href": "labs/lab02_path-mediation.html",
    "title": "Lab 02 — Path analysis & mediation (observed variables)",
    "section": "",
    "text": "In this lab you will:\n\nFit a simple mediation model as a system of regressions in lavaan\nCompute direct, indirect, and total effects via defined parameters\nCompare delta-method vs bootstrap inference for the indirect effect\nTest a theoretically motivated constraint (full mediation: (c’ = 0))\nExtend to covariates and parallel mediators\n(Optional, advanced) See a concrete example of equivalent just-identified models"
  },
  {
    "objectID": "labs/lab02_path-mediation.html#a-write-the-model",
    "href": "labs/lab02_path-mediation.html#a-write-the-model",
    "title": "Lab 02 — Path analysis & mediation (observed variables)",
    "section": "1a) Write the model",
    "text": "1a) Write the model\n\nLabel the paths \\((a)\\), \\((b)\\), \\((c')\\)\nDefine ind := a*b and tot := cprime + a*b\n\n\n\nShow code\nmod_med &lt;- '\n  M ~ a*X\n  Y ~ cprime*X + b*M\n\n  ind := a*b\n  tot := cprime + (a*b)\n'"
  },
  {
    "objectID": "labs/lab02_path-mediation.html#b-fit-inspect",
    "href": "labs/lab02_path-mediation.html#b-fit-inspect",
    "title": "Lab 02 — Path analysis & mediation (observed variables)",
    "section": "1b) Fit + inspect",
    "text": "1b) Fit + inspect\n\n\nShow code\nfit_med &lt;- sem(mod_med, data = dat, meanstructure = TRUE)\nsummary(fit_med, standardized = TRUE)\n\n\nlavaan 0.6-19 ended normally after 1 iteration\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         7\n\n  Number of observations                           400\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  M ~                                                                   \n    X          (a)    0.463    0.049    9.521    0.000    0.463    0.430\n  Y ~                                                                   \n    X       (cprm)   -0.010    0.052   -0.185    0.853   -0.010   -0.008\n    M          (b)    0.659    0.048   13.604    0.000    0.659    0.603\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .M                -0.062    0.049   -1.248    0.212   -0.062   -0.056\n   .Y                -0.031    0.048   -0.648    0.517   -0.031   -0.026\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .M                 0.973    0.069   14.142    0.000    0.973    0.815\n   .Y                 0.914    0.065   14.142    0.000    0.914    0.641\n\nDefined Parameters:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n    ind               0.305    0.039    7.800    0.000    0.305    0.259\n    tot               0.296    0.057    5.185    0.000    0.296    0.251"
  },
  {
    "objectID": "labs/lab02_path-mediation.html#c-extract-only-the-pieces-you-need",
    "href": "labs/lab02_path-mediation.html#c-extract-only-the-pieces-you-need",
    "title": "Lab 02 — Path analysis & mediation (observed variables)",
    "section": "1c) Extract only the pieces you need",
    "text": "1c) Extract only the pieces you need\n\n\nShow code\npe &lt;- parameterEstimates(fit_med, standardized = TRUE)\npe[pe$op %in% c(\"~\",\":=\"), c(\"lhs\",\"op\",\"rhs\",\"label\",\"est\",\"se\",\"z\",\"pvalue\",\"std.all\")]\n\n\n   lhs op          rhs  label    est    se      z pvalue std.all\n1    M  ~            X      a  0.463 0.049  9.521  0.000   0.430\n2    Y  ~            X cprime -0.010 0.052 -0.185  0.853  -0.008\n3    Y  ~            M      b  0.659 0.048 13.604  0.000   0.603\n10 ind :=          a*b    ind  0.305 0.039  7.800  0.000   0.259\n11 tot := cprime+(a*b)    tot  0.296 0.057  5.185  0.000   0.251\n\n\nQuestions (answer in words)\n\nAre the estimates close to the generating values \\((a=0.50)\\), \\((b=0.60)\\), \\((c'=0.10)\\)?\nWhat is your estimate of the indirect effect \\((ab)\\)? Is it close to \\((0.30)\\)?\nWhat does lavaan use (by default) to get the SE for ind := a*b?"
  },
  {
    "objectID": "labs/lab02_path-mediation.html#compare-nested-models-lrt",
    "href": "labs/lab02_path-mediation.html#compare-nested-models-lrt",
    "title": "Lab 02 — Path analysis & mediation (observed variables)",
    "section": "Compare nested models (LRT)",
    "text": "Compare nested models (LRT)\n\n\nShow code\nanova(fit_med, fit_full)\n\n\n\nChi-Squared Difference Test\n\n         Df  AIC  BIC Chisq Chisq diff RMSEA Df diff Pr(&gt;Chisq)\nfit_med   0 2237 2265  0.00                                    \nfit_full  1 2235 2259  0.03     0.0343     0       1       0.85\n\n\nInterpretation questions\n\nWhat does a significant χ² difference imply here?\nIn this simulated world (true \\((c'=0.10)\\)), should you expect full mediation to be rejected as \\((N)\\) grows? Why?\nIn your substantive area, what theoretical arguments would justify fixing \\((c'=0)\\) (if any)?"
  },
  {
    "objectID": "labs/lab02_path-mediation.html#a-fit-without-z-misspecified-on-purpose",
    "href": "labs/lab02_path-mediation.html#a-fit-without-z-misspecified-on-purpose",
    "title": "Lab 02 — Path analysis & mediation (observed variables)",
    "section": "4a) Fit without Z (misspecified on purpose)",
    "text": "4a) Fit without Z (misspecified on purpose)\n\n\nShow code\nfit_noZ &lt;- sem(mod_med, data = dat2, meanstructure = TRUE)\nparameterEstimates(fit_noZ)[parameterEstimates(fit_noZ)$op %in% c(\"~\",\":=\"),\n                            c(\"lhs\",\"op\",\"rhs\",\"label\",\"est\",\"se\",\"pvalue\")]\n\n\n   lhs op          rhs  label    est    se pvalue\n1    M  ~            X      a  0.513 0.057  0.000\n2    Y  ~            X cprime -0.020 0.063  0.758\n3    Y  ~            M      b  0.846 0.050  0.000\n10 ind :=          a*b    ind  0.434 0.055  0.000\n11 tot := cprime+(a*b)    tot  0.415 0.075  0.000"
  },
  {
    "objectID": "labs/lab02_path-mediation.html#b-fit-with-z-included",
    "href": "labs/lab02_path-mediation.html#b-fit-with-z-included",
    "title": "Lab 02 — Path analysis & mediation (observed variables)",
    "section": "4b) Fit with Z included",
    "text": "4b) Fit with Z included\n\n\nShow code\nmod_withZ &lt;- '\n  M ~ a*X + d*Z\n  Y ~ cprime*X + b*M + e*Z\n\n  ind := a*b\n  tot := cprime + (a*b)\n'\nfit_withZ &lt;- sem(mod_withZ, data = dat2, meanstructure = TRUE)\nparameterEstimates(fit_withZ)[parameterEstimates(fit_withZ)$op %in% c(\"~\",\":=\"),\n                              c(\"lhs\",\"op\",\"rhs\",\"label\",\"est\",\"se\",\"pvalue\")]\n\n\n   lhs op          rhs  label   est    se pvalue\n1    M  ~            X      a 0.500 0.049    0.0\n2    M  ~            Z      d 0.578 0.049    0.0\n3    Y  ~            X cprime 0.097 0.059    0.1\n4    Y  ~            M      b 0.594 0.053    0.0\n5    Y  ~            Z      e 0.558 0.060    0.0\n15 ind :=          a*b    ind 0.297 0.040    0.0\n16 tot := cprime+(a*b)    tot 0.394 0.060    0.0\n\n\nQuestions\n\nCompare \\((b)\\) and \\((c')\\) from fit_noZ vs fit_withZ. Which one looks more biased and why?\nIn real research, why is “include covariates” not a magic causal fix?\nHow would you argue for including a covariate in a preregistered SEM?"
  },
  {
    "objectID": "labs/lab02_path-mediation.html#take-home-lab",
    "href": "labs/lab02_path-mediation.html#take-home-lab",
    "title": "Lab 02 — Path analysis & mediation (observed variables)",
    "section": "Take-home (lab)",
    "text": "Take-home (lab)\n\nMediation is a system of equations; the indirect effect is a defined parameter \\((ab)\\)\nFor \\((ab)\\), bootstrap CIs are often more trustworthy than normal-theory tests\nTesting “full mediation” is a constraint test—not a goal by itself\nCovariates help, but causal claims still require assumptions and design"
  },
  {
    "objectID": "slides/03_model-fit_diagnostics_respecification.html#today-in-the-workflow",
    "href": "slides/03_model-fit_diagnostics_respecification.html#today-in-the-workflow",
    "title": "Model fit & diagnostics",
    "section": "Today in the workflow",
    "text": "Today in the workflow\nSpecify → Identify → Estimate → Evaluate → Revise/Report\n\n\n\nToday: how we evaluate models: global fit + local diagnostics → disciplined respecification.\nWe keep the focus on observed-variable models; CFA-specific diagnostics come in deck 04."
  },
  {
    "objectID": "slides/03_model-fit_diagnostics_respecification.html#learning-objectives",
    "href": "slides/03_model-fit_diagnostics_respecification.html#learning-objectives",
    "title": "Model fit & diagnostics",
    "section": "Learning objectives",
    "text": "Learning objectives\nBy the end of this session you should be able to:\n\nState what “model fit” means: S vs Σ̂(θ) (exact vs approximate fit)\nDistinguish global fit from local misfit\nCompute and report core indices (χ², CFI/TLI, RMSEA + CI, SRMR) in lavaan\nUse residuals and modification indices (MI + EPC/SEPC) responsibly\nFollow a respecification protocol that avoids “fit hacking”"
  },
  {
    "objectID": "slides/03_model-fit_diagnostics_respecification.html#the-object-of-interest",
    "href": "slides/03_model-fit_diagnostics_respecification.html#the-object-of-interest",
    "title": "Model fit & diagnostics",
    "section": "The object of interest",
    "text": "The object of interest\nModel fit is about reproducing the observed covariance matrix.\n\\[\nH_0:\\ \\hat{\\Sigma}(\\theta) = \\Sigma\n\\]\n\n\n\n\n\n\nFit indices summarize “how close” the model-implied covariance structure is to the data."
  },
  {
    "objectID": "slides/03_model-fit_diagnostics_respecification.html#fit-is-a-property-of-a-model-data-estimator",
    "href": "slides/03_model-fit_diagnostics_respecification.html#fit-is-a-property-of-a-model-data-estimator",
    "title": "Model fit & diagnostics",
    "section": "Fit is a property of a model + data + estimator",
    "text": "Fit is a property of a model + data + estimator\nFit indices are not “truth meters”.\nThey depend on:\n\nsample size \\((N)\\)\nmodel degrees of freedom \\((df)\\)\nestimator and distributional assumptions (ML, robust ML, WLSMV, …)\nmodel complexity (how constrained the model is)"
  },
  {
    "objectID": "slides/03_model-fit_diagnostics_respecification.html#quick-example-dataset-same-structure-as-your-exercise-2",
    "href": "slides/03_model-fit_diagnostics_respecification.html#quick-example-dataset-same-structure-as-your-exercise-2",
    "title": "Model fit & diagnostics",
    "section": "Quick example dataset (same structure as your Exercise 2)",
    "text": "Quick example dataset (same structure as your Exercise 2)\nWe simulate data from a “true” structural model and then fit a simplified (misspecified) model to create misfit.\n\nN &lt;- 483\n\nm_true &lt;- \"\n  lifeSatisfaction ~ .05*attachment + .25*selfEsteem + .40*parentalSupport + .30*salary\n  selfEsteem       ~ .40*parentalSupport + .20*attachment\n  attachment ~~ .30*parentalSupport\n\"\n\nm_fit &lt;- \"\n  lifeSatisfaction ~ selfEsteem + salary     # omits some true predictors\n  selfEsteem       ~ parentalSupport + attachment\n  # attachment ~~ parentalSupport            # (omitted on purpose)\n\"\n\nE2 &lt;- simulateData(m_true, sample.nobs = N, seed = 12)\nfit &lt;- sem(m_fit, data = E2, meanstructure = TRUE)"
  },
  {
    "objectID": "slides/03_model-fit_diagnostics_respecification.html#families-of-fit-indices",
    "href": "slides/03_model-fit_diagnostics_respecification.html#families-of-fit-indices",
    "title": "Model fit & diagnostics",
    "section": "Families of fit indices",
    "text": "Families of fit indices\n\nχ²-based (exact-fit test)\nComparative / incremental (CFI, TLI, NFI)\nParsimony (RMSEA + CI; AIC/BIC)\nResidual-based / absolute (SRMR, RMR; and other “standalone” indices)\n\n\n\n\nYou need at least one index from each of: comparative + approximate + residual-based."
  },
  {
    "objectID": "slides/03_model-fit_diagnostics_respecification.html#χ²-test-what-it-is-and-why-it-annoys-people",
    "href": "slides/03_model-fit_diagnostics_respecification.html#χ²-test-what-it-is-and-why-it-annoys-people",
    "title": "Model fit & diagnostics",
    "section": "χ² test: what it is (and why it annoys people)",
    "text": "χ² test: what it is (and why it annoys people)\nUnder ML, the likelihood ratio test yields:\n\\[\n\\chi^2 = (N-1)\\,F_{\\mathrm{ML}}\n\\]\nwith \\((df = \\frac{p(p+1)}{2} - t)\\) (non-redundant moments minus free parameters).\nWhy it rejects so often:\n\nwith large \\((N)\\), tiny misspecifications become detectable\nreal data rarely satisfy “exact fit” assumptions"
  },
  {
    "objectID": "slides/03_model-fit_diagnostics_respecification.html#χ²-assumptions-classical-ml",
    "href": "slides/03_model-fit_diagnostics_respecification.html#χ²-assumptions-classical-ml",
    "title": "Model fit & diagnostics",
    "section": "χ² assumptions (classical ML)",
    "text": "χ² assumptions (classical ML)\nThe textbook χ² calibration relies on:\n\nindependent observations\ncorrect model form\nmultivariate normality for endogenous observed variables (in ML)\nsufficiently large \\((N)\\)\n\n…and it is sensitive to:\n\nnon-normality\nmissing data handling\nclustering (design effects)\n\n(Robust corrections and missing-data strategies come in deck 06.)"
  },
  {
    "objectID": "slides/03_model-fit_diagnostics_respecification.html#lavaan-core-fit-measures",
    "href": "slides/03_model-fit_diagnostics_respecification.html#lavaan-core-fit-measures",
    "title": "Model fit & diagnostics",
    "section": "lavaan: core fit measures",
    "text": "lavaan: core fit measures\n\nfitMeasures(fit, c(\"npar\", \"chisq\", \"df\", \"pvalue\",\n                   \"cfi\", \"tli\",\n                   \"rmsea\", \"rmsea.ci.lower\", \"rmsea.ci.upper\",\n                   \"srmr\"))\n\n\n\n\nWe will later discuss robust variants (scaled χ², robust CFI/RMSEA) and when they matter."
  },
  {
    "objectID": "slides/03_model-fit_diagnostics_respecification.html#comparative-indices-cfitli-baseline-model-logic",
    "href": "slides/03_model-fit_diagnostics_respecification.html#comparative-indices-cfitli-baseline-model-logic",
    "title": "Model fit & diagnostics",
    "section": "Comparative indices (CFI/TLI): baseline model logic",
    "text": "Comparative indices (CFI/TLI): baseline model logic\nComparative indices evaluate improvement over a baseline (independence) model.\nBaseline idea: each variable has its own variance; covariances are fixed to 0.\n\nbm &lt;- \"\n  lifeSatisfaction ~~ lifeSatisfaction\n  selfEsteem ~~ selfEsteem\n  salary ~~ salary\n  parentalSupport ~~ parentalSupport\n  attachment ~~ attachment\n\"\nfit_bm &lt;- sem(bm, data = E2, meanstructure = TRUE)"
  },
  {
    "objectID": "slides/03_model-fit_diagnostics_respecification.html#visual-intuition-baseline-vs-user-model",
    "href": "slides/03_model-fit_diagnostics_respecification.html#visual-intuition-baseline-vs-user-model",
    "title": "Model fit & diagnostics",
    "section": "Visual intuition: baseline vs user model",
    "text": "Visual intuition: baseline vs user model\n\n\nBaseline model (no covariances)\n\n\n\n\n\n\n\n\n\nchisq    df   cfi \n  277    10     0 \n\n\n\nUser model is evaluated relative to baseline.\nCFI uses the improvement in \\[\n\\delta = \\chi^2 - df\n\\] compared to baseline (and saturated).\n\n\n chisq     df    cfi \n62.984  3.000  0.725"
  },
  {
    "objectID": "slides/03_model-fit_diagnostics_respecification.html#cfi-formula-and-why-df-matters",
    "href": "slides/03_model-fit_diagnostics_respecification.html#cfi-formula-and-why-df-matters",
    "title": "Model fit & diagnostics",
    "section": "CFI formula (and why df matters)",
    "text": "CFI formula (and why df matters)\n\\[\n\\mathrm{CFI}=\\frac{\\delta(\\text{Baseline})-\\delta(\\text{User})}{\\delta(\\text{Baseline})-\\delta(\\text{Saturated})}\n\\qquad\n\\text{with}\\ \\delta=\\chi^2-df,\\ \\delta(\\text{Saturated})=0\n\\]\nImplication: \\(CFI\\)/\\(TLI\\) are functions of both misfit and \\(df\\).\nTwo models can have the same χ² but different CFI if their \\(df\\) differ.\n\nfitMeasures(fit, c(\"cfi\", \"tli\", \"nnfi\"))\n\n\n\n\nAll bounded between 0.0 and 1.0, with values closer to 1 (ONE) indicating better fit."
  },
  {
    "objectID": "slides/03_model-fit_diagnostics_respecification.html#parsimony-approximate-fit-rmsea",
    "href": "slides/03_model-fit_diagnostics_respecification.html#parsimony-approximate-fit-rmsea",
    "title": "Model fit & diagnostics",
    "section": "Parsimony & approximate fit: RMSEA",
    "text": "Parsimony & approximate fit: RMSEA\nRMSEA targets approximate (not exact) fit.\nA common ML form:\n\\[\n\\mathrm{RMSEA}=\\sqrt{\\max\\left(\\frac{\\chi^2-df}{df(N-1)},0\\right)}\n\\]\n\nprefers parsimony: penalizes low \\((df)\\) models less forgivingly\nalways report the confidence interval\n\n\nfitMeasures(fit, c(\"rmsea\", \"rmsea.ci.lower\", \"rmsea.ci.upper\"))\n\n\n\n\nIt is bounded between 0.0 and 1.0, with values closer to 0 (ZERO) indicating better fit."
  },
  {
    "objectID": "slides/03_model-fit_diagnostics_respecification.html#residual-based-fit-srmr",
    "href": "slides/03_model-fit_diagnostics_respecification.html#residual-based-fit-srmr",
    "title": "Model fit & diagnostics",
    "section": "Residual-based fit: SRMR",
    "text": "Residual-based fit: SRMR\nSRMR summarizes the average standardized residual:\n\ncompare observed correlations vs model-implied correlations\nless sensitive to \\((N)\\) than χ², but sensitive to model structure\n\n\nfitMeasures(fit, c(\"srmr\", \"rmr\"))\n\n\n\n\nSRMR is often most informative when paired with residual inspection (next slides).\n\n\n\n\n\n\nIt is bounded between 0.0 and 1.0, with values closer to 0 (ZERO) indicating better fit."
  },
  {
    "objectID": "slides/03_model-fit_diagnostics_respecification.html#what-to-report-minimum-set",
    "href": "slides/03_model-fit_diagnostics_respecification.html#what-to-report-minimum-set",
    "title": "Model fit & diagnostics",
    "section": "What to report (minimum set)",
    "text": "What to report (minimum set)\nIn manuscripts, prefer a consistent minimal bundle:\n\nestimator + missing data strategy\nχ², \\(df\\), \\(p\\)\n\\(CFI\\) and \\(TLI\\)\n\\(RMSEA\\) with 90% \\(CI\\) (and \\(SRMR\\))\nlocal diagnostics summary (what you checked, what you changed, and why)"
  },
  {
    "objectID": "slides/03_model-fit_diagnostics_respecification.html#global-vs-local-fit",
    "href": "slides/03_model-fit_diagnostics_respecification.html#global-vs-local-fit",
    "title": "Model fit & diagnostics",
    "section": "Global vs local fit",
    "text": "Global vs local fit\n\nGlobal fit: one-number summaries of overall mismatch (χ², CFI/TLI, RMSEA, SRMR)\nLocal fit: where the mismatch lives\n\nresidual covariance/correlation matrices\nstandardized residuals\nMI + EPC/SEPC\n\n\n\n\n\nGlobal fit can look “ok” while a few parameters are seriously wrong (and vice versa)."
  },
  {
    "objectID": "slides/03_model-fit_diagnostics_respecification.html#residuals-where-does-the-model-fail",
    "href": "slides/03_model-fit_diagnostics_respecification.html#residuals-where-does-the-model-fail",
    "title": "Model fit & diagnostics",
    "section": "Residuals: “where does the model fail?”",
    "text": "Residuals: “where does the model fail?”\nlavaan can return observed, implied, and residual covariances.\n\nres &lt;- lavResiduals(fit, type = \"raw\")\nnames(res)\n\n[1] \"type\"    \"cov\"     \"mean\"    \"cov.z\"   \"mean.z\"  \"summary\"\n\nres$cov     # residual covariance\n\n                 lfStsf slfEst salary prntlS attchm\nlifeSatisfaction  0.007                            \nselfEsteem        0.009  0.000                     \nsalary            0.015  0.039  0.000              \nparentalSupport   0.322  0.000  0.000  0.000       \nattachment        0.110  0.000  0.000  0.000  0.000\n\n\nIn practice you inspect:\n\nlargest residual covariances/correlations\npatterns (blocks, specific pairs, method effects)"
  },
  {
    "objectID": "slides/03_model-fit_diagnostics_respecification.html#standardized-residuals-local-z-scores",
    "href": "slides/03_model-fit_diagnostics_respecification.html#standardized-residuals-local-z-scores",
    "title": "Model fit & diagnostics",
    "section": "Standardized residuals (local z-scores)",
    "text": "Standardized residuals (local z-scores)\nStandardized residuals scale residuals by their sampling variability.\n\nres_std &lt;- residuals(fit, type = \"cor\")\nres_std$cov  # standardized residual covariances\n\n                 lfStsf slfEst salary prntlS attchm\nlifeSatisfaction  0.000                            \nselfEsteem        0.006  0.000                     \nsalary            0.012  0.037  0.000              \nparentalSupport   0.296  0.000  0.000  0.000       \nattachment        0.094  0.000  0.000  0.000  0.000\n\n\nHeuristic: large absolute standardized residuals flag local misfit.\n(We avoid “magic cutoffs”; interpret in context + patterns, but remember, you expect each of them to be \\(zero\\).)"
  },
  {
    "objectID": "slides/03_model-fit_diagnostics_respecification.html#step-5-model-modification-the-dangerous-step",
    "href": "slides/03_model-fit_diagnostics_respecification.html#step-5-model-modification-the-dangerous-step",
    "title": "Model fit & diagnostics",
    "section": "Step 5: model modification (the dangerous step)",
    "text": "Step 5: model modification (the dangerous step)\nThe goal is not “better numbers”.\nThe goal is:\n\na model that is more plausible given theory and diagnostics\nchanges that are transparent and ideally replicable"
  },
  {
    "objectID": "slides/03_model-fit_diagnostics_respecification.html#modification-indices-the-lagrange-multiplier-idea",
    "href": "slides/03_model-fit_diagnostics_respecification.html#modification-indices-the-lagrange-multiplier-idea",
    "title": "Model fit & diagnostics",
    "section": "Modification indices: the Lagrange Multiplier idea",
    "text": "Modification indices: the Lagrange Multiplier idea\nMI approximates how much χ² would decrease if a fixed parameter were freed.\n\nMI is a score test (local improvement)\nit does not tell you the direction/magnitude of the new parameter\n\nSo you inspect MI together with EPC (expected parameter change).\n\nmi &lt;- modificationIndices(fit, sort. = TRUE)\nhead(mi[, c(\"lhs\",\"op\",\"rhs\",\"mi\",\"epc\",\"sepc.all\")], 10)\n\n                lhs op              rhs     mi    epc sepc.all\n19 lifeSatisfaction  ~  parentalSupport 58.234  0.416    0.339\n18 lifeSatisfaction ~~       selfEsteem 52.562 -0.941   -0.880\n27  parentalSupport  ~ lifeSatisfaction 45.077  0.256    0.314\n21       selfEsteem  ~ lifeSatisfaction 33.931 -0.587   -0.620\n20 lifeSatisfaction  ~       attachment  5.473  0.114    0.100\n22       selfEsteem  ~           salary  0.752  0.041    0.037\n32       attachment  ~       selfEsteem  0.556  2.784    3.020\n28  parentalSupport  ~       selfEsteem  0.555 -6.106   -7.100\n24           salary  ~       selfEsteem  0.552  0.028    0.031\n23           salary  ~ lifeSatisfaction  0.524  0.073    0.086"
  },
  {
    "objectID": "slides/03_model-fit_diagnostics_respecification.html#epc-vs-sepc-why-you-want-both",
    "href": "slides/03_model-fit_diagnostics_respecification.html#epc-vs-sepc-why-you-want-both",
    "title": "Model fit & diagnostics",
    "section": "EPC vs SEPC (why you want both)",
    "text": "EPC vs SEPC (why you want both)\n\nEPC: expected unstandardized change (units matter)\nSEPC: expected standardized change (comparability)\n\nIf an MI is huge but EPC is tiny, the “improvement” may be statistically detectable but substantively trivial (especially with large \\(N\\))."
  },
  {
    "objectID": "slides/03_model-fit_diagnostics_respecification.html#a-disciplined-respecification-protocol",
    "href": "slides/03_model-fit_diagnostics_respecification.html#a-disciplined-respecification-protocol",
    "title": "Model fit & diagnostics",
    "section": "A disciplined respecification protocol",
    "text": "A disciplined respecification protocol\n\nCheck admissibility\nconvergence, Heywood cases (negative variances), huge SE, non-identified warnings\nInspect local misfit\nresiduals → standardized residuals → MI/EPC\nApply theory filter\nis the modification plausible and consistent with your construct/design? How can I justify it? What are the consequences on my theory/model?\nChange one thing at a time\nrefit, re-check, document\nValidate\nholdout sample / replication / preregistration (when feasible)"
  },
  {
    "objectID": "slides/03_model-fit_diagnostics_respecification.html#pitfall-callout-models-that-fit-are-not-necessarily-true",
    "href": "slides/03_model-fit_diagnostics_respecification.html#pitfall-callout-models-that-fit-are-not-necessarily-true",
    "title": "Model fit & diagnostics",
    "section": "Pitfall callout: “models that fit” are not necessarily true",
    "text": "Pitfall callout: “models that fit” are not necessarily true\nRemember that just because your model fits the data, you cannot conclude that your model is correct nor that the data generating process follows your hypothesized paths.\n\nopposite arrows can imply the same covariance structure (equivalence)\npost-hoc modifications capitalize on chance\nmeasurement error in observed variables contaminates estimates\n\nAs usual all models are false, but some are useful."
  },
  {
    "objectID": "slides/03_model-fit_diagnostics_respecification.html#exercises-lab-03",
    "href": "slides/03_model-fit_diagnostics_respecification.html#exercises-lab-03",
    "title": "Model fit & diagnostics",
    "section": "Exercises (Lab 03)",
    "text": "Exercises (Lab 03)\nGo to:\n\nlabs/lab03_fit-diagnostics_MI_residuals.qmd\n\nYou’ll practice:\n\nExtracting and reporting fit indices\nInspecting residual matrices (raw + standardized)\nUsing MI + EPC/SEPC to propose theory-justified modifications\nDocumenting a respecification path transparently"
  },
  {
    "objectID": "slides/03_model-fit_diagnostics_respecification.html#take-home-3-things",
    "href": "slides/03_model-fit_diagnostics_respecification.html#take-home-3-things",
    "title": "Model fit & diagnostics",
    "section": "Take-home: 3 things",
    "text": "Take-home: 3 things\n\nFit indices quantify mismatch between S and Σ̂(θ); they are not “truth”\n\nAlways pair global fit with local diagnostics (residuals + MI/EPC)\n\nRespecification is a scientific decision: theory + transparency + validation"
  },
  {
    "objectID": "slides/03_model-fit_diagnostics_respecification.html#optional-beyond-fixed-cutoffs",
    "href": "slides/03_model-fit_diagnostics_respecification.html#optional-beyond-fixed-cutoffs",
    "title": "Model fit & diagnostics",
    "section": "Optional: beyond fixed cutoffs",
    "text": "Optional: beyond fixed cutoffs\nRules like “CFI &gt; .95” or “RMSEA &lt; .06” can be misleading because fit indices depend on:\n\nmodel structure (df, factor loadings, cross-loadings, residual correlations)\ndistributional features (non-normality, ordinal data)\nestimation method and sample size\n\nExtra (later / self-study): dynamic fit indices & simulation-informed expectations\n\nGroskurth et al. (2023) — fit cutoffs depend on analysis characteristics\nMcNeish & Wolf (2023) — pushing against universal cutoffs\nDynamic fit index app (for exploring scenario-dependent thresholds)"
  },
  {
    "objectID": "slides/03_model-fit_diagnostics_respecification.html#references",
    "href": "slides/03_model-fit_diagnostics_respecification.html#references",
    "title": "Model fit & diagnostics",
    "section": "References",
    "text": "References\n(We’ll finalize citations/keys in refs/references.bib when polishing the course website.)"
  },
  {
    "objectID": "labs/lab03_fit-diagnostics_MI_residuals.html",
    "href": "labs/lab03_fit-diagnostics_MI_residuals.html",
    "title": "Lab 03 — Fit & diagnostics: residuals, MI, and disciplined respecification",
    "section": "",
    "text": "In this lab you will learn to:\n\nExtract and report core global fit indices (χ², CFI/TLI, RMSEA+CI, SRMR)\nInspect local misfit using residual matrices (raw + standardized)\nUse modification indices (MI) together with EPC / SEPC (not MI alone)\nApply a disciplined respecification protocol: one change at a time, theory filter, document\n\nImportant constraint for this lab:\nYou are not allowed to add paths “because MI says so”. Each change needs a short substantive rationale."
  },
  {
    "objectID": "labs/lab03_fit-diagnostics_MI_residuals.html#a-extract-key-indices",
    "href": "labs/lab03_fit-diagnostics_MI_residuals.html#a-extract-key-indices",
    "title": "Lab 03 — Fit & diagnostics: residuals, MI, and disciplined respecification",
    "section": "1a) Extract key indices",
    "text": "1a) Extract key indices\n\n\nShow code\nfitMeasures(\n  fit0,\n  c(\"npar\",\"chisq\",\"df\",\"pvalue\",\"cfi\",\"tli\",\n    \"rmsea\",\"rmsea.ci.lower\",\"rmsea.ci.upper\",\"srmr\")\n)\n\n\n          npar          chisq             df         pvalue            cfi \n         8.000         72.623          3.000          0.000          0.788 \n           tli          rmsea rmsea.ci.lower rmsea.ci.upper           srmr \n         0.505          0.219          0.177          0.264          0.067"
  },
  {
    "objectID": "labs/lab03_fit-diagnostics_MI_residuals.html#b-interpret",
    "href": "labs/lab03_fit-diagnostics_MI_residuals.html#b-interpret",
    "title": "Lab 03 — Fit & diagnostics: residuals, MI, and disciplined respecification",
    "section": "1b) Interpret",
    "text": "1b) Interpret\nAnswer in 3–5 sentences:\n\nDoes the model seem globally plausible?\nWhich indices are most informative here and why?\nIf χ² is significant, what are two non-mutually-exclusive reasons?"
  },
  {
    "objectID": "labs/lab03_fit-diagnostics_MI_residuals.html#a-residual-covariances",
    "href": "labs/lab03_fit-diagnostics_MI_residuals.html#a-residual-covariances",
    "title": "Lab 03 — Fit & diagnostics: residuals, MI, and disciplined respecification",
    "section": "3a) Residual covariances",
    "text": "3a) Residual covariances\n\n\nShow code\n# Play with the different 'type of residuals'\n# 'cor', 'cor.bollen', 'cor.bentler', 'raw'\nres_cov &lt;- lavResiduals(fit0)\n# res_cov$resid is S - Sigma_hat\nres_cov$cov\n\n\n                 lfStsf slfEst salary prntlS attchm\nlifeSatisfaction -0.005                            \nselfEsteem       -0.005  0.000                     \nsalary           -0.008 -0.018  0.000              \nparentalSupport   0.288  0.000  0.000  0.000       \nattachment        0.076  0.000  0.000  0.000  0.000\n\n\nTasks\n\nIdentify the top 3 largest absolute standardized residual covariances.\nFor each, propose a candidate explanation (omitted path? omitted covariance? shared cause?)."
  },
  {
    "objectID": "labs/lab03_fit-diagnostics_MI_residuals.html#a-create-model-m1-by-adding-exactly-one-theoretically-justified-parameter",
    "href": "labs/lab03_fit-diagnostics_MI_residuals.html#a-create-model-m1-by-adding-exactly-one-theoretically-justified-parameter",
    "title": "Lab 03 — Fit & diagnostics: residuals, MI, and disciplined respecification",
    "section": "5a) Create model m1 by adding exactly one theoretically justified parameter",
    "text": "5a) Create model m1 by adding exactly one theoretically justified parameter\nCommon modifications include:\n\nadding a covariance among exogenous variables (~~)\nadding a missing regression (~)\n\nCreate m1 below and refit.\n\n\nShow code\nm1 &lt;- \"\n  lifeSatisfaction ~ selfEsteem + salary\n  selfEsteem       ~ parentalSupport + attachment\n\n  # ADD ONE PARAMETER HERE (exactly one line)\n  attachment ~~ parentalSupport\n  # OR: lifeSatisfaction ~ parentalSupport\n  # OR: lifeSatisfaction ~ attachment\n\"\nfit1 &lt;- sem(m1, data = dat, meanstructure = TRUE)"
  },
  {
    "objectID": "labs/lab03_fit-diagnostics_MI_residuals.html#b-compare-global-fit",
    "href": "labs/lab03_fit-diagnostics_MI_residuals.html#b-compare-global-fit",
    "title": "Lab 03 — Fit & diagnostics: residuals, MI, and disciplined respecification",
    "section": "5b) Compare global fit",
    "text": "5b) Compare global fit\n\n\nShow code\nfitMeasures(fit0, c(\"chisq\",\"df\",\"cfi\",\"tli\",\"rmsea\",\"srmr\"))\n\n\n chisq     df    cfi    tli  rmsea   srmr \n72.623  3.000  0.788  0.505  0.219  0.067 \n\n\nShow code\nfitMeasures(fit1, c(\"chisq\",\"df\",\"cfi\",\"tli\",\"rmsea\",\"srmr\"))\n\n\n chisq     df    cfi    tli  rmsea   srmr \n72.859  5.000  0.820  0.640  0.168  0.068"
  },
  {
    "objectID": "labs/lab03_fit-diagnostics_MI_residuals.html#c-χ²-difference-test-nested-models",
    "href": "labs/lab03_fit-diagnostics_MI_residuals.html#c-χ²-difference-test-nested-models",
    "title": "Lab 03 — Fit & diagnostics: residuals, MI, and disciplined respecification",
    "section": "5c) χ² difference test (nested models)",
    "text": "5c) χ² difference test (nested models)\n\n\nShow code\nanova(fit0, fit1)\n\n\n\nChi-Squared Difference Test\n\n     Df  AIC  BIC Chisq Chisq diff RMSEA Df diff Pr(&gt;Chisq)\nfit0  3 2746 2779  72.6                                    \nfit1  5 5476 5530  72.9      0.237     0       2       0.89"
  },
  {
    "objectID": "labs/lab03_fit-diagnostics_MI_residuals.html#d-re-check-local-misfit",
    "href": "labs/lab03_fit-diagnostics_MI_residuals.html#d-re-check-local-misfit",
    "title": "Lab 03 — Fit & diagnostics: residuals, MI, and disciplined respecification",
    "section": "5d) Re-check local misfit",
    "text": "5d) Re-check local misfit\n\n\nShow code\nres1_std &lt;- residuals(fit1)$cov\nres1_std\n\n\n                 lfStsf slfEst salary prntlS attchm\nlifeSatisfaction -0.003                            \nselfEsteem       -0.003  0.000                     \nsalary           -0.005 -0.009  0.000              \nparentalSupport   0.364  0.000  0.021  0.000       \nattachment        0.098  0.000  0.006  0.000  0.000\n\n\nInterpretation questions\n\nDid the single change reduce the largest residuals you identified?\nDid it improve the global indices meaningfully?\nIs the change defensible theoretically, or did you “chase fit”?"
  },
  {
    "objectID": "labs/lab03_fit-diagnostics_MI_residuals.html#what-you-should-take-away",
    "href": "labs/lab03_fit-diagnostics_MI_residuals.html#what-you-should-take-away",
    "title": "Lab 03 — Fit & diagnostics: residuals, MI, and disciplined respecification",
    "section": "What you should take away",
    "text": "What you should take away\n\nGlobal fit summarizes mismatch; it doesn’t locate problems.\nLocal diagnostics (residuals + MI/EPC) tell you where mismatch lives.\nRespecification must be theory-filtered, done one step at a time, and reported transparently."
  },
  {
    "objectID": "labs/lab03_fit-diagnostics_MI_residuals.html#whats-next",
    "href": "labs/lab03_fit-diagnostics_MI_residuals.html#whats-next",
    "title": "Lab 03 — Fit & diagnostics: residuals, MI, and disciplined respecification",
    "section": "What’s next",
    "text": "What’s next\n\nNext we shift to measurement models (CFA), where local diagnostics include:\n\ncross-loadings (often fixed to 0)\ncorrelated errors\nweak items / low loadings"
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#today-in-the-workflow",
    "href": "slides/04_cfa_measurement_reliability.html#today-in-the-workflow",
    "title": "CFA: measurement models, identification, reliability",
    "section": "Today in the workflow",
    "text": "Today in the workflow\nSpecify → Identify → Estimate → Evaluate → Revise/Report\n\n\n\nToday: the measurement part — CFA (and reliability from CFA).\nTwo-step mindset: measure first, then relate constructs (SEM deck 05)."
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#learning-objectives",
    "href": "slides/04_cfa_measurement_reliability.html#learning-objectives",
    "title": "CFA: measurement models, identification, reliability",
    "section": "Learning objectives",
    "text": "Learning objectives\nBy the end of this session you should be able to:\n\nExplain the difference between EFA and CFA (and why CFA is confirmatory)\nWrite the CFA measurement model in equations and matrices\nUnderstand identification & scaling (marker vs std.lv)\nFit CFA models in lavaan and interpret loadings, factor correlations, and residual variances\nUse local diagnostics in CFA (residuals, MI/EPC) without “fit hacking”\nCompute and report reliability from CFA (ω-family; and (briefly) bifactor implications)"
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#outline",
    "href": "slides/04_cfa_measurement_reliability.html#outline",
    "title": "CFA: measurement models, identification, reliability",
    "section": "Outline",
    "text": "Outline\n\nFactor analysis: what problem are we solving?\nEFA vs CFA (confirmatory stance)\nCFA model: equations, matrices, implied covariance\nIdentification and constraints (scaling + rules)\nCFA in R (lavaan) + interpretation\nReliability from CFA\nBifactor model (keep your guard up)"
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#factor-analysis",
    "href": "slides/04_cfa_measurement_reliability.html#factor-analysis",
    "title": "CFA: measurement models, identification, reliability",
    "section": "Factor analysis",
    "text": "Factor analysis\nFactor analysis models the idea that a small number of latent dimensions explain systematic covariance among many observed variables."
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#exploratory-factor-analysis-efa",
    "href": "slides/04_cfa_measurement_reliability.html#exploratory-factor-analysis-efa",
    "title": "CFA: measurement models, identification, reliability",
    "section": "Exploratory Factor Analysis (EFA)",
    "text": "Exploratory Factor Analysis (EFA)\nEFA: discover a plausible loading pattern.\n\nloadings are “free” (rotation chooses a representation)\nuseful for exploration and item development\nweak theory → strong exploration"
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#confirmatory-factor-analysis-cfa",
    "href": "slides/04_cfa_measurement_reliability.html#confirmatory-factor-analysis-cfa",
    "title": "CFA: measurement models, identification, reliability",
    "section": "Confirmatory Factor Analysis (CFA)",
    "text": "Confirmatory Factor Analysis (CFA)\nCFA: test a specific measurement hypothesis.\n\nyou specify which loadings are zero vs free\nyou can impose constraints (equal loadings, orthogonality, hierarchies)\nfit and diagnostics evaluate a theoretically constrained model\n\n\n\n\n\nCFA is not “EFA with nicer output”: it is a confirmatory claim with theoretical commitments."
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#general-formula-your-original",
    "href": "slides/04_cfa_measurement_reliability.html#general-formula-your-original",
    "title": "CFA: measurement models, identification, reliability",
    "section": "General formula (your original)",
    "text": "General formula (your original)\nThe general CFA model can be written as:\n\\[\n\\begin{aligned}\n\\mathbf{x} &= \\mathbf{\\Lambda}_x\\,\\mathbf{\\xi} + \\mathbf{\\delta} \\\\\n\\mathbf{y} &= \\mathbf{\\Lambda}_y\\,\\mathbf{\\eta} + \\mathbf{\\epsilon}\n\\end{aligned}\n\\]\nwhere () and () are observed variables, () and () are latent factors, and () and () are errors of measurement."
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#the-general-formula-explained-scalar-form",
    "href": "slides/04_cfa_measurement_reliability.html#the-general-formula-explained-scalar-form",
    "title": "CFA: measurement models, identification, reliability",
    "section": "The general formula explained (scalar form)",
    "text": "The general formula explained (scalar form)\n\\[\n\\begin{aligned}\ny &= b_0 + b_1 x + \\epsilon \\\\\ny_1 &= \\tau_1 + \\lambda_1\\eta + \\epsilon_1\n\\end{aligned}\n\\]\n\\[\n\\begin{bmatrix}\n  y_1 \\\\\n  y_2 \\\\\n  y_3\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n  \\tau_1 \\\\\n  \\tau_2 \\\\\n  \\tau_3\n\\end{bmatrix}\n+\n\\begin{bmatrix}\n  \\lambda_1 \\\\\n  \\lambda_2 \\\\\n  \\lambda_3\n\\end{bmatrix}\n(\\eta_1)\n+\n\\begin{bmatrix}\n  \\epsilon_1 \\\\\n  \\epsilon_2 \\\\\n  \\epsilon_3\n\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#measurement-first-implications-reflective-realism",
    "href": "slides/04_cfa_measurement_reliability.html#measurement-first-implications-reflective-realism",
    "title": "CFA: measurement models, identification, reliability",
    "section": "Measurement-first implications (reflective realism)",
    "text": "Measurement-first implications (reflective realism)\nWhen we draw () (()) from latent to observed, we assume reflective latent variables:\n\nARROWS are ARROWS: the construct affects responses\n“realist” interpretation: the latent variable is something that exists (at least as a stable attribute)\nobserved scores = construct signal + measurement error\n\nPragmatic “just a summary” interpretations are not neutral: they imply different measurement models (PCA/EGA/…)."
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#the-implied-covariance-the-single-most-important-equation",
    "href": "slides/04_cfa_measurement_reliability.html#the-implied-covariance-the-single-most-important-equation",
    "title": "CFA: measurement models, identification, reliability",
    "section": "The implied covariance (the single most important equation)",
    "text": "The implied covariance (the single most important equation)\nFor a standard CFA with latent covariance () and residual covariance ():\n\\[\n\\Sigma = \\Lambda \\Phi \\Lambda' + \\Theta\n\\]\nThis is why:\n\nloadings (()) and factor correlations (()) jointly shape observed covariances\ncorrelated residuals (off-diagonal ()) are extra covariance not explained by factors"
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#matrices-your-original-visual-slide",
    "href": "slides/04_cfa_measurement_reliability.html#matrices-your-original-visual-slide",
    "title": "CFA: measurement models, identification, reliability",
    "section": "Matrices (your original visual slide)",
    "text": "Matrices (your original visual slide)\n\n\nLambda: matrix of loadings\n\n\nPhi: latent variance-covariance matrix\n\n\nTheta: residual variance-covariance matrix"
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#cfa-model-families-you-will-see-a-lot",
    "href": "slides/04_cfa_measurement_reliability.html#cfa-model-families-you-will-see-a-lot",
    "title": "CFA: measurement models, identification, reliability",
    "section": "CFA “model families” you will see a lot",
    "text": "CFA “model families” you will see a lot\nKey design choices:\n\none factor vs multiple factors\nare factors correlated?\northogonal vs oblique\nhierarchical / second-order?\nbifactor structure?\n\nAll have statistical and theoretical consequences."
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#a-quick-visual-tour-common-cfa-structures",
    "href": "slides/04_cfa_measurement_reliability.html#a-quick-visual-tour-common-cfa-structures",
    "title": "CFA: measurement models, identification, reliability",
    "section": "A quick visual tour: common CFA structures",
    "text": "A quick visual tour: common CFA structures"
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#one-factor-model",
    "href": "slides/04_cfa_measurement_reliability.html#one-factor-model",
    "title": "CFA: measurement models, identification, reliability",
    "section": "One-factor model",
    "text": "One-factor model"
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#two-factor-model-correlated-factors",
    "href": "slides/04_cfa_measurement_reliability.html#two-factor-model-correlated-factors",
    "title": "CFA: measurement models, identification, reliability",
    "section": "Two-factor model (correlated factors)",
    "text": "Two-factor model (correlated factors)"
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#two-factor-model-orthogonal-factors",
    "href": "slides/04_cfa_measurement_reliability.html#two-factor-model-orthogonal-factors",
    "title": "CFA: measurement models, identification, reliability",
    "section": "Two-factor model (orthogonal factors)",
    "text": "Two-factor model (orthogonal factors)"
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#hierarchical-model-second-order-factor",
    "href": "slides/04_cfa_measurement_reliability.html#hierarchical-model-second-order-factor",
    "title": "CFA: measurement models, identification, reliability",
    "section": "Hierarchical model (second-order factor)",
    "text": "Hierarchical model (second-order factor)"
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#in-r-lavaan-grammar-for-cfa",
    "href": "slides/04_cfa_measurement_reliability.html#in-r-lavaan-grammar-for-cfa",
    "title": "CFA: measurement models, identification, reliability",
    "section": "In R (lavaan grammar for CFA)",
    "text": "In R (lavaan grammar for CFA)\nCore operator:\n\n=~ defines a factor from its indicators\n\n\nm &lt;- '\n  F1 =~ y1 + y2 + y3\n  F2 =~ y4 + y5 + y6\n  F1 ~~ F2          # factor covariance (oblique)\n'\n\nfit &lt;- cfa(m, data = dat)  # or sem(m, data = dat)\nsummary(fit, standardized = TRUE, fit.measures = TRUE)"
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#constraints-scaling-your-original-slide",
    "href": "slides/04_cfa_measurement_reliability.html#constraints-scaling-your-original-slide",
    "title": "CFA: measurement models, identification, reliability",
    "section": "Constraints (scaling) — your original slide",
    "text": "Constraints (scaling) — your original slide\nTo estimate latent-variable models, you must scale each factor. Two common strategies:\n\nStandardize latent variables: fix factor means to 0 and factor variances to 1 (std.lv = TRUE).\nMarker method: set one loading (()) per factor to 1 (lavaan default).\n\n\nfit &lt;- cfa(m, data = dat, std.lv = TRUE)"
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#constraints-explained-marker-vs-standardization",
    "href": "slides/04_cfa_measurement_reliability.html#constraints-explained-marker-vs-standardization",
    "title": "CFA: measurement models, identification, reliability",
    "section": "Constraints explained (marker vs standardization)",
    "text": "Constraints explained (marker vs standardization)\n\n\n\\[\n\\Sigma = \\Lambda\\Phi\\Lambda' + \\Theta\n\\]\nMarker method (fix one loading to 1)\nStandardization (fix factor variance to 1)\n(Scaling changes the metric of unstandardized loadings, not the implied covariance model.)"
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#identification-rules-your-original-framing",
    "href": "slides/04_cfa_measurement_reliability.html#identification-rules-your-original-framing",
    "title": "CFA: measurement models, identification, reliability",
    "section": "Identification rules (your original framing)",
    "text": "Identification rules (your original framing)\nFor CFA, common identification rules include:\n\nthe t-rule\nthe Three-Indicator Rule\nthe Two-Indicator Rule"
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#the-t-rule",
    "href": "slides/04_cfa_measurement_reliability.html#the-t-rule",
    "title": "CFA: measurement models, identification, reliability",
    "section": "The t-rule",
    "text": "The t-rule\nNecessary but not sufficient:\n\\[\nt \\leq \\frac{q(q+1)}{2}\n\\]\nwhere (t) is the number of free parameters and (q) the number of observed variables.\nIntuition: the number of nonredundant elements in (S) is the maximum number of “equations”; if unknowns exceed equations, identification is impossible."
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#the-three-indicator-rule",
    "href": "slides/04_cfa_measurement_reliability.html#the-three-indicator-rule",
    "title": "CFA: measurement models, identification, reliability",
    "section": "The Three-Indicator Rule",
    "text": "The Three-Indicator Rule\nA sufficient (not necessary) condition (with diagonal ()):\n\nOne-factor model: at least three indicators with nonzero loadings.\nMultifactor model is identified if:\n\n≥ 3 indicators per factor\neach row of () has one and only one nonzero element (simple structure)\n() is diagonal"
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#the-two-indicator-rule",
    "href": "slides/04_cfa_measurement_reliability.html#the-two-indicator-rule",
    "title": "CFA: measurement models, identification, reliability",
    "section": "The Two-Indicator Rule",
    "text": "The Two-Indicator Rule\nA sufficient (not necessary) condition for models with &gt;1 factor:\n\n() diagonal\neach factor scaled (one () fixed to 1, or std.lv=TRUE)\nplus:\n\n≥ 2 indicators per factor\neach row of (): one nonzero element\n() diagonal\neach row of () has at least one nonzero off-diagonal element"
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#cfa-evaluation-where-deck-03-plugs-in",
    "href": "slides/04_cfa_measurement_reliability.html#cfa-evaluation-where-deck-03-plugs-in",
    "title": "CFA: measurement models, identification, reliability",
    "section": "CFA evaluation (where deck 03 plugs in)",
    "text": "CFA evaluation (where deck 03 plugs in)\nGlobal indices are the same as in deck 03 (χ², CFI/TLI, RMSEA+CI, SRMR).\nWhat becomes CFA-specific is local misfit interpretation:\n\nbig residual correlations → local dependence / method effects / cross-loadings\nMI/EPC candidates typically propose:\n\ncross-loadings (theory-threatening)\ncorrelated residuals (requires a clear justification)\nfactor covariances / (rarely) indicator-level regressions\n\n\n\n\n\nFit ≠ validity. “Improving fit” can destroy the meaning of a factor model if you add substantively implausible parameters."
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#a-disciplined-cfa-respecification-mindset",
    "href": "slides/04_cfa_measurement_reliability.html#a-disciplined-cfa-respecification-mindset",
    "title": "CFA: measurement models, identification, reliability",
    "section": "A disciplined CFA respecification mindset",
    "text": "A disciplined CFA respecification mindset\n\nFirst: check items (loadings, residual variances, signs)\nThen: check patterns (blocks of residual correlations)\nMI/EPC only after you have a hypothesis for the misfit\nPrefer fewer, theory-consistent modifications over many “small fixes”\nReport the respecification path transparently (what changed and why)"
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#live-example-lavaan-holzinger-swineford-1939",
    "href": "slides/04_cfa_measurement_reliability.html#live-example-lavaan-holzinger-swineford-1939",
    "title": "CFA: measurement models, identification, reliability",
    "section": "Live example (lavaan): Holzinger & Swineford (1939)",
    "text": "Live example (lavaan): Holzinger & Swineford (1939)\n\ndat &lt;- HolzingerSwineford1939\n\nm_hs &lt;- '\n  visual  =~ x1 + x2 + x3\n  textual =~ x4 + x5 + x6\n  speed   =~ x7 + x8 + x9\n'\nfit_hs &lt;- cfa(m_hs, data = dat, std.lv = TRUE)"
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#interpret-loadings-and-factor-correlations",
    "href": "slides/04_cfa_measurement_reliability.html#interpret-loadings-and-factor-correlations",
    "title": "CFA: measurement models, identification, reliability",
    "section": "Interpret loadings and factor correlations",
    "text": "Interpret loadings and factor correlations\n\npe &lt;- parameterEstimates(fit_hs, standardized = TRUE)\npe[pe$op %in% c(\"=~\",\"~~\") & pe$lhs %in% c(\"visual\",\"textual\",\"speed\"),\n   c(\"lhs\",\"op\",\"rhs\",\"est\",\"se\",\"pvalue\",\"std.all\")]\n\n       lhs op     rhs   est    se pvalue std.all\n1   visual =~      x1 0.900 0.081      0   0.772\n2   visual =~      x2 0.498 0.077      0   0.424\n3   visual =~      x3 0.656 0.074      0   0.581\n4  textual =~      x4 0.990 0.057      0   0.852\n5  textual =~      x5 1.102 0.063      0   0.855\n6  textual =~      x6 0.917 0.054      0   0.838\n7    speed =~      x7 0.619 0.070      0   0.570\n8    speed =~      x8 0.731 0.066      0   0.723\n9    speed =~      x9 0.670 0.065      0   0.665\n19  visual ~~  visual 1.000 0.000     NA   1.000\n20 textual ~~ textual 1.000 0.000     NA   1.000\n21   speed ~~   speed 1.000 0.000     NA   1.000\n22  visual ~~ textual 0.459 0.064      0   0.459\n23  visual ~~   speed 0.471 0.073      0   0.471\n24 textual ~~   speed 0.283 0.069      0   0.283"
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#reliability-from-cfa-ω-family",
    "href": "slides/04_cfa_measurement_reliability.html#reliability-from-cfa-ω-family",
    "title": "CFA: measurement models, identification, reliability",
    "section": "Reliability from CFA (ω family)",
    "text": "Reliability from CFA (ω family)\n\nreliability(fit_hs)\n\n       visual textual speed\nalpha   0.626   0.883 0.688\nomega   0.625   0.885 0.688\nomega2  0.625   0.885 0.688\nomega3  0.612   0.885 0.686\navevar  0.371   0.721 0.424\n\n\n\n\n\nWe emphasize ω-family reliability because it aligns with the CFA model; α is a special (often unrealistic) case."
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#graphical-representation",
    "href": "slides/04_cfa_measurement_reliability.html#graphical-representation",
    "title": "CFA: measurement models, identification, reliability",
    "section": "Graphical representation",
    "text": "Graphical representation"
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#a-hierarchical-intelligence-example-your-original-wisc-slide",
    "href": "slides/04_cfa_measurement_reliability.html#a-hierarchical-intelligence-example-your-original-wisc-slide",
    "title": "CFA: measurement models, identification, reliability",
    "section": "A hierarchical intelligence example (your original WISC slide)",
    "text": "A hierarchical intelligence example (your original WISC slide)\nTheory: test scores are affected by specific abilities (e.g., processing speed) that are influenced by an overarching factor ((g)).\n\n\n\n\nIn practice, you should validate first-order abilities before jumping to a second-order model."
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#second-order-cfa-syntax-template",
    "href": "slides/04_cfa_measurement_reliability.html#second-order-cfa-syntax-template",
    "title": "CFA: measurement models, identification, reliability",
    "section": "Second-order CFA (syntax template)",
    "text": "Second-order CFA (syntax template)\n\nm2 &lt;- \"\nVCI =~ SI + VC + CO\nPRI =~ BD + PCn + MR\nWMI =~ DS + LN\nPSI =~ CD + SS\ng   =~ VCI + PRI + WMI + PSI\n\"\nfit2 &lt;- sem(m2, std.lv = TRUE, sample.cov = S, sample.nobs = N)"
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#a-second-theoretical-model-bifactor-your-original",
    "href": "slides/04_cfa_measurement_reliability.html#a-second-theoretical-model-bifactor-your-original",
    "title": "CFA: measurement models, identification, reliability",
    "section": "A second theoretical model: bifactor (your original)",
    "text": "A second theoretical model: bifactor (your original)\nParallel theories: test scores are affected by a general factor ((g)) and by specific abilities that explain remaining variance.\nAll factors are set to be orthogonal."
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#bifactor-model-in-r-your-original-structure",
    "href": "slides/04_cfa_measurement_reliability.html#bifactor-model-in-r-your-original-structure",
    "title": "CFA: measurement models, identification, reliability",
    "section": "Bifactor model in R (your original structure)",
    "text": "Bifactor model in R (your original structure)\n\nmb &lt;- \"\nVCI =~ a*SI + a*VC + a*CO\nPRI =~ b*BD + b*PCn + b*MR\nWMI =~ c*DS + c*LN\nPSI =~ d*CD + d*SS\ng   =~ SI + VC + CO + BD + PCn + MR + DS + LN + CD + SS\n\"\n\nfitb &lt;- sem(\n  mb,\n  orthogonal = TRUE,\n  std.lv = TRUE,\n  sample.cov = S,\n  sample.nobs = N\n)"
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#bifactor-interpretation-requires-diagnostics-not-just-fit",
    "href": "slides/04_cfa_measurement_reliability.html#bifactor-interpretation-requires-diagnostics-not-just-fit",
    "title": "CFA: measurement models, identification, reliability",
    "section": "Bifactor: interpretation requires diagnostics (not just fit)",
    "text": "Bifactor: interpretation requires diagnostics (not just fit)\nBifactor often improves fit by absorbing residual covariance. Before interpreting:\n\nis the general factor strong enough? (ECV / ωH / H)\nare specific factors meaningful or “junk factors”?\ndo constraints (orthogonality, equal loadings) make sense?\n\n\n# semTools helpers for bifactor diagnostics (when you fit a bifactor model)\n# bifactorIndices(fitb)\n# reliability(fitb)   # omega family; ωH is especially relevant\n\n\n\n\nA bifactor model that “fits” can still be a bad measurement story."
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#exercises-lab-04",
    "href": "slides/04_cfa_measurement_reliability.html#exercises-lab-04",
    "title": "CFA: measurement models, identification, reliability",
    "section": "Exercises (Lab 04)",
    "text": "Exercises (Lab 04)\nGo to:\n\nlabs/lab04_cfa_reliability_omegas.qmd\n\nYou will practice:\n\nFit and compare 1-factor vs correlated-factors CFA\nInspect local misfit (residual correlations + MI/EPC) with a theory filter\nCompute reliability (ω) from CFA and report it\n(Optional) Fit a bifactor model and evaluate interpretability (ωH / ECV)"
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#take-home-3-things",
    "href": "slides/04_cfa_measurement_reliability.html#take-home-3-things",
    "title": "CFA: measurement models, identification, reliability",
    "section": "Take-home: 3 things",
    "text": "Take-home: 3 things\n\nCFA is a confirmatory measurement claim: zeros and constraints are theory\n\nIdentification/scaling is not a nuisance—it’s the metric of your construct\n\nReliability and validity are model-based: fit helps, but fit ≠ validity"
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#further-reading-self-study",
    "href": "slides/04_cfa_measurement_reliability.html#further-reading-self-study",
    "title": "CFA: measurement models, identification, reliability",
    "section": "Further reading / self-study",
    "text": "Further reading / self-study\n\nextras/ex10_bifactor_esem_method-factors.qmd — bifactor/ESEM/method factors (advanced)\nextras/ex05_miivs_factor-score-regression.qmd — factor scores & regression (later)\nClassic SEM measurement chapters (CFA fundamentals; see course website reading list)"
  },
  {
    "objectID": "slides/04_cfa_measurement_reliability.html#references",
    "href": "slides/04_cfa_measurement_reliability.html#references",
    "title": "CFA: measurement models, identification, reliability",
    "section": "References",
    "text": "References\n(Add citations/keys once the course bibliography is finalized for the website.)"
  },
  {
    "objectID": "labs/lab04_cfa_reliability_omegas.html",
    "href": "labs/lab04_cfa_reliability_omegas.html",
    "title": "Lab 04 — CFA: measurement, local misfit, and ω reliability",
    "section": "",
    "text": "In this lab you will:\n\nFit and compare CFA models (1-factor vs correlated factors)\nInspect local misfit for CFA (residual correlations, MI + EPC/SEPC)\nMake theory-filtered respecification choices (and document them)\nCompute and report reliability from CFA (ω family via semTools)\n(Optional) Fit a bifactor model and evaluate interpretability (not just fit)"
  },
  {
    "objectID": "labs/lab04_cfa_reliability_omegas.html#model-1-one-general-factor",
    "href": "labs/lab04_cfa_reliability_omegas.html#model-1-one-general-factor",
    "title": "Lab 04 — CFA: measurement, local misfit, and ω reliability",
    "section": "Model 1: One general factor",
    "text": "Model 1: One general factor\n\n\nShow code\nm1 &lt;- '\n  g =~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9\n'\nfit1 &lt;- cfa(m1, data = dat, std.lv = TRUE)\nsummary(fit1, fit.measures = TRUE, standardized = TRUE)\n\n\nlavaan 0.6-19 ended normally after 18 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        18\n\n  Number of observations                           301\n\nModel Test User Model:\n                                                      \n  Test statistic                               312.264\n  Degrees of freedom                                27\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                               918.852\n  Degrees of freedom                                36\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.677\n  Tucker-Lewis Index (TLI)                       0.569\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -3851.224\n  Loglikelihood unrestricted model (H1)      -3695.092\n                                                      \n  Akaike (AIC)                                7738.448\n  Bayesian (BIC)                              7805.176\n  Sample-size adjusted Bayesian (SABIC)       7748.091\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.187\n  90 Percent confidence interval - lower         0.169\n  90 Percent confidence interval - upper         0.206\n  P-value H_0: RMSEA &lt;= 0.050                    0.000\n  P-value H_0: RMSEA &gt;= 0.080                    1.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.143\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  g =~                                                                  \n    x1                0.510    0.068    7.550    0.000    0.510    0.438\n    x2                0.259    0.071    3.649    0.000    0.259    0.220\n    x3                0.252    0.068    3.689    0.000    0.252    0.223\n    x4                0.985    0.057   17.375    0.000    0.985    0.848\n    x5                1.084    0.063   17.181    0.000    1.084    0.841\n    x6                0.917    0.054   17.092    0.000    0.917    0.838\n    x7                0.196    0.066    2.975    0.003    0.196    0.180\n    x8                0.203    0.061    3.323    0.001    0.203    0.201\n    x9                0.309    0.060    5.143    0.000    0.309    0.307\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .x1                1.098    0.092   11.895    0.000    1.098    0.808\n   .x2                1.315    0.108   12.188    0.000    1.315    0.951\n   .x3                1.212    0.099   12.186    0.000    1.212    0.950\n   .x4                0.380    0.048    7.963    0.000    0.380    0.281\n   .x5                0.486    0.059    8.193    0.000    0.486    0.293\n   .x6                0.356    0.043    8.295    0.000    0.356    0.298\n   .x7                1.145    0.094   12.215    0.000    1.145    0.967\n   .x8                0.981    0.080   12.202    0.000    0.981    0.960\n   .x9                0.919    0.076   12.105    0.000    0.919    0.906\n    g                 1.000                               1.000    1.000"
  },
  {
    "objectID": "labs/lab04_cfa_reliability_omegas.html#model-2-three-correlated-factors-the-classic-hs-structure",
    "href": "labs/lab04_cfa_reliability_omegas.html#model-2-three-correlated-factors-the-classic-hs-structure",
    "title": "Lab 04 — CFA: measurement, local misfit, and ω reliability",
    "section": "Model 2: Three correlated factors (the classic HS structure)",
    "text": "Model 2: Three correlated factors (the classic HS structure)\n\n\nShow code\nm3 &lt;- '\n  visual  =~ x1 + x2 + x3\n  textual =~ x4 + x5 + x6\n  speed   =~ x7 + x8 + x9\n'\nfit3 &lt;- cfa(m3, data = dat, std.lv = TRUE)\nsummary(fit3, fit.measures = TRUE, standardized = TRUE)\n\n\nlavaan 0.6-19 ended normally after 20 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        21\n\n  Number of observations                           301\n\nModel Test User Model:\n                                                      \n  Test statistic                                85.306\n  Degrees of freedom                                24\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                               918.852\n  Degrees of freedom                                36\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.931\n  Tucker-Lewis Index (TLI)                       0.896\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -3737.745\n  Loglikelihood unrestricted model (H1)      -3695.092\n                                                      \n  Akaike (AIC)                                7517.490\n  Bayesian (BIC)                              7595.339\n  Sample-size adjusted Bayesian (SABIC)       7528.739\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.092\n  90 Percent confidence interval - lower         0.071\n  90 Percent confidence interval - upper         0.114\n  P-value H_0: RMSEA &lt;= 0.050                    0.001\n  P-value H_0: RMSEA &gt;= 0.080                    0.840\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.065\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  visual =~                                                             \n    x1                0.900    0.081   11.128    0.000    0.900    0.772\n    x2                0.498    0.077    6.429    0.000    0.498    0.424\n    x3                0.656    0.074    8.817    0.000    0.656    0.581\n  textual =~                                                            \n    x4                0.990    0.057   17.474    0.000    0.990    0.852\n    x5                1.102    0.063   17.576    0.000    1.102    0.855\n    x6                0.917    0.054   17.082    0.000    0.917    0.838\n  speed =~                                                              \n    x7                0.619    0.070    8.903    0.000    0.619    0.570\n    x8                0.731    0.066   11.090    0.000    0.731    0.723\n    x9                0.670    0.065   10.305    0.000    0.670    0.665\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  visual ~~                                                             \n    textual           0.459    0.064    7.189    0.000    0.459    0.459\n    speed             0.471    0.073    6.461    0.000    0.471    0.471\n  textual ~~                                                            \n    speed             0.283    0.069    4.117    0.000    0.283    0.283\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .x1                0.549    0.114    4.833    0.000    0.549    0.404\n   .x2                1.134    0.102   11.146    0.000    1.134    0.821\n   .x3                0.844    0.091    9.317    0.000    0.844    0.662\n   .x4                0.371    0.048    7.779    0.000    0.371    0.275\n   .x5                0.446    0.058    7.642    0.000    0.446    0.269\n   .x6                0.356    0.043    8.277    0.000    0.356    0.298\n   .x7                0.799    0.081    9.823    0.000    0.799    0.676\n   .x8                0.488    0.074    6.573    0.000    0.488    0.477\n   .x9                0.566    0.071    8.003    0.000    0.566    0.558\n    visual            1.000                               1.000    1.000\n    textual           1.000                               1.000    1.000\n    speed             1.000                               1.000    1.000"
  },
  {
    "objectID": "labs/lab04_cfa_reliability_omegas.html#a-compare-global-fit",
    "href": "labs/lab04_cfa_reliability_omegas.html#a-compare-global-fit",
    "title": "Lab 04 — CFA: measurement, local misfit, and ω reliability",
    "section": "1a) Compare global fit",
    "text": "1a) Compare global fit\nExtract a minimal set of indices:\n\n\nShow code\nget_fit &lt;- function(f) {\n  fitMeasures(f, c(\"chisq\",\"df\",\"pvalue\",\"cfi\",\"tli\",\"rmsea\",\"rmsea.ci.lower\",\"rmsea.ci.upper\",\"srmr\"))\n}\n\nrbind(one_factor = get_fit(fit1),\n      three_factor = get_fit(fit3))\n\n\n             chisq df  pvalue   cfi   tli  rmsea rmsea.ci.lower rmsea.ci.upper\none_factor   312.3 27 0.0e+00 0.677 0.569 0.1874         0.1690          0.206\nthree_factor  85.3 24 8.5e-09 0.931 0.896 0.0921         0.0714          0.114\n               srmr\none_factor   0.1431\nthree_factor 0.0652\n\n\nQuestions\n\nWhich model fits better globally? Which indices support that conclusion?\nDo you expect the 3-factor model to always fit better? Why/why not?"
  },
  {
    "objectID": "labs/lab04_cfa_reliability_omegas.html#b-compare-with-a-χ²-difference-test-nested",
    "href": "labs/lab04_cfa_reliability_omegas.html#b-compare-with-a-χ²-difference-test-nested",
    "title": "Lab 04 — CFA: measurement, local misfit, and ω reliability",
    "section": "1b) Compare with a χ² difference test (nested?)",
    "text": "1b) Compare with a χ² difference test (nested?)\n\n\nShow code\nanova(fit1, fit3)\n\n\n\nChi-Squared Difference Test\n\n     Df  AIC  BIC Chisq Chisq diff RMSEA Df diff Pr(&gt;Chisq)    \nfit3 24 7517 7595  85.3                                        \nfit1 27 7738 7805 312.3        227 0.498       3     &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nQuestion\n\nIs this comparison a valid nested χ² test here? Why (think: is the 1-factor model nested in the 3-factor model)?\n\n\n\n\n\n\n\nEven when anova() runs, you must reason about nesting. Not every model comparison is a proper LRT."
  },
  {
    "objectID": "labs/lab04_cfa_reliability_omegas.html#a-standardized-loadings",
    "href": "labs/lab04_cfa_reliability_omegas.html#a-standardized-loadings",
    "title": "Lab 04 — CFA: measurement, local misfit, and ω reliability",
    "section": "2a) Standardized loadings",
    "text": "2a) Standardized loadings\n\n\nShow code\npe3 &lt;- parameterEstimates(fit3, standardized = TRUE)\nload3 &lt;- subset(pe3, op == \"=~\")[, c(\"lhs\",\"rhs\",\"est\",\"se\",\"pvalue\",\"std.all\")]\nload3\n\n\n      lhs rhs   est    se pvalue std.all\n1  visual  x1 0.900 0.081      0   0.772\n2  visual  x2 0.498 0.077      0   0.424\n3  visual  x3 0.656 0.074      0   0.581\n4 textual  x4 0.990 0.057      0   0.852\n5 textual  x5 1.102 0.063      0   0.855\n6 textual  x6 0.917 0.054      0   0.838\n7   speed  x7 0.619 0.070      0   0.570\n8   speed  x8 0.731 0.066      0   0.723\n9   speed  x9 0.670 0.065      0   0.665\n\n\nTasks\n\nIdentify the weakest indicator(s) by std.all.\nIdentify any signs that look strange (e.g., negative loadings, extremely low/high)."
  },
  {
    "objectID": "labs/lab04_cfa_reliability_omegas.html#b-residual-variances",
    "href": "labs/lab04_cfa_reliability_omegas.html#b-residual-variances",
    "title": "Lab 04 — CFA: measurement, local misfit, and ω reliability",
    "section": "2b) Residual variances",
    "text": "2b) Residual variances\n\n\nShow code\nresvar3 &lt;- subset(pe3, op == \"~~\" & lhs %in% vars & rhs %in% vars)[, c(\"lhs\",\"est\",\"std.all\")]\nresvar3\n\n\n   lhs   est std.all\n10  x1 0.549   0.404\n11  x2 1.134   0.821\n12  x3 0.844   0.662\n13  x4 0.371   0.275\n14  x5 0.446   0.269\n15  x6 0.356   0.298\n16  x7 0.799   0.676\n17  x8 0.488   0.477\n18  x9 0.566   0.558\n\n\nQuestion\n\nDo any residual variances look “too small” or “too large”? What might that mean substantively?"
  },
  {
    "objectID": "labs/lab04_cfa_reliability_omegas.html#c-factor-correlations",
    "href": "labs/lab04_cfa_reliability_omegas.html#c-factor-correlations",
    "title": "Lab 04 — CFA: measurement, local misfit, and ω reliability",
    "section": "2c) Factor correlations",
    "text": "2c) Factor correlations\n\n\nShow code\nphi3 &lt;- subset(pe3, op == \"~~\" & lhs %in% c(\"visual\",\"textual\",\"speed\") &\n                 rhs %in% c(\"visual\",\"textual\",\"speed\") & lhs != rhs)[, c(\"lhs\",\"rhs\",\"est\",\"std.all\")]\nphi3\n\n\n       lhs     rhs   est std.all\n22  visual textual 0.459   0.459\n23  visual   speed 0.471   0.471\n24 textual   speed 0.283   0.283\n\n\nQuestions\n\nAre factor correlations high? What would make you worry about discriminant validity?\nIn your area, what theory would justify correlated factors?"
  },
  {
    "objectID": "labs/lab04_cfa_reliability_omegas.html#take-home",
    "href": "labs/lab04_cfa_reliability_omegas.html#take-home",
    "title": "Lab 04 — CFA: measurement, local misfit, and ω reliability",
    "section": "Take-home",
    "text": "Take-home\n\nCFA is a measurement hypothesis: zeros and constraints are theory.\nPair global fit with CFA-specific local diagnostics (residual correlations + MI/EPC).\nRespecify with discipline: one change at a time, theory filter, transparent reporting.\nReliability should match your measurement model: ω from CFA is usually a better default than α."
  },
  {
    "objectID": "labs/lab05_sem_capstone_eat.html",
    "href": "labs/lab05_sem_capstone_eat.html",
    "title": "Lab 05 — SEM capstone with the EAT dataset",
    "section": "",
    "text": "This lab is a full SEM workflow exercise (measurement + structure):\n\nApply the Two-Step rule (identify/fit measurement first, then structure)\nEvaluate the model using fit indices + diagnostics (global + local)\nUse MI + EPC/SEPC to propose a theory-justified modification\nCompare a latent SEM vs a sum-score path model\n\nYou will produce: - a short “model checking log” (what you checked, what you changed, why) - a figure of your final model (R / PowerPoint / hand-drawn)"
  },
  {
    "objectID": "labs/lab05_sem_capstone_eat.html#a-specify-the-measurement-model",
    "href": "labs/lab05_sem_capstone_eat.html#a-specify-the-measurement-model",
    "title": "Lab 05 — SEM capstone with the EAT dataset",
    "section": "1a) Specify the measurement model",
    "text": "1a) Specify the measurement model\n\n\nShow code\nm_cfa &lt;- \"\n  peerPressure =~ PP1 + PP2 + PP3 + PP4\n  socialMedia  =~ SM1 + SM2 + SM3 + SM4\n  socialComparison =~ SC1 + SC2 + SC3\n  eatingDisorder =~ ED1 + ED2\n\""
  },
  {
    "objectID": "labs/lab05_sem_capstone_eat.html#b-fit-and-check-convergence",
    "href": "labs/lab05_sem_capstone_eat.html#b-fit-and-check-convergence",
    "title": "Lab 05 — SEM capstone with the EAT dataset",
    "section": "1b) Fit and check convergence",
    "text": "1b) Fit and check convergence\n\n\nShow code\nfit_cfa &lt;- sem(m_cfa, data = dE4_1, std.lv = TRUE)\nlavInspect(fit_cfa, \"converged\")\n\n\n[1] TRUE"
  },
  {
    "objectID": "labs/lab05_sem_capstone_eat.html#c-inspect-measurement-results",
    "href": "labs/lab05_sem_capstone_eat.html#c-inspect-measurement-results",
    "title": "Lab 05 — SEM capstone with the EAT dataset",
    "section": "1c) Inspect measurement results",
    "text": "1c) Inspect measurement results\n\n\nShow code\nsummary(fit_cfa, standardized = TRUE, fit.measures = TRUE)\n\n\nlavaan 0.6-19 ended normally after 30 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        32\n\n  Number of observations                          1423\n\nModel Test User Model:\n                                                      \n  Test statistic                               421.825\n  Degrees of freedom                                59\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                              3150.947\n  Degrees of freedom                                78\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.882\n  Tucker-Lewis Index (TLI)                       0.844\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)             -28616.602\n  Loglikelihood unrestricted model (H1)     -28405.690\n                                                      \n  Akaike (AIC)                               57297.204\n  Bayesian (BIC)                             57465.541\n  Sample-size adjusted Bayesian (SABIC)      57363.888\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.066\n  90 Percent confidence interval - lower         0.060\n  90 Percent confidence interval - upper         0.072\n  P-value H_0: RMSEA &lt;= 0.050                    0.000\n  P-value H_0: RMSEA &gt;= 0.080                    0.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.042\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                      Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  peerPressure =~                                                          \n    PP1                  1.016    0.036   27.977    0.000    1.016    0.821\n    PP2                  0.998    0.037   26.980    0.000    0.998    0.786\n    PP3                  0.424    0.033   12.944    0.000    0.424    0.370\n    PP4                  0.468    0.034   13.945    0.000    0.468    0.397\n  socialMedia =~                                                           \n    SM1                  0.592    0.039   15.294    0.000    0.592    0.517\n    SM2                  0.575    0.040   14.449    0.000    0.575    0.486\n    SM3                  0.554    0.039   14.234    0.000    0.554    0.479\n    SM4                  0.645    0.041   15.928    0.000    0.645    0.541\n  socialComparison =~                                                      \n    SC1                  0.881    0.038   23.042    0.000    0.881    0.662\n    SC2                  0.940    0.038   24.865    0.000    0.940    0.718\n    SC3                  0.856    0.039   22.167    0.000    0.856    0.637\n  eatingDisorder =~                                                        \n    ED1                  0.720    0.067   10.709    0.000    0.720    0.596\n    ED2                  0.671    0.064   10.491    0.000    0.671    0.547\n\nCovariances:\n                      Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  peerPressure ~~                                                          \n    socialMedia         -0.013    0.039   -0.345    0.730   -0.013   -0.013\n    socialComparsn       0.126    0.035    3.636    0.000    0.126    0.126\n    eatingDisorder      -0.035    0.042   -0.822    0.411   -0.035   -0.035\n  socialMedia ~~                                                           \n    socialComparsn       0.422    0.037   11.347    0.000    0.422    0.422\n    eatingDisorder       0.052    0.049    1.056    0.291    0.052    0.052\n  socialComparison ~~                                                      \n    eatingDisorder       0.368    0.042    8.679    0.000    0.368    0.368\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .PP1               0.500    0.053    9.365    0.000    0.500    0.326\n   .PP2               0.615    0.054   11.489    0.000    0.615    0.382\n   .PP3               1.133    0.044   25.604    0.000    1.133    0.863\n   .PP4               1.175    0.046   25.410    0.000    1.175    0.843\n   .SM1               0.958    0.048   20.116    0.000    0.958    0.733\n   .SM2               1.068    0.051   21.126    0.000    1.068    0.763\n   .SM3               1.033    0.048   21.355    0.000    1.033    0.771\n   .SM4               1.005    0.052   19.225    0.000    1.005    0.707\n   .SC1               0.993    0.054   18.400    0.000    0.993    0.561\n   .SC2               0.831    0.053   15.544    0.000    0.831    0.485\n   .SC3               1.075    0.055   19.543    0.000    1.075    0.595\n   .ED1               0.942    0.094    9.995    0.000    0.942    0.645\n   .ED2               1.052    0.085   12.310    0.000    1.052    0.700\n    peerPressure      1.000                               1.000    1.000\n    socialMedia       1.000                               1.000    1.000\n    socialComparsn    1.000                               1.000    1.000\n    eatingDisorder    1.000                               1.000    1.000\n\n\nTasks\n\nReport the standardized loadings and identify any weak items.\nCheck residual variances (Heywood cases? negative variances?).\nExtract the core fit indices: CFI, TLI, RMSEA, SRMR.\n\n\n\nShow code\nfitMeasures(fit_cfa, c(\"cfi\", \"tli\", \"rmsea\", \"srmr\"))\n\n\n  cfi   tli rmsea  srmr \n0.882 0.844 0.066 0.042"
  },
  {
    "objectID": "labs/lab05_sem_capstone_eat.html#a-add-structural-regressions-among-the-latent-variables",
    "href": "labs/lab05_sem_capstone_eat.html#a-add-structural-regressions-among-the-latent-variables",
    "title": "Lab 05 — SEM capstone with the EAT dataset",
    "section": "2a) Add structural regressions among the latent variables",
    "text": "2a) Add structural regressions among the latent variables\n\n\nShow code\nm_sem &lt;- \"\n  # CFA model\n  peerPressure =~ PP1 + PP2 + PP3 + PP4\n  socialMedia  =~ SM1 + SM2 + SM3 + SM4\n  socialComparison =~ SC1 + SC2 + SC3\n  eatingDisorder =~ ED1 + ED2\n\n  # Structural model\n  eatingDisorder ~ socialComparison\n  socialComparison ~ peerPressure + socialMedia\n\""
  },
  {
    "objectID": "labs/lab05_sem_capstone_eat.html#b-fit-and-inspect",
    "href": "labs/lab05_sem_capstone_eat.html#b-fit-and-inspect",
    "title": "Lab 05 — SEM capstone with the EAT dataset",
    "section": "2b) Fit and inspect",
    "text": "2b) Fit and inspect\n\n\nShow code\nfit_sem &lt;- sem(m_sem, data = dE4_1, std.lv = TRUE)\nsummary(fit_sem, standardized = TRUE, fit.measures = TRUE)\n\n\nlavaan 0.6-19 ended normally after 30 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        30\n\n  Number of observations                          1423\n\nModel Test User Model:\n                                                      \n  Test statistic                               430.575\n  Degrees of freedom                                61\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                              3150.947\n  Degrees of freedom                                78\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.880\n  Tucker-Lewis Index (TLI)                       0.846\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)             -28620.977\n  Loglikelihood unrestricted model (H1)     -28405.690\n                                                      \n  Akaike (AIC)                               57301.954\n  Bayesian (BIC)                             57459.770\n  Sample-size adjusted Bayesian (SABIC)      57364.470\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.065\n  90 Percent confidence interval - lower         0.060\n  90 Percent confidence interval - upper         0.071\n  P-value H_0: RMSEA &lt;= 0.050                    0.000\n  P-value H_0: RMSEA &gt;= 0.080                    0.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.044\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                      Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  peerPressure =~                                                          \n    PP1                  1.019    0.036   27.954    0.000    1.019    0.823\n    PP2                  0.996    0.037   26.873    0.000    0.996    0.785\n    PP3                  0.423    0.033   12.909    0.000    0.423    0.369\n    PP4                  0.468    0.034   13.932    0.000    0.468    0.396\n  socialMedia =~                                                           \n    SM1                  0.582    0.039   15.049    0.000    0.582    0.509\n    SM2                  0.576    0.040   14.452    0.000    0.576    0.487\n    SM3                  0.557    0.039   14.279    0.000    0.557    0.481\n    SM4                  0.653    0.041   16.062    0.000    0.653    0.548\n  socialComparison =~                                                      \n    SC1                  0.799    0.037   21.609    0.000    0.885    0.665\n    SC2                  0.847    0.037   22.797    0.000    0.937    0.716\n    SC3                  0.777    0.037   20.925    0.000    0.860    0.640\n  eatingDisorder =~                                                        \n    ED1                  0.654    0.066    9.920    0.000    0.700    0.579\n    ED2                  0.645    0.065    9.945    0.000    0.690    0.563\n\nRegressions:\n                     Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  eatingDisorder ~                                                        \n    socialComparsn      0.344    0.047    7.322    0.000    0.356    0.356\n  socialComparison ~                                                      \n    peerPressure        0.139    0.038    3.636    0.000    0.125    0.125\n    socialMedia         0.455    0.049    9.221    0.000    0.411    0.411\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  peerPressure ~~                                                       \n    socialMedia      -0.014    0.039   -0.354    0.723   -0.014   -0.014\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .PP1               0.495    0.054    9.205    0.000    0.495    0.323\n   .PP2               0.619    0.054   11.521    0.000    0.619    0.384\n   .PP3               1.134    0.044   25.612    0.000    1.134    0.864\n   .PP4               1.175    0.046   25.414    0.000    1.175    0.843\n   .SM1               0.969    0.048   20.363    0.000    0.969    0.741\n   .SM2               1.067    0.051   21.069    0.000    1.067    0.762\n   .SM3               1.030    0.048   21.257    0.000    1.030    0.768\n   .SM4               0.995    0.053   18.929    0.000    0.995    0.700\n   .SC1               0.986    0.054   18.198    0.000    0.986    0.558\n   .SC2               0.836    0.054   15.566    0.000    0.836    0.488\n   .SC3               1.068    0.055   19.361    0.000    1.068    0.591\n   .ED1               0.971    0.094   10.279    0.000    0.971    0.665\n   .ED2               1.026    0.093   11.017    0.000    1.026    0.683\n    peerPressure      1.000                               1.000    1.000\n    socialMedia       1.000                               1.000    1.000\n   .socialComparsn    1.000                               0.816    0.816\n   .eatingDisorder    1.000                               0.873    0.873\n\n\nShow code\nfitMeasures(fit_sem, c(\"cfi\", \"tli\", \"rmsea\", \"srmr\"))\n\n\n  cfi   tli rmsea  srmr \n0.880 0.846 0.065 0.044 \n\n\nQuestions\n\nAre the key hypotheses supported (sign + magnitude + uncertainty)?\nHow does fit compare to the CFA-only model? (Interpret carefully.)\n\n(Optional)\n\n\nShow code\nanova(fit_cfa, fit_sem)\n\n\n\nChi-Squared Difference Test\n\n        Df   AIC   BIC Chisq Chisq diff  RMSEA Df diff Pr(&gt;Chisq)  \nfit_cfa 59 57297 57466   422                                       \nfit_sem 61 57302 57460   431       8.75 0.0487       2      0.013 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "labs/lab05_sem_capstone_eat.html#a-standardized-residual-covariances-local-misfit",
    "href": "labs/lab05_sem_capstone_eat.html#a-standardized-residual-covariances-local-misfit",
    "title": "Lab 05 — SEM capstone with the EAT dataset",
    "section": "3a) Standardized residual covariances (local misfit)",
    "text": "3a) Standardized residual covariances (local misfit)\n\n\nShow code\nres_std &lt;- residuals(fit_sem, type = \"standardized\")$cov\nres_std\n\n\n       PP1    PP2    PP3    PP4    SM1    SM2    SM3    SM4    SC1    SC2\nPP1  0.000                                                               \nPP2  4.114  0.000                                                        \nPP3 -0.956 -1.461  0.000                                                 \nPP4 -1.782 -0.714  3.843  0.000                                          \nSM1 -0.025  0.866  0.527 -1.447  0.000                                   \nSM2 -0.201  0.135  1.297 -0.472 -0.979  0.000                            \nSM3  0.527  0.490  0.127 -0.211 -3.014  1.973  0.000                     \nSM4 -1.102 -0.389  1.354 -0.710 -2.151  1.660  2.005  0.000              \nSC1 -0.195 -0.601  0.677  0.508 -0.370 -2.178 -0.679 -0.570  0.000       \nSC2  0.298 -0.359  1.676  0.657 14.915 -1.812 -0.951 -1.042 -3.833  0.000\nSC3  0.244  0.045  1.346  1.211 -3.254 -3.230 -1.506 -2.873  4.203 -1.867\nED1 -0.693 -0.951 -2.649 -0.337 -2.138 -2.846 -1.096 -1.179  1.416 -1.514\nED2 -1.299 -2.440 -0.893 -1.020 -0.471 -0.566 -1.018  0.947  0.108 -1.475\n       SC3    ED1    ED2\nPP1                     \nPP2                     \nPP3                     \nPP4                     \nSM1                     \nSM2                     \nSM3                     \nSM4                     \nSC1                     \nSC2                     \nSC3  0.000              \nED1  1.659  0.000       \nED2  1.978  0.000  0.000\n\n\nFind the largest absolute residual covariances:\n\n\nShow code\nR &lt;- res_std\ndiag(R) &lt;- NA\ntop_res &lt;- as.data.frame(as.table(R))\ntop_res &lt;- top_res[order(abs(top_res$Freq), decreasing = TRUE), ]\nhead(top_res, 10)\n\n\n    Var1 Var2  Freq\n122  SM1  SC2 14.92\n62   SC2  SM1 14.92\n115  SC3  SC1  4.20\n139  SC1  SC3  4.20\n2    PP2  PP1  4.11\n14   PP1  PP2  4.11\n30   PP4  PP3  3.84\n42   PP3  PP4  3.84\n114  SC2  SC1 -3.83\n126  SC1  SC2 -3.83"
  },
  {
    "objectID": "labs/lab05_sem_capstone_eat.html#b-modification-indices-mi-effect-size-epcsepc",
    "href": "labs/lab05_sem_capstone_eat.html#b-modification-indices-mi-effect-size-epcsepc",
    "title": "Lab 05 — SEM capstone with the EAT dataset",
    "section": "3b) Modification indices (MI) + effect size (EPC/SEPC)",
    "text": "3b) Modification indices (MI) + effect size (EPC/SEPC)\n\n\nShow code\nmi &lt;- modificationIndices(fit_sem, sort. = TRUE)\nhead(mi[, c(\"lhs\",\"op\",\"rhs\",\"mi\",\"epc\",\"sepc.all\")], 15)\n\n\n                 lhs op rhs     mi    epc sepc.all\n120              SM1 ~~ SC2 328.97  0.565    0.628\n49       socialMedia =~ SC2  56.91  0.378    0.289\n57  socialComparison =~ SM1  54.67  0.292    0.283\n121              SM1 ~~ SC3  51.71 -0.235   -0.231\n50       socialMedia =~ SC3  30.54 -0.277   -0.206\n119              SM1 ~~ SC1  22.07 -0.151   -0.154\n143              SC1 ~~ SC3  19.17  0.293    0.285\n74               PP1 ~~ PP2  18.34  0.665    1.201\n97               PP3 ~~ PP4  15.33  0.126    0.109\n58  socialComparison =~ SM2  13.08 -0.146   -0.137\n142              SC1 ~~ SC2  12.91 -0.277   -0.304\n138              SM4 ~~ SC2   9.69 -0.101   -0.110\n117              SM1 ~~ SM3   8.09 -0.112   -0.112\n51       socialMedia =~ ED1   8.02 -0.130   -0.108\n105              PP3 ~~ ED1   7.86 -0.091   -0.087\n\n\nTasks\n\nDo the top residual pairs match the top MI suggestions?\nPick one candidate modification that you can justify substantively.\nWrite a 1–2 sentence justification (content overlap? method effect? plausible local dependence?)."
  },
  {
    "objectID": "labs/lab05_sem_capstone_eat.html#a-add-one-residual-correlation-and-refit",
    "href": "labs/lab05_sem_capstone_eat.html#a-add-one-residual-correlation-and-refit",
    "title": "Lab 05 — SEM capstone with the EAT dataset",
    "section": "4a) Add one residual correlation and refit",
    "text": "4a) Add one residual correlation and refit\n\n\nShow code\nm_sem_mod &lt;- \"\n  # CFA model\n  peerPressure =~ PP1 + PP2 + PP3 + PP4\n  socialMedia  =~ SM1 + SM2 + SM3 + SM4\n  socialComparison =~ SC1 + SC2 + SC3\n  eatingDisorder =~ ED1 + ED2\n\n  # Structural model\n  eatingDisorder ~ socialComparison\n  socialComparison ~ peerPressure + socialMedia\n\n  # Residual correlation (one modification)\n  SM1 ~~ SC2\n\"\nfit_sem_mod &lt;- sem(m_sem_mod, data = dE4_1, std.lv = TRUE)"
  },
  {
    "objectID": "labs/lab05_sem_capstone_eat.html#b-compare-fit-nested-test",
    "href": "labs/lab05_sem_capstone_eat.html#b-compare-fit-nested-test",
    "title": "Lab 05 — SEM capstone with the EAT dataset",
    "section": "4b) Compare fit + nested test",
    "text": "4b) Compare fit + nested test\n\n\nShow code\nrbind(\n  original = fitMeasures(fit_sem, c(\"cfi\",\"tli\",\"rmsea\",\"srmr\")),\n  modified = fitMeasures(fit_sem_mod, c(\"cfi\",\"tli\",\"rmsea\",\"srmr\"))\n)\n\n\n           cfi   tli  rmsea   srmr\noriginal 0.880 0.846 0.0653 0.0440\nmodified 0.995 0.994 0.0130 0.0233\n\n\nShow code\nanova(fit_sem, fit_sem_mod)\n\n\n\nChi-Squared Difference Test\n\n            Df   AIC   BIC Chisq Chisq diff RMSEA Df diff Pr(&gt;Chisq)    \nfit_sem_mod 60 56948 57111  74.4                                        \nfit_sem     61 57302 57460 430.6        356   0.5       1     &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "labs/lab05_sem_capstone_eat.html#c-re-check-diagnostics",
    "href": "labs/lab05_sem_capstone_eat.html#c-re-check-diagnostics",
    "title": "Lab 05 — SEM capstone with the EAT dataset",
    "section": "4c) Re-check diagnostics",
    "text": "4c) Re-check diagnostics\n\n\nShow code\nmi_mod &lt;- modificationIndices(fit_sem_mod, sort. = TRUE)\nhead(mi_mod[, c(\"lhs\",\"op\",\"rhs\",\"mi\",\"epc\",\"sepc.all\")], 10)\n\n\n               lhs op            rhs    mi    epc sepc.all\n75             PP1 ~~            PP2 19.27  0.679    1.226\n98             PP3 ~~            PP4 15.29  0.126    0.109\n106            PP3 ~~            ED1  8.04 -0.092   -0.089\n51     socialMedia =~            SC3  7.89 -0.127   -0.094\n120            SM1 ~~            SC1  5.37  0.075    0.074\n52     socialMedia =~            ED1  4.89 -0.092   -0.076\n129            SM2 ~~            ED1  4.21 -0.068   -0.068\n160   peerPressure  ~ eatingDisorder  3.99 -0.090   -0.097\n153   peerPressure ~~ eatingDisorder  3.99 -0.090   -0.090\n69  eatingDisorder =~            SM2  3.93 -0.077   -0.070\n\n\nDocumentation (write these down in your log)\n\nWhat did you change and why?\nWhat evidence supported it (residuals? MI+EPC?)?\nDoes the modification change interpretation of the constructs or paths?"
  },
  {
    "objectID": "labs/lab05_sem_capstone_eat.html#a-compare-key-standardized-structural-coefficients",
    "href": "labs/lab05_sem_capstone_eat.html#a-compare-key-standardized-structural-coefficients",
    "title": "Lab 05 — SEM capstone with the EAT dataset",
    "section": "7a) Compare key standardized structural coefficients",
    "text": "7a) Compare key standardized structural coefficients\nExtract standardized regressions from both models:\n\n\nShow code\npe_lat &lt;- parameterEstimates(fit_sem_mod, standardized = TRUE)\nlat_paths &lt;- subset(pe_lat, op == \"~\" &\n                      lhs %in% c(\"eatingDisorder\",\"socialComparison\"))[, \n                    c(\"lhs\",\"rhs\",\"est\",\"se\",\"pvalue\",\"std.all\")]\nlat_paths\n\n\n                lhs              rhs   est    se pvalue std.all\n14   eatingDisorder socialComparison 0.377 0.049      0   0.371\n15 socialComparison     peerPressure 0.133 0.036      0   0.126\n16 socialComparison      socialMedia 0.324 0.045      0   0.306\n\n\n\n\nShow code\npe_sum &lt;- parameterEstimates(fit_path, standardized = TRUE)\nsum_paths &lt;- subset(pe_sum, op == \"~\")[, c(\"lhs\",\"rhs\",\"est\",\"se\",\"pvalue\",\"std.all\")]\nsum_paths\n\n\n               lhs              rhs   est    se pvalue std.all\n1   eatingDisorder socialComparison 0.139 0.016      0   0.223\n2 socialComparison     peerPressure 0.097 0.023      0   0.106\n3 socialComparison      socialMedia 0.258 0.026      0   0.253"
  },
  {
    "objectID": "labs/lab05_sem_capstone_eat.html#b-discussion-write-a-short-paragraph",
    "href": "labs/lab05_sem_capstone_eat.html#b-discussion-write-a-short-paragraph",
    "title": "Lab 05 — SEM capstone with the EAT dataset",
    "section": "7b) Discussion (write a short paragraph)",
    "text": "7b) Discussion (write a short paragraph)\n\nWhich paths change the most (magnitude / uncertainty)?\nDoes the pattern of support for hypotheses change?\nOffer at least two measurement-driven explanations for differences:\n\nunequal loadings / reliability differences\ncorrelated residuals / local dependence\nattenuation / error-in-variables logic\nfactor correlation vs sum-score correlation differences"
  },
  {
    "objectID": "labs/lab05_sem_capstone_eat.html#deliverables",
    "href": "labs/lab05_sem_capstone_eat.html#deliverables",
    "title": "Lab 05 — SEM capstone with the EAT dataset",
    "section": "Deliverables",
    "text": "Deliverables\n\nA 1-page model-checking log:\n\nCFA fit + key issues\nSEM fit + key issues\ndiagnostics used (residuals, MI/EPC)\nwhat you modified and why\n\nA diagram of the final SEM\nA short comparison of latent vs sum-score conclusions"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#today-in-the-workflow",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#today-in-the-workflow",
    "title": "Structural Equation Models",
    "section": "Today in the workflow",
    "text": "Today in the workflow\nSpecify → Identify → Estimate → Evaluate → Revise/Report\n\n\n\nToday: full SEM = measurement model (CFA) + structural model (paths among latent variables).\nWe will repeat fit/diagnostics on purpose: by now it should become a habit (global + local)."
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#learning-objectives",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#learning-objectives",
    "title": "Structural Equation Models",
    "section": "Learning objectives",
    "text": "Learning objectives\nBy the end of this session you should be able to:\n\nConnect the CFA measurement model to the SEM structural model (two-step mindset)\nUnderstand how SEM is represented in matrices (Λ, B, Γ, Φ, Ψ, Θ)\nFit a full SEM in lavaan and interpret parameters + fit indices + diagnostics\nCompare plausible SEMs (nested comparisons) and justify modifications transparently"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#outline",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#outline",
    "title": "Structural Equation Models",
    "section": "Outline",
    "text": "Outline\n\nIntroduction\nIdentification\nExample\nExercise\nResults"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#structural-equation-models",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#structural-equation-models",
    "title": "Structural Equation Models",
    "section": "Structural equation models",
    "text": "Structural equation models\nUp to now, we have seen how to model the relationship between different variables/constructs at the same time (path analysis) and how to build a measurement model with one or more latent variables.\nA complete SEM takes both of these things and put them together"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#the-two-parts-of-a-sem",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#the-two-parts-of-a-sem",
    "title": "Structural Equation Models",
    "section": "The two parts of a SEM",
    "text": "The two parts of a SEM\n\nThe measurement model \\[\n\\begin{aligned}\nx = \\Lambda_x\\xi + \\delta\ny =\\Lambda_y\\eta + \\epsilon\n\\end{aligned}\n\\]\nThe structural model \\[\n\\begin{aligned}\n\\eta = B\\eta + \\Gamma\\xi + \\zeta\n\\end{aligned}\n\\]\n\nalready seen in the first slides"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#matrices",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#matrices",
    "title": "Structural Equation Models",
    "section": "Matrices",
    "text": "Matrices\nThese models (can) have all the possible matrices: - Loadings and coefficients matrices \\[\n\\begin{aligned}\n\\Lambda^x &  - relation among  \\xi  and  x\n    \\Lambda^y &  - relation among  \\eta  and  y\n    B &  - relation among  \\eta  and  \\eta\n    \\Gamma &  - relation among  \\xi  and  \\eta\n\\end{aligned}\n\\] - Covariance matrices \\[\n\\begin{aligned}\n\\Theta^\\delta &  -  x  errors\n    \\Theta^\\epsilon &  -  y  errors\n    \\Psi &  -  \\eta  errors\n    \\Phi &  - relations among  \\eta\n\\end{aligned}\n\\] Different models are allowew based on the way we define relationships among variables"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#lavaan-matrices",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#lavaan-matrices",
    "title": "Structural Equation Models",
    "section": "… lavaan matrices",
    "text": "… lavaan matrices\nlavaan does not distinguish between endogenous and exogenous variables. This leads to an easier parametrization and to four matrices only: 1. \\(\\Lambda\\) factor loadings matrix \\([p x m]\\) 1. \\(\\Theta\\) measurement residual errors covariance matrix \\([p x p]\\) 1. \\(B\\) regression coefficients matrix \\([m x m]\\) 1. \\(\\Psi\\) residual structural errors covariance matrix \\([m x m]\\) With p being the number of manifest variables and m being the number of latent variables."
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#the-lavaan-matrices",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#the-lavaan-matrices",
    "title": "Structural Equation Models",
    "section": "The lavaan matrices",
    "text": "The lavaan matrices\n{Lambda: matrix of loadings}\n\n{Beta: regression coefficients}\n\n{Psi: residual structural errors matrix}\n\n{Theta: observed variance-covariance matrix}"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#a-sem-example---simulation",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#a-sem-example---simulation",
    "title": "Structural Equation Models",
    "section": "A SEM example - simulation",
    "text": "A SEM example - simulation\n\nlibrary(lavaan)\ndSEM &lt;- simulateData(\"xi =~ .74*x1 + .65*x2\n                      eta =~ .56*y1 + .75*y2\n                      eta ~ .30*xi\n                     \", sample.nobs = 1000)"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#a-sem-example---specification-and-constraints",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#a-sem-example---specification-and-constraints",
    "title": "Structural Equation Models",
    "section": "A SEM example - specification and constraints",
    "text": "A SEM example - specification and constraints\n\nfit &lt;- sem(model = \"xi =~ x1 + x2\n                     eta =~ y1 + y2\n                     eta ~ xi\", data = dSEM)\n\nConstraints\nTo estimate the model we need to set constraints: - the sem or cfa functions default is setting to 1 one loading for each latent variable - an alternative is to standardized latent variables using the std.lv = TRUE option"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#constraints-default",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#constraints-default",
    "title": "Structural Equation Models",
    "section": "Constraints: default",
    "text": "Constraints: default\n\n\n[...]\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  xi =~                                                                 \n    x1                1.000                               0.727    0.570\n    x2                1.004    0.304    3.297    0.001    0.730    0.602\n  eta =~                                                                \n    y1                1.000                               0.440    0.372\n    y2                2.324    1.063    2.186    0.029    1.021    0.799\n\n[...]\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .x1                1.102    0.168    6.570    0.000    1.102    0.676\n   .x2                0.937    0.167    5.613    0.000    0.937    0.637\n   .y1                1.204    0.103   11.701    0.000    1.204    0.862\n   .y2                0.592    0.474    1.249    0.212    0.592    0.362\n    xi                0.529    0.169    3.129    0.002    1.000    1.000\n   .eta               0.181    0.083    2.173    0.030    0.937    0.937\n\n[...]"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#constraints-std.lvt",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#constraints-std.lvt",
    "title": "Structural Equation Models",
    "section": "Constraints: std.lv=T",
    "text": "Constraints: std.lv=T\n\n\n[...]\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  xi =~                                                                 \n    x1                0.727    0.116    6.258    0.000    0.727    0.570\n    x2                0.730    0.116    6.298    0.000    0.730    0.602\n  eta =~                                                                \n    y1                0.425    0.098    4.346    0.000    0.440    0.372\n    y2                0.988    0.239    4.127    0.000    1.021    0.799\n\n[...]\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .x1                1.102    0.168    6.570    0.000    1.102    0.676\n   .x2                0.937    0.167    5.613    0.000    0.937    0.637\n   .y1                1.204    0.103   11.701    0.000    1.204    0.862\n   .y2                0.592    0.474    1.249    0.212    0.592    0.362\n    xi                1.000                               1.000    1.000\n   .eta               1.000                               0.937    0.937\n\n[...]"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#lavaan-matrices-1",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#lavaan-matrices-1",
    "title": "Structural Equation Models",
    "section": "lavaan matrices",
    "text": "lavaan matrices\n\ninspect(fit, \"std\") # OR \"est\"\n\n\n\n$lambda\n      xi   eta\nx1 0.570 0.000\nx2 0.602 0.000\ny1 0.000 0.372\ny2 0.000 0.799\n\n$theta\n      x1    x2    y1    y2\nx1 0.676                  \nx2 0.000 0.637            \ny1 0.000 0.000 0.862      \ny2 0.000 0.000 0.000 0.362\n\n\n\n\n$psi\n       xi   eta\nxi  1.000      \neta 0.000 0.937\n\n$beta\n       xi eta\nxi  0.000   0\neta 0.252   0"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#sem-identification",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#sem-identification",
    "title": "Structural Equation Models",
    "section": "SEM identification",
    "text": "SEM identification\nOnce again, remember that identification is a topic relevant to all structural equation models.\nIf an unknown parameter in \\(\\theta\\) can be written as a function of one or more elements of \\(\\Sigma\\), that parameter is identified.\nIf all unknown parameters in \\(\\theta\\) are identified, the model is identified. - the t-rule (again) - the Two-Steps rule"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#two-steps-rule",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#two-steps-rule",
    "title": "Structural Equation Models",
    "section": "Two-Steps rule",
    "text": "Two-Steps rule\n\nStep 1. Treat the model as a confirmatory factor analysis: view the original \\(x\\) and \\(y\\) as \\(x\\) variables and the original \\(\\xi\\) and \\(\\eta\\) as \\(\\xi\\) variables. The only relationship between latent variables of interest are their variance and covariance \\(Phi\\). That is, ignore the \\(B\\), \\(\\Gamma\\), and \\(\\Psi\\) elements.\n\\(\\rightarrow\\) apply CFA identification rules\nStep 2. Examine the latent variable equation of the original model (\\(\\eta = B\\eta + \\Gamma\\xi + \\zeta\\)), assuming that each latent variable is an observed variable that is perfectly measured."
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#two-steps-rule-1",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#two-steps-rule-1",
    "title": "Structural Equation Models",
    "section": "Two-Steps rule",
    "text": "Two-Steps rule\nSummary\nIf the first step shows that the measurement parameters are identified and the second step shows that the latent variable model parameters also are identified, then this is suficient to identify the whole model."
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#political-democracy-dataset",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#political-democracy-dataset",
    "title": "Structural Equation Models",
    "section": "Political democracy dataset",
    "text": "Political democracy dataset\nBollen (1989) studied the relation between industrialization in 1960 and political democracy of developing countries in 1960 and 1965.\nWe have 11 variables\n\n\n    y1  y2    y3  y4   y5   y6    y7   y8   x1   x2   x3\n1 2.50 0.0  3.33 0.0 1.25 0.00  3.73 3.33 4.44 3.64 2.56\n2 1.25 0.0  3.33 0.0 6.25 1.10  6.67 0.74 5.38 5.06 3.57\n3 7.50 8.8 10.00 9.2 8.75 8.09 10.00 8.21 5.96 6.26 5.22\n\n\nA first latent variable, Industrialization (\\(I = x_1 + x_2 + x_3\\))\nA second latent variable, political democracy in 1960 (\\(D60 = y_1 + y_2 + y_3 + y_4\\))\nA third latent variable, political democracy in 1965 (\\(D65 = y_5 + y_6 + y_7 + y_8\\)).\nLET'S APLLY THE TWO-STEPS RULE"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#step-1---model-plot",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#step-1---model-plot",
    "title": "Structural Equation Models",
    "section": "Step 1 - model plot",
    "text": "Step 1 - model plot\nThe CFA model"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#step-1---model-specification-and-results",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#step-1---model-specification-and-results",
    "title": "Structural Equation Models",
    "section": "Step 1 - model specification and results",
    "text": "Step 1 - model specification and results\nThe CFA model\n\nm &lt;- \"I =~ x1 + x2 + x3\nD60 =~ y1 + y2 + y3 + y4\nD65 =~ y5 + y6 + y7 + y8\n\"\n\n\nfit1 &lt;- sem(m, data = PoliticalDemocracy)\nfit1@Fit@converged\n\n[1] TRUE\n\n\nPARAMETERS ARE ALL IDENTIFIED. LET'S GO TO STEP 2"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#step-2---model-plot",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#step-2---model-plot",
    "title": "Structural Equation Models",
    "section": "Step 2 - model plot",
    "text": "Step 2 - model plot\nThe structural model"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#step-2---model-specification-and-results",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#step-2---model-specification-and-results",
    "title": "Structural Equation Models",
    "section": "Step 2 - model specification and results",
    "text": "Step 2 - model specification and results\nThe structural model\n\nm2 &lt;- \"I =~ x1 + x2 + x3\nD60 =~ y1 + y2 + y3 + y4\nD65 =~ y5 + y6 + y7 + y8\nD65 ~ I + D60\nD60 ~ I\n\"\n\n\nfit2 &lt;- sem(m2, data = PoliticalDemocracy)\nfit2@Fit@converged\n\n[1] TRUE\n\n\nSTRUCTURAL PARAMETERS ARE ALSO IDENTIFIED.\nLET'S DEFINE THE MODEL CONSIDERING LONGITUDINAL MEASURES"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#final-model",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#final-model",
    "title": "Structural Equation Models",
    "section": "Final model",
    "text": "Final model\nThe modified model"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#final-model-specification",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#final-model-specification",
    "title": "Structural Equation Models",
    "section": "Final model specification",
    "text": "Final model specification\nThe modified model\n\nm3 &lt;- \"I =~ x1 + x2 + x3\nD60 =~ y1 + y2 + y3 + y4\nD65 =~ y5 + y6 + y7 + y8\nD65 ~ I + D60\nD60 ~ I\ny1 ~~ y5\ny2 ~~ y6\ny3 ~~ y7\ny4 ~~ y8\n\"\n\nSAME ITEMS AT DIFFERENT TIME POINTS HAVE CORRELATED RESIDUALS"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#final-model-results",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#final-model-results",
    "title": "Structural Equation Models",
    "section": "Final model results",
    "text": "Final model results\nThe modified model\n\n(fit3 &lt;- sem(m3, data = PoliticalDemocracy))\n\nlavaan 0.6-19 ended normally after 58 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        29\n\n  Number of observations                            75\n\nModel Test User Model:\n                                                      \n  Test statistic                                50.835\n  Degrees of freedom                                37\n  P-value (Chi-square)                           0.064\n\ninspect(fit3, what = \"fitmeasures\")[\n  c(\"cfi\", \"srmr\", \"rmsea\")]\n\n       cfi       srmr      rmsea \n0.97952316 0.05011528 0.07060935 \n\n\nMODEL FIT IS GOOD!"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#model-comparisons",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#model-comparisons",
    "title": "Structural Equation Models",
    "section": "Model comparisons",
    "text": "Model comparisons\n\nanova(fit1,fit2,fit3)\n\nWarning: lavaan-&gt;lavTestLRT():  \n   some models have the same degrees of freedom\n\n\n\nChi-Squared Difference Test\n\n     Df    AIC    BIC  Chisq Chisq diff   RMSEA Df diff Pr(&gt;Chisq)    \nfit3 37 3166.3 3233.5 50.835                                          \nfit1 41 3179.9 3237.9 72.462     21.626 0.24239       4  0.0002378 ***\nfit2 41 3179.9 3237.9 72.462      0.000 0.00000       0               \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#model-comparisons-1",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#model-comparisons-1",
    "title": "Structural Equation Models",
    "section": "Model comparisons",
    "text": "Model comparisons\nWe can also compare the models using fit indices:\n\n\n\n\n\n\nchisq\ndf\ncfi\ntli\nsrmr\nrmsea\naic\nbic\n\n\n\n\nmodel1\n72.462\n41\n0.953\n0.938\n0.055\n0.101\n3179.918\n3237.855\n\n\nmodel2\n72.462\n41\n0.953\n0.938\n0.055\n0.101\n3179.918\n3237.855\n\n\nmodel3\n50.835\n37\n0.980\n0.970\n0.050\n0.071\n3166.292\n3233.499\n\n\n\n\n\nWHAT IS THE BEST MODEL? QUESTIONS? COMMENTS?"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#the-eat-dataset",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#the-eat-dataset",
    "title": "Structural Equation Models",
    "section": "The EAT dataset",
    "text": "The EAT dataset\nThe dataset includes 13 items that measure ‘peer pressure’, ‘social media use’, ‘social comparison’, and ‘eating disorders’.\n\nload(\"../data/Exercise4_1.Rdata\")\nround(head(dE4_1),2)\n\n    PP1   PP2   PP3   PP4   SM1   SM2   SM3   SM4   SC1   SC2   SC3   ED1   ED2\n1  0.23  1.91  0.59 -0.70  2.31  1.06  1.43 -0.77  1.18  2.20  0.18 -0.38  1.61\n2 -0.65 -3.18 -0.84 -0.43  0.69  0.10  1.24  0.51 -1.87 -1.17 -1.23 -1.74 -1.73\n3  0.26 -1.46 -0.43 -0.05 -0.21 -0.46 -0.02  1.26  1.39  1.03  0.90  1.07  2.04\n4 -0.68 -0.29 -0.08 -2.24 -0.64  0.47 -0.76  0.58  1.22  0.97  2.73  0.71  0.32\n5 -0.06  0.89  0.04 -0.41  0.17  1.02  0.18  0.61  3.74  1.38  1.85  1.25  0.66\n6 -0.29 -2.74 -0.52  2.58  0.15 -1.08  1.08  0.99  1.32 -0.24  0.93 -0.97 -0.68"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#the-theoretical-model",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#the-theoretical-model",
    "title": "Structural Equation Models",
    "section": "The theoretical model",
    "text": "The theoretical model"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#the-exercise",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#the-exercise",
    "title": "Structural Equation Models",
    "section": "The exercise",
    "text": "The exercise\n\nApply the two-step rule:\n\nTest the CFA model\nTest the structural model\n\nInspect model results and fit indices\n\nAre the hypotheses confirmed?\nDoes the model fit the data well?\n\nIf the model is not satisfactory, understand why and change it\nDraw the model (in R, ppt, or with a pencil)\nTry to fit a simple path model using sum scores instead of latent scores"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#model-specification",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#model-specification",
    "title": "Structural Equation Models",
    "section": "Model specification",
    "text": "Model specification\nSTEP 1 and 2\n\nm1 &lt;- \"\n # CFA model\n peerPressure =~ PP1 + PP2 + PP3 + PP4\n socialMedia =~ SM1 + SM2 + SM3 + SM4\n socialComparison =~ SC1 + SC2 + SC3\n eatingDisorder =~ ED1 + ED2\n\"\nfit1 &lt;- sem(m1, data = dE4_1, std.lv=T)\nfit1@Fit@converged\nm2 &lt;- \"\n [...]\n # Structural model\n eatingDisorder ~ socialComparison\n socialComparison ~ peerPressure + socialMedia\"\nfit2 &lt;- sem(m2, data = dE4_1, std.lv=T)\nfit2@Fit@converged\n\nOK?"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#results-and-fit",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#results-and-fit",
    "title": "Structural Equation Models",
    "section": "Results and fit",
    "text": "Results and fit\n\nsummary(fitE4_1, std=T)\n\n\n\n[...]\nRegressions:\n                     Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  eatingDisorder ~                                                        \n    socialComparsn      0.344    0.047    7.322    0.000    0.356    0.356\n  socialComparison ~                                                      \n    peerPressure        0.139    0.038    3.636    0.000    0.125    0.125\n    socialMedia         0.455    0.049    9.221    0.000    0.411    0.411\n\n[...]\n\n\n\nfitmeasures(fitE4_1, \n            fit.measures = \n            c(\"cfi\", \"tli\", \"srmr\", \"rmsea\"))\n\n  cfi   tli  srmr rmsea \n0.880 0.846 0.044 0.065"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#model-modification",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#model-modification",
    "title": "Structural Equation Models",
    "section": "Model modification",
    "text": "Model modification\n\nmodificationIndices(fitE4_1, sort. = T)[1:10,]\n\n                 lhs op rhs      mi    epc sepc.lv sepc.all sepc.nox\n120              SM1 ~~ SC2 328.967  0.565   0.565    0.628    0.628\n49       socialMedia =~ SC2  56.910  0.378   0.378    0.289    0.289\n57  socialComparison =~ SM1  54.668  0.292   0.323    0.283    0.283\n121              SM1 ~~ SC3  51.713 -0.235  -0.235   -0.231   -0.231\n50       socialMedia =~ SC3  30.539 -0.277  -0.277   -0.206   -0.206\n119              SM1 ~~ SC1  22.069 -0.151  -0.151   -0.154   -0.154\n143              SC1 ~~ SC3  19.170  0.293   0.293    0.285    0.285\n74               PP1 ~~ PP2  18.341  0.665   0.665    1.201    1.201\n97               PP3 ~~ PP4  15.333  0.126   0.126    0.109    0.109\n58  socialComparison =~ SM2  13.081 -0.146  -0.162   -0.137   -0.137\n\n\n\nm2.1 &lt;- \"\n[...]\n# Residual correlations\nSM1 ~~ SC2\n\"\nfitmeasures(fit2.1, ...)\n\n\n\n  cfi   tli  srmr rmsea \n0.995 0.994 0.023 0.013"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#why-sum-scores-can-mislead-measurement-error-attenuation",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#why-sum-scores-can-mislead-measurement-error-attenuation",
    "title": "Structural Equation Models",
    "section": "Why sum scores can mislead (measurement error → attenuation)",
    "text": "Why sum scores can mislead (measurement error → attenuation)\nIf an observed score (X) is a noisy measure of a latent (X^*), measurement error tends to attenuate associations.\nA classic intuition (simple linear setting):\n\\[\n\\hat\\beta_{\\text{observed}} \\approx \\hat\\beta_{\\text{latent}} \\times \\rho_{xx}\n\\]\nwhere (_{xx}) is reliability of (X).\n\n\n\nThis is exactly why latent-variable SEM can change “structural” conclusions even when factor scores correlate highly with sum scores."
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#sum-scores",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#sum-scores",
    "title": "Structural Equation Models",
    "section": "Sum scores",
    "text": "Sum scores\n\nd2 &lt;- data.frame(\n  peerPressure = dE4_1$PP1 + dE4_1$PP2 + dE4_1$PP3 + dE4_1$PP4, \n  socialMedia = dE4_1$SM1 + dE4_1$SM2 + dE4_1$SM3 + dE4_1$SM4,\n  socialComparison = dE4_1$SC1 + dE4_1$SC2 + dE4_1$SC3,\n  eatingDisorder = dE4_1$ED1 + dE4_1$ED2)\npath &lt;- \"\neatingDisorder ~ socialComparison\nsocialComparison ~ peerPressure + socialMedia\"\nfitP &lt;- sem(path, d2)\nfitmeasures(fitP, fit.measures = \n              c(\"cfi\", \"tli\", \"srmr\", \"rmsea\"))\n\n  cfi   tli  srmr rmsea \n0.978 0.946 0.019 0.037"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#sum-scores-vs-latent-scores",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#sum-scores-vs-latent-scores",
    "title": "Structural Equation Models",
    "section": "Sum scores VS latent scores",
    "text": "Sum scores VS latent scores\nHowever, the debate is still open:\n\nThinking twice about sum scores\n\nThinking thrice about sum scores, and then some more about measurement and analysis\n\nPsychometric properties of sum scores and factor scores differ even when their correlation is 0.98: A response to Widaman and Revelle\n\nOr some more Schimmack:\n\nSchimmack vs Gelman 1\nSchimmack vs Gelman 2"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#the-ground-truth",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#the-ground-truth",
    "title": "Structural Equation Models",
    "section": "The ground truth",
    "text": "The ground truth\n\n# peer pressure AND social media -&gt; social comparison -&gt; eating disorder\nmE4_1 &lt;- \"\n # CFA model\n peerPressure =~ .75*PP1 + .72*PP2 + .59*PP3 + .65*PP4\n socialMedia =~ .45*SM1 + .55*SM2 + .59*SM3 + .65*SM4\n socialComparison =~ .81*SC1 + .75*SC2 + .86*SC3\n eatingDisorder =~ .70*ED1 + .65*ED2\n \n # Structural model\n eatingDisorder ~ .37*socialComparison\n socialComparison ~ .23*peerPressure + .41*socialMedia\n \n # Misspecifications\n # within construct\n PP1 ~~ .43*PP2\n # between construct\n SM1 ~~ .53*SC2\n\""
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#sum-scores-vs-latent-scores-1",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#sum-scores-vs-latent-scores-1",
    "title": "Structural Equation Models",
    "section": "Sum scores VS latent scores",
    "text": "Sum scores VS latent scores\nHowever, the debate is still open:\n\nThinking twice about sum scores\n\nThinking thrice about sum scores, and then some more about measurement and analysis\n\nPsychometric properties of sum scores and factor scores differ even when their correlation is 0.98: A response to Widaman and Revelle\n\nOr some more Schimmack:\n\nSchimmack vs Gelman 1\nSchimmack vs Gelman 2"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#the-indifference-of-the-indicator",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#the-indifference-of-the-indicator",
    "title": "Structural Equation Models",
    "section": "The indifference of the indicator",
    "text": "The indifference of the indicator\n\nHow many indicators do we need?\nHow should I select them?\n… LET'S SEE THE ADDITIONAL CODE"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#take-home-3-things",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#take-home-3-things",
    "title": "Structural Equation Models",
    "section": "Take-home: 3 things",
    "text": "Take-home: 3 things\n\nSEM is measurement + structure — structural paths do not rescue poor measurement\n\nTreat fit indices and diagnostics as routine checks (global + local), not as a one-time hurdle\n\nComparing models is scientific: theory → constraints → estimation → evaluation → transparent revision"
  },
  {
    "objectID": "slides/05_sem_measurement-plus-structure_capstone.html#references",
    "href": "slides/05_sem_measurement-plus-structure_capstone.html#references",
    "title": "Structural Equation Models",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "slides/01_sem-foundations_workflow_lavaan.html#model-evaluation",
    "href": "slides/01_sem-foundations_workflow_lavaan.html#model-evaluation",
    "title": "SEM foundations: language, workflow, first lavaan steps",
    "section": "4) Model evaluation",
    "text": "4) Model evaluation\nIs the model adequate? Do our parameter generate a theoretical matrix (\\(\\boldsymbol{\\Sigma}\\)) which is close to the empirical covariance matrix \\(\\boldsymbol{S}\\)?\n\nGlobal fit: is the overall model plausible?\nLocal fit: where does the model misfit?\n\n\n\n\nWe’ll do this properly in deck 03. Today: just remember that fit ≠ truth.\n\n\n\nFormally:\n\\[\nH_0 : \\boldsymbol{\\hat{\\Sigma}}(\\theta) = \\boldsymbol{\\Sigma}\n\\]\nwhere \\(\\boldsymbol{\\Sigma}\\) is the true covariance matrix among model variables, \\(\\theta\\) the parameters vector, and \\(\\boldsymbol{\\hat{\\Sigma}}\\) the reproduced covariance matrix."
  },
  {
    "objectID": "slides/02_path-analysis_mediation_equivalence.html#path-analysis",
    "href": "slides/02_path-analysis_mediation_equivalence.html#path-analysis",
    "title": "Path analysis & mediation",
    "section": "Path analysis",
    "text": "Path analysis\nA path model is a set of linear regressions estimated jointly, with an explicit covariance structure and with at least one variable working as mediator.\n\nAs usual, depicting the models is always the best way to understand our models.\n\n\n\nActually, this looks like a full SEM. Why? And why it isn’t, given the way latent variables should be represented?."
  },
  {
    "objectID": "slides/02_path-analysis_mediation_equivalence.html#indirect-effects-are-just-products",
    "href": "slides/02_path-analysis_mediation_equivalence.html#indirect-effects-are-just-products",
    "title": "Path analysis & mediation",
    "section": "Indirect effects are just products",
    "text": "Indirect effects are just products\nThe indirect effect is a product \\((ab)\\). Even if \\((\\hat a)\\) and \\((\\hat b)\\) are approximately normal, the product is not.\nA common large-sample approximation (delta method):\n\\[\n\\mathrm{Var}(\\widehat{ab}) \\approx\nb^2\\mathrm{Var}(\\hat a) + a^2\\mathrm{Var}(\\hat b) + 2ab\\,\\mathrm{Cov}(\\hat a,\\hat b)\n\\]\nSobel test (same idea, historically popular):\n\\[\nz = \\frac{\\widehat{ab}}{\\sqrt{\\widehat{\\mathrm{Var}}(\\widehat{ab})}}\n\\]\n\n\n\nIn practice, bootstrap is often preferred for indirect effects (especially with small–moderate \\(N\\))."
  },
  {
    "objectID": "slides/03_model-fit_diagnostics_respecification.html#quick-example-dataset",
    "href": "slides/03_model-fit_diagnostics_respecification.html#quick-example-dataset",
    "title": "Model fit & diagnostics",
    "section": "Quick example dataset",
    "text": "Quick example dataset\nWe simulate data from a “true” structural model and then fit a simplified (misspecified) model to create misfit.\n\nN &lt;- 483\n\nm_true &lt;- \"\n  lifeSatisfaction ~ .05*attachment + .25*selfEsteem + .40*parentalSupport + .30*salary\n  selfEsteem       ~ .40*parentalSupport + .20*attachment\n  attachment ~~ .30*parentalSupport\n\"\n\nm_fit &lt;- \"\n  lifeSatisfaction ~ selfEsteem + salary     # omits some true predictors\n  selfEsteem       ~ parentalSupport + attachment\n  # attachment ~~ parentalSupport            # (omitted on purpose)\n\"\n\nE2 &lt;- simulateData(m_true, sample.nobs = N, seed = 12)\nfit &lt;- sem(m_fit, data = E2, meanstructure = TRUE)"
  },
  {
    "objectID": "slides/03_model-fit_diagnostics_respecification.html#step-5-model-modification-the-dangerousmagic-step",
    "href": "slides/03_model-fit_diagnostics_respecification.html#step-5-model-modification-the-dangerousmagic-step",
    "title": "Model fit & diagnostics",
    "section": "Step 5: model modification (the dangerous/magic step)",
    "text": "Step 5: model modification (the dangerous/magic step)\n\n\n\nWHERE QRPs HAPPEN\n\n\n\nThe goal is not “better numbers”.\nThe goal is:\n\na model that is more plausible given theory and diagnostics\nchanges that are transparent and ideally replicable"
  },
  {
    "objectID": "slides/03_model-fit_diagnostics_respecification.html#oh-no-my-p-values",
    "href": "slides/03_model-fit_diagnostics_respecification.html#oh-no-my-p-values",
    "title": "Model fit & diagnostics",
    "section": "Oh NO, my p values!",
    "text": "Oh NO, my p values!"
  },
  {
    "objectID": "slides/03_model-fit_diagnostics_respecification.html#modification-indices",
    "href": "slides/03_model-fit_diagnostics_respecification.html#modification-indices",
    "title": "Model fit & diagnostics",
    "section": "Modification indices",
    "text": "Modification indices\nMI approximates how much χ² would decrease if a fixed parameter were freed.\n\nMI is a score test (local improvement)\nit does not tell you the direction/magnitude of the new parameter\n\nSo you inspect MI together with EPC (expected parameter change).\n\nmi &lt;- modificationIndices(fit, sort. = TRUE)\nhead(mi[, c(\"lhs\",\"op\",\"rhs\",\"mi\",\"epc\",\"sepc.all\")], 10)\n\n                lhs op              rhs     mi    epc sepc.all\n19 lifeSatisfaction  ~  parentalSupport 58.234  0.416    0.339\n18 lifeSatisfaction ~~       selfEsteem 52.562 -0.941   -0.880\n27  parentalSupport  ~ lifeSatisfaction 45.077  0.256    0.314\n21       selfEsteem  ~ lifeSatisfaction 33.931 -0.587   -0.620\n20 lifeSatisfaction  ~       attachment  5.473  0.114    0.100\n22       selfEsteem  ~           salary  0.752  0.041    0.037\n32       attachment  ~       selfEsteem  0.556  2.784    3.020\n28  parentalSupport  ~       selfEsteem  0.555 -6.106   -7.100\n24           salary  ~       selfEsteem  0.552  0.028    0.031\n23           salary  ~ lifeSatisfaction  0.524  0.073    0.086"
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#workflow-map",
    "href": "slides/06_robustness_missing_reporting.html#workflow-map",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Workflow map",
    "text": "Workflow map\nSpecify → Identify → Estimate → Evaluate → Report\nToday we practice a sensitivity mindset:\n\nSame model, different reasonable choices → does the conclusion change?"
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#learning-objectives",
    "href": "slides/06_robustness_missing_reporting.html#learning-objectives",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Learning objectives",
    "text": "Learning objectives\nBy the end of today you can:\n\nDistinguish MCAR / MAR / MNAR and what FIML assumes\nExplain what MLR corrects (robust SE + scaled test statistic)\nDecide when bootstrap CIs are needed (and when they’re overkill)\nCombine global + local diagnostics without fishing\nWrite a defensible reporting paragraph"
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#plan-for-today",
    "href": "slides/06_robustness_missing_reporting.html#plan-for-today",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Plan for today",
    "text": "Plan for today\n\nSimulate a “realistic messy” dataset (skewness + MAR missingness)\n\nFit the same SEM under different choices\n\nCompare conclusions (parameters, SE, CIs, fit, local misfit)\n\nTurn results into reporting decisions\n\n\nAdd figure: one pipeline diagram showing “Same model → different estimation choices → compare conclusions”."
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#why-simulate",
    "href": "slides/06_robustness_missing_reporting.html#why-simulate",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Why simulate?",
    "text": "Why simulate?\nReal SEM work is rarely “clean”:\n\nindicators are skewed\nresiduals are non-normal\nmissingness is not random\nindirect effects are asymmetric\n\nWe simulate this so we can see what changes and what doesn’t."
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#setup",
    "href": "slides/06_robustness_missing_reporting.html#setup",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Setup",
    "text": "Setup\n\nlibrary(lavaan)\n\nset.seed(1234)\nN &lt;- 600"
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#population-model-measurement-structural",
    "href": "slides/06_robustness_missing_reporting.html#population-model-measurement-structural",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Population model (measurement + structural)",
    "text": "Population model (measurement + structural)\nA simple measurement-first SEM:\n\npeer pressure → social comparison\n\nsocial media → social comparison\n\nsocial comparison → eating disorder symptoms\n\n\nmodel_pop &lt;- \"\n# Measurement\npeer  =~ 0.80*p1 + 0.70*p2 + 0.60*p3 + 0.70*p4\nmedia =~ 0.70*m1 + 0.80*m2 + 0.60*m3 + 0.70*m4\ncomp  =~ 0.70*c1 + 0.70*c2 + 0.60*c3\neat   =~ 0.70*e1 + 0.60*e2\n\n# Structural\ncomp ~ 0.40*peer + 0.50*media\neat  ~ 0.35*comp\n\"\ndat &lt;- simulateData(model_pop, sample.nobs = N)"
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#make-indicators-skewed",
    "href": "slides/06_robustness_missing_reporting.html#make-indicators-skewed",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Make indicators skewed",
    "text": "Make indicators skewed\nWe “Likert-ify” some indicators by applying a monotone transform (skewness).\n\nskew_vars &lt;- c(\"p1\",\"p2\",\"m1\",\"m2\",\"c1\")\nfor (v in skew_vars) dat[[v]] &lt;- exp(dat[[v]] / 2)"
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#quick-distribution-check",
    "href": "slides/06_robustness_missing_reporting.html#quick-distribution-check",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Quick distribution check",
    "text": "Quick distribution check\n\nhist(dat$p1, main = \"Skewed indicator: p1\", xlab = \"p1\")\n\n\n\nAdd conceptual graphic: normal vs skewed distributions with same mean/variance but different tails."
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#add-heavy-tails-non-normal-residual-behavior",
    "href": "slides/06_robustness_missing_reporting.html#add-heavy-tails-non-normal-residual-behavior",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Add heavy tails (non-normal residual behavior)",
    "text": "Add heavy tails (non-normal residual behavior)\nWe inject a small number of outliers in two indicators (a common real-life pattern).\n\nset.seed(1234)\nix &lt;- sample(seq_len(N), size = round(0.03*N))  # ~3% outliers\ndat$m4[ix] &lt;- dat$m4[ix] + rnorm(length(ix), mean = 0, sd = 4)\ndat$c3[ix] &lt;- dat$c3[ix] + rnorm(length(ix), mean = 0, sd = 4)"
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#a-simple-non-normality-summary-no-extra-packages",
    "href": "slides/06_robustness_missing_reporting.html#a-simple-non-normality-summary-no-extra-packages",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "A simple non-normality summary (no extra packages)",
    "text": "A simple non-normality summary (no extra packages)\n\nskew &lt;- function(x) {\n  x &lt;- x[is.finite(x)]\n  m &lt;- mean(x); s &lt;- sd(x)\n  mean((x - m)^3) / s^3\n}\nkurt_excess &lt;- function(x) {\n  x &lt;- x[is.finite(x)]\n  m &lt;- mean(x); s &lt;- sd(x)\n  mean((x - m)^4) / s^4 - 3\n}\n\nround(c(skew = skew(dat$p1), kurt_excess = kurt_excess(dat$p1)), 2)\n\n       skew kurt_excess \n       2.83       14.79"
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#create-mar-missingness-20",
    "href": "slides/06_robustness_missing_reporting.html#create-mar-missingness-20",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Create MAR missingness (~20%)",
    "text": "Create MAR missingness (~20%)\nMissingness depends on an observed variable (MAR), not on the missing value itself.\nWe make e1 and m3 more likely to be missing when peer pressure is high.\n\nset.seed(1234)\n\n# a proxy observed score for peer (in real life: a sum score, previous wave, etc.)\npeer_obs &lt;- rowMeans(dat[, c(\"p1\",\"p2\",\"p3\",\"p4\")])\n\np_miss &lt;- plogis(scale(peer_obs))            # 0..1\nmiss   &lt;- runif(N) &lt; (p_miss * 0.45)         # tune to ~20%\n\ndat$e1[miss] &lt;- NA\ndat$m3[miss] &lt;- NA\n\nround(colMeans(is.na(dat)), 3)\n\n p1  p2  p3  p4  m1  m2  m3  m4  c1  c2  c3  e1  e2 \n0.0 0.0 0.0 0.0 0.0 0.0 0.2 0.0 0.0 0.0 0.0 0.2 0.0"
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#missingness-what-would-you-check",
    "href": "slides/06_robustness_missing_reporting.html#missingness-what-would-you-check",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Missingness: what would you check?",
    "text": "Missingness: what would you check?\n\n% missing per variable\npatterns (is it concentrated in a subset?)\nassociation between missingness and observed variables (supports MAR plausibility)\n\n\nAdd small schematic: MCAR vs MAR vs MNAR (arrows from observed/unobserved to missingness indicator R)."
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#the-analysis-model-same-model-throughout",
    "href": "slides/06_robustness_missing_reporting.html#the-analysis-model-same-model-throughout",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "The analysis model (same model throughout)",
    "text": "The analysis model (same model throughout)\n\nmodel_sem &lt;- \"\n# Measurement\npeer  =~ p1 + p2 + p3 + p4\nmedia =~ m1 + m2 + m3 + m4\ncomp  =~ c1 + c2 + c3\neat   =~ e1 + e2\n\n# Structural\ncomp ~ peer + media\neat  ~ comp\n\""
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#a-helper-extract-the-same-key-parameters-each-time",
    "href": "slides/06_robustness_missing_reporting.html#a-helper-extract-the-same-key-parameters-each-time",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "A helper: extract the same key parameters each time",
    "text": "A helper: extract the same key parameters each time\nWe track the same hypotheses in every fit:\n\npeer → comp\nmedia → comp\ncomp → eat\n\n\nkey_paths &lt;- function(fit) {\n  pe &lt;- parameterEstimates(fit)\n  pe &lt;- pe[pe$op == \"~\" & pe$lhs %in% c(\"comp\",\"eat\"), ]\n  pe[pe$rhs %in% c(\"peer\",\"media\",\"comp\"),\n     c(\"lhs\",\"op\",\"rhs\",\"est\",\"se\",\"z\",\"pvalue\")]\n}"
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#concepts-technical-but-actionable",
    "href": "slides/06_robustness_missing_reporting.html#concepts-technical-but-actionable",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Concepts (technical, but actionable)",
    "text": "Concepts (technical, but actionable)\n\nMCAR: missingness unrelated to observed/unobserved → listwise unbiased (but inefficient)\nMAR: missingness depends on observed variables → FIML OK (under correct model)\nMNAR: missingness depends on unobserved/missing values → both listwise & FIML can be biased\n\nKey point:\n\nFIML is not “imputation”. It’s likelihood-based estimation using all available cases assuming MAR."
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#fit-1-ml-default-missing-handling-listwise",
    "href": "slides/06_robustness_missing_reporting.html#fit-1-ml-default-missing-handling-listwise",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Fit 1 — ML, default missing handling (listwise)",
    "text": "Fit 1 — ML, default missing handling (listwise)\n\nfit_list &lt;- sem(model_sem, data = dat)  # default: listwise deletion\nfitMeasures(fit_list, c(\"nobs\",\"chisq\",\"df\",\"cfi\",\"tli\",\"rmsea\",\"srmr\"))\n\n chisq     df    cfi    tli  rmsea   srmr \n56.219 61.000  1.000  1.009  0.000  0.030"
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#fit-2-ml-fiml",
    "href": "slides/06_robustness_missing_reporting.html#fit-2-ml-fiml",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Fit 2 — ML + FIML",
    "text": "Fit 2 — ML + FIML\n\nfit_fiml &lt;- sem(model_sem, data = dat, missing = \"fiml\")\nfitMeasures(fit_fiml, c(\"nobs\",\"chisq\",\"df\",\"cfi\",\"tli\",\"rmsea\",\"srmr\"))\n\n chisq     df    cfi    tli  rmsea   srmr \n54.717 61.000  1.000  1.010  0.000  0.027"
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#sensitivity-check-did-the-conclusion-change",
    "href": "slides/06_robustness_missing_reporting.html#sensitivity-check-did-the-conclusion-change",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Sensitivity check: did the conclusion change?",
    "text": "Sensitivity check: did the conclusion change?\n\nrbind(\n  listwise = key_paths(fit_list),\n  fiml     = key_paths(fit_fiml)\n)\n\n             lhs op   rhs   est    se     z pvalue\nlistwise.14 comp  ~  peer 0.362 0.103 3.523  0.000\nlistwise.15 comp  ~ media 0.424 0.093 4.578  0.000\nlistwise.16  eat  ~  comp 0.430 0.125 3.436  0.001\nfiml.14     comp  ~  peer 0.409 0.089 4.592  0.000\nfiml.15     comp  ~ media 0.450 0.085 5.280  0.000\nfiml.16      eat  ~  comp 0.427 0.124 3.442  0.001\n\n\n\n\n\n\n\n\nInterpretation rule of thumb (today)\n\n\nIf your substantive conclusion changes under a reasonable alternative (e.g., listwise → FIML), treat the result as fragile and investigate why."
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#what-mlr-does-the-technical-version",
    "href": "slides/06_robustness_missing_reporting.html#what-mlr-does-the-technical-version",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "What MLR does (the technical version)",
    "text": "What MLR does (the technical version)\nMLR (robust ML) typically:\n\nkeeps similar point estimates\nadjusts standard errors using a “sandwich” (empirical) correction\nreports a scaled test statistic (robust χ²) and robust fit indices\n\nUse case:\n\nnon-normality (skewness, heavy tails)\nmild misspecification\n“psychology-shaped” data"
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#fit-3-mlr-fiml",
    "href": "slides/06_robustness_missing_reporting.html#fit-3-mlr-fiml",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Fit 3 — MLR + FIML",
    "text": "Fit 3 — MLR + FIML\n\nfit_mlr &lt;- sem(model_sem, data = dat,\n               missing = \"fiml\",\n               estimator = \"MLR\")\nfitMeasures(fit_mlr, c(\"nobs\",\"chisq\",\"df\",\"cfi\",\"tli\",\"rmsea\",\"srmr\"))\n\n chisq     df    cfi    tli  rmsea   srmr \n54.717 61.000  1.000  1.010  0.000  0.027"
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#sensitivity-check-do-se-p-values-change",
    "href": "slides/06_robustness_missing_reporting.html#sensitivity-check-do-se-p-values-change",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Sensitivity check: do SE / p-values change?",
    "text": "Sensitivity check: do SE / p-values change?\n\nrbind(\n  fiml_ML  = key_paths(fit_fiml),\n  fiml_MLR = key_paths(fit_mlr)\n)\n\n             lhs op   rhs   est    se     z pvalue\nfiml_ML.14  comp  ~  peer 0.409 0.089 4.592  0.000\nfiml_ML.15  comp  ~ media 0.450 0.085 5.280  0.000\nfiml_ML.16   eat  ~  comp 0.427 0.124 3.442  0.001\nfiml_MLR.14 comp  ~  peer 0.409 0.091 4.496  0.000\nfiml_MLR.15 comp  ~ media 0.450 0.146 3.085  0.002\nfiml_MLR.16  eat  ~  comp 0.427 0.125 3.430  0.001\n\n\n\n\n\n\n\n\nPitfall\n\n\nDon’t mix-and-match reporting: - If you estimate MLR, report robust fit statistics (scaled χ², robust RMSEA/CFI/TLI). - Don’t copy/paste the ML χ² from another run."
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#why-bootstrap-is-special-for-indirect-effects",
    "href": "slides/06_robustness_missing_reporting.html#why-bootstrap-is-special-for-indirect-effects",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Why bootstrap is special for indirect effects",
    "text": "Why bootstrap is special for indirect effects\nIndirect effects are products of coefficients:\n[ ab = a b ]\nEven if (a) and (b) are roughly normal, (ab) is often skewed → normal-theory CIs can be misleading."
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#optional-add-an-indirect-effect-to-the-model",
    "href": "slides/06_robustness_missing_reporting.html#optional-add-an-indirect-effect-to-the-model",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "(Optional) Add an indirect effect to the model",
    "text": "(Optional) Add an indirect effect to the model\n\nmodel_sem_ind &lt;- paste0(model_sem, \"\\n\\n# Indirect effect\\nind_peer := (comp~peer)*(eat~comp)\\n\")\n\n\nIf lavaan complains about label reuse depending on version, label paths explicitly (a* and b) and redefine ind := ab."
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#fit-4-bootstrap-seci-keep-small-for-live-teaching",
    "href": "slides/06_robustness_missing_reporting.html#fit-4-bootstrap-seci-keep-small-for-live-teaching",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Fit 4 — Bootstrap SE/CI (keep small for live teaching)",
    "text": "Fit 4 — Bootstrap SE/CI (keep small for live teaching)\nFor live demos keep bootstrap modest (e.g., 300–800).\nFor papers, use ~2000+.\n\nfit_boot &lt;- sem(model_sem, data = dat,\n                missing = \"fiml\",\n                se = \"bootstrap\",\n                bootstrap = 500)"
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#compare-ci-for-key-paths-normal-vs-bootstrap",
    "href": "slides/06_robustness_missing_reporting.html#compare-ci-for-key-paths-normal-vs-bootstrap",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Compare CI for key paths (normal vs bootstrap)",
    "text": "Compare CI for key paths (normal vs bootstrap)\n\npe_norm &lt;- parameterEstimates(fit_fiml, ci = TRUE)\npe_boot &lt;- parameterEstimates(fit_boot, ci = TRUE, boot.ci.type = \"perc\")\n\nsel &lt;- function(pe) {\n  pe[pe$op == \"~\" & pe$lhs %in% c(\"comp\",\"eat\") &\n       pe$rhs %in% c(\"peer\",\"media\",\"comp\"),\n     c(\"lhs\",\"op\",\"rhs\",\"est\",\"ci.lower\",\"ci.upper\")]\n}\n\nlist(\n  normal_CI = sel(pe_norm),\n  boot_CI   = sel(pe_boot)\n)\n\n$normal_CI\n    lhs op   rhs   est ci.lower ci.upper\n14 comp  ~  peer 0.409    0.235    0.584\n15 comp  ~ media 0.450    0.283    0.616\n16  eat  ~  comp 0.427    0.184    0.670\n\n$boot_CI\n    lhs op   rhs   est ci.lower ci.upper\n14 comp  ~  peer 0.409    0.236    0.601\n15 comp  ~ media 0.450    0.242    0.801\n16  eat  ~  comp 0.427    0.188    0.692\n\n\n\n\n\n\n\n\nDecision heuristic (today)\n\n\nBootstrap is most valuable when: - your target parameter is a product (indirect effects), - distributions are skewed / small N, - normal CIs would be suspect."
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#global-fit-quick-recap",
    "href": "slides/06_robustness_missing_reporting.html#global-fit-quick-recap",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Global fit (quick recap)",
    "text": "Global fit (quick recap)\nGlobal fit indices summarize average discrepancy:\n\nχ² (sample-size sensitive)\nCFI/TLI (incremental)\nRMSEA (+ CI; small df behavior)\nSRMR (residual-based)\n\nBut:\n\nGood global fit does not guarantee good measurement or correct structure."
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#local-fit-residuals-and-mi",
    "href": "slides/06_robustness_missing_reporting.html#local-fit-residuals-and-mi",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Local fit: residuals and MI",
    "text": "Local fit: residuals and MI\n\n# Residual correlations (a small block)\nresid(fit_mlr, type = \"cor\")$cov[1:6, 1:6]\n\n              p1            p2           p3            p4            m1\np1 -2.220446e-16  2.260205e-02 -0.027764125 -1.156267e-02 -5.688705e-02\np2  2.260205e-02  2.220446e-16  0.008962091 -1.205551e-02  3.437288e-03\np3 -2.776412e-02  8.962091e-03  0.000000000  2.145905e-02 -1.029635e-02\np4 -1.156267e-02 -1.205551e-02  0.021459052 -1.110223e-16  3.037465e-02\nm1 -5.688705e-02  3.437288e-03 -0.010296345  3.037465e-02  2.220446e-16\nm2  1.572566e-02  3.943457e-02  0.010333999 -2.492806e-02  1.005055e-02\n            m2\np1  0.01572566\np2  0.03943457\np3  0.01033400\np4 -0.02492806\nm1  0.01005055\nm2  0.00000000\n\n\n\nmodificationIndices(fit_mlr, sort. = TRUE)[1:10, c(\"lhs\",\"op\",\"rhs\",\"mi\",\"epc\")]\n\n     lhs op rhs    mi    epc\n132   p4 ~~  e2 4.658  0.116\n147   m2 ~~  e2 4.044 -0.074\n94    p1 ~~  m1 3.794 -0.047\n84   eat =~  m1 3.541  0.124\n109   p2 ~~  c1 3.434 -0.042\n125   p4 ~~  m2 3.237 -0.064\n85   eat =~  m2 3.024 -0.113\n56  peer =~  c1 2.961 -0.207\n96    p1 ~~  m3 2.841 -0.061\n101   p1 ~~  e1 2.573  0.065\n\n\n\nAdd schematic: “CFI looks fine” but highlight a single large residual correlation and its substantive interpretation."
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#a-disciplined-respecification-rule",
    "href": "slides/06_robustness_missing_reporting.html#a-disciplined-respecification-rule",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "A disciplined respecification rule",
    "text": "A disciplined respecification rule\nOnly consider modifications that are:\n\ntheoretically defensible\n\nconsistent with measurement-first logic\n\nreported transparently (what was changed and why)\n\n\n\n\n\n\n\nPitfall: “MI shopping”\n\n\nIf you add correlated errors because they “fix RMSEA”, you can end up fitting noise."
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#what-you-must-report-minimum",
    "href": "slides/06_robustness_missing_reporting.html#what-you-must-report-minimum",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "What you must report (minimum)",
    "text": "What you must report (minimum)\n\nModel specification (measurement + structural)\nEstimator (ML / MLR / DWLS / ULS / …)\nMissing data handling (listwise / FIML / …) + assumption (MAR)\nχ²(df), p (robust/scaled if applicable)\nCFI, TLI, RMSEA (+ CI), SRMR\nAny respecifications (with theory rationale)\nIf bootstrap: type + number of draws + CI type"
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#example-reporting-paragraph-template",
    "href": "slides/06_robustness_missing_reporting.html#example-reporting-paragraph-template",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Example reporting paragraph (template)",
    "text": "Example reporting paragraph (template)\n\nThe SEM was estimated in lavaan using robust maximum likelihood (MLR) with FIML for missing data under a MAR assumption. Model fit was evaluated using the scaled χ² test and robust fit indices (CFI, TLI, RMSEA with 90% CI, SRMR). Key parameters were interpreted based on standardized estimates and robust standard errors. Where relevant, confidence intervals were obtained via bootstrap percentile CIs (B = 500 for teaching; ≥ 2000 for publication)."
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#take-home-the-sensitivity-mindset",
    "href": "slides/06_robustness_missing_reporting.html#take-home-the-sensitivity-mindset",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Take-home: the sensitivity mindset",
    "text": "Take-home: the sensitivity mindset\nFor any important claim, ask:\n\nDoes it survive FIML vs listwise?\nDoes it survive ML vs MLR?\nDoes it survive bootstrap vs normal CI (when relevant)?\nDoes it survive local diagnostics (residuals/MI)?\n\nIf not, don’t panic—learn what the data are telling you."
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#exercises-lab-6",
    "href": "slides/06_robustness_missing_reporting.html#exercises-lab-6",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Exercises → Lab 6",
    "text": "Exercises → Lab 6\nIn the lab you will:\n\nIncrease missingness to ~40% and re-run the sensitivity checks\n\nSimulate MNAR and compare to MAR\n\nIdentify 1–2 large MIs, justify (or reject) a modification\n\nWrite a short “Methods + Results” reporting paragraph\n\n\nLink placeholder: add a direct link to /labs/06_robustness_lab.qmd once created."
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#things-to-remember",
    "href": "slides/06_robustness_missing_reporting.html#things-to-remember",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "3 things to remember",
    "text": "3 things to remember\n\nMissing data handling can change conclusions — check sensitivity\n\nRobust SE protect against inflated significance — don’t trust ML by default\n\nFit indices are diagnostics, not verdicts — always check local fit"
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#further-reading-optional",
    "href": "slides/06_robustness_missing_reporting.html#further-reading-optional",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Further reading (optional)",
    "text": "Further reading (optional)\n\nMissing data in SEM (FIML, MAR assumptions)\nRobust estimation (MLR/MLM and non-normality)\nBootstrap inference for indirect effects\nReporting standards for SEM in psychology\n\n\nAdd 2–3 concrete citations once we confirm keys in refs/references.bib."
  },
  {
    "objectID": "slides/06_robustness_missing_reporting.html#references",
    "href": "slides/06_robustness_missing_reporting.html#references",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#workflow-map",
    "href": "slides/06_missing-data_robustness_reporting.html#workflow-map",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Workflow map",
    "text": "Workflow map\nSpecify → Identify → Estimate → Evaluate → Report\nToday we practice a sensitivity mindset:\n\nSame model, different reasonable choices → does the conclusion change?"
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#learning-objectives",
    "href": "slides/06_missing-data_robustness_reporting.html#learning-objectives",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Learning objectives",
    "text": "Learning objectives\nBy the end of today you can:\n\nDistinguish MCAR / MAR / MNAR and what FIML assumes\nExplain what MLR corrects (robust SE + scaled test statistic)\nDecide when bootstrap CIs are needed (and when they’re overkill)\nCombine global + local diagnostics without fishing\nWrite a defensible reporting paragraph"
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#plan-for-today",
    "href": "slides/06_missing-data_robustness_reporting.html#plan-for-today",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Plan for today",
    "text": "Plan for today\n\nSimulate a “realistic messy” dataset (skewness + MAR missingness)\n\nFit the same SEM under different choices\n\nCompare conclusions (parameters, SE, CIs, fit, local misfit)\n\nTurn results into reporting decisions\n\n\nAdd figure: one pipeline diagram showing “Same model → different estimation choices → compare conclusions”."
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#why-simulate",
    "href": "slides/06_missing-data_robustness_reporting.html#why-simulate",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Why simulate?",
    "text": "Why simulate?\nReal SEM work is rarely “clean”:\n\nindicators are skewed\nresiduals are non-normal\nmissingness is not random\nindirect effects are asymmetric\n\nWe simulate this so we can see what changes and what doesn’t."
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#setup",
    "href": "slides/06_missing-data_robustness_reporting.html#setup",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Setup",
    "text": "Setup\n\nlibrary(lavaan)\n\nset.seed(1234)\nN &lt;- 600"
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#population-model-measurement-structural",
    "href": "slides/06_missing-data_robustness_reporting.html#population-model-measurement-structural",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Population model (measurement + structural)",
    "text": "Population model (measurement + structural)\nA simple measurement-first SEM:\n\npeer pressure → social comparison\n\nsocial media → social comparison\n\nsocial comparison → eating disorder symptoms\n\n\nmodel_pop &lt;- \"\n# Measurement\npeer  =~ 0.80*p1 + 0.70*p2 + 0.60*p3 + 0.70*p4\nmedia =~ 0.70*m1 + 0.80*m2 + 0.60*m3 + 0.70*m4\ncomp  =~ 0.70*c1 + 0.70*c2 + 0.60*c3\neat   =~ 0.70*e1 + 0.60*e2\n\n# Structural\ncomp ~ 0.40*peer + 0.50*media\neat  ~ 0.35*comp\n\"\ndat &lt;- simulateData(model_pop, sample.nobs = N)"
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#make-indicators-skewed",
    "href": "slides/06_missing-data_robustness_reporting.html#make-indicators-skewed",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Make indicators skewed",
    "text": "Make indicators skewed\nWe “Likert-ify” some indicators by applying a monotone transform (skewness).\n\nskew_vars &lt;- c(\"p1\",\"p2\",\"m1\",\"m2\",\"c1\")\nfor (v in skew_vars) dat[[v]] &lt;- exp(dat[[v]] / 2)"
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#quick-distribution-check",
    "href": "slides/06_missing-data_robustness_reporting.html#quick-distribution-check",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Quick distribution check",
    "text": "Quick distribution check\n\nhist(dat$p1, main = \"Skewed indicator: p1\", xlab = \"p1\")\n\n\n\nAdd conceptual graphic: normal vs skewed distributions with same mean/variance but different tails."
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#add-heavy-tails-non-normal-residual-behavior",
    "href": "slides/06_missing-data_robustness_reporting.html#add-heavy-tails-non-normal-residual-behavior",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Add heavy tails (non-normal residual behavior)",
    "text": "Add heavy tails (non-normal residual behavior)\nWe inject a small number of outliers in two indicators (a common real-life pattern).\n\nset.seed(1234)\nix &lt;- sample(seq_len(N), size = round(0.03*N))  # ~3% outliers\ndat$m4[ix] &lt;- dat$m4[ix] + rnorm(length(ix), mean = 0, sd = 4)\ndat$c3[ix] &lt;- dat$c3[ix] + rnorm(length(ix), mean = 0, sd = 4)"
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#a-simple-non-normality-summary-no-extra-packages",
    "href": "slides/06_missing-data_robustness_reporting.html#a-simple-non-normality-summary-no-extra-packages",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "A simple non-normality summary (no extra packages)",
    "text": "A simple non-normality summary (no extra packages)\n\nskew &lt;- function(x) {\n  x &lt;- x[is.finite(x)]\n  m &lt;- mean(x); s &lt;- sd(x)\n  mean((x - m)^3) / s^3\n}\nkurt_excess &lt;- function(x) {\n  x &lt;- x[is.finite(x)]\n  m &lt;- mean(x); s &lt;- sd(x)\n  mean((x - m)^4) / s^4 - 3\n}\n\nround(c(skew = skew(dat$p1), kurt_excess = kurt_excess(dat$p1)), 2)\n\n       skew kurt_excess \n       2.83       14.79"
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#create-mar-missingness-20",
    "href": "slides/06_missing-data_robustness_reporting.html#create-mar-missingness-20",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Create MAR missingness (~20%)",
    "text": "Create MAR missingness (~20%)\nMissingness depends on an observed variable (MAR), not on the missing value itself.\nWe make e1 and m3 more likely to be missing when peer pressure is high.\n\nset.seed(1234)\n\n# a proxy observed score for peer (in real life: a sum score, previous wave, etc.)\npeer_obs &lt;- rowMeans(dat[, c(\"p1\",\"p2\",\"p3\",\"p4\")])\n\np_miss &lt;- plogis(scale(peer_obs))            # 0..1\nmiss   &lt;- runif(N) &lt; (p_miss * 0.45)         # tune to ~20%\n\ndat$e1[miss] &lt;- NA\ndat$m3[miss] &lt;- NA\n\nround(colMeans(is.na(dat)), 3)\n\n p1  p2  p3  p4  m1  m2  m3  m4  c1  c2  c3  e1  e2 \n0.0 0.0 0.0 0.0 0.0 0.0 0.2 0.0 0.0 0.0 0.0 0.2 0.0"
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#missingness-what-would-you-check",
    "href": "slides/06_missing-data_robustness_reporting.html#missingness-what-would-you-check",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Missingness: what would you check?",
    "text": "Missingness: what would you check?\n\n% missing per variable\npatterns (is it concentrated in a subset?)\nassociation between missingness and observed variables (supports MAR plausibility)\n\n\nAdd small schematic: MCAR vs MAR vs MNAR (arrows from observed/unobserved to missingness indicator R)."
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#the-analysis-model-same-model-throughout",
    "href": "slides/06_missing-data_robustness_reporting.html#the-analysis-model-same-model-throughout",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "The analysis model (same model throughout)",
    "text": "The analysis model (same model throughout)\n\nmodel_sem &lt;- \"\n# Measurement\npeer  =~ p1 + p2 + p3 + p4\nmedia =~ m1 + m2 + m3 + m4\ncomp  =~ c1 + c2 + c3\neat   =~ e1 + e2\n\n# Structural\ncomp ~ peer + media\neat  ~ comp\n\""
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#a-helper-extract-the-same-key-parameters-each-time",
    "href": "slides/06_missing-data_robustness_reporting.html#a-helper-extract-the-same-key-parameters-each-time",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "A helper: extract the same key parameters each time",
    "text": "A helper: extract the same key parameters each time\nWe track the same hypotheses in every fit:\n\npeer → comp\nmedia → comp\ncomp → eat\n\n\nkey_paths &lt;- function(fit) {\n  pe &lt;- parameterEstimates(fit)\n  pe &lt;- pe[pe$op == \"~\" & pe$lhs %in% c(\"comp\",\"eat\"), ]\n  pe[pe$rhs %in% c(\"peer\",\"media\",\"comp\"),\n     c(\"lhs\",\"op\",\"rhs\",\"est\",\"se\",\"z\",\"pvalue\")]\n}"
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#concepts-technical-but-actionable",
    "href": "slides/06_missing-data_robustness_reporting.html#concepts-technical-but-actionable",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Concepts (technical, but actionable)",
    "text": "Concepts (technical, but actionable)\n\nMCAR: missingness unrelated to observed/unobserved → listwise unbiased (but inefficient)\nMAR: missingness depends on observed variables → FIML OK (under correct model)\nMNAR: missingness depends on unobserved/missing values → both listwise & FIML can be biased\n\nKey point:\n\nFIML is not “imputation”. It’s likelihood-based estimation using all available cases assuming MAR."
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#fit-1-ml-default-missing-handling-listwise",
    "href": "slides/06_missing-data_robustness_reporting.html#fit-1-ml-default-missing-handling-listwise",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Fit 1 — ML, default missing handling (listwise)",
    "text": "Fit 1 — ML, default missing handling (listwise)\n\nfit_list &lt;- sem(model_sem, data = dat)  # default: listwise deletion\nfitMeasures(fit_list, c(\"nobs\",\"chisq\",\"df\",\"cfi\",\"tli\",\"rmsea\",\"srmr\"))\n\n chisq     df    cfi    tli  rmsea   srmr \n56.219 61.000  1.000  1.009  0.000  0.030"
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#fit-2-ml-fiml",
    "href": "slides/06_missing-data_robustness_reporting.html#fit-2-ml-fiml",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Fit 2 — ML + FIML",
    "text": "Fit 2 — ML + FIML\n\nfit_fiml &lt;- sem(model_sem, data = dat, missing = \"fiml\")\nfitMeasures(fit_fiml, c(\"nobs\",\"chisq\",\"df\",\"cfi\",\"tli\",\"rmsea\",\"srmr\"))\n\n chisq     df    cfi    tli  rmsea   srmr \n54.717 61.000  1.000  1.010  0.000  0.027"
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#sensitivity-check-did-the-conclusion-change",
    "href": "slides/06_missing-data_robustness_reporting.html#sensitivity-check-did-the-conclusion-change",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Sensitivity check: did the conclusion change?",
    "text": "Sensitivity check: did the conclusion change?\n\nrbind(\n  listwise = key_paths(fit_list),\n  fiml     = key_paths(fit_fiml)\n)\n\n             lhs op   rhs   est    se     z pvalue\nlistwise.14 comp  ~  peer 0.362 0.103 3.523  0.000\nlistwise.15 comp  ~ media 0.424 0.093 4.578  0.000\nlistwise.16  eat  ~  comp 0.430 0.125 3.436  0.001\nfiml.14     comp  ~  peer 0.409 0.089 4.592  0.000\nfiml.15     comp  ~ media 0.450 0.085 5.280  0.000\nfiml.16      eat  ~  comp 0.427 0.124 3.442  0.001\n\n\n\n\n\n\n\n\nInterpretation rule of thumb (today)\n\n\nIf your substantive conclusion changes under a reasonable alternative (e.g., listwise → FIML), treat the result as fragile and investigate why."
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#what-mlr-does-the-technical-version",
    "href": "slides/06_missing-data_robustness_reporting.html#what-mlr-does-the-technical-version",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "What MLR does (the technical version)",
    "text": "What MLR does (the technical version)\nMLR (robust ML) typically:\n\nkeeps similar point estimates\nadjusts standard errors using a “sandwich” (empirical) correction\nreports a scaled test statistic (robust χ²) and robust fit indices\n\nUse case:\n\nnon-normality (skewness, heavy tails)\nmild misspecification\n“psychology-shaped” data"
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#fit-3-mlr-fiml",
    "href": "slides/06_missing-data_robustness_reporting.html#fit-3-mlr-fiml",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Fit 3 — MLR + FIML",
    "text": "Fit 3 — MLR + FIML\n\nfit_mlr &lt;- sem(model_sem, data = dat,\n               missing = \"fiml\",\n               estimator = \"MLR\")\nfitMeasures(fit_mlr, c(\"nobs\",\"chisq\",\"df\",\"cfi\",\"tli\",\"rmsea\",\"srmr\"))\n\n chisq     df    cfi    tli  rmsea   srmr \n54.717 61.000  1.000  1.010  0.000  0.027"
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#sensitivity-check-do-se-p-values-change",
    "href": "slides/06_missing-data_robustness_reporting.html#sensitivity-check-do-se-p-values-change",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Sensitivity check: do SE / p-values change?",
    "text": "Sensitivity check: do SE / p-values change?\n\nrbind(\n  fiml_ML  = key_paths(fit_fiml),\n  fiml_MLR = key_paths(fit_mlr)\n)\n\n             lhs op   rhs   est    se     z pvalue\nfiml_ML.14  comp  ~  peer 0.409 0.089 4.592  0.000\nfiml_ML.15  comp  ~ media 0.450 0.085 5.280  0.000\nfiml_ML.16   eat  ~  comp 0.427 0.124 3.442  0.001\nfiml_MLR.14 comp  ~  peer 0.409 0.091 4.496  0.000\nfiml_MLR.15 comp  ~ media 0.450 0.146 3.085  0.002\nfiml_MLR.16  eat  ~  comp 0.427 0.125 3.430  0.001\n\n\n\n\n\n\n\n\nPitfall\n\n\nDon’t mix-and-match reporting: - If you estimate MLR, report robust fit statistics (scaled χ², robust RMSEA/CFI/TLI). - Don’t copy/paste the ML χ² from another run."
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#why-bootstrap-is-special-for-indirect-effects",
    "href": "slides/06_missing-data_robustness_reporting.html#why-bootstrap-is-special-for-indirect-effects",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Why bootstrap is special for indirect effects",
    "text": "Why bootstrap is special for indirect effects\nIndirect effects are products of coefficients:\n[ ab = a b ]\nEven if (a) and (b) are roughly normal, (ab) is often skewed → normal-theory CIs can be misleading."
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#optional-add-an-indirect-effect-to-the-model",
    "href": "slides/06_missing-data_robustness_reporting.html#optional-add-an-indirect-effect-to-the-model",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "(Optional) Add an indirect effect to the model",
    "text": "(Optional) Add an indirect effect to the model\n\nmodel_sem_ind &lt;- paste0(model_sem, \"\\n\\n# Indirect effect\\nind_peer := (comp~peer)*(eat~comp)\\n\")\n\n\nIf lavaan complains about label reuse depending on version, label paths explicitly (a* and b) and redefine ind := ab."
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#fit-4-bootstrap-seci-keep-small-for-live-teaching",
    "href": "slides/06_missing-data_robustness_reporting.html#fit-4-bootstrap-seci-keep-small-for-live-teaching",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Fit 4 — Bootstrap SE/CI (keep small for live teaching)",
    "text": "Fit 4 — Bootstrap SE/CI (keep small for live teaching)\nFor live demos keep bootstrap modest (e.g., 300–800).\nFor papers, use ~2000+.\n\nfit_boot &lt;- sem(model_sem, data = dat,\n                missing = \"fiml\",\n                se = \"bootstrap\",\n                bootstrap = 500)"
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#compare-ci-for-key-paths-normal-vs-bootstrap",
    "href": "slides/06_missing-data_robustness_reporting.html#compare-ci-for-key-paths-normal-vs-bootstrap",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Compare CI for key paths (normal vs bootstrap)",
    "text": "Compare CI for key paths (normal vs bootstrap)\n\npe_norm &lt;- parameterEstimates(fit_fiml, ci = TRUE)\npe_boot &lt;- parameterEstimates(fit_boot, ci = TRUE, boot.ci.type = \"perc\")\n\nsel &lt;- function(pe) {\n  pe[pe$op == \"~\" & pe$lhs %in% c(\"comp\",\"eat\") &\n       pe$rhs %in% c(\"peer\",\"media\",\"comp\"),\n     c(\"lhs\",\"op\",\"rhs\",\"est\",\"ci.lower\",\"ci.upper\")]\n}\n\nlist(\n  normal_CI = sel(pe_norm),\n  boot_CI   = sel(pe_boot)\n)\n\n$normal_CI\n    lhs op   rhs   est ci.lower ci.upper\n14 comp  ~  peer 0.409    0.235    0.584\n15 comp  ~ media 0.450    0.283    0.616\n16  eat  ~  comp 0.427    0.184    0.670\n\n$boot_CI\n    lhs op   rhs   est ci.lower ci.upper\n14 comp  ~  peer 0.409    0.236    0.601\n15 comp  ~ media 0.450    0.242    0.801\n16  eat  ~  comp 0.427    0.188    0.692\n\n\n\n\n\n\n\n\nDecision heuristic (today)\n\n\nBootstrap is most valuable when: - your target parameter is a product (indirect effects), - distributions are skewed / small N, - normal CIs would be suspect."
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#global-fit-quick-recap",
    "href": "slides/06_missing-data_robustness_reporting.html#global-fit-quick-recap",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Global fit (quick recap)",
    "text": "Global fit (quick recap)\nGlobal fit indices summarize average discrepancy:\n\nχ² (sample-size sensitive)\nCFI/TLI (incremental)\nRMSEA (+ CI; small df behavior)\nSRMR (residual-based)\n\nBut:\n\nGood global fit does not guarantee good measurement or correct structure."
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#local-fit-residuals-and-mi",
    "href": "slides/06_missing-data_robustness_reporting.html#local-fit-residuals-and-mi",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Local fit: residuals and MI",
    "text": "Local fit: residuals and MI\n\n# Residual correlations (a small block)\nresid(fit_mlr, type = \"cor\")$cov[1:6, 1:6]\n\n              p1            p2           p3            p4            m1\np1 -2.220446e-16  2.260205e-02 -0.027764125 -1.156267e-02 -5.688705e-02\np2  2.260205e-02  2.220446e-16  0.008962091 -1.205551e-02  3.437288e-03\np3 -2.776412e-02  8.962091e-03  0.000000000  2.145905e-02 -1.029635e-02\np4 -1.156267e-02 -1.205551e-02  0.021459052 -1.110223e-16  3.037465e-02\nm1 -5.688705e-02  3.437288e-03 -0.010296345  3.037465e-02  2.220446e-16\nm2  1.572566e-02  3.943457e-02  0.010333999 -2.492806e-02  1.005055e-02\n            m2\np1  0.01572566\np2  0.03943457\np3  0.01033400\np4 -0.02492806\nm1  0.01005055\nm2  0.00000000\n\n\n\nmodificationIndices(fit_mlr, sort. = TRUE)[1:10, c(\"lhs\",\"op\",\"rhs\",\"mi\",\"epc\")]\n\n     lhs op rhs    mi    epc\n132   p4 ~~  e2 4.658  0.116\n147   m2 ~~  e2 4.044 -0.074\n94    p1 ~~  m1 3.794 -0.047\n84   eat =~  m1 3.541  0.124\n109   p2 ~~  c1 3.434 -0.042\n125   p4 ~~  m2 3.237 -0.064\n85   eat =~  m2 3.024 -0.113\n56  peer =~  c1 2.961 -0.207\n96    p1 ~~  m3 2.841 -0.061\n101   p1 ~~  e1 2.573  0.065\n\n\n\nAdd schematic: “CFI looks fine” but highlight a single large residual correlation and its substantive interpretation."
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#a-disciplined-respecification-rule",
    "href": "slides/06_missing-data_robustness_reporting.html#a-disciplined-respecification-rule",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "A disciplined respecification rule",
    "text": "A disciplined respecification rule\nOnly consider modifications that are:\n\ntheoretically defensible\n\nconsistent with measurement-first logic\n\nreported transparently (what was changed and why)\n\n\n\n\n\n\n\nPitfall: “MI shopping”\n\n\nIf you add correlated errors because they “fix RMSEA”, you can end up fitting noise."
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#what-you-must-report-minimum",
    "href": "slides/06_missing-data_robustness_reporting.html#what-you-must-report-minimum",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "What you must report (minimum)",
    "text": "What you must report (minimum)\n\nModel specification (measurement + structural)\nEstimator (ML / MLR / DWLS / ULS / …)\nMissing data handling (listwise / FIML / …) + assumption (MAR)\nχ²(df), p (robust/scaled if applicable)\nCFI, TLI, RMSEA (+ CI), SRMR\nAny respecifications (with theory rationale)\nIf bootstrap: type + number of draws + CI type"
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#example-reporting-paragraph-template",
    "href": "slides/06_missing-data_robustness_reporting.html#example-reporting-paragraph-template",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Example reporting paragraph (template)",
    "text": "Example reporting paragraph (template)\n\nThe SEM was estimated in lavaan using robust maximum likelihood (MLR) with FIML for missing data under a MAR assumption. Model fit was evaluated using the scaled χ² test and robust fit indices (CFI, TLI, RMSEA with 90% CI, SRMR). Key parameters were interpreted based on standardized estimates and robust standard errors. Where relevant, confidence intervals were obtained via bootstrap percentile CIs (B = 500 for teaching; ≥ 2000 for publication)."
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#take-home-the-sensitivity-mindset",
    "href": "slides/06_missing-data_robustness_reporting.html#take-home-the-sensitivity-mindset",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Take-home: the sensitivity mindset",
    "text": "Take-home: the sensitivity mindset\nFor any important claim, ask:\n\nDoes it survive FIML vs listwise?\nDoes it survive ML vs MLR?\nDoes it survive bootstrap vs normal CI (when relevant)?\nDoes it survive local diagnostics (residuals/MI)?\n\nIf not, don’t panic—learn what the data are telling you."
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#exercises-lab-6",
    "href": "slides/06_missing-data_robustness_reporting.html#exercises-lab-6",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Exercises → Lab 6",
    "text": "Exercises → Lab 6\nIn the lab you will:\n\nIncrease missingness to ~40% and re-run the sensitivity checks\n\nSimulate MNAR and compare to MAR\n\nIdentify 1–2 large MIs, justify (or reject) a modification\n\nWrite a short “Methods + Results” reporting paragraph\n\n\nLink placeholder: add a direct link to /labs/06_robustness_lab.qmd once created."
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#things-to-remember",
    "href": "slides/06_missing-data_robustness_reporting.html#things-to-remember",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "3 things to remember",
    "text": "3 things to remember\n\nMissing data handling can change conclusions — check sensitivity\n\nRobust SE protect against inflated significance — don’t trust ML by default\n\nFit indices are diagnostics, not verdicts — always check local fit"
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#further-reading-optional",
    "href": "slides/06_missing-data_robustness_reporting.html#further-reading-optional",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "Further reading (optional)",
    "text": "Further reading (optional)\n\nMissing data in SEM (FIML, MAR assumptions)\nRobust estimation (MLR/MLM and non-normality)\nBootstrap inference for indirect effects\nReporting standards for SEM in psychology\n\n\nAdd 2–3 concrete citations once we confirm keys in refs/references.bib."
  },
  {
    "objectID": "slides/06_missing-data_robustness_reporting.html#references",
    "href": "slides/06_missing-data_robustness_reporting.html#references",
    "title": "Lesson 6 — When SEM Goes Wrong",
    "section": "References",
    "text": "References"
  }
]